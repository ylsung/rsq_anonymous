{"instructions": ["What was agreed upon on sample transcripts?", "What was said on speech overlap?", "What\u2019s the current status of recordings and transcriptions?", "What was the future of data collection?", "What were the main discussion points of the meeting?"], "outputs": ["To save time, speaker mn005 will only mark the sample of transcribed data for regions of overlapping speech, as opposed to marking all acoustic events. The digits extraction task will be delegated to whomever is working on acoustics for the Meeting Recorder project.", "Efforts by speaker mn005 are in progress to detect overlapping speech. For a single transcribed meeting, speaker mn005 reported approximately 300 cases of overlap. Future work will involve manually deriving time marks from sections of overlapping speech for the same meeting, and then experimenting with different measures, e.g. energy increase, to determine a set of acoustically salient features for identifying speaker overlap. ", "Approximately 12-13 hours of Meeting Recorder data have been collected, roughly 45 minutes of which have been transcribed. Additional meetings by other ICSI research groups will be recorded. A suggestion was made that multi-channel data also be collected in cooperation with local media broadcasters, and that such events might be recorded live from ICSI. ", "The group aims to collect over 100 hours of Meeting Recorder data in total. Speaker consent forms are being revised. It was suggested that subjects should sign a new consent form after 10 recording sessions.", "The group discussed topics including a potential collaboration with another ICSI member regarding the analysis of inference structures, efforts by speaker mn005 to detect speaker overlap, the current status of recordings and transcriptions, and future efforts to collect meeting data. In addition to weekly meetings by the BMR group, efforts are in progress to record meetings by other ICSI research groups, as well as routine discussions by non-ICSI members."], "input": "Professor E: So . OK . Doesn't look like it crashed . That 's great .\nGrad G: So I think maybe what 's causing it to crash is I keep starting it and then stopping it to see if it 's working . And so I think starting it and then stopping it and starting it again causes it to crash . So , I won't do that anymore .\nPostdoc B: And it looks like you 've found a way of uh mapping the location to the {disfmarker} without having people have to give their names each time ?\nPhD A: Sounds like an initialization thing .\nPostdoc B: I mean it 's like you have the {disfmarker} So you know that {disfmarker}\nGrad G: No .\nPostdoc B: I mean , are you going to write down {pause} that I sat here ?\nGrad G: I 'm gonna collect the digit forms and write it down .\nPostdoc B: OK .\nPhD C: Oh , OK .\nGrad G: So {disfmarker} So they should be right with what 's on the digit forms . OK , so I 'll go ahead and start with digits . u And I should say that uh , you just pau you just read each line an and then pause briefly .\nProfessor E: And start by giving the transcript number .\nPhD A: Tran\nPhD D: Transcript {disfmarker} Uh . OK , OK .\nPhD A: Oh sorry , go ahead .\nProfessor E: So uh , you see , Don , the unbridled excitement of the work that we have on this project .\nGrad H: OK .\nProfessor E: It 's just uh {disfmarker}\nGrad H: Umh .\nProfessor E: Uh , you know , it doesn't seem like a bad idea to have {comment} that information .\nGrad G: And I 'm surprised I sort of {disfmarker} I 'm surprised I forgot that ,\nProfessor E: Yeah , I {disfmarker} I 'd {disfmarker} I think it 's some\nGrad G: but uh I think that would be a good thing to add . After I just printed out a zillion of them .\nProfessor E: Yeah , well , that 's {disfmarker} Um , so I {disfmarker} I do have a {disfmarker} a an agenda suggestion . Uh , we {disfmarker} I think the things that we talk about in this meeting uh tend to be a mixture of uh procedural uh mundane things and uh research points and um I was thinking I think it was a meeting a couple of weeks ago that we {disfmarker} we spent much of the time talking about the mundane stuff cuz that 's easier to get out of the way and then we sort of drifted into the research and maybe five minutes into that Andreas had to leave . So {vocalsound} uh I 'm suggesting we turn it around and {disfmarker} and uh sort of we have {disfmarker} anybody has some mundane points that we could send an email later , uh hold them for a bit , and let 's talk about the {disfmarker} the research - y kind of things . Um , so um the one th one thing I know that we have on that is uh we had talked a {disfmarker} a couple weeks before um uh about the uh {disfmarker} the stuff you were doing with {disfmarker} with uh um uh l l attempting to locate events , we had a little go around trying to figure out what you meant by \" events \" but I think , you know , what we had meant by \" events \" I guess was uh points of overlap between speakers . But I th I gather from our discussion a little earlier today that you also mean uh interruptions with something else\nPhD D: Yeah .\nProfessor E: like some other noise .\nPhD D: Uh - huh . Yeah .\nProfessor E: Yes ? You mean that as an event also .\nPhD D: To\nProfessor E: So at any rate you were {disfmarker} you 've {disfmarker} you 've done some work on that\nPhD D: right .\nProfessor E: and um then the other thing would be it might be nice to have a preliminary discussion of some of the other uh research uh areas that uh we 're thinking about doing . Um , I think especially since you {disfmarker} you haven't been in {disfmarker} in these meetings for a little bit , maybe you have some discussion of some of the p the plausible things to look at now that we 're starting to get data , uh and one of the things I know that also came up uh is some discussions that {disfmarker} that uh {disfmarker} that uh Jane had with Lokendra uh about some {disfmarker} some {disfmarker} some um uh work about I {disfmarker} I {disfmarker} I d I {disfmarker} I don't want to try to say cuz I {disfmarker} I 'll say it wrong , but anyway some {disfmarker} some potential collaboration there about {disfmarker} about the {disfmarker} about the {disfmarker} working with these data .\nPhD C: Oh . Sure .\nProfessor E: So . So , uh .\nGrad G: You wanna just go around ?\nProfessor E: Uh . {pause} Well , I don't know if we {disfmarker} if this is sort of like everybody has something to contribute sort of thing , I think there 's just just a couple {disfmarker} a couple people primarily um but um Uh , wh why don't {disfmarker} Actually I think that {disfmarker} that last one I just said we could do fairly quickly so why don't you {disfmarker} you start with that .\nPostdoc B: OK . Shall I {disfmarker} shall I just start ? OK .\nProfessor E: Yeah , just explain what it was .\nPostdoc B: Um , so , uh , he was interested in the question of {disfmarker} you know , relating to his {disfmarker} to the research he presented recently , um of inference structures , and uh , the need to build in , um , this {disfmarker} this sort of uh mechanism for understanding of language . And he gave the example in his talk about how {pause} um , e a I 'm remembering it just off the top of my head right now , but it 's something about how um , i \" Joe slipped \" you know , \" John had washed the floor \" or something like that . And I don't have it quite right , but that kind of thing , where you have to draw the inference that , OK , there 's this time sequence , but also the {disfmarker} the {disfmarker} the causal aspects of the uh floor and {disfmarker} and how it might have been the cause of the fall and that um it was the other person who fell than the one who cleaned it and it {disfmarker} {comment} These sorts of things . So , I looked through the transcript that we have so far , {comment} and um , fou identified a couple different types of things of that type and um , one of them was something like uh , during the course of the transcript , um um , w we had gone through the part where everyone said which channel they were on and which device they were on , and um , the question was raised \" Well , should we restart the recording at this point ? \" And {disfmarker} and Dan Ellis said , \" Well , we 're just so far ahead of the game right now {pause} we really don't need to \" . Now , how would you interpret that without a lot of inference ? So , the inferences that are involved are things like , OK , so , how do you interpret \" ahead of the game \" ? You know . So it 's the {disfmarker} it 's {pause} i What you {disfmarker} what you int what you draw {disfmarker} you know , the conclusions that you need to draw are that space is involved in recording ,\nGrad G: Hmm , metaphorically .\nPostdoc B: that um , i that {pause} i we have enough space , and he continues , like \" we 're so ahead of the game cuz now we have built - in downsampling \" . So you have to sort of get the idea that um , \" ahead of the game \" is sp speaking with respect to space limitations , that um that in fact downsampling is gaining us enough space , and that therefore we can keep the recording we 've done so far . But there are a lot of different things like that .\nGrad G: So , do you think his interest is in using this as {pause} a data source , or {pause} training material , or what ?\nProfessor E: Well , I {disfmarker} I should maybe interject to say this started off with a discussion that I had with him , so um we were trying to think of ways that his interests could interact with ours\nGrad G: Mm - hmm .\nProfessor E: and um uh I thought that if we were going to project into the future when we had a lot of data , uh and um such things might be useful for that in or before we invested too much uh effort into that he should uh , with Jane 's help , look into some of the data that we 're {disfmarker} already have and see , is there anything to this at all ?\nGrad G: Mm - hmm .\nProfessor E: Is there any point which you think that , you know , you could gain some advantage and some potential use for it . Cuz it could be that you 'd look through it and you say \" well , this is just the wrong {pause} task for {disfmarker} for him to pursue his {disfmarker} \"\nGrad G: Wrong , yeah .\nProfessor E: And {disfmarker} and uh I got the impression from your mail that in fact there was enough things like this just in the little sample that {disfmarker} that you looked at that {disfmarker} that it 's plausible at least .\nPostdoc B: It 's possible . Uh , he was {disfmarker} he {disfmarker} he {disfmarker} you know {disfmarker} We met and he was gonna go and uh you know , y look through them more systematically\nProfessor E: Yeah .\nPostdoc B: and then uh meet again .\nProfessor E: Yeah .\nPostdoc B: So it 's , you know , not a matter of a {disfmarker}\nProfessor E: Yeah .\nPostdoc B: But , yeah , I think {disfmarker} I think it was optimistic .\nProfessor E: So anyway , that 's {disfmarker} that 's e a quite different thing from anything we 've talked about that , you know , might {disfmarker} might {disfmarker} might come out from some of this .\nPhD C: But he can use text , basically . I mean , he 's talking about just using text\nPostdoc B: That 's his major {disfmarker} I mentioned several that w had to do with implications drawn from intonational contours\nPhD C: pretty much , or {disfmarker} ?\nPostdoc B: and {pause} that wasn't as directly relevant to what he 's doing . He 's interested in these {disfmarker} these knowledge structures ,\nPhD C: OK .\nPhD D: Yeah , interesting .\nPostdoc B: inferences that you draw {pause} i from {disfmarker}\nProfessor E: I mean , he certainly could use text , but we were in fact looking to see if there {disfmarker} is there {disfmarker} is there something in common between our interest in meetings and his interest in {disfmarker} in {disfmarker} in this stuff . So .\nGrad G: And I imagine that transcripts of speech {disfmarker} I mean text that is speech {disfmarker} probably has more of those than sort of prepared writing . I {disfmarker} I don't know whether it would or not , but it seems like it would .\nProfessor E: I don't know , probably de probably depends on what the prepared writing was . But .\nPostdoc B: Yeah , I don't think I would make that leap , because i in narratives , you know {disfmarker} I mean , if you spell out everything in a narrative , it can be really tedious ,\nGrad G: Mm - hmm .\nPostdoc B: so .\nGrad G: Yeah , I 'm just thinking , you know , when you 're {disfmarker} when you 're face to face , you have a lot of backchannel and {disfmarker} And {disfmarker}\nPostdoc B: Oh . That aspect .\nGrad G: Yeah . And so I think it 's just easier to do that sort of broad inference jumping if it 's face to face . I mean , so , if I just read that Dan was saying \" we 're ahead of the game \" {comment} in that {disfmarker} in that context ,\nPostdoc B: Well {disfmarker} Yeah .\nGrad G: I might not realize that he was talking about disk space as opposed to anything else .\nPostdoc B: I {disfmarker} you know , I {disfmarker} I had several that had to do with backchannels and this wasn't one of them .\nGrad G: Uh - huh .\nPostdoc B: This {disfmarker} this one really does um m make you leap from {disfmarker} So he said , you know , \" we 're ahead of the game , w we have built - in downsampling \" .\nGrad G: Mm - hmm .\nPostdoc B: And the inference , i if you had it written down , would be {disfmarker}\nGrad G: I guess it would be the same .\nPostdoc B: Uh - huh . But there are others that have backchannelling , it 's just he was less interested in those .\nPhD F: Can I {disfmarker} Sorry to interrupt . Um , I f f f I 've {disfmarker} @ @ {comment} d A minute {disfmarker} uh , several minutes ago , I , like , briefly was {disfmarker} was not listening and {disfmarker} So who is \" he \" in this context ?\nPhD C: Yeah , there 's a lot of pronoun {disfmarker}\nPhD F: OK . So I was just realizing we 've {disfmarker} You guys have been talking about \" he \" um for at least uh , I don't know , three {disfmarker} three four minutes without ever mentioning the person 's name again .\nPhD C: I believe it . Yeah . Actually to make it worse , {comment} uh , Morgan uses \" you \" and \" you \"\nPhD F: So this is {disfmarker} this is {disfmarker} this is {disfmarker} gonna be a big , big problem if you want to later do uh , you know , indexing , or speech understanding of any sort .\nGrad G: It 's in my notes .\nPhD C: with gaze and no identification , or {disfmarker} I just wrote this down . Yeah , actually . Cuz Morgan will say well , \" you had some ideas \"\nPhD D: Yeah .\nPhD F: You just wrote this ?\nPhD C: and he never said Li - He looked {disfmarker}\nGrad G: Well , I think he 's doing that intentionally ,\nPhD C: Right , so it 's great .\nGrad G: aren't you ?\nPhD C: So this is really great\nPhD F: Right .\nPhD C: because the thing is , because he 's looking at the per even for addressees in the conversation ,\nPhD D: Yeah .\nPhD F: Mm - hmm .\nPhD C: I bet you could pick that up in the acoustics . Just because your gaze is also correlated with the directionality of your voice .\nProfessor E: Uh - huh . Could be .\nPostdoc B: Can we\nProfessor E: Yeah . That would be tou\nGrad G: Oh , that would be interesting .\nPhD C: Yeah , so that , I mean , to even know um when {disfmarker}\nPhD D: Yeah .\nPhD C: Yeah , if you have the P Z Ms you should be able to pick up what a person is looking at from their voice .\nGrad G: Well , especially with Morgan , with the way we have the microphones arranged . I 'm sort of right on axis and it would be very hard to tell .\nPhD C: Right .\nGrad G: Uh .\nPostdoc B: Oh , but you 'd have the {disfmarker}\nPhD C: Put Morgan always like this\nPostdoc B: You 'd have fainter {disfmarker}\nPhD C: and {disfmarker}\nPostdoc B: Wouldn't you get fainter reception out here ?\nProfessor E: Well , these {disfmarker}\nGrad G: Sure , but I think if I 'm talking like this ? Right now I 'm looking at Jane and talking , now I 'm looking at Chuck and talking , I don't think the microphones would pick up that difference .\nPhD C: But you don't have this {disfmarker} this problem .\nPostdoc B: I see .\nPhD C: Morgan is the one who does this most .\nGrad G: So if I 'm talking at you , or I 'm talking at you .\nProfessor E: I probably been affect No , I th I think I 've been affected by too many conversations where we were talking about lawyers and talking about {disfmarker} and concerns about \" oh gee is somebody going to say something bad ? \" and so on .\nGrad G: Lawyers .\nProfessor E: And so I {disfmarker} so I 'm {disfmarker} I 'm tending to stay away from people 's names even though uh {disfmarker}\nPostdoc B: I am too .\nPhD C: Even though you could pick up later on , just from the acoustics who you were t who you were looking at .\nPostdoc B: I am too .\nGrad G: And we did mention who \" he \" was .\nPhD C: Yeah .\nProfessor E: Yeah .\nPhD F: Right , but I missed it .\nGrad G: Early in the conversation .\nPhD F: But {disfmarker} it was uh {disfmarker}\nPhD C: Yeah , yeah .\nProfessor E: Yeah .\nGrad G: Do {disfmarker} Sh - Can I say\nProfessor E: Yeah . No no , there 's {disfmarker}\nPhD F: Yeah .\nGrad G: or {disfmarker} or is that just too sensitive ?\nProfessor E: No no , it isn't sensitive at all .\nPostdoc B: Well {disfmarker}\nProfessor E: I was just {disfmarker} I was just {disfmarker} I was overreacting just because we 've been talking about it .\nPostdoc B: And in fact , it is {disfmarker} it is {disfmarker} it is sensitive .\nPhD C: No , but that {disfmarker} it 's interesting .\nProfessor E: It 's OK to {disfmarker}\nPostdoc B: I {disfmarker} I came up with something from the Human Subjects people that I wanted to mention . I mean , it fits into the m area of the mundane , but they did say {disfmarker} You know , I asked her very specifically about this clause of how , um , you know , it says \" no individuals will be identified uh , \" in any publication using the data . \" OK , well , individuals being identified , let 's say you have a {disfmarker} a snippet that says , \" Joe s uh thinks such - and - such about {disfmarker} about this field , but I think he 's wrongheaded . \" Now I mean , we 're {disfmarker} we 're gonna be careful not to have the \" wrongheaded \" part in there , but {disfmarker} but you know , let 's say we say , you know , \" Joe used to think so - and - so about this area , in his publication he says that but I think he 's changed his mind . \" or whatever . Then the issue of {disfmarker} of being able to trace Joe , because we know he 's well - known in this field , and all this and {disfmarker} and tie it to the speaker , whose name was just mentioned a moment ago , can be sensitive .\nProfessor E: b But I {disfmarker}\nPostdoc B: So I think it 's really {disfmarker} really kind of adaptive and wise to not mention names any more than we have to because if there 's a slanderous aspect to it , then how much to we wanna be able to have to remove ?\nProfessor E: Yeah , well , there 's that . But I {disfmarker} I mean I think also to some extent it 's just educating the Human Subjects people , in a way , because there 's {disfmarker} If uh {disfmarker} You know , there 's court transcripts , there 's {disfmarker} there 's transcripts of radio shows {disfmarker} I mean people say people 's names all the time . So I think it {disfmarker} it can't be bad to say people 's names . It 's just that {disfmarker} i I mean you 're right that there 's more poten If we never say anybody 's name , then there 's no chance of {disfmarker} of {disfmarker} of slandering anybody ,\nPhD C: But , then it won't {disfmarker} I mean , if we {disfmarker} if we {disfmarker}\nProfessor E: but {disfmarker}\nGrad G: It 's not a meeting .\nPhD C: Yeah . I mean we should do whatever 's natural in a meeting if {disfmarker} if we weren't being recorded .\nProfessor E: Yeah . Right , so I {disfmarker} So my behavior is probably not natural .\nPhD C: \" If Person X {disfmarker} \"\nProfessor E: So .\nPostdoc B: Well , my feeling on it was that it wasn't really important who said it , you know .\nProfessor E: Yeah .\nPhD F: Well , if you ha since you have to um go over the transcripts later anyway , you could make it one of the jobs of the {pause} people who do that to mark\nGrad G: Well , we t we t we talked about this during the anon anonymization .\nPhD F: Right .\nGrad G: If we wanna go through and extract from the audio and the written every time someone says a name . And I thought that our conclusion was that we didn't want to do that .\nProfessor E: Yeah , we really can't . But a actually , I 'm sorry . I really would like to push {disfmarker} finish this off .\nPostdoc B: I understand . No I just {disfmarker} I just was suggesting that it 's not a bad policy p potentially .\nProfessor E: So it 's {disfmarker}\nPostdoc B: So , we need to talk about this later .\nProfessor E: Yeah , I di I didn't intend it an a policy though .\nPostdoc B: Uh - huh .\nProfessor E: It was {disfmarker} it was just it was just unconscious {disfmarker} well , semi - conscious behavior . I sorta knew I was doing it but it was {disfmarker}\nPhD F: Well , I still don't know who \" he \" is .\nProfessor E: I {disfmarker} I do I don't remember who \" he \" is .\nPhD C: No , you have to say , you still don't know who \" he \" is , with that prosody .\nProfessor E: Ah . Uh , we were talking about Dan at one point {comment} and we were talking about Lokendra at another point .\nPostdoc B: Yeah , depends on which one you mean .\nProfessor E: And I don't {disfmarker} I don't remember which {disfmarker} which part .\nPhD F: Oh .\nPhD C: It 's ambiguous , so it 's OK .\nProfessor E: Uh , I think {disfmarker}\nGrad G: Well , the inference structures was Lokendra .\nPhD F: But no . The inference stuff was {disfmarker} was {disfmarker} was Lokendra .\nProfessor E: Yeah . Yeah . Yeah .\nPhD F: OK . That makes sense , yeah .\nPhD C: And the downsampling must have been Dan .\nProfessor E: Um {disfmarker}\nGrad G: Yeah .\nProfessor E: Good {disfmarker} Yeah .\nPhD C: It 's an inference .\nProfessor E: Yeah , you could do all these inferences , yeah .\nGrad G: Yeah .\nProfessor E: Yeah . Um , I {disfmarker} I would like to move it into {disfmarker} into uh what Jose uh has been doing\nPostdoc B: Yeah .\nProfessor E: because he 's actually been doing something .\nPhD D: Uh - huh . OK .\nProfessor E: So . {vocalsound} Right .\nPhD F: As opposed to the rest of us .\nPhD D: Well - {comment} {vocalsound} OK . I {disfmarker} I remind that me {disfmarker} my first objective eh , in the project is to {disfmarker} to study difference parameters to {disfmarker} to find a {disfmarker} a good solution to detect eh , the overlapping zone in eh speech recorded . But eh , {vocalsound} tsk , {comment} {vocalsound} ehhh {comment} In that way {comment} I {disfmarker} {vocalsound} I {disfmarker} {vocalsound} I begin to {disfmarker} to study and to analyze the ehn {disfmarker} the recorded speech eh the different session to {disfmarker} to find and to locate and to mark eh the {disfmarker} the different overlapping zone . And eh so eh I was eh {disfmarker} I am transcribing the {disfmarker} the first session and I {disfmarker} I have found eh , eh one thousand acoustic events , eh besides the overlapping zones , eh I {disfmarker} I {disfmarker} I mean the eh breaths eh aspiration eh , eh , talk eh , eh , clap , eh {disfmarker} {comment} I don't know what is the different names eh you use to {disfmarker} to name the {disfmarker} the {pause} n speech\nPhD A: Nonspeech sounds ?\nPhD D: Yeah .\nGrad G: Oh , I don't think we 've been doing it at that level of detail . So .\nPhD D: Yeah . Eh , {vocalsound} I {disfmarker} I {disfmarker} I do I don't need to {disfmarker} to {disfmarker} to mmm {vocalsound} {disfmarker} to m to label the {disfmarker} the different acoustic , but I prefer because eh I would like to {disfmarker} to study if eh , I {disfmarker} I will find eh , eh , a good eh parameters eh to detect overlapping I would like to {disfmarker} to {disfmarker} to test these parameters eh with the {disfmarker} another eh , eh acoustic events , to nnn {disfmarker} {vocalsound} to eh {disfmarker} to find what is the ehm {disfmarker} the false {disfmarker} eh , the false eh hypothesis eh , nnn , which eh are produced when we use the {disfmarker} the ehm {disfmarker} this eh parameter {disfmarker} eh I mean pitch eh , eh , difference eh , feature {disfmarker}\nGrad G: Mm - hmm .\nPhD A: You know {disfmarker} I think some of these um that are the nonspeech overlapping events may be difficult even for humans to tell that there 's two there .\nGrad G: So it was {disfmarker}\nPhD D: Yeah .\nPhD A: I mean , if it 's a tapping sound , you wouldn't necessarily {disfmarker} or , you know , something like that , it 'd be {disfmarker} it might be hard to know that it was two separate events .\nPhD D: Yeah . Yeah . Yeah . Yeah .\nGrad G: Well {disfmarker} You weren't talking about just overlaps\nPhD D: Ye\nGrad G: were you ? You were just talking about acoustic events .\nPhD D: I {disfmarker} I {disfmarker} I {disfmarker} I t I t I talk eh about eh acoustic events in general ,\nGrad G: Someone starts , someone stops {disfmarker} Yeah .\nPhD A: Oh .\nPhD D: but eh my {disfmarker} my objective eh will be eh to study eh overlapping zone .\nGrad G: Mm - hmm .\nPhD D: Eh ? {comment} n Eh in twelve minutes I found eh , eh one thousand acoustic events .\nProfessor E: How many overlaps were there uh in it ? No no , how many of them were the overlaps of speech , though ?\nPhD D: How many ? Eh almost eh three hundred eh in one session\nGrad G: Oh , God !\nPhD D: in five {disfmarker} eh in forty - five minutes .\nPhD A: Three hundred overlapping speech {disfmarker}\nPhD D: Alm - Three hundred overlapping zone .\nGrad G: Ugh .\nPhD C: Overlapping speech .\nPhD D: With the overlapping zone , overlapping speech {disfmarker} speech what eh different duration .\nPhD A: Mm - hmm .\nProfessor E: Sure .\nPostdoc B: Does this {disfmarker} ? So if you had an overlap involving three people , how many times was that counted ?\nPhD D: Yeah , three people , two people . Eh , um I would like to consider eh one people with difference noise eh in the background , be\nProfessor E: No no , but I think what she 's asking is {pause} if at some particular for some particular stretch you had three people talking , instead of two , did you call that one event ?\nPhD D: Oh . Oh . Yeah . I consider one event eh for th for that eh for all the zone . This {disfmarker} th I {disfmarker} I {disfmarker} I con I consider {disfmarker} I consider eh an acoustic event , the overlapping zone , the period where three speaker or eh {disfmarker} are talking together .\nGrad G: Well {disfmarker} So let 's {disfmarker}\nPostdoc B: For\nGrad G: So let 's say me and Jane are talking at the same time , and then Liz starts talking also over all of us . How many events would that be ?\nPhD D: So - I don't understand .\nGrad G: So , two people are talking , {comment} and then a third person starts talking .\nPhD D: Yeah ?\nGrad G: Is there an event right here ?\nPhD D: Eh no . No no . For me is the overlapping zone , because {disfmarker} because you {disfmarker} you have s you have more one {disfmarker} eh , more one voice eh , eh produced in a {disfmarker} in {disfmarker} in a moment .\nProfessor E: I see .\nGrad G: So i if two or more people are talking .\nProfessor E: OK . Yeah . So I think {disfmarker} Yeah . We just wanted to understand how you 're defining it .\nPhD D: Yeah . If\nProfessor E: So then , in the region between {disfmarker} since there {disfmarker} there is some continuous region , in between regions where there is only one person speaking .\nPhD D: Uh - huh .\nProfessor E: And one contiguous region like that you 're calling an event .\nPhD D: Uh - huh .\nProfessor E: Is it {disfmarker} Are you calling the beginning or the end of it the event ,\nPhD D: Yeah .\nProfessor E: or are you calling the entire length of it the event ?\nPhD D: I consider the {disfmarker} the , nnn {disfmarker} the nnn , nnn {disfmarker} eh , the entirety eh , eh , all {disfmarker} all the time there were {disfmarker} the voice has overlapped .\nProfessor E: OK .\nPhD D: This is the idea . But eh I {disfmarker} I don't distinguish between the {disfmarker} the numbers of eh speaker . Uh , I 'm not considering {vocalsound} eh the {disfmarker} the {disfmarker} ehm {vocalsound} eh , the fact of eh , eh , for example , what did you say ? Eh at first eh , eh two talkers are uh , eh speaking , and eh , eh a third person eh join to {disfmarker} to that . For me , it 's eh {disfmarker} it 's eh , all overlap zone , with eh several numbers of speakers is eh , eh the same acoustic event . Wi - but {disfmarker} uh , without any mark between the zone {disfmarker} of the overlapping zone with two speakers eh speaking together , and the zone with the three speakers .\nPostdoc B: That would j just be one .\nPhD D: It {disfmarker} One . One .\nPostdoc B: OK .\nPhD D: Eh , with eh , a beginning mark and the ending mark . Because eh {vocalsound} for me , is the {disfmarker} is the zone with eh some kind of eh distortion the spectral .\nProfessor E: Got it .\nPhD D: I don't mind {disfmarker} By the moment , by the moment .\nGrad G: Well , but {disfmarker} But you could imagine that three people talking has a different spectral characteristic than two .\nPhD D: I {disfmarker} I don't {disfmarker} Yeah , but eh {disfmarker} but eh I have to study . {comment} What will happen in a general way ,\nProfessor E: Could .\nGrad G: So . You had to start somewhere .\nProfessor E: Yeah . We just w\nPhD C: So there 's a lot of overlap .\nPhD D: I {disfmarker} {vocalsound} I don't know what eh will {disfmarker} will happen with the {disfmarker}\nGrad G: Yep .\nPhD C: So .\nGrad G: That 's a lot of overlap ,\nPhD D: Yeah ?\nProfessor E: So again , that 's {disfmarker} that 's three {disfmarker} three hundred in forty - five minutes that are {disfmarker} that are speakers , just speakers .\nGrad G: yeah , for forty - five minutes .\nPhD D: Yeah . Yeah .\nProfessor E: Uh - huh . OK . Yeah .\nPostdoc B: But a {disfmarker} a {disfmarker} a th\nProfessor E: So that 's about eight per minute .\nPostdoc B: But a thousand events in twelve minutes , that 's {disfmarker}\nPhD D: Yeah , {pause} but {disfmarker} Yeah .\nPhD C: But that can include taps .\nPhD D: But {disfmarker}\nProfessor E: Uh . Yeah .\nPostdoc B: Well , but a thousand taps in eight minutes is a l in twelve minutes is a lot .\nPhD D: General .\nPhD C: Actually {disfmarker}\nPhD D: I {disfmarker} I con I consider {disfmarker} I consider acoustic events eh , the silent too .\nPostdoc B: Silent .\nGrad G: Silence starting or silence ending {disfmarker}\nPhD D: Yeah , silent , ground to {disfmarker} bec to detect {disfmarker} eh because I consider acoustic event all the things are not eh speech .\nPhD C: Oh , OK .\nProfessor E: Mm - hmm .\nPhD A: Oh .\nPhD D: In ge in {disfmarker} in {disfmarker} in a general point of view .\nPhD C: Oh .\nProfessor E: OK , so how many of those thousand were silence ?\nPhD C: Alright .\nPhD D: in the per\nPhD F: Not speech {disfmarker} not speech or too much speech .\nPhD D: Too much speech .\nProfessor E: Right . So how many of those thousand were silence , silent sections ?\nPhD D: Yeah . Uh silent , I {disfmarker} I {disfmarker} I {disfmarker} I don't {disfmarker} I {disfmarker} I haven't the {disfmarker} eh I {disfmarker} I would like to {disfmarker} to do a stylistic study\nProfessor E: Yeah .\nPhD D: and give you eh with the report eh from eh the {disfmarker} the study from the {disfmarker} the {disfmarker} the session {disfmarker} one session .\nProfessor E: Yeah . Yeah .\nPhD D: And I {disfmarker} I found that eh another thing . When eh {vocalsound} eh I w I {disfmarker} {vocalsound} I was eh look at eh nnn , the difference speech file , um , for example , eh if eh we use the ehm {disfmarker} the mixed file , to {disfmarker} to transcribe , the {disfmarker} the events and the words , I {disfmarker} I saw that eh the eh speech signal , collected by the eh this kind of mike {disfmarker} eh of this kind of mike , eh are different from the eh mixed signal eh , we eh {disfmarker} collected by headphone .\nGrad G: Yep .\nPhD D: And {disfmarker} It 's right .\nProfessor E: Yeah .\nGrad G: Right .\nPhD D: But the problem is {vocalsound} the following . The {disfmarker} the {disfmarker} the {disfmarker} I {disfmarker} I {disfmarker} I knew that eh the signal eh , eh would be different , but eh the {disfmarker} the problem is eh , eh we eh detected eh difference events in the speech file eh collected by {disfmarker} by that mike uh qui compared with the mixed file . And so if {disfmarker} when you transcribe eh only eh using the nnn {disfmarker} the mixed file , it 's possible {disfmarker} eh if you use the transcription to evaluate a different system , it 's possible you eh {disfmarker} in the eh i and you use the eh speech file collected by the eh fet mike , to eh {disfmarker} to nnn {disfmarker} to do the experiments {pause} with the {disfmarker} the system ,\nProfessor E: Mm - hmm .\nGrad G: Right .\nPhD D: its possible to evaluate eh , eh {disfmarker} or to consider eh acoustic events that {disfmarker} which you marked eh in the mixed file , but eh they don't appear in the eh speech signal eh collected by the {disfmarker} by the mike .\nGrad G: Right . The {disfmarker} the reason that I generated the mixed file was for IBM to do word level transcription , not speech event transcription .\nPhD D: Yeah . Yeah . Oh , it 's a good idea . It 's a good idea I think .\nGrad G: So I agree that if someone wants to do speech event transcription , that the mixed signals here {disfmarker}\nPhD D: Yeah .\nGrad G: I mean , if I 'm tapping on the table , you it 's not gonna show up on any of the mikes , but it 's gonna show up rather loudly in the PZM .\nPhD D: Yeah . Yeah . Yeah . So and I {disfmarker} I {disfmarker} {vocalsound} I say eh that eh , eh , or this eh only because eh I c I {disfmarker} I {disfmarker} {vocalsound} in my opinion , it 's necessary to eh {disfmarker} to eh {disfmarker} to put the transcription on the speech file , collected by the objective signal .\nGrad G: So .\nPhD D: I mean the {disfmarker} the {disfmarker} the signal collected by the {disfmarker} eh , the real mike in the future , in the prototype to {disfmarker} to eh correct the initial eh segmentation eh with the eh real speech\nProfessor E: Mm - hmm . The {disfmarker} the {disfmarker} the far - field , yeah .\nPhD D: you have to {disfmarker} to analyze {disfmarker} you have to {disfmarker} to process . Because I {disfmarker} I found a difference .\nProfessor E: Yeah , well , just {disfmarker} I mean , just in that {disfmarker} that one s ten second , or whatever it was , example that Adam had that {disfmarker} that we {disfmarker} we passed on to others a few months ago , there was that business where I g I guess it was Adam and Jane were talking at the same time and {disfmarker} and uh , in the close - talking mikes you couldn't hear the overlap , and in the distant mike you could . So yeah , it 's clear that if you wanna study {disfmarker} if you wanna find all the places where there were overlap , it 's probably better to use a distant mike .\nPhD F: That 's good .\nProfessor E: On the other hand , there 's other phenomena that are going on at the same time for which it might be useful to look at the close - talking mikes ,\nPhD D: Yeah .\nPhD C: But why can't you use the combination of the close - talking mikes , time aligned ?\nProfessor E: so it 's {disfmarker}\nGrad G: If you use the combination of the close - talking mikes , you would hear Jane interrupting me , but you wouldn't hear the paper rustling . And so if you 're interested in {disfmarker}\nPhD C: I {disfmarker} I mean if you 're interested in speakers overlapping other speakers and not the other kinds of nonspeech , that 's not a problem ,\nProfessor E: Some {comment} of it 's masking {disfmarker} masked .\nPhD D: Yeah .\nPhD A: Were you interrupting him or was he interrupting you ?\nProfessor E: Right .\nPhD C: right ?\nGrad G: Right .\nPhD D: Yeah .\nGrad G: Although the other issue is that the {pause} mixed close - talking mikes {disfmarker} I mean , I 'm doing weird normalizations and things like that .\nPhD C: But it 's known .\nPhD D: Yeah .\nPhD C: I mean , the normalization you do is over the whole conversation\nGrad G: Yep .\nPhD C: isn't it , over the whole meeting .\nGrad G: Right . Yep .\nPhD C: So if you wanted to study people overlapping people , that 's not a problem .\nPhD D: I {disfmarker} I {disfmarker} I think eh I saw the nnn {disfmarker} the {disfmarker} eh but eh I eh {disfmarker} I have eh any results . I {disfmarker} I {disfmarker} I saw the {disfmarker} the speech file collected by eh the fet mike , and eh eh signal eh to eh {disfmarker} to noise eh relation is eh low . It 's low .\nProfessor E: Mm - hmm .\nPhD D: It 's very low . You would comp if we compare it with eh the headphone .\nGrad G: Yep .\nPhD D: And I {disfmarker} I found that nnn {disfmarker} that eh , {vocalsound} ehm , pr probably ,\nGrad G: Did {disfmarker} Did you\nPhD D: I 'm not sure eh by the moment , but it 's {disfmarker} it 's probably that eh a lot of eh , {vocalsound} eh for example , in the overlapping zone , on eh {disfmarker} in {disfmarker} in several eh parts of the files where you {disfmarker} you can find eh , eh {vocalsound} eh , smooth eh eh speech eh from eh one eh eh talker in the {disfmarker} in the meeting ,\nProfessor E: Mm - hmm . Mm - hmm .\nPhD D: it 's probably in {disfmarker} in that eh {disfmarker} in {disfmarker} in those files you {disfmarker} you can not find {disfmarker} you can not process because eh it 's confused with {disfmarker} with noise .\nProfessor E: Mm - hmm .\nPhD D: And there are {vocalsound} a lot of I think . But I have to study with more detail . But eh my idea is to {disfmarker} to process only {pause} nnn , this eh {disfmarker} nnn , this kind of s of eh speech . Because I think it 's more realistic . I 'm not sure it 's a good idea , but eh {disfmarker}\nProfessor E: No {disfmarker} i\nGrad G: Well , it 's more realistic but it 'll {disfmarker} it 'll be a lot harder .\nPhD D: Yeah .\nProfessor E: Well , it 'd be hard , but on the other hand as you point out , if your {disfmarker} if i if {disfmarker} if your concern is to get uh the overlapping people {disfmarker} people 's speech , you will {disfmarker} you will get that somewhat better .\nPhD D: Mm - hmm . Yeah .\nProfessor E: Um , Are you making any use {disfmarker} uh you were {disfmarker} you were working with th the data that had already been transcribed .\nPhD D: With {disfmarker} By Jane .\nProfessor E: Does it uh {disfmarker} Yes .\nPhD D: Yeah .\nProfessor E: Now um did you make any use of that ? See I was wondering cuz we st we have these ten hours of other stuff that is not yet transcribed .\nPhD D: Yeah . Yeah .\nProfessor E: Do you {disfmarker}\nPhD D: The {disfmarker} the transcription by Jane , t eh i eh , I {disfmarker} I {disfmarker} I want to use to {disfmarker} to nnn , {vocalsound} eh to put {disfmarker} i i it 's a reference for me . But eh the transcription {disfmarker} eh for example , I {disfmarker} I don't {disfmarker} I {disfmarker} I 'm not interested in the {disfmarker} in the {disfmarker} in the words , transcription words , eh transcribed eh eh in {disfmarker} eh follow in the {disfmarker} {vocalsound} in the {disfmarker} in the speech file , but eh eh Jane eh for example eh put a mark eh at the beginning eh of each eh talker , in the {disfmarker} in the meeting , um eh she {disfmarker} she nnn includes information about the zone where eh there are eh {disfmarker} there is an overlapping zone . But eh there isn't any {disfmarker} any mark , time {disfmarker} temporal mark , to {disfmarker} to c eh {disfmarker} to mmm {vocalsound} {disfmarker} e - heh , to label {comment} the beginning and the end of the {disfmarker} of the\nProfessor E: Mm - hmm . OK . Right , so she is {disfmarker}\nPhD D: ta I 'm {disfmarker} I {disfmarker} I {disfmarker} I think eh we need this information to\nProfessor E: Right . So the twelve {disfmarker} you {disfmarker} you {disfmarker} it took you twelve hours {disfmarker} of course this included maybe some {disfmarker} some time where you were learning about what {disfmarker} what you wanted to do , but {disfmarker} but uh , it took you something like twelve hours to mark the forty - five minutes , your\nGrad G: Twelve minutes .\nPhD D: Twelve minutes .\nProfessor E: s Twelve minutes !\nPhD D: Twelve minutes . Twelve .\nProfessor E: I thought you did forty - five minutes of {disfmarker}\nPhD D: No , forty - five minutes is the {disfmarker} is the session , all the session .\nPostdoc B: Oh .\nProfessor E: Oh , you haven't done the whole session .\nPhD D: Yeah , all is the {vocalsound} the session .\nProfessor E: This is just twelve minutes .\nPhD D: Tw - twelve hours of work to {disfmarker} {vocalsound} to segment eh and label eh twelve minutes from a session of part {disfmarker} of f\nProfessor E: Oh . So {comment} let me back up again . So the {disfmarker} when you said there were three hundred speaker overlaps ,\nPhD D: Yeah .\nProfessor E: that 's in twelve minutes ?\nPhD D: No no no . I {disfmarker} I consider all the {disfmarker} all the session because eh I {disfmarker} I count the nnn {disfmarker} the nnn {disfmarker} the overlappings marked by {disfmarker} by Jane ,\nProfessor E: Oh , OK .\nPostdoc B: Oh , I see .\nPhD D: in {disfmarker} in {disfmarker} in {disfmarker} in the {pause} fin in {disfmarker} in the {pause} forty - five minutes .\nProfessor E: OK . So it 's three hundred in forty - five minutes , but you have {disfmarker} you have time uh , uh marked {disfmarker} twelve minute {disfmarker} the {disfmarker} the {disfmarker} the um overlaps in twelve minutes of it .\nPhD D: Yeah .\nProfessor E: Got it .\nPhD F: So , can I ask {disfmarker} {vocalsound} can I ask whether you found {disfmarker} uh , you know , how accurate uh Jane 's uh uh labels were as far as {disfmarker}\nGrad G: Well , not just the overlaps , everything .\nPhD F: you know , did she miss some overlaps ? or did she n ?\nPhD D: But , by {disfmarker} by the moment , I {disfmarker} I don't compare , my {disfmarker} my temporal mark with eh Jane , but eh I {disfmarker} I want to do it . Because eh eh i per perhaps I have eh errors in the {disfmarker} in the marks , I {disfmarker} and if I {disfmarker} I compare with eh Jane , it 's probably I {disfmarker} I {disfmarker} I can correct and {disfmarker} and {disfmarker} and {disfmarker} to get eh eh a more accurately eh eh transcription in the file .\nProfessor E: Yeah .\nGrad G: Well , also Jane {disfmarker} Jane was doing word level .\nPhD D: Yeah .\nProfessor E: Yeah .\nGrad G: So we weren't concerned with {comment} exactly when an overlap started and stopped .\nPhD F: Right . Right .\nPhD C: Well , not only a word level , but actually\nPhD D: Well {disfmarker}\nPhD F: I 'm expect I 'm not expecting {disfmarker}\nPhD D: No , it 's {disfmarker}\nPhD C: I mean , you didn't need to show the exact point of interruption , you just were showing at the level of the phrase or the level of the speech spurt , or {disfmarker}\nGrad G: Right .\nProfessor E: Mm - hmm .\nGrad G: Yep .\nPostdoc B: Well {disfmarker}\nPhD D: Yeah . Yeah .\nPostdoc B: Well , yeah , b yeah , I would say time bin . So my {disfmarker} my goal is to get words with reference to a time bin , {pause} beginning and end point .\nPhD C: Yeah .\nPhD D: Yeah .\nPhD C: Right .\nPhD D: Yeah .\nPostdoc B: And {disfmarker} and sometimes , you know , it was like you could have an overlap where someone said something in the middle ,\nPhD D: Yeah .\nPostdoc B: but , yeah , w it just wasn't important for our purposes to have it that {disfmarker} i disrupt that unit in order to have , you know , a the words in the order in which they were spoken , it would have {disfmarker} it would have been hard with the interface that we have .\nPhD D: Yeah .\nPostdoc B: Now , my {disfmarker} a Adam 's working on a of course , on a revised overlapping interface ,\nPhD D: Uh - huh .\nGrad G: Right .\nPhD D: I {disfmarker} I {disfmarker} I think {disfmarker} It 's {disfmarker} it 's a good eh work ,\nPostdoc B: but {disfmarker}\nPhD D: but eh I think we need eh eh more information .\nPhD F: No , of course .\nPostdoc B: Yeah .\nPhD F: I expect you to find more overlaps than {disfmarker} than Jane\nGrad G: Always need more for {disfmarker}\nPostdoc B: Yeah .\nPhD D: No , no . I {disfmarker} I have to go to {disfmarker}\nPhD F: because you 're looking at it at a much more detailed level .\nPhD D: I want eh {disfmarker} I wanted to eh compare the {disfmarker} the transcription .\nProfessor E: I have {disfmarker}\nGrad G: But if it takes sixty to one {disfmarker}\nProfessor E: Well , I but I have a suggestion about that . Um , obviously this is very , very time - consuming , and you 're finding lots of things which I 'm sure are gonna be very interesting , but in the interests of making progress , uh might I s how {disfmarker} how would it affect your time if you only marked speaker overlaps ?\nPhD D: Only .\nProfessor E: Yes .\nPhD D: Yeah .\nProfessor E: Do not mark any other events ,\nPhD D: Uh - huh .\nProfessor E: but only mark speaker {disfmarker} Do you think that would speed it up quite a bit ?\nPhD D: OK . OK . I {disfmarker} I {disfmarker} I {disfmarker} I w I {disfmarker} I wanted to {disfmarker}\nProfessor E: Do y do you think that would speed it up ? Uh , speed up your {disfmarker} your {disfmarker} your marking ?\nPhD D: nnn , I don't understand very .\nProfessor E: It took you a long time {pause} to mark twelve minutes .\nPhD D: Yeah . Oh , yeah , yeah .\nProfessor E: Now , my suggestion was for the other thirty - three {disfmarker}\nPhD D: On - only to mark {disfmarker} only to mark overlapping zone , but {disfmarker}\nProfessor E: Yeah , and my question is , if you did that , if you followed my suggestion , would it take much less time ?\nPhD D: Oh , yeah . Sure .\nProfessor E: Yeah OK .\nPhD D: Yeah sure .\nProfessor E: Then I think it 's a good idea .\nPhD D: Sure sure .\nProfessor E: Then I think it 's a good idea , because it\nPhD D: Sure , because I {disfmarker} I need a lot of time to {disfmarker} to put the label or to do that . Yeah .\nProfessor E: Yeah , I mean , we we know that there 's noise .\nGrad G: And\nPhD D: Uh - huh .\nProfessor E: There 's {disfmarker} there 's uh continual noise uh from fans and so forth , and there is uh more impulsive noise from uh taps and so forth\nPhD D: Yeah .\nProfessor E: and {disfmarker} and something in between with paper rustling . We know that all that 's there and it 's a g worthwhile thing to study , but obviously it takes a lot of time to mark all of these things .\nPhD D: Yeah .\nProfessor E: Whereas th i I would think that uh you {disfmarker} we can study more or less as a distinct phenomenon the overlapping of people talking .\nPhD D: Uh - huh . OK . OK .\nProfessor E: So . Then you can get the {disfmarker} Cuz you need {disfmarker} If it 's three hundred uh {disfmarker} i i it sounds like you probably only have fifty or sixty or seventy events right now that are really {disfmarker}\nPhD D: Yeah .\nProfessor E: And {disfmarker} and you need to have a lot more than that to have any kind of uh even visual sense of {disfmarker} of what 's going on , much less any kind of reasonable statistics .\nGrad G: Right .\nPhD C: Now , why do you need to mark speaker overlap by hand if you can infer it from the relative energy in the {disfmarker}\nGrad G: Well , that 's {disfmarker} That 's what I was gonna bring up .\nPhD C: I mean , you shouldn't need to do this p completely by hand ,\nProfessor E: Um , OK , yeah . So let 's back up because you weren't here for an earlier conversation .\nPhD C: right ? I 'm sorry .\nProfessor E: So the idea was that what he was going to be doing was experimenting with different measures such as the increase in energy , such as the energy in the LPC residuals , such as {disfmarker} I mean there 's a bunch of things {disfmarker} I mean , increased energy is - is sort of an obvious one .\nPhD C: Mm - hmm . In the far - field mike .\nProfessor E: Yeah .\nPhD C: Oh , OK .\nProfessor E: Um , and uh , it 's not obvious , I mean , you could {disfmarker} you could do the dumbest thing and get {disfmarker} get it ninety percent of the time . But when you start going past that and trying to do better , it 's not obvious what combination of features is gonna give you the {disfmarker} you know , the right detector . So the idea is to have some ground truth first . And so the i the idea of the manual marking was to say \" OK this , i you know , it 's {disfmarker} it 's really here \" .\nPhD A: But I think Liz is saying why not get it out of the transcripts ?\nPhD C: What I mean is {pause} get it from the close - talking mikes .\nProfessor E: Uh , yeah .\nPhD C: A or ge get a first pass from those ,\nProfessor E: We t we t w we t we talked about that .\nPhD C: and then go through sort of {disfmarker} It 'd be a lot faster probably to {disfmarker}\nPhD F: And you can {disfmarker}\nGrad G: Yeah , that 's his , uh {disfmarker}\nProfessor E: We {disfmarker} we {disfmarker} we talked about that . s But so it 's a bootstrapping thing and the thing is ,\nPhD C: Yeah , I just {disfmarker}\nProfessor E: the idea was , i we i i we thought it would be useful for him to look at the data anyway , and {disfmarker} and then whatever he could mark would be helpful ,\nPhD C: Right .\nProfessor E: and we could {disfmarker} Uh it 's a question of what you bootstrap from . You know , do you bootstrap from a simple measurement which is right most of the time and then you g do better , or do you bootstrap from some human being looking at it and then {disfmarker} then do your simple measurements , uh from the close - talking mike . I mean , even with the close - talking mike you 're not gonna get it right all the time .\nPhD C: Well , that 's what I wonder , because um {disfmarker} or how bad it is ,\nProfessor E: Well\nPhD C: be um , because that would be interesting\nGrad G: I 'm working on a program to do that , and {disfmarker}\nPhD C: especially because the bottleneck is the transcription . Right ? I mean , we 've got a lot more data than we have transcriptions for . We have the audio data , we have the close - talking mike ,\nProfessor E: Yeah .\nPhD C: so I mean it seems like one kind of project that 's not perfect , but {disfmarker} um , that you can get the training data for pretty quickly is , you know , if you infer form the close - talking mikes where the on - off points are of speech ,\nProfessor E: Right , we discussed that .\nPhD C: you know , how can we detect that from a far - field ?\nGrad G: And {disfmarker}\nPostdoc B: Oh .\nGrad G: I 've {disfmarker} I 've written a program to do that ,\nPhD C: OK , I 'm sorry I missed the {disfmarker}\nGrad G: and it , uh {disfmarker}\nProfessor E: It 's OK .\nGrad G: and {disfmarker} so {disfmarker} but it 's {disfmarker} it 's doing something very , very simple . It just takes a threshold , based on {disfmarker} on the volume ,\nPhD C: Uh - huh .\nPhD F: Or you can set the threshold low and then weed out the false alarms by hand .\nPhD C: Right , by hand . Yeah .\nPhD F: Yeah .\nGrad G: um , and then it does a median filter , and then it looks for runs . And , it seems to work , I 've {disfmarker} I 'm sort of fiddling with the parameters , to get it to actually generate something , and I haven't {disfmarker} I don't {disfmarker} what I 'm working on {disfmarker} was working on {disfmarker} was getting it to a form where we can import it into the user interface that we have , {pause} into Transcriber . And so {disfmarker} I told {disfmarker} I said it would take about a day . I 've worked on it for about half a day ,\nGrad H: I have to go .\nGrad G: so give me another half day and I we 'll have something we can play with .\nPhD C: OK .\nProfessor E: See , this is where we really need the Meeting Recorder query stuff to be working , because we 've had these meetings and we 've had this discussion about this , and I 'm sort of remembering a little bit about what we decided ,\nPhD C: Right . I 'm sorry . I just {disfmarker}\nProfessor E: but I couldn't remember all of it .\nPhD C: It\nProfessor E: So , I think it was partly that , you know , give somebody a chance to actually look at the data and see what these are like , partly that we have e some ground truth to compare against , you know , when {disfmarker} when he {disfmarker} he gets his thing going ,\nGrad G: But {disfmarker}\nProfessor E: uh , and {disfmarker}\nPhD C: Well , it 's definitely good to have somebody look at it . I was just thinking as a way to speed up you know , the amount of {disfmarker}\nPostdoc B: Mm - hmm .\nProfessor E: That was {disfmarker} that was exactly the notion that {disfmarker} that {disfmarker} that we discussed .\nPhD C: OK .\nGrad G: Thanks .\nPostdoc B: Another thing we discussed was um that {disfmarker}\nPhD C: It looks good .\nProfessor E: So .\nPhD C: I 'll be in touch . Thanks .\nProfessor E: S See ya . Yeah .\nPostdoc B: Was that um there m {pause} there was this already a script I believe uh that Dan had written , {comment} that uh handle bleedthrough , I mean cuz you have this {disfmarker} this close {disfmarker} you have contamination from other people who speak loudly .\nGrad G: Yeah , and I haven't tried using that . It would probably help the program that I 'm doing to first feed it through that . It 's a cross - correlation filter . So I {disfmarker} I haven't tried that , but that {disfmarker} If {disfmarker} It {disfmarker} it might be something {disfmarker} it might be a good way of cleaning it up a little .\nPostdoc B: So , some thought of maybe having {disfmarker} Yeah , having that be a preprocessor and then run it through yours .\nGrad G: Exactly . Yep .\nProfessor E: But {disfmarker} but that 's a refinement\nPostdoc B: That 's what we were discussing .\nProfessor E: and I think we wanna see {disfmarker} try the simple thing first , cuz you add this complex thing up uh afterwards that does something good y y yo you sort of wanna see what the simple thing does first .\nGrad G: Yep .\nProfessor E: But uh , having {disfmarker} having somebody have some experience , again , with {disfmarker} with uh {disfmarker} with marking it from a human standpoint , we 're {disfmarker} I mean , I don't expect Jose to {disfmarker} to do it for uh f fifty hours of {disfmarker} {comment} of speech , but I mean we {disfmarker} {comment} if uh {disfmarker} if he could speed up what he was doing by just getting the speaker overlaps so that we had it , say , for forty - five minutes , then at least we 'd have three hundred examples of it .\nPhD D: Yeah . Sure . Sure .\nProfessor E: And when {disfmarker} when uh Adam was doing his automatic thing he could then compare to that and see what it was different .\nPhD C: Oh yeah , definitely .\nPhD A: You know , I did {disfmarker} I did uh something almost identical to this at one of my previous jobs , and it works pretty well . I mean , i almost exactly what you described , an energy detector with a median filter , you look for runs . And uh , you know , you can {disfmarker}\nGrad G: It seemed like the right thing to do .\nPhD A: Yeah . I mean , you {disfmarker} you can get y I mean , you get them pretty close .\nGrad G: That was with zero literature search .\nPhD A: And so I think doing that to generate these possibilities and then going through and saying yes or no on them would be a quick way to {disfmarker} to do it .\nGrad G: That 's good validation .\nPhD A: Yeah .\nPostdoc B: Is this proprietary ?\nPhD A: Uh . {comment} No . No .\nGrad G: Yeah , do you have a patent on it ?\nPhD A: It was when I was working for the government .\nProfessor E: Oh , then everybody owns it . It 's the people .\nPostdoc B: Well , I mean , is this something that we could just co - opt , or is it {disfmarker} ?\nPhD A: Nah .\nPostdoc B: No . OK .\nProfessor E: Well , i i i he 's pretty close , anyway . I think {disfmarker} I think it 's {disfmarker}\nPhD A: Yeah , he 's {disfmarker} it {disfmarker} it doesn't take a long time .\nPostdoc B: Right . I just thought if it was tried and true , then {disfmarker} {comment} and he 's gone through additional levels of {disfmarker} of development .\nGrad G: Just output . Although if you {disfmarker} if you have some parameters like what 's a good window size for the median filter {disfmarker}\nPhD A: Oh ! {comment} I have to remember . I 'll think about it , and try to remember .\nPhD F: And it might be different for government people .\nGrad G: That 's alright .\nProfessor E: Yeah , good enough for government work , as they say .\nPhD C: They {disfmarker} they {disfmarker}\nPhD A: Di - dif different {disfmarker} different bandwidth .\nPhD F: They\nGrad G: I was doing pretty short , you know , tenth of a second , {comment} sorts of numbers .\nPhD F: OK .\nProfessor E: Uh , I don't know , it {disfmarker} if {disfmarker} if we want to uh {disfmarker} So , uh , maybe we should move on to other {disfmarker} other things in limited time .\nPostdoc B: Can I ask one question about his statistics ? So {disfmarker} so in the tw twelve minutes , um , if we took three hundred and divided it by four , which is about the length of twelve minutes , i Um , I 'd expect like there should be seventy - five overlaps .\nProfessor E: Yeah .\nPostdoc B: Did you find uh more than seventy - five overlaps in that period , or {disfmarker} ?\nPhD D: More than ?\nPostdoc B: More than {disfmarker} How many overlaps in your twelve minutes ?\nPhD D: How many ? Eh , not @ @ I Onl - only I {disfmarker} I transcribe eh only twelve minutes from the\nProfessor E: Yeah .\nPhD D: but eh I {disfmarker} I don't co eh {disfmarker} I don't count eh the {disfmarker} the overlap .\nPostdoc B: The overlaps . OK .\nPhD D: I consider I {disfmarker} I {disfmarker} The {disfmarker} the nnn {disfmarker} The {disfmarker} the three hundred is eh considered only you {disfmarker} your transcription . I have to {disfmarker} {vocalsound} to finish transcribing . So .\nGrad G: I b I bet they 're more , because the beginning of the meeting had a lot more overlaps than {disfmarker} than sort of the middle .\nPhD D: Yeah .\nGrad G: Middle or end .\nPostdoc B: I 'm not sure .\nPhD D: Yeah .\nGrad G: Because i we 're {disfmarker} we 're dealing with the {disfmarker} Uh , in the early meetings , we 're recording while we 're saying who 's talking on what microphone , {comment} and things like that ,\nPhD D: Yeah .\nGrad G: and that seems to be a lot of overlap .\nPostdoc B: I think it 's an empirical question .\nPhD D: Yeah .\nPostdoc B: I think we could find that out .\nPhD D: Yeah .\nGrad G: Yep .\nPostdoc B: I 'm {disfmarker} I 'm not sure that the beginning had more .\nProfessor E: So {disfmarker} so I was gonna ask , I guess about any {disfmarker} any other things that {disfmarker} that {disfmarker} that either of you wanted to talk about , especially since Andreas is leaving in five minutes , that {disfmarker} that you wanna go with .\nPhD C: Can I just ask about the data , like very straightforward question is where we are on the amount of data and the amount of transcribed data , just cuz I 'm {disfmarker} I wanted to get a feel for that to sort of be able to know what {disfmarker} what can be done first and like how many meetings are we recording\nProfessor E: Right so there 's this {disfmarker} this {disfmarker} There 's this forty - five minute piece that Jane transcribed .\nPhD C: and {disfmarker}\nProfessor E: That piece was then uh sent to IBM so they could transcribe so we have some comparison point . Then there 's s a larger piece that 's been recorded and uh put on CD - ROM and sent uh to IBM . Right ? And then we don't know .\nPhD C: How many meetings is that ? Like {disfmarker} how many {disfmarker}\nGrad G: What 's that ?\nProfessor E: That was about ten hours , and there was about {disfmarker}\nPhD C: t ten {disfmarker} It 's like ten meetings or something ? Uh - huh .\nGrad G: Yeah , something like that . And then {disfmarker} then we\nPhD A: Ten meetings that have been sent to IBM ?\nPhD C: And {disfmarker}\nProfessor E: Yeah .\nGrad G: Well , I haven't sent them yet because I was having this problem with the {pause} missing files .\nProfessor E: Oh . Oh , that 's right , that had {disfmarker} those have not been sent .\nPhD A: H how many total have we recorded now , altogether ?\nProfessor E: We 're saying about {pause} twelve hours .\nGrad G: About twelve {pause} by now . Twelve or thirteen .\nPhD C: Uh - huh . And we 're recording only this meeting , like continuously we 're only recording this one now ? or {disfmarker} ?\nProfessor E: No . No , so the {disfmarker} the {disfmarker} that 's the {disfmarker} that 's the biggest one {disfmarker} uh , chunk so far ,\nGrad G: Nope .\nPhD A: It was the morning one .\nPhD C: OK .\nProfessor E: but there 's at least one meeting recorded of uh the uh uh natural language guys .\nGrad G: Jerry .\nPhD C: Do they meet every week ,\nProfessor E: And then there {disfmarker}\nPhD C: or every {disfmarker}\nProfessor E: Uh , they do . w w And we talked to them about recording some more and we 're going to , uh , we 've started having a morning meeting , today uh i starting a w a week or two ago , on the uh front - end issues , and we 're recording those , uh there 's a network services and applications group here who 's agreed to have their meetings recorded ,\nPhD C: Great .\nProfessor E: and we 're gonna start recording them . They 're {disfmarker} They meet on Tuesdays . We 're gonna start recording them next week . So actually , we 're gonna h start having a {disfmarker} a pretty significant chunk and so , you know , {vocalsound} Adam 's sort of struggling with trying to get things to be less buggy , and come up quicker when they do crash and stuff {disfmarker} things like that , now that uh {disfmarker} {vocalsound} the things are starting to happen . So right now , yeah , I th I 'd say the data is predominantly meeting meetings , but there are scattered other meetings in it and that {disfmarker} that amount is gonna grow uh so that the meeting meetings will probably ultimately {disfmarker} i if we 're {disfmarker} if we collect fifty or sixty hours , the meeting meetings it will probably be , you know , twenty or thirty percent of it , not {disfmarker} not {disfmarker} not eighty or ninety . But .\nPhD C: So there 's probably {disfmarker} there 's three to four a week ,\nGrad G: That 's what we 're aiming for .\nPhD C: that we 're aiming for .\nProfessor E: Yeah .\nPhD C: And they 're each about an hour or something .\nProfessor E: Yeah , yeah .\nGrad G: Although {disfmarker} Yeah . We 'll find out tomorrow whether we can really do this or not .\nPhD C: So {disfmarker} OK .\nProfessor E: Yeah and th the {disfmarker} the other thing is I 'm not pos I 'm sort of thinking as we 've been through this a few times , that I really don't know {disfmarker} maybe you wanna do it once for the novelty , but I don't know if in general we wanna have meetings that we record from outside this group do the digits .\nGrad G: Right .\nProfessor E: Because it 's just an added bunch of weird stuff .\nPhD C: Yeah .\nProfessor E: And , you know , we {disfmarker} we h we 're highly motivated . Uh in fact , the morning group is really motivated cuz they 're working on connected digits , so it 's {disfmarker}\nGrad G: Actually that 's something I wanted to ask , is I have a bunch of scripts to help with the transcription of the digits .\nProfessor E: Yeah .\nGrad G: We don't have to hand - transcribe the digits because we 're reading them and I have those .\nPhD C: Right .\nProfessor E: Yeah .\nGrad G: And so I have some scripts that let you very quickly extract the sections of each utterance . But I haven't been ru I haven't been doing that . Um , if I did that , is someone gonna be working on it ?\nProfessor E: Uh , yeah , I {disfmarker} I think definitely s so Absolutely .\nGrad G: I mean , is it something of interest ?\nProfessor E: Yeah , whoever we have working on the acoustics for the Meeting Recorder are gonna start with that .\nGrad G: OK . I mean , I I 'm {disfmarker} I 'm interested in it , I just don't have time to do it now .\nPhD F: I was {disfmarker} these meetings {disfmarker} I 'm sure someone thought of this , but these {disfmarker} this uh reading of the numbers would be extremely helpful to do um adaptation .\nGrad G: So\nPhD F: Um .\nGrad G: Yep . Yep .\nPhD C: Actually I have o\nGrad G: I {disfmarker} I would really like someone to do adaptation .\nPhD F: Mm - hmm .\nGrad G: So if we got someone interested in that , I think it would be great for Meeting Recorder .\nProfessor E: Well {disfmarker} I mean , one of the things I wanted to do , uh , that I I talked to {disfmarker} to Don about , is one of the possible things he could do or m also , we could have someone else do it , is to do block echo cancellation ,\nGrad G: Since it 's the same people over and over .\nPhD F: Mm - hmm .\nProfessor E: to try to get rid of some of the effects of the {disfmarker} the {disfmarker} the far - field effects . Um , I mean we have {disfmarker} the party line has been that echo cancellation is not the right way to handle the situation\nPhD F: Mm - hmm .\nProfessor E: because people move around , and uh , if {disfmarker} if it 's {disfmarker} if it 's uh not a simple echo , like a cross - talk kind of echo , but it 's actually room acoustics , it 's {disfmarker} it 's {disfmarker} it 's {disfmarker} you can't really do inversion ,\nPhD F: Mm - hmm .\nProfessor E: and even echo cancellation is going to uh be something {disfmarker} It may {disfmarker} you {disfmarker} Someone may be moving enough that you are not able to adapt quickly and so the tack that we 've taken is more \" lets come up with feature approaches and multi - stream approaches and so forth , that will be robust to it for the recognizer and not try to create a clean signal \" .\nPhD F: Mm - hmm .\nProfessor E: Uh , that 's the party line . But it occurred to me a few months ago that uh party lines are always , you know , sort of dangerous . It 's good {disfmarker} {vocalsound} good to sort of test them , actually . And so we haven't had anybody try to do a good serious job on echo cancellation and we should know how well that can do . So that 's something I 'd like somebody to do at some point , just take these digits , take the far - field mike signal , and the close uh mike signal , and apply really good echo cancellation . Um , there was a {disfmarker} have been some nice talks recently by {disfmarker} by Lucent on {disfmarker} on their b\nPhD F: Hmm .\nProfessor E: the block echo cancellation particularly appealed to me , uh you know , trying and change it sample by sample , but you have some reasonable sized blocks . {comment} And um , you know , th\nPhD A: W what is the um {disfmarker} the artifact you try to {disfmarker} you 're trying to get rid of when you do that ?\nPhD F: Ciao .\nProfessor E: Uh so it 's {disfmarker} it {disfmarker} you have a {disfmarker} a direct uh {disfmarker} Uh , what 's the difference in {disfmarker} If you were trying to construct a linear filter , that would um {disfmarker}\nPhD F: I 'm signing off .\nProfessor E: Yeah . that would subtract off {comment} the um uh parts of the signal that were the aspects of the signal that were different between the close - talk and the distant . You know , so {disfmarker} so uh um I guess in most echo cancellation {disfmarker} Yeah , so you {disfmarker} Given that um {disfmarker} Yeah , so you 're trying to {disfmarker} So you 'd {disfmarker} There 's a {disfmarker} a distance between the close and the distant mikes so there 's a time delay there , and after the time delay , there 's these various reflections . And if you figure out well what 's the {disfmarker} there 's a {disfmarker} a least squares algorithm that adjusts itself {disfmarker} adjusts the weight so that you try to subtract {disfmarker} essentially to subtract off uh different uh {disfmarker} different reflections . Right ? So let 's take the simple case where you just had {disfmarker} you had some uh some delay in a satellite connection or something and then there 's a {disfmarker} there 's an echo . It comes back . And you want to adjust this filter so that it will maximally reduce the effect of this echo .\nPhD A: So that would mean like if you were listening to the data that was recorded on one of those . Uh , just the raw data , you would {disfmarker} you might hear kind of an echo ? And {disfmarker} and then this {disfmarker} noise cancellation would get\nProfessor E: Well , I 'm {disfmarker} I 'm {disfmarker} I 'm saying {disfmarker} That 's a simplified version of what 's really happening . {comment} What 's really happening is {disfmarker} Well , when I 'm talking to you right now , you 're getting the direct sound from my speech , but you 're also getting , uh , the indirect sound that 's bounced around the room a number of times . OK ? So now , if you um try to r you {disfmarker} To completely remove the effect of that is sort of impractical for a number of technical reasons , but I {disfmarker} but {disfmarker} not to try to completely remove it , that is , invert the {disfmarker} the room response , but just to try to uh uh eliminate some of the {disfmarker} the effect of some of the echos . Um , a number of people have done this so that , say , if you 're talking to a speakerphone , uh it makes it more like it would be , if you were talking right up to it . So this is sort of the st the straight - forward approach . You say I {disfmarker} I {disfmarker} I want to use this uh {disfmarker} this item but I want to subtract off various kinds of echos . So you construct a filter , and you have this {disfmarker} this filtered version uh of the speech um gets uh uh {disfmarker} gets subtracted off from the original speech . Then you try to {disfmarker} you try to minimize the energy in some sense . And so um {disfmarker} uh with some constraints .\nPhD A: Kind of a clean up thing , that {disfmarker}\nProfessor E: It 's a clean up thing . Right .\nPhD A: OK .\nProfessor E: So , echo cancelling is {disfmarker} is , you know , commonly done in telephony , and {disfmarker} and {disfmarker} and it 's sort of the obvious thing to do in this situation if you {disfmarker} if , you know , you 're gonna be talking some distance from a mike .\nPhD A: When uh , I would have meetings with the folks in Cambridge when I was at BBN over the phone , they had a um {disfmarker} some kind of a special speaker phone and when they would first connect me , it would come on and we 'd hear all this noise . And then it was uh {disfmarker} And then it would come on and it was very clear ,\nProfessor E: Yeah .\nPhD A: you know .\nProfessor E: Right . So it 's taking samples , it 's doing adaptation , it 's adjusting weights , and then it 's getting the sum . So um , uh anyway that 's {disfmarker} that 's kind of a reasonable thing that I 'd like to have somebody try {disfmarker} somebody look {disfmarker} And {disfmarker} and the digits would be a reasonable thing to do that with . I think that 'd be enough data {disfmarker} plenty of data to do that with , and i for that sort of task you wouldn't care whether it was uh large vocabulary speech or anything . Uh . {vocalsound} Um\nPostdoc B: Is Brian Kingsbury 's work related to that , or is it a different type of reverberation ?\nProfessor E: Brian 's {comment} Kingsbury 's work is an example of what we did f f from the opposite dogma . Right ? Which is what I was calling the \" party line \" , which is that uh doing that sort of thing is not really what we want . We want something more flexible , uh i i where people might change their position , and there might be , you know {disfmarker} There 's also um oh yeah , noise . So the echo cancellation does not really allow for noise . It 's if you have a clean situation but you just have some delays , Then we 'll figure out the right {disfmarker} the right set of weights for your taps for your filter in order to produce the effect of those {disfmarker} those echos . But um if there 's noise , then the very signal that it 's looking at is corrupted so that it 's decision about what the right {disfmarker} you know , right {disfmarker} right uh {disfmarker} delays are {disfmarker} is , uh {disfmarker} is {disfmarker} right delayed signal is {disfmarker} is {disfmarker} is {disfmarker} uh is incorrect . And so , in a noisy situation , um , also in a {disfmarker} in a situation that 's very reverberant {disfmarker} {comment} with long reverberation times {comment} and really long delays , it 's {disfmarker} it 's sort of typically impractical . So for those kind of reasons , and also a {disfmarker} a c a complete inversion , if you actually {disfmarker} I mentioned that it 's kind of hard to really do the inversion of the room acoustics . Um , that 's difficult because um often times the {disfmarker} the um {disfmarker} {vocalsound} the system transfer function is such that when it 's inverted you get something that 's unstable , and so , if you {disfmarker} you do your estimate of what the system is , and then you try to invert it , you get a filter that actually uh , you know , rings , and {disfmarker} and uh goes to infinity . So it 's {disfmarker} so there 's {disfmarker} there 's {disfmarker} there 's that sort of technical reason , and the fact that things move , and there 's air currents {disfmarker} I mean there 's all sorts of {disfmarker} all sorts of reasons why it 's not really practical . So for all those kinds of reasons , uh we {disfmarker} we {disfmarker} we sort of um , concluded we didn't want to in do inversion , and we 're even pretty skeptical of echo cancellation , which isn't really inversion , and um we decided to do this approach of taking {disfmarker} uh , just picking uh features , which were {disfmarker} uh will give you more {disfmarker} something that was more stable , in the presence of , or absence of , room reverberation , and that 's what Brian was trying to do . So , um , let me just say a couple things that I was {disfmarker} I was gonna bring up . Uh . Let 's see . I guess you {disfmarker} you actually already said this thing about the uh {disfmarker} about the consent forms , which was that we now don't have to {disfmarker} So this was the human subjects folks who said this , {comment} or that {disfmarker} that {disfmarker} ?\nPostdoc B: The a apparently {disfmarker} I mean , we 're gonna do a revised form , of course . Um but once a person has signed it once , then that 's valid for a certain number of meetings . She wanted me to actually estimate how many meetings and put that on the consent form . I told her that would be a little bit difficult to say . So I think from a s practical standpoint , maybe we could have them do it once every ten meetings , or something . It won't be that many people who do it {pause} that often , but um just , you know , so long as they don't forget that they 've done it , I guess .\nProfessor E: OK . Um , back on the data thing , so there 's this sort of one hour , ten hour , a hundred hour sort of thing that {disfmarker} that we have . We have {disfmarker} we have an hour uh that {disfmarker} that is transcribed , we have {disfmarker} we have twelve hours that 's recorded but not transcribed , and at the rate we 're going , uh by the end of the semester we 'll have , I don't know , forty or fifty or something , if we {disfmarker} if this really uh {disfmarker} Well , do we have that much ?\nPhD C: Not really . It 's three to four per week .\nProfessor E: Let 's see , we have {disfmarker}\nPhD C: So that 's what {disfmarker} You know , that {disfmarker}\nProfessor E: uh eight weeks , uh is {disfmarker}\nPhD C: So that 's not a lot of hours .\nProfessor E: Eight weeks times three hours is twenty - four , so that 's {disfmarker} Yeah , so like thirty {disfmarker} thirty hours ?\nPhD A: Three {disfmarker} Three hours .\nPhD C: Yeah . I mean , is there {disfmarker} I know this sounds {pause} tough but we 've got the room set up . Um I was starting to think of some projects where you would use well , similar to what we talked about with uh energy detection on the close - talking mikes . There are a number of interesting questions that you can ask about how interactions happen in a meeting , that don't require any transcription . So what are the patterns , the energy patterns over the meeting ? And I 'm really interested in this {vocalsound} but we don't have a whole lot of data . So I was thinking , you know , we 've got the room set up and you can always think of , also for political reasons , if ICSI collected you know , two hundred hours , that looks different than forty hours , even if we don't transcribe it ourselves ,\nProfessor E: But I don't think we 're gonna stop at the end of this semester .\nPhD C: so {disfmarker}\nProfessor E: Right ? So , I th I think that if we are able to keep that up for a few months , we are gonna have more like a hundred hours .\nPhD C: I mean , is there {disfmarker} Are there any other meetings here that we can record , especially meetings that have some kind of conflict in them {comment} or some kind of deci I mean , that are less well {disfmarker} I don't {disfmarker} uh , that have some more emotional aspects to them , or strong {disfmarker}\nGrad G: We had some good ones earlier .\nPhD C: There 's laughter , um I 'm talking more about strong differences of opinion meetings , maybe with manager types , or {disfmarker}\nGrad G: I think it 's hard to record those .\nPhD C: To be allowed to record them ?\nPostdoc B: It 's also likely that people will cancel out afterwards .\nPhD C: OK .\nProfessor E: Yeah , people will get {disfmarker}\nPostdoc B: But I {disfmarker} but I wanted to raise the KPFA idea .\nPhD C: OK . Well , if there is , anyway .\nProfessor E: Yeah , I was gonna mention that .\nGrad G: Oh , that 's a good idea . That 's {disfmarker} That would be a good match .\nProfessor E: Yeah . So {disfmarker} Yeah . So I {disfmarker} I {disfmarker} uh , I {disfmarker} I 'd mentioned to Adam , and {disfmarker} that was another thing I was gonna talk {disfmarker} uh , mention to them before {disfmarker} {comment} that uh there 's uh {disfmarker} It {disfmarker} it oc it occurred to me that we might be able to get some additional data by talking to uh acquaintances in local broadcast media . Because , you know , we had talked before about the problem about using found data , {comment} that {disfmarker} that uh it 's just set up however they have it set up and we don't have any say about it and it 's typically one microphone , in a , uh , uh {disfmarker} or {disfmarker} and {disfmarker} and so it doesn't really give us the {disfmarker} the {disfmarker} the uh characteristics we want . Um and so I do think we 're gonna continue recording here and record what we can . But um , it did occur to me that we could go to friends in broadcast media and say \" hey you have this panel show , {pause} or this {disfmarker} you know , this discussion show , and um can you record multi - channel ? \" And uh they may be willing to record it uh with {disfmarker}\nPhD C: With lapel mikes or something ?\nProfessor E: Well , they probably already use lapel , but they might be able to have it {disfmarker} it wouldn't be that weird for them to have another mike that was somewhat distant .\nPhD C: Right .\nProfessor E: It wouldn't be exactly this setup , but it would be that sort of thing , and what we were gonna get from UW , you know , assuming they {disfmarker} they {disfmarker} they start recording , isn't {disfmarker} als also is not going to be this exact setup .\nPhD C: Right . No , I think that 'd be great , if we can get more data .\nProfessor E: So , {comment} I {disfmarker} I {disfmarker} I {disfmarker} I was thinking of looking into that . the other thing that occurred to me after we had that discussion , in fact , is that it 's even possible , since of course , many radio shows are not live , {comment} uh that we could invite them to have like some of their {disfmarker} {comment} record some of their shows here .\nPostdoc B: Wow !\nPhD C: Well {disfmarker} Or {disfmarker} The thing is , they 're not as averse to wearing one of these head - mount I mean , they 're on the radio ,\nGrad G: Right , as we are .\nPhD C: right ? So . {comment} Um , I think that 'd be fantastic\nProfessor E: Right .\nPhD C: cuz those kinds of panels and {disfmarker} Those have interesting\nProfessor E: Yeah .\nPhD C: Th - that 's an {disfmarker} a side of style {disfmarker} a style that we 're not collecting here , so it 'd be great .\nProfessor E: And {disfmarker} and the {disfmarker} I mean , the other side to it was the {disfmarker} what {disfmarker} which is where we were coming from {disfmarker} I 'll {disfmarker} I 'll talk to you more about it later {comment} is that {disfmarker} is that there 's {disfmarker} there 's uh the radio stations and television stations already have stuff worked out presumably , uh related to , you know , legal issues and {disfmarker} and permissions and all that . I mean , they already do what they do {disfmarker} do whatever they do . So it 's {disfmarker} uh , it 's {disfmarker} So it 's {disfmarker} so it 's another source . So I think it 's something we should look into , you know , we 'll collect what we collect here hopefully they will collect more at UW also and um {disfmarker} and maybe we have this other source . But yeah I think that it 's not unreasonable to aim at getting , you know , significantly in excess of a hundred hours . I mean , that was sort of our goal . The thing was , I was hoping that we could {disfmarker} @ @ in the {disfmarker} under this controlled situation we could at least collect , you know , thirty to fifty hours . And at the rate we 're going we 'll get pretty close to that I think this semester . And if we continue to collect some next semester , I think we should , uh {disfmarker}\nPhD C: Right . Yeah I was mostly trying to think , \" OK , if you start a project , within say a month , you know , how much data do you have to work with . And you {disfmarker} you wanna s you wanna sort of fr freeze your {disfmarker} your data for awhile so um right now {disfmarker} and we don't have the transcripts back yet from IBM right ? Do {disfmarker} Oh , do we now ?\nProfessor E: Well , we don't even have it for this f you know , forty - five minutes , that was {disfmarker}\nPhD C: So um , not complaining , I was just trying to think , you know , what kinds of projects can you do now versus uh six months from now\nProfessor E: Yeah .\nPhD C: and they 're pretty different , because\nProfessor E: Yeah . So I was thinking right now it 's sort of this exploratory stuff where you {disfmarker} you look at the data , you use some primitive measures and get a feeling for what the scatter plots look like ,\nGrad G: Right .\nPhD C: um {disfmarker} Right . Right , right .\nProfessor E: and {disfmarker} and {disfmarker} and uh {disfmarker} and meanwhile we collect , and it 's more like yeah , three months from now , or six months from now you can {disfmarker} you can do a lot of other things .\nPhD C: Cuz I 'm not actually sure , just logistically that I can spend {disfmarker} you know , I don't wanna charge the time that I have on the project too early , before there 's enough data to make good use of the time . And that 's {disfmarker} and especially with the student\nGrad G: Right .\nPhD C: uh for instance this guy who seems {disfmarker}\nProfessor E: Yeah .\nPhD C: Uh anyway , I shouldn't say too much , but um if someone came that was great and wanted to do some real work and they have to end by the end of this school year in the spring , how much data will I have to work with , with that person . And so it 's {disfmarker}\nProfessor E: i Yeah , so I would think , exploratory things now . Uh , three months from now {disfmarker} Um , I mean the transcriptions I think are a bit of an unknown cuz we haven't gotten those back yet as far as the timing , but I think as far as the collection , it doesn't seem to me l like , uh , unreasonable to say that uh in January , you know , ro roughly uh {disfmarker} which is roughly three months from now , we should have at least something like , you know , twenty - five , thirty hours .\nPhD C: And we just don't know about the transcription part of that ,\nProfessor E: So that 's {disfmarker}\nPostdoc B: Yeah , we need to {disfmarker} I think that there 's a possibility that the transcript will need to be adjusted afterwards ,\nPhD C: so . I mean , it {disfmarker}\nPostdoc B: and uh es especially since these people won't be uh used to dealing with multi - channel uh transcriptions .\nPhD C: Right .\nProfessor E: Yeah .\nPostdoc B: So I think that we 'll need to adjust some {disfmarker} And also if we wanna add things like um , well , more refined coding of overlaps , then definitely I think we should count on having an extra pass through . I wanted to ask another a a aspect of the data collection . There 'd be no reason why a person couldn't get together several uh , you know , friends , and come and argue about a topic if they wanted to , right ?\nProfessor E: If they really have something they wanna talk about as opposed to something @ @ {disfmarker} I mean , what we 're trying to stay away from was artificial constructions , but I think if it 's a real {disfmarker} Why not ? Yeah .\nPhD C: I mean , I 'm thinking , politically {disfmarker}\nGrad G: Stage some political debates .\nPostdoc B: You could do this ,\nPhD C: Well yeah ,\nPostdoc B: you know . You could .\nPhD C: or just if you 're {disfmarker} if you ha If there are meetings here that happen that we can record even if we don't {pause} um have them do the digits , {comment} or maybe have them do a shorter {pause} digit thing {comment} like if it was , you know , uh , one string of digits , or something , they 'd probably be willing to do .\nGrad G: We don't have to do the digits at all if we don't want to .\nPhD C: Then , having the data is very valuable , cuz I think it 's um politically better for us to say we have this many hours of audio data , especially with the ITR , if we put in a proposal on it . It 'll just look like ICSI 's collected a lot more audio data . Um , whether it 's transcribed or not um , is another issue , but there 's {disfmarker} there are research questions you can answer without the transcriptions , or at least that you can start to answer .\nPostdoc B: It seems like you could hold some meetings .\nGrad G: Yep .\nPostdoc B: You know , you and maybe Adam ?\nPhD C: So .\nPostdoc B: You {disfmarker} you could {disfmarker} you could maybe hold some additional meetings , if you wanted .\nPhD A: Would it help at all {disfmarker} I mean , we 're already talking about sort of two levels of detail in meetings . One is uh um without doing the digits {disfmarker} Or , I guess the full - blown one is where you do the digits , and everything , and then talk about doing it without digits , what if we had another level , just to collect data , which is without the headsets and we just did the table - mounted stuff .\nPhD C: Need the close - talking mikes .\nPhD A: You do , OK .\nPhD C: I mean , absolutely ,\nProfessor E: Yeah . Yeah .\nPhD C: yeah . I 'm really scared {disfmarker}\nGrad G: It seems like it 's a big part of this corpus is to have the close - talking mikes .\nPhD A: I see , OK .\nPhD C: Um or at least , like , me personally ? I would {disfmarker} {comment} I {disfmarker} couldn't use that data .\nProfessor E: Yeah .\nPostdoc B: I agree . And Mari also ,\nPhD C: Um .\nPostdoc B: we had {disfmarker} This came up when she she was here . That 's important .\nPhD C: So it 's a great idea ,\nProfessor E: Yeah , I {disfmarker} I {disfmarker} b By the {disfmarker} by the way , I don't think the transcriptions are actually , in the long run , such a big bottleneck .\nPhD C: and if it were true than I would just do that , but it 's not that bad {disfmarker} like the room is not the bottleneck , and we have enough time in the room , it 's getting the people to come in and put on the {disfmarker} and get the setup going .\nProfessor E: I think the issue is just that we 're {disfmarker} we 're blazing that path . Right ? And {disfmarker} and um {disfmarker} d Do you have any idea when {disfmarker} when uh the {disfmarker} you 'll be able to send uh the ten hours to them ?\nGrad G: Well , I 've been burning two C Ds a day , which is about all I can do with the time I have .\nProfessor E: Yeah . Yeah .\nGrad G: So it 'll be early next week .\nProfessor E: Yeah , OK . So early next week we send it to them , and then {disfmarker} then we check with them to see if they 've got it and we {disfmarker} we start , you know asking about the timing for it .\nGrad G: Yep .\nProfessor E: So I think once they get it sorted out about how they 're gonna do it , which I think they 're pretty well along on , cuz they were able to read the files and so on .\nGrad G: Yep .\nProfessor E: Right ?\nGrad G: Yeah , but {disfmarker}\nProfessor E: Well {disfmarker}\nGrad G: Yeah , who knows where they are .\nPhD A: Have they ever responded to you ?\nGrad G: Nope .\nProfessor E: Yeah , but {disfmarker} You know , so they {disfmarker} they {disfmarker} they have {disfmarker} you know , they 're volunteering their time and they have a lot of other things to do ,\nPhD C: What if {disfmarker}\nGrad G: Yeah , you {disfmarker} we can't complain .\nProfessor E: right ? But they {disfmarker} But at any rate , they 'll {disfmarker} I {disfmarker} I think once they get that sorted out , they 're {disfmarker} they 're making cassettes there , then they 're handing it to someone who they {disfmarker} who 's {disfmarker} who is doing it , and uh I think it 's not going to be {disfmarker} I don't think it 's going to be that much more of a deal for them to do thirty hours then to do one hour , I think . It 's not going to be thirty\nGrad G: Yep . I think that 's probably true .\nPhD C: Really ? So it 's the amount of {disfmarker}\nProfessor E: It 's {disfmarker} it 's just getting it going .\nGrad G: It 's pipeline , pipeline issues .\nPhD C: Right . What about these lunch meetings {disfmarker}\nGrad G: Once the pipeline fills .\nPhD C: I mean , I don't know , if there 's any way without too much more overhead , even if we don't ship it right away to IBM even if we just collect it here for awhile , {comment} to record you know , two or three more meeting a week , just to have the data , even if they 're um not doing the digits , but they do wear the headphones ?\nProfessor E: But the lunch meetings are pretty much one person getting up and {disfmarker}\nPhD C: No , I meant , um , sorry , the meetings where people eat their lunch downstairs , maybe they don't wanna be recorded , but {disfmarker}\nGrad G: Oh , and we 're just chatting ?\nPhD C: Just the ch the chatting .\nGrad G: Yeah , we have a lot of those .\nPhD C: I actually {disfmarker} I actually think that 's {pause} useful {pause} data , um {pause} the chatting ,\nGrad G: Yeah , the problem with that is I would {disfmarker} I think I would feel a little constrained to {disfmarker} You know ? Uh , some of the meetings {disfmarker}\nPhD C: but {disfmarker} OK . You don't wanna do it , cuz {disfmarker} OK .\nGrad G: You know , our \" soccer ball \" meeting ?\nPhD C: Alright .\nGrad G: I guess none of you were there for our soccer ball meeting .\nPhD C: Alright , {comment} so I 'll just throw it out there , if anyone knows of one more m or two more wee meetings per week that happen at ICSI , um that we could record , I think it would be worth it .\nGrad G: That was hilarious .\nProfessor E: Yeah . Well , we should also check with Mari again , because they {disfmarker} because they were really intending , you know , maybe just didn't happen , but they were really intending to be duplicating this in some level . So then that would double {pause} what we had . Uh . And there 's a lot of different meetings at UW uh {disfmarker} I mean really m a lot more {comment} than we have here right cuz we 're not right on campus ,\nGrad G: Right .\nProfessor E: so .\nPhD A: Is the uh , notion of recording any of Chuck 's meetings dead in the water , or is that still a possibility ?\nProfessor E: Uh , {vocalsound} they seem to have some problems with it . We can {disfmarker} we can talk about that later . Um , but , again , Jerry is {disfmarker} Jerry 's open {disfmarker} So I mean , we have two speech meetings , one uh network meeting , uh Jerry was open to it but I {disfmarker} I s One of the things that I think is a little {disfmarker} a little bit of a limitation , there is a think when the people are not involved uh in our work , we probably can't do it every week . You know ? I {disfmarker} I {disfmarker} I {disfmarker} I think that {disfmarker} that people are gonna feel uh {disfmarker} are gonna feel a little bit constrained . Now , it might get a little better if we don't have them do the digits all the time . And the {disfmarker} then {disfmarker} so then they can just really sort of try to {disfmarker} put the mikes on and then just charge in and {disfmarker}\nGrad G: Yep .\nPhD C: What if we give people {disfmarker} you know , we cater a lunch in exchange for them having their meeting here or something ?\nPostdoc B: Well , you know , I {disfmarker} I do think eating while you 're doing a meeting is going to be increasing the noise .\nPhD C: OK .\nPostdoc B: But I had another question , which is um , you know , in principle , w um , I know that you don't want artificial topics ,\nPhD C: Alright , alright , alright .\nPostdoc B: but um it does seem to me that we might be able to get subjects from campus to come down and do something that wouldn't be too artificial . I mean , we could {disfmarker} political discussions , or {disfmarker} or something or other ,\nPhD C: No , definitely .\nPostdoc B: and i you know , people who are {disfmarker} Because , you know , there 's also this constraint . We d it 's like , you know , the {disfmarker} the {disfmarker} uh goldibears {disfmarker} goldi goldilocks , it 's like you don't want meetings that are too large , but you don't want meetings that are too small . And um {disfmarker} a and it just seems like maybe we could exploit the subj human subject p p pool , in the positive sense of the word .\nPhD A: Well , even {disfmarker} I mean , coming down from campus is sort of a big thing , but what about\nPostdoc B: We could pay subjects .\nPhD A: or what about people in the {disfmarker} in the building ?\nPhD C: Yeah , I was thinking , there 's all these other peo\nPhD A: I mean , there 's the State of California downstairs , and {disfmarker}\nPhD C: Yeah . I mean {disfmarker}\nGrad G: I just really doubt that uh any of the State of California meetings would be recordable and then releasable to the general public .\nPostdoc B: Yeah .\nPhD A: Oh .\nPhD C: Mm - hmm .\nGrad G: So I {disfmarker} I mean I talked with some people at the Haas Business School who are i who are interested in speech recognition\nPhD C: Alright , well .\nGrad G: and , they sort of hummed and hawed and said \" well maybe we could have meetings down here \" , but then I got email from them that said \" no , we decided we 're not really interested and we don't wanna come down and hold meetings . \" So , I think it 's gonna be a problem to get people regularly .\nPhD A: What about Joachim , maybe he can {disfmarker}\nProfessor E: But {disfmarker} but we c But I think , you know , we get some scattered things from this and that . And I {disfmarker} I d I do think that maybe we can get somewhere with the {disfmarker} with the radio .\nPhD C: Mm - hmm .\nProfessor E: Uh i I have better contacts in radio than in television , but {disfmarker}\nPhD A: You could get a lot of lively discussions from those radio ones .\nPhD C: Well , and they 're already {disfmarker} they 're {disfmarker} these things are already recorded ,\nGrad G: Yep .\nProfessor E: Yeah .\nPhD C: we don't have to ask them to {disfmarker} even {disfmarker} and I 'm not sure wh how they record it , but they must record from individual {disfmarker}\nProfessor E: n Well {disfmarker} No , I 'm not talking about ones that are already recorded . I 'm talking about new ones\nPhD C: Why {disfmarker} why not ?\nProfessor E: because {disfmarker} because {disfmarker} because we would be asking them to do something different .\nPhD C: Well , we can find out . I know for instance Mark Liberman was interested uh in {disfmarker} in LDC getting {pause} data , uh , and {disfmarker}\nProfessor E: Right , that 's the found data idea .\nPhD C: Yeah .\nProfessor E: But what I 'm saying is uh if I talk to people that I know who do these th who produce these things we could ask them if they could record an extra channel , let 's say , of a distant mike .\nPhD C: Mm - hmm .\nProfessor E: And u I think routinely they would not do this . So , since I 'm interested in the distant mike stuff , I wanna make sure that there is at least that somewhere\nPhD C: Right . Great . OK .  \nProfessor E: and uh {disfmarker} But if we ask them to do that they might be intrigued enough by the idea that they uh might be e e willing to {disfmarker} the {disfmarker} I might be able to talk them into it .\nPhD C: Mm - hmm .\nGrad G: Um . We 're getting towards the end of our disk space , so we should think about trying to wrap up here .\nPhD C: That 's a good way to end a meeting .\nProfessor E: OK . Well I don't {disfmarker} why don't we {disfmarker} why d u why don't we uh uh turn them {disfmarker} turn\nGrad G: OK , leave {disfmarker} leave them on for a moment until I turn this off , cuz that 's when it crashed last time .\nPostdoc B: Oh . That 's good to know .\nProfessor E: Turning off the microphone made it crash . Well {disfmarker}\nPostdoc B: That 's good to know .\nProfessor E: OK .", "source": "meeting_summ", "evaluation": "rouge"}
{"instructions": ["How did the Prime Minister debate about the delaying of the government's response towards Covid-19?", "What did the opposition party and the Prime Minister commented about companies laying off workers in the midst of pandemic?", "What was the debate over the situation of long-term care?", "What was the questioning about the reports on long-term care facilities?", "What was the debate about a particular fundraising campaign?", "What policy the government was going to roll out to ease the deficit?", "What was the debate about the economic bilateral relations with the UK?", "What was the discussion about imports and supply chains?", "What was the controversy about China hoarding PPE amid the pandemic?", "What was the debate about government giving money to companies which did not put the amount into proper use?", "What was the discussion about the government's policy to improve long-term care facilities and protect the seniors?", "What was the discussion about the seniors care crisis?", "Summarize the whole meeting."], "outputs": ["In response to the opposition party, the Prime Minister answered that the government rolled out the Canada emergency response benefit extremely quickly, and they had been helping the small businesses with the Canada emergency business account. The opposition party was not very satisfied because he thought that the government did not reach out to as many businesses as possible. Also, the opposition party made a few comments on the rent relief program which was too rigid and hard to apply.", "The Prime Minister explained that the government recognized that several organizations and companies were facing difficulties because of COVID-19 and they were supporting people all over the country through that program. Although the opposition party was getting rigorous about the intensity of the question, the Prime Minister kept emphasizing that the government's priority had always been workers in difficulty so that they do not lose their jobs. This applied to all organizations and companies in the country to the extent possible.", "The opposition party questioned about sending military groups to provinces in order to fix long-term care. The Prime Minister answered that the government needed to make sure seniors across the country were properly cared for, and they sent in the military to help the provinces. The opposition party also questioned about applying the national standards so that long-term care was governed by the same principles as the Canada Health Act. The Prime Minister elaborated that due the Covid-19, pushing the project had become extremely difficult.", "The opposition party questioned that the report was delayed in issuing by the government and was not acted upon. The minister answered that the report was done and given up through the chain of command, and once the government received this report, it was forwarded to the appropriate authorities. The minister denied the fact that the report was released and acted upon late.", "The opposition party claimed that the Minister of Digital Government has been promoting a fundraising campaign to sue Global News for their story criticizing the Chinese Communist Party, and the opposition party thought the minister was supporting the Communist Party of China and threatening our media and freedom of expression. The Minister explained that community outreach was a very important part of the work of a member of Parliament and WeChat was one of many social media sites regularly used by members, and the minister did not share any personal views on Wechat.", "The minister argued that it was very important to be transparent with our investments and the government would look at the investments and the figures every day and be transparent about it. The minister promised that Canada would have a good economy in the future, and the government would not raise taxes after the crisis to tackle the deficit. Hence, the opposition party demanded a regular economy update.", "The opposition party claimed that the government was not cooperating with the UK, its largest trading partner, protecting the viability of their international supply chains and capitalizing on the opportunities. The minister explained that the UK, of course, was a very important trading partner for Canada, and CETA would continue to apply to trade with the U.K. during this period while they went through Brexit.", "The opposition party claimed that the supply chain in Canada amidst the pandemic was not stable enough and the government was not doing anything. The minister explained that they would continue to work with countries around the globe to ensure that Canada's supply chains and those global supply chains, particularly for essential goods, for agricultural products, for medical supplies, would continue to remain open.", "The opposition party claimed that China was procuring and hoarding PPE during January. And in April, the minister stated there were not enough supplies in the national emergency stockpile. The opposition party was triggered by the fact that the minister approved a donation of 16 tonnes of PPE for China on January 31, claiming it would not compromise the country's supply. The minister explained that the government was doing so because they had multiple complementary supply chains operating at the same time for PPE production.", "The opposition party claimed that the government had been providing financial support to companies such as Air Canada, which did not pay a single cent in tax nor did it use the money to reimburse customers. The minister explained that the government did not bias against any company, , and it was thought that it was very important to protect employees in every sector of the economy and across Canada.The fight against tax evasion was a priority for the government. The minister promised that they would continue to target companies that use tax evasion schemes.", "The opposition party claimed that people across Canada were appalled by the situation in care homes which left seniors suffering. The minister explained that the government was fully aware of the situation. The minister promised that they would fully play their role federal level with advice, with guidance, with support and with investments. They were going to have those conversations about how best they can improve the care for all seniors.", "The opposition party claimed that the seniors care crisis was a national problem, and the federal government was not taking immediate response. The opposition party pointed out that these failures were the product of systemic neglect.The minister replied that they were fully aware that in long-term care facilities both seniors and persons living with a disability face unique challenges. And considering the severity of this report, the federal government promptly shared it with the Province of Ontario, and the Province of Ontario has initiated an investigation based on the report's findings.", "The meeting basically discussed the crisis across Canada amidst the pandemic. The opposition party questioned the ministers for responding late to the situation, and the financial support was not given to those who were really in need. The ministers promised that they were trying to reach out to as many companies as possible and the opposition party was not very satisfied with the answer. Canada's economy was heavily stricken by the pandemic and the opposition party was prompting the ministers to roll out several measures. Last but not least, they stressed on the long-term care issue, and the ministers promised that they were paying attention to it."], "input": "The Chair (Hon. Anthony Rota (NipissingTimiskaming, Lib.)): I call this meeting to order. Welcome to the 12th meeting of the House of Commons Special Committee on the COVID-19 Pandemic. This will be the first hybrid meeting of the committee. Some members will be participating via videoconference and some will be participating in person. This follows the order made by the House on May26,2020. Members who have already participated in a virtual meeting of the special committee may actually not notice any change, except for the fact that some members are also participating from the floor of the House. An additional rubric, that of statements by members, was also added to the proceedings of the committee. In order to ensure that those joining the meeting via video conference can be seen and heard by those in the chamber, two screens have been set up in the chamber on either side of the Speakers chair. Sound amplification for virtual interventions will be available, and members in the chamber can listen to the floor sound or interpretation using the earpieces on their desks. Before speaking, please wait until I recognize you by name. Please also direct your remarks through the Chair. Thank you. For those of you joining via video conference, I would like to remind you to leave your mike on mute when you are not speaking. Also, please note that if you want to speak in English, you should be on the English channel. If you want to speak French, you should be on the French channel. Should you wish to alternate between the two languages, you should change the channel to the language that you are speaking each time you switch languages. Should members participating by videoconference need to request the floor outside their designated speaking times, they should activate their microphone and state that they have a point of order. Those in the chamber can simply rise in the usual way. Please note that today's proceedings will be televised in the same way as a typical sitting of the House. Next we'll move on to ministerial announcements. I understand that there are no ministerial announcements today, so we'll move on to petitions. We'll be presenting petitions for a period not exceeding 15 minutes. I would like to remind members that any petition presented during a meeting of the special committee must have already been certified by the clerk of petitions. For members participating in person, we ask that they please come and drop the signed certificates off at the table once the petitions are presented. First on our list for presenting petitions is Ms. May, who is joining us virtually.\nMs. Elizabeth May (SaanichGulf Islands, GP): Mr. Chair, what an honour to be the first voice coming to you from the screens on either side of the Speaker of the House. I speak to you from SaanichGulf Islands on the traditional territory of the WSNEC people. Hych'ka Siem. I'm presenting a petition, number 431-00215, and it has been certified. The petitioners call on this House to take note of the fact that Canada is the only country with a universal health care system that does not include the provision of necessary prescription medications. They note that the system across Canada is a patchwork that leaves three million Canadians unprepared and uninsured to be able to purchase necessary medications. They call on the House assembled to put in place a system of universal national pharmacare, bringing down the cost of drugs through bulk purchasing. I think I'll call that a summary, Mr. Chair. Thank you very much.\nThe Chair: The next petition will be presented by Mr. Genuis.\nMr. Garnett Genuis (Sherwood ParkFort Saskatchewan, CPC): Thank you very much, Mr. Chair. I'm pleased to be presenting two petitions before the committee today. The first petition is in support of Bill S-204. This Senate public bill, been put forward by Senator Salma Ataullahjan in the Senate, would make it a criminal offence for someone to go abroad to receive an organ for which there has not been consent. It also has a mechanism by which somebody could be deemed inadmissible to Canada for being involved in the horrible practice of forced organ harvesting and trafficking. This bill has been before various Parliaments for over 10 years, and petitioners are hopeful that this Parliament will be the one that finally takes action to address forced organ harvesting and trafficking. The second petition is put forward by folks who are concerned about Bill C-7, particularly the efforts by the government through Bill C-7 to remove vital safeguards that are currently associated with Canada's euthanasia regime. Petitioners are not happy about the fact that the government is trying to eliminate the 10-day reflection period and remove other safeguards that only four short years ago the government thought were essential for the euthanasia and assisted suicide system that they were putting in place. The petitioners call on the government to address that, and they are not supportive of these particular efforts to remove vital safeguards from that regime. Thank you very much.\nThe Chair: Is anyone else presenting petitions? Seeing none, we'll move on to statements by members. We will now proceed to Statements by Members for a period not exceeding 15minutes. Each statement will be for one minute. The first will be from Mr.Samson. Mr.Samson, you have the floor.\nMr. Darrell Samson (SackvillePrestonChezzetcook, Lib.): Good afternoon, everyone. It's an honour to be presenting an S. O. 31. This spring has been a difficult one for Nova Scotia and the communities of SackvillePrestonChezzetcook. While residents have banded together to tackle the challenges presented by COVID-19, we have also had to mourn the passing of three remarkable local women: RCMP Constable Heidi Stevenson, well known by many in Cole Harbour and the surrounding areas; our own Sub-Lieutenant Abbigail Cowbrough, who was based out of 12 Wing Shearwater; and Captain Jenn Casey of the Canadian Forces Snowbirds. All three women died in the line of duty in separate tragic events while serving our country. These three brave women, who served with honour on land, at sea and in the air, represent the absolute best of us. Heidi, Abbigail and Jenn were inspirational and will not be forgotten. Thank you.\nThe Chair: Next we'll go to Mr. Bezan.\nMr. James Bezan (SelkirkInterlakeEastman, CPC): Thank you, Mr. Chair. Canada needs a prime minister who will create jobs and opportunity, but instead we have a prime minister who is piling up crippling national debt. Yesterday the PBO predicted the federal deficit this year will hit over $252 billion. That is almost equivalent to an average year of government spending before the Liberal government. After five years with this debt, Prime Minister, Canada's national debt is set to hit $1 trillion, with almost nothing to show for it. Industries from coast to coast are either closed or are struggling. Canadian workers need and deserve a prime minister who supports our energy sector and gets our natural resources and agriculture products to market, who supports small business and will make our tax system encourage job creation and growth, and who will bring advanced manufacturing jobs to Canada and keep the automotive industry growing. Most importantly, we need a Conservative prime minister who will get the government finances under control after the massive debt left by this prime minister.\nThe Chair: Next we'll go to Mr. Anandasangaree.\nMr. Gary Anandasangaree (ScarboroughRouge Park, Lib.): Mr. Chair, I speak today with a very heavy heart. Since the COVID-19 outbreak, we've seen a disproportionate number of deaths in long-term care homes. I'm thankful for the Canadian Armed Forces who were deployed to the Altamont care home in my riding and four other facilities across the GTA. The CAF have brought forward horrifying allegations in the operation of these homes. They include residents being given expired or improper doses of medication; not being cleaned or changed for a prolonged period of time; being forcibly fed, causing choking; being bed-bound for weeks; receiving inadequate nutrition, and much more. Mr. Chair, I call upon Premier Ford to place these five homes under a mandatory management order and to appoint a third party manager to address and rectify these violations. I also call upon the Premier to undertake an independent public inquiry into the tragedy we face in long-term care facilities across Ontario. Finally, Mr. Chair, we need to work with the provinces and territories to set national standards of care for the most vulnerable in our society. We can and must do better. Thank you, Mr. Chair.\nThe Chair: We have a point of order. Go ahead, Ms. May.\nMs. Elizabeth May: Thank you, Mr. Chair. I hesitate to interrupt colleagues, but I'm concerned about the petition practice, which, as I understand it, is to summarize a petition but not make a speech. I felt one of our colleagues was trespassing on our usual rules.\nThe Chair: I will remind honourable members that when a petition is presented, we're expected to give a prcis and make it as concise as possible. Thank you. Mr.Champoux, you have the floor.\nMr. Martin Champoux (Drummond, BQ): Mr.Chair, I would like to recognize the resilience of Quebeckers concerned for their jobs or their businesses during the COVID-19 crisis. They need us to plan for after the crisis, and we must do so now. To do so, we need the proper information. We need to know the status of the public finances. That is why the Bloc Qubcois is demanding that the government present an economic update, and that it do so before June17. This is not about making a spectacle. Everyone knows that the deficit will be huge. We had to provide the people with support and we all agree on that. But we have to know to what extent. We also have to know where we are starting from so that we can plan where we are going. This is about respecting the public, because they are the ones who will be paying the bill. In closing, I would like to remind the government that one group is not really contributing to the public purse at the moment. I am talking about the tech giants, the GAFAM group, that have never before been used to the extent that they are now, and that are still not paying a cent in tax in Canada. The Liberals promised to correct this injustice. Now is a great time for them to do so.\nThe Chair: We'll now go to Ms. Sidhu.\nMs. Sonia Sidhu (Brampton South, Lib.): Mr. Chair, this week is National Paramedic Services Week. I want to take this opportunity to thank the Peel region police, paramedic and firefighting services for keeping Bramptonians safe. In my riding, organizations have stepped up to help our community. Organizations such as the Khalsa Aid Society, the Interfaith Council of Peel, the Brampton YMCA, the Prayer Stone Peoples Church, Unity in the Community, Ste. Louise Outreach Centre, Knights Table, the Yogi Divine Society, Vraj Community Service, Regeneration Brampton and many more have made our community stronger during this difficult time. I also have to address the report that came out yesterday from our brave Canadian Armed Forces. Like many Canadians, I was shocked by this report from the long-term care centres, including one in my riding. The examples of abuse described in the report are unacceptable. Our seniors deserve dignity and respect. We must find a solution. We need to fix this.\nThe Chair: We'll now go to Mrs. Stubbs.\nMrs. Shannon Stubbs (Lakeland, CPC): Mr. Chair, Canada's oil and gas sector is in crisis, made worse by five years of bad policies, red tape and barriers to pipelines. Just in the last two months, we saw the largest production cut in Canadian history. Active rigs dropped by 92% and tens of thousands of oil and gas workers lost their jobs, adding to the 200,000 since 2015. Energy is Canada's biggest investor, and exporting could lead the recovery if there are actions, not just words. On March 25, the finance minister promised help in hours or days, not weeks, but he's letting Canadians down. Sixty-three days later, small oil and gas companies still can't apply for BDC loans, and last week's large employer loan terms are predatory, with interest rates escalating to 14% by year five. Those are payday loan rates. The required stock options being at record lows could make the government the largest shareholder. That's not emergency assistance; it's pandemic profiteering. Programs can't help workers if businesses can't or won't actually get the support. The Liberals' death-by-delay tactics are doing exactly what foreign activists in other countries want: to shut down Canada's oil.\nThe Chair: Ms.Bessette, the floor is yours.\nMrs. Lyne Bessette (BromeMissisquoi, Lib.): Mr.Chair, in times of crisis, we stick together. I can state that this is certainly the case in BromeMissisquoi. In the last weeks, I have been calling volunteer action centres in my constituency so that they can tell me their news. I would like to take the time that I have to highlight the work that community organizations are doing tirelessly in my constituency. The crisis has made us realize the extent to which food banks and meals-on-wheels can not only relieve hunger, but also relieve thousands of shut-in seniors of their loneliness. Let me also highlight the devotion of the volunteers giving generously of their time, particularly the initiative of Mabel Hastings in the volunteer aid centre in Mansonville. Like me, she sends out a daily newsletter to keep the public informed about the many resources available for their support. COVID-19 is bringing out the best in our community and I am certain that, together, we will get through it.\nThe Chair: We will go to Mr. Virani.\nMr. Arif Virani (ParkdaleHigh Park, Lib.): Mr. Chair, during the COVID-19 pandemic I have been inspired by the courageous work of so many essential workers. I want to thank everyone on the front lines for keeping us safe, keeping us fed and keeping our communities functioning. I want to make special note of one particular essential health care worker, a woman who is a quarantine manager with the Public Health Agency of Canada. I have personally seen her working tirelessly over the past three months to keep all of us safe. That woman is my wife, Suchita Jain. Suchi, I love you, I am very proud of you and I thank you for all of the sacrifices you are making. I want to highlight another woman from my riding of ParkdaleHigh Park, Rachelle LeBlanc. She is a local designer. When the pandemic broke, she saw the need for protective barriers for small shops in Parkdale, so she set about collecting donations. She then put her design talents to work and started designing free-standing protective shields. Rachelle's team has now delivered 25 free COVID protective shields to small shopkeepers in Parkdale, and the team is on track to building 100 more. It's the compassion of Canadians like Rachelle that gives meaning to the phrase we are all in this together.\nThe Chair: Mr.Godin, you have the floor.\nMr. Jol Godin (PortneufJacques-Cartier, CPC): Mr.Chair, the school year has been shattered and our graduating classes must be proud of what they have achieved amid the COVID-19 pandemic. Young men, young women, be proud of your accomplishments! You can believe in the future. Keep learning. It will give you tools that will serve you all your lives. What you have achieved in this extraordinary year will set you apart from the others. I invite you to be inspired by that and turn it to your advantage. The current government has the obligation to promote the values that will lead you to become involved in your communities. Your willingness to learn or to work makes you into better citizens. Knowledge and experience are irreplaceable and invaluable. I implore this government, which is unaware of the damage it is causing, to immediately announce all the positions that have already been approved under the Canada summer jobs program. Urgent action is needed. Let us have confidence in our organizations, our companies, and let us support our youth, a rich resource that we must equip and motivate. I congratulate all the young graduates in the beautiful constituency of PortneufJacques-Cartier.\nThe Chair: We will now go to Mr. Fergus.\nMr. Greg Fergus (HullAylmer, Lib.): Mr.Chair, this pandemic lets us see what Canadians are made of. This coming Saturday, May30, more than 2,000Christians of all denominations are coming together virtually for prayer and for action. When the going gets tough, Canadians get going. This could not be more true than with respect to what will be happening on May 30. This Saturday, in more than 2,000 churches and homes, thousands of faith-filled Canadians are gathering to pray and act on those prayers as part of Stand United Canada. They will gather through television, Facebook Live and Instagram Live. Then they are going to deliver much-needed support to at-risk Canadians who live in disadvantaged areas. This is faith in action. I'm sure I speak for all parliamentarians when I wish success to Stand United Canada. I hope it inspires more Canadians to follow in its footsteps. Thank you, Mr. Chair.\nThe Chair: We will now go to Ms. Harder.\nMs. Rachael Harder (Lethbridge, CPC): The best way to safeguard the truth is to allow people to speak freely, but from the very beginning of this pandemic, the Liberals have silenced dissent. Sadly, their short-sightedness has been to the detriment of Canadians. Early on, they propagated the notion that human-to-human transmission wasn't possible. They said that closing the borders wasn't necessary. They told us that wearing face masks wouldn't help. It is undeniable that the Liberal government has put Canadians in danger by silencing alternative points of view and has spread misinformation. Ironically, however, they have now gone ahead and crowned themselves the arbiters of truth. They are spending millions of dollars to censor what Canadians can and cannot say. They are determining what is true and what is not, what is right and what is wrong, what is in and what is out. When freedom of speech is repressed, it is safe to say that democracy is under siege. I call upon the government to restore the personal liberties that are granted under our Canadian Charter of Rights and Freedoms. This is Canada. We are not an autocracy; we are a democracy.\nThe Chair: We will now go to Mr. Nater.\nMr. John Nater (PerthWellington, CPC): Mr. Chair, small businesses have always been the cornerstone of communities across this country. They provide employment and economic stability and are always the first to support community functions and activities, but small businesses have been particularly hard hit due to COVID-19. They have shut their doors temporarily, and now many worry they'll never be able to open their doors again. With the season cancellations at the Stratford Festival, Drayton Entertainment and Stratford Summer Music, businesses in the tourism, hospitality, accommodation and retail sectors in PerthWellington are struggling. Every day, I talk to small business owners who can't access the Canada emergency business account, and others who find the convoluted commercial rent assistance program to be out of reach. The program is needlessly complicated, frustratingly slow and excessively restrictive. Mr. Chair, the government needs to go back, fix these programs and ensure that support goes to the small businesses that need it.\nThe Chair: We will now go to Ms. Collins.\nMs. Laurel Collins (Victoria, NDP): Mr. Chair, Canadians have been shaken by this pandemic. It has exposed the gaps in our health care system and our social safety net. It has shown how vulnerable we all are when disaster hits. It has brought us to a crossroads. We can go backwards to so-called business as usual, with horrific conditions in long-term care homes, widespread inequality and no real action on climate change, or we can build for better. In Victoria, people in the community, organizations and municipal leaders have been calling for a new way forward. The City of Victoria has a plan for reinvention, resilience and recovery. Organizations like Greater Victoria Acting Together; Common Vision, Common Action; and Kairos Victoria are exploring ideas for a sustainable and just recovery. We can build for better. We can invest in the infrastructure. We need to fight climate change, homelessness and inequality. We can build a Canada where we take better care of the planet and each other.\nThe Chair: We now move to Ms.DeBellefeuille.\nMrs. Claude DeBellefeuille (SalaberrySurot, BQ): Mr.Chair, in this time of pandemic, it is with heartfelt emotion that I want to highlight the excellent work of all the guardian angels at the CISSS de la Montrgie-Ouest. From the bottom of my heart, I want to thank the entire staff, as well as the retirees who have come back to provide their assistance. I admire the managers, at all levels and in all services, working tirelessly so that their teams can answer the call in this difficult situation. My fellow managers and the management teams of the Support Program for the Autonomy of Seniors, both in home support and in residential care, you have my heartfelt congratulations for the herculean work you have done. My thoughts go particularly to Lyne Ricard and Vronique Proulx, managers working diligently with their teams of professionals to support the seniors living in intermediate resources, as we call them. I also warmly recognize the director of nursing services, Chantal Careau, who is facing the current challenge with passion and humanity. Once again, my congratulations go to the entire organization of the CISSS de la Montrgie-Ouest for their remarkable work in this difficult and very demanding time.\nThe Chair: We will go to Mr. Barlow.\nMr. John Barlow (Foothills, CPC): During the worst of times, we see the best in people. Heroes are born, characters revealed, resiliency is sowed. I cannot say enough about my constituents in Foothillsfront-line health care workers, grocery store clerks, restaurateurs, farmersfor all they are doing to keep our community safe and healthy. I want to shine a light on some of our hidden heroes, such as Owen Plumb, a grade 9 student in Okotoks who is using his 3D printer to build PPE for front-line health care workers. He partnered with the Rotary Club and Evergreen Solutions in Okotoks to help with the manufacturing and assembly. There is also Sam Schofield, the volunteer president of the Pincher Creek Chamber of Commerce, overnight built a resiliency website for COVID-19 by building training tools for businesses throughout his area. He also helped develop the Foothills Business Recovery Taskforce, which is a resource for businesses throughout southern Alberta in my riding. Finally, to the employees of Cargill Foods in High River, I know this has been a very difficult time and that many of you have lost loved ones. I want to say thank you for tirelessly doing all you can to protect our food supply and keep food on our table. Each and every one of you is a hero. Thank you.  Some hon. members: Hear, hear!\nThe Chair: We will now go to Mr. Simms.\nMr. Scott Simms (Coast of BaysCentralNotre Dame, Lib.): Thank you, Chair. I would like to take this time to salute those who go above and beyond the call of duty to provide care and comfort to others. In my 16 years in the House of Commons I have never experienced anything like this, when we find our lives are at a standstill and there is so much sorrow felt by families who suffer from the effects of COVID-19. However, here are two examples of kindness right here in Newfoundland and Labrador. Shanna and Fred Patey of Bishop's Falls, along with a few of their friends, spend hours next to the Trans-Canada Highway with just a barbeque and a cooler. They serve free meals for truckers crossing our province each and every day. So far they have provided over 1,500 meals. There is also Mitch Strickland of Grand Falls-Windsor, who owns Appy's Diner. He has continually provided food for the local hospital and other front-line workers through his donations. To all our front-line workers in grocery stores and delivery trucks, and to doctors, nurses, LPNs, paramedics, first responders and, of course, our brave women and men in the military, we will be forever grateful and blessed because of you. Thank you.  Some hon. members: Hear, hear!\nThe Chair: That's all the time we have today for Statements by Members. Before going on, I just want to remind all the members that it is a one-minute statement, so if you don't mind, please time it before coming in because we do have limited time. The other thing that has come up is that some of you just naturally speak very quickly. I'm not here to judge anybody's way of speaking, but try to consider the translators and interpreters to make sure that everyone understands what is said, because they are working diligently to try to get both languages out. In sum, there are two things: please slow down and please make sure the statement is confined to one minute. We now move to Questions to Ministers. Please note that we will suspend the proceedings every 45minutes in order to allow the employees who are providing support for the sitting to substitute for each other safely.  Our first question goes to the Leader of the Opposition, Mr. Scheer.\nHon. Andrew Scheer (Leader of the Opposition): Thank you very much, Mr. Chair. In the early days of the pandemic and the lockdown that followed, Canadians were told by this government that programs would be rolled out very quickly and that gaps and shortcomings would be changed as time went on. While many Canadians are being let down by this government's response and its unnecessarily rigid programs, Conservatives identified solutions weeks ago, yet here we are, two and a half months later, and many of these programs still have not been improved. I have a simple question for the Prime Minister. On April 26 the Conservatives asked the Prime Minister to change the criteria for the Canada emergency business account so that small businesses that don't happen to have a business bank account could qualify for those types of programs. It's now May 27. Is the Prime Minister going to make that change?\nRight Hon. Justin Trudeau (Prime Minister): Mr. Chair, we knew from the beginning of this pandemic that we did need to move extremely quickly, and that's what we did. We rolled out the Canada emergency response benefit extremely quickly. Eight million Canadians have had that as a replacement for paycheques lost because of COVID-19. We also moved forward on the wage subsidy and a range of other programs to support workers and small businesses. What we've done in terms of helping small businesses with the Canada emergency business account has had a massive impact on small businesses across the country, but we understand that certain companies and businesses have particularities that mean it's a little more difficult for them to qualify. We are working with them through their regional development agencies, and we encourage them to approach their local RDAs, which will be able to help them get the money they deserve.\nHon. Andrew Scheer: Mr. Chair, these are very simple technical fixes that can be made by this government. There's no excuse for the delay. It's May 27. They've known about these problems for weeks. They're trying to get patted on the back for actions they took back in March, and yet they are letting so many Canadians down by not making these very simple changes. For example, companies that have acquired another company in the last year have employees whose jobs are threatened. The businesses are not allowed to qualify for the wage subsidy because their revenue is now counted together. We have identified this gap. Again, it's a simple question. Will companies that have acquired another company still be allowed to use the wage subsidy to keep workers on the job, yes or no?\nRight Hon. Justin Trudeau: Mr. Chair, I know that there are many different types of businesses across this country that need support. We have moved forward on supporting as many of them as we possibly can, and we continue to work on filling gaps. I know the member opposite has talked to me a number of times about a tractor company in his riding. I can assure you that finance officials are engaged with that company to see if there's a way to make sure we're getting them the support they need.\nHon. Andrew Scheer: It's actually a very simple fix. I can save him and his officials a lot of time. The government used the word amalgamation when it announced the changes to that program. He can make this very clear, and save a lot of work, just by including the word acquisition. Will he do that?\nRight Hon. Justin Trudeau: Mr. Chair, I can assure you that finance officials are working closely with Brandt Tractor. They're continuing to work with a range of businesses across the country that, for various reasons, are not able to apply for the help we have now. We will continue to work to make sure people who need the help get it.\nHon. Andrew Scheer: Mr. Chair, it's literally one word. We can email him the text. We can send him the page in the dictionary where that word is defined, if that would help. Another gap that is letting people down is in the rent relief program. The government has set the parameters to qualify for the rent relief program for companies that have experienced a 70% revenue loss. There are untold thousands of businesses that have experienced a 50%, 55%, 60% or 65% loss that are ineligible but have no capacity to pay the rent. We called on the government weeks ago to have a more flexible sliding scale to allow more companies to access this program to keep more people on the job and more businesses open. Will the government introduce some flexibility to this program to help more businesses survive?\nRight Hon. Justin Trudeau: Mr. Chair, from the beginning of this pandemic, our public servants and policy-makers have been moving creatively and quickly to try to get help to as many people as we possibly can, with our focus being on the people who need it the most. Obviously, this pandemic is affecting everyone and every business across the country in different ways, but our focus has been on ensuring that those who most need it are getting the help they can. We will, of course, continue to work with the parties opposite and all Canadians to ensure that we're getting help to everyone who needs it, but our focus has always been on the most vulnerable, first and foremost.\nThe Chair: The floor now goes to Mr.Blanchet.\nMr. Yves-Franois Blanchet (BeloeilChambly, BQ): Thank you, Mr.Chair. My question is for the Prime Minister. If the Liberal Party of Canada had not taken advantage of the emergency programs, would it have laid off all its staff?\nRight Hon. Justin Trudeau: Mr.Chair, we recognized that a number of organizations and companies were facing difficulties because of COVID-19. People work for those organizations, as accountants, receptionists, assistants or labourers, and those people need to be supported. We are supporting people all over the country through that program.\nMr. Yves-Franois Blanchet: Is the Liberal Party one of those organizations in difficulty?\nRight Hon. Justin Trudeau: Any company or organization that can demonstrate a significant drop in its income, whether that be in donations, receipts, profits\nThe Chair: The floor goes to Mr.Blanchet.\nMr. Yves-Franois Blanchet: Is the Liberal Party of Canada in difficulty, as an organization?\nRight Hon. Justin Trudeau: Mr.Chair, we created specific criteria to help organizations in difficulty. Any organization experiencing those difficulties can apply.\nMr. Yves-Franois Blanchet: In the Magdalen Islands, fishing companies in difficulty and in need of assistance will not have the money that the Liberals are going to take. Is the Liberal Party of Canada in difficulty, as an organization?\nRight Hon. Justin Trudeau: Mr.Chair, we have invested in assistance for fishers all across the country. We recognize that it is a difficult situation because of COVID-19. We will be here for our fishers and for industries in difficulty.\nMr. Yves-Franois Blanchet: I am not catching many answers, it seems to me. A company in Drummondville that manufactures isolation membranes is in difficulty because a federal program is inadequate. Compared to that company, is the Liberal Party of Canada in difficulty, as an organization?\nRight Hon. Justin Trudeau: Mr.Chair, there are clear criteria for submitting applications under these programs. Companies and organizations that receive money qualify for those programs.\nMr. Yves-Franois Blanchet: If the program criteria establish that the Liberal Party is an organization in difficulty, does that mean that the criteria to determine whether an organization is in difficulty are poorly designed?\nRight Hon. Justin Trudeau: Mr.Chair, all through this pandemic, our priority has been to be here for workers in difficulty so that they do not lose their jobs. This applies to all organizations and companies in the country to the extent possible. That is what we are in the process of doing.\nMr. Yves-Franois Blanchet: Given the answers from the Prime Minister, let me ask this question: is the Prime Minister in difficulty?\nRight Hon. Justin Trudeau: No, Mr.Chair. We are doing important work for all Canadians, every day.\nMr. Yves-Franois Blanchet: Restaurant owners on rue Ontario in Montreal feel that they will not make it through the crisis and that they will never open their doors again. They are in difficulty. By comparison, is the Liberal Party of Canada an organization in difficulty that will not open its doors again after the crisis? We can but hope.\nRight Hon. Justin Trudeau: Mr.Chair, we established criteria for that program in order to help those working for various organizations. Any organization that receives the subsidy has qualified for it.\nMr. Yves-Franois Blanchet: Is there a consensus in the Liberal Party caucus that the Liberal Party is in difficulty as an organization?\nRight Hon. Justin Trudeau: Mr.Chair, we are working every day to help Canadians and workers in difficulty. We are going to continue to do that work.\nMr. Yves-Franois Blanchet: Does answering a question put the Prime Minister in difficulty?\nRight Hon. Justin Trudeau: Mr.Chair, it is a pleasure to be here in the House and to answer questions from Canadians and from members of the opposition.\nMr. Yves-Franois Blanchet: You are going to answer a question from a Quebecker, I hope. Companies are struggling in Saguenay, in the Gasp, in Beloeil. Would those companies not deserve to be saved by the money that the supposedly struggling Liberal Party has taken?\nRight Hon. Justin Trudeau: I am always very happy to answer questions from all Canadians currently sitting in the House. We will be here to help workers in difficulty all across the country, including in Quebec.\nMr. Yves-Franois Blanchet: If the Prime Minister is so happy to answer questions, I hope he will be delirious with joy to answer this one. Is the Liberal Party in difficulty?\nRight Hon. Justin Trudeau: Mr.Chair, we established a program to help those working in organizations and who could lose their jobs because of COVID-19. We are here to help workers in organizations and companies all over the country.\nThe Chair: We'll now go on to Mr. Singh.\nMr. Jagmeet Singh (Burnaby South, NDP): Thank you very much, Mr. Chair. The conditions of seniors as outlined by the military were appalling, but seniors need more than just compassionate words. They need action. Will the Prime Minister stop hiding behind excuses and actually show leadership to fix long-term care?\nRight Hon. Justin Trudeau: Mr. Chair, the Constitution of Canada is not an excuse. It lays out the divisions of powers and responsibilities, and we respect the provinces' jurisdiction over long-term care facilities. However, from the very beginning, we have indicated our willingness to support the provinces on this very important issue. We need to make sure our seniors right across the country are properly cared for, which is why we sent in the military and why we are there to help the provinces.\nMr. Jagmeet Singh: The former federal health minister, Dr. Philpott, said, We need to stop using jurisdiction as an excuse to not have federal leadership. That is a former federal health minister. Now, we know from the military report that staff were afraid to use vital equipment because of the cost. Will the Prime Minister call for an end to profit in long-term care?\nRight Hon. Justin Trudeau: Mr. Chair, over the past couple of days I've had very good conversations with the premiers of both Quebec and Ontario on this important issue. I look forward to discussing issues around long-term care with all the premiers of the provinces and territories tomorrow evening as well. This is something that Canadians have seen needs concerted action. We will be there to support the provinces.\nMr. Jagmeet Singh: Needles were reused and expired medication was used, according to military reports. Will the Prime Minister call for an end to profit in the care of our seniors?\nRight Hon. Justin Trudeau: Mr. Chair, the contents of that report were deeply disturbing and troubling for all Canadians. That is why we are committed to working with the provinces to fix this situation. Ontarians and indeed people right across the country are deeply preoccupied by what they've seen going on. We need to fix this, and we will do that together.\nMr. Jagmeet Singh: The military report found that cockroaches and flies were present and that food was rotten. Will the Prime Minister call for national standards so that long-term care is governed by the same principles as the Canada Health Act?\nRight Hon. Justin Trudeau: Mr. Chair, our priority right now is ensuring that we are supporting the provinces in their need to make sure that all seniors are protected right across the country in all those institutions. Going forward, we absolutely will need to have more conversations about how we can ensure that every senior across the country is properly supported.\nMr. Jagmeet Singh: The military report found that respecting the dignity of patients was not a priority. Will the Prime Minister call for national standards and for long-term care to be governed by the same principles as the Canada Health Act?\nRight Hon. Justin Trudeau: Mr. Chair, all Canadians know we need to do better by our seniors. This is something we all take very seriously, and all orders of government will work together to make sure that right now, and going forward, we improve our systems. The federal government will be there to work with the provinces on making that happen.\nMr. Jagmeet Singh: Mr. Chair, the Prime Minister has said that he's willing to work with the provinces. I'm saying that we need to see federal leadership. We need a commitment at the federal level that the Prime Minister will push for things that people need, which is to remove profit from long-term care and to establish national standards. Will the Prime Minister go beyond working with provinces and show some leadership?\nRight Hon. Justin Trudeau: Mr.Chair, I will always be here to stand up for Canadians in all different situations. We are going to work with the provinces, fully respecting jurisdictions, to make sure that, all across the country, Canadians in long-term care are supported as required and receive the services and the care they deserve.\nThe Chair: Mr. Singh, we have 30 seconds. Ask a brief question, please.\nMr. Jagmeet Singh: Thank you very much. The COVID-19 crisis should not be used as an excuse to avoid presenting solutions to the missing and murdered indigenous women and girls committee, in particular by delaying action on the calls for justice. This is the same government that would not recognize it as a genocide, the same government that delayed the United Nations declaration legislation and the same government that is still taking indigenous kids to court. Will this government commit to core funding for indigenous services to help women and girls and ensure that the calls for justice are implemented without delay?\nRight Hon. Justin Trudeau: Mr. Chair, we continue to work very closely with partners on the calls for justice even as we act in many areas, including better funding for shelters and for victims of domestic violence. We will continue to work with those partners, but people will understand that many of those partners are very focused right now on helping front-line workers, not on establishing the report. We will continue to work with them on the report, but the COVID-19 situation has made that more difficult.\nThe Chair: I want to thank the honourable members who are shouting time, but I do have a timer here, and I am taking care of it. I appreciate the help, but I do want to remind them that I have the proper machinery here. We will now go to Mr. Bezan.\nMr. James Bezan: Thank you, Chair. My question is to the Prime Minister. He was just talking about the tragic conditions in long-term care facilities in Ontario, and there was a report out from Quebec today. I want to commend the Canadian Armed Forces for witnessing these appalling conditions, putting it in the context of a report, and providing care to our loved ones in these long-term care facilities. The government is saying they didn't receive the report from the department until May 22, but this report came out on May 14. What happened to that report for eight days?\nThe Chair: We will go to the honourable minister. We seem to have a technical issue, Mr. Sajjan. We can't hear you. You might want to put down your bar and keep it down while you're speaking.\nHon. Harjit S. Sajjan (Minister of National Defence): Mr. Chair, I want to thank our Canadian Armed Forces members for the tremendous work they are doing. They did their duty, noted down their observations and reported them. While those observations were being reported directly to the managers, a report was being compiled. This report was given to me on the 21st. I then forwarded it to the Minister of Public Safety on the 22nd, and that report was then given to the provincial authorities very quickly afterwards.\nMr. James Bezan: I trust that you got the report on the 21st, but the report was written on the 14th, so what happened with that report for seven days? Why wasn't it acted upon? Could you just explain that? Our loved ones were at risk during that entire time.\nHon. Harjit S. Sajjan: Mr. Chair, as we stated, this report was done and given up through the chain of command, and the appropriate leadership did their due diligence. Once we received this report, it was forwarded to the appropriate authorities. Again, I want to commend our Canadian Armed Forces members for not only the tremendous work they are doing but also for doing their duty.\nMr. James Bezan: That report from Ontario documented appalling conditions, horrific care that was being given to the clients, and also the way that the staff conducted themselves. We know that there are 39 members of the Canadian Armed Forces currently infected with COVID-19. Minister, do you believe that the infection could have been transmitted from staff to our soldiers serving in long-term care facilities because proper protocols were not being followed?\nHon. Harjit S. Sajjan: Mr. Chair, when it comes to any type of activities that we send our Canadian Armed Forces on, we do our due diligence to make sure that we have the right protocols in place and the appropriate training. This is why we have taken the time to make sure our folks not only did the appropriate training but had the appropriate equipment. We have the right protocols in place, and we will make sure that our members who are infected by COVID will get the appropriate treatment as well.\nMr. James Bezan: Does the Minister of National Defence believe that our soldiers serving in Operation Laser, who have put themselves in harm's way in battling the COVID virus as a war, deserve to have hazard pay benefits?\nHon. Harjit S. Sajjan: Mr. Chair, when it comes to looking after Canadian Armed Forces personnel, yes, we are actually in the process as we speak of making sure that our members have the appropriate hazard pay. This is currently being drafted, and we will have more to say on this shortly.\nMr. James Bezan: I hope that means it's a yes. I do encourage the government to provide that compensation to our soldiers and troops serving in Operation Laser. I would finally like to come back to the issue of the timeline from May 14 to May 21, when that report was in the department for one week. Under our parliamentary system, ministers are accountable for the conduct of their departments. Will the minister take responsibility for that report sitting on someone's desk for seven days and not being turned over to the proper authorities?\nHon. Harjit S. Sajjan: Mr. Chair, I want to make it very clear: When it comes to the observations that were made, those were immediately reported to the appropriate management of the care facilities and to the appropriate links within the province. At the same time, this report was being compiled and pushed up to the chain of command, and they did their due diligence. As I stated, it was given to us, and on the same day it was forwarded to the Minister of Public Safety, who immediately then sent it to the provincial authorities.\nMr. James Bezan: Was one of those authorities that this was sent to the RCMP?\nHon. Harjit S. Sajjan: Mr. Chair, as stated, this will not only be given to the proper authorities but the appropriate steps will be taken now.\nThe Chair: We'll now go to Ms. Falk. Ms. Falk.\nMrs. Rosemarie Falk (BattlefordsLloydminster, CPC): Thank you, Chair. Yesterday it was revealed that the Minister of Digital Government has been promoting a fundraising campaign to sue Global News for their story criticizing the Chinese Communist Party. Why is the minister using her authority to support the Communist Party of China and threatening our media and freedom of expression?\nHon. Joyce Murray (Minister of Digital Government): Mr. Chair, we value the important work of media right across the country. Attacking the integrity of hard-working journalists is simply not acceptable. Like many members on all sides of the House.... WeChat is a social media platform used to engage and share information with\nThe Chair: Now we'll go back to Ms. Falk. Ms. Falk.\nMrs. Rosemarie Falk: Is the minister aware of the efforts that the United Front carries out on behalf of the Chinese Communist Party to influence how Canadians view the People's Republic of China?\nHon. Joyce Murray: Thank you for that question. Mr. Chair, I want to just be clear. The participation in the WeChat group, much like Facebook, is guided by posted\nThe Chair: We'll now go back to Ms. Falk.\nMrs. Rosemarie Falk: Is the minister an active participant in the efforts by the Communists to muzzle a Canadian journalist and deprive Canadians of the facts about China?\nHon. Joyce Murray: Muzzling journalists is never acceptable, and our government is very clear on that. I will say that the individual in question posted something outside of the guidelines of my WeChat group and is no longer\nThe Chair: We'll now go back to Ms. Falk. Ms. Falk, I just want to point out that we do have interpreters listening and trying to interpret. They'd appreciate it....\nMrs. Rosemarie Falk: My questions are short. That's probably what it is.\nThe Chair: Take a deep breath.\nMrs. Rosemarie Falk: Chair, the Liberals can't shrug this off. The minister admitted to theBreaker that her own political staff manages this WeChat. This is someone who is paid by Canadian taxpayers. Why is the minister using tax dollars to help China attack Global News and freedom of expression?\nHon. Joyce Murray: I think the member knows very well that the people who post on WeChat are free to post what they choose within certain guidelines. Those guidelines were ignored. That person is no longer part of my WeChat group. The post was completely unacceptable, and I do not share the views of the individual.\nMrs. Rosemarie Falk: Chair, Sam Cooper is an investigative Canadian journalist who has uncovered many different criminal rackets that can be linked back to Beijing. Has the minister apologized to Sam Cooper for attempting to shut down his work?\nHon. Joyce Murray: As we all know, community outreach is a very important part of the work of a member of Parliament. WeChat is one of many social media sites regularly used by members\nThe Chair: We go back to Ms. Falk.\nMrs. Rosemarie Falk: Chair, when will the minister apologize to Sam Cooper and Global News?\nHon. Joyce Murray: Mr. Chair, I have been very clear that I do not share the views of the person who posted on my WeChat site, who operated outside of my\nThe Chair: We'll now go back to Ms. Falk.\nMrs. Rosemarie Falk: Chair, in December 2018 the Liberals passed Bill C-76. This included provisions to prevent foreign interference in Canadian society. Does the government believe that Joyce Murray's actions have violated this portion of the act?\nHon. Bill Blair (Minister of Public Safety and Emergency Preparedness): Mr. Chair, I want to assure the member that we are always vigilant in any foreign interference in our national security or issues of political interference in our society. It's monitored carefully by the national security establishment, according to the law as it exists in this country, and we will remain vigilant.\nMrs. Rosemarie Falk: Chair, in May 2019, the Liberals launched their digital charter. One of the principles was strong democracy, a commitment to defend freedom of expression. Will the Liberals hold Joyce Murray's WeChat accountable if it has violated this part of the charter?\nHon. Bill Blair: Mr. Chair, we are absolutely committed to the rule of law and will always uphold it. I think, as the minister has made very clear, she was not involved in this process and has no control over the individual who posted that matter.\nMrs. Rosemarie Falk: Chair, unfortunately I don't believe that was a sufficient answer. This is really a yes or no. Will the government hold Joyce Murray's WeChat accountable if it has violated their part of the charter?\nHon. Bill Blair: Again, Mr. Chair, I want to assure the member that our government remains committed to the rule of law and we will always work tirelessly to uphold the laws of this country.\nMrs. Rosemarie Falk: Is that a yes or a no?\nHon. Bill Blair: Again, I think it was very clear. We will always uphold the laws of Canada.\nMrs. Rosemarie Falk: Still, was that a yes or a no? I'm not hearing a yes or a no.\nHon. Bill Blair: I am doing my very best, Mr. Chair, to answer the question for the House and to assure the member opposite that our government will always remain committed to the rule of law. That is unequivocal.\nThe Chair: We will now move on to the honourable member. The floor is yours, Mr.Deltell.\nMr. Grard Deltell (Louis-Saint-Laurent, CPC): Thank you, Mr.Chair. I am very happy and proud to be participating in this discussion in the House of Commons today. My question is very simple: how much is Canada's deficit?\nHon. Bill Morneau (Minister of Finance): Mr.Chair, we continue to be transparent with our measures. Of course, we want to make sure that our investments, our economy\nThe Chair: The floor is yours, Mr.Deltell.\nMr. Grard Deltell: Let me ask my question to the honourable Minister of Finance once more, since he is talking about transparency. My question is really simple: how much is Canada's deficit?\nHon. Bill Morneau: Mr.Chair, our economic situation is very fluid. We have made major investments and we are making sure that our economy is working.\nMr. Grard Deltell: Mr.Chair, the minister's answer is not fluid at all. But the question is really simple: how much is Canada's deficit?\nHon. Bill Morneau: Mr.Chair, it is important to be transparent with our investments. We look at the investments and the figures every day.\nMr. Grard Deltell: Mr.Chair, the Minister of Finance may not know what the deficit is, but one great Canadian does know. And he knows that he knows. Could the Minister of Finance be very clear, very fluid and, above all, very transparent with Canadians? What is Canada's deficit?\nHon. Bill Morneau: Mr.Chair, I want to be very clear with Canadians: our economic situation is very difficult. The situation is fluid. We are making investments to ensure that our economy will be strong in the future.\nMr. Grard Deltell: Mr.Chair, with all due respect to the Minister of Finance, let me point out that, though he is not very clear, Canada's Parliamentary Budget Officer was clear yesterday. The deficit is $260billion. That is the real number. Why does the government not have the courage to state it clearly, as the Parliamentary Budget Officer did yesterday?\nHon. Bill Morneau: Mr.Chair, we always want to be clear and transparent. It is very important for the situation to be stable in order to ensure our future. That is our economic approach. We are making investments now so that the situation becomes more stable.\nMr. Grard Deltell: Mr.Chair, I know that the Minister of Finance is very good with figures. But he is not able to give us one. Perhaps he could comment on the statement that the Parliamentary Budget Officer made yesterday, that the emergency assistance must have an end date, and if it does not, we are heading to levels of taxation that have not been seen in this country for generations. What is the government going to do to make sure that Canadians will not be overtaxed after this crisis?\nHon. Bill Morneau: Mr.Chair, we think it's very important to make investments. That way, we will have a resilient economy in the future. That's very important. That way, we know that we'll have a good economy in the future. When we have more information, we will\nThe Chair: Mr.Deltell, you have the floor.\nMr. Grard Deltell: Mr.Chair, will the minister commit not to raise taxes after the crisis?\nHon. Bill Morneau: Mr.Chair, I have said several times that we do not have a plan to raise taxes. That's very important.\nMr. Grard Deltell: Finally a clear answer! However, I'm not convinced that he will apply it. In fact, the Parliamentary Budget Officer himself has said that there isn't much ammunition left without shifting into a large structural deficit, which can lead directly to tax increases. If the Minister of Finance can't even say today what the deficit is today, how can he be credible when he says that he won't raise taxes?\nHon. Bill Morneau: Mr.Chair, I think what's most important is that during this pandemic, Canadians and companies across the country need the Government of Canada's help. That is our approach. That way, we will have an economy that will function in the future. Of course, this is important for future generations.\nMr. Grard Deltell: When will there be an economic update?\nHon. Bill Morneau: \nMr. Grard Deltell: Mr.Chair, all observers are expecting an economic update to know where we're going. When will that happen?\nHon. Bill Morneau: Mr.Chair, we want our economic update to be accurate. That's why we are looking at information that allow us to make good forecasts.\nThe Chair: We'll now go to Mr. Hoback.\nMr. Randy Hoback (Prince Albert, CPC): Mr. Chair, the United States, Australia, India, Japan, New Zealand, South Korea and Vietnam have created an economic prosperity group to diversify some of their key supply chains away from China. Canada has a free trade agreement with six of these seven countries. Why are we not part of this group?\nHon. Mary Ng (Minister of Small Business, Export Promotion and International Trade): Mr. Chair, I thank the hon. member for that question. Indeed, we have been working diligently with all of these countries to make sure that we are keeping global supply chains open during this critical time. I think everyone agrees that keeping supply chains open for medical goods, critical agriculture and essential goods is absolutely essential and\nThe Chair: We'll go back to Mr. Hoback.\nMr. Randy Hoback: Mr. Chair, this government is refusing to come to terms with what COVID-19 will mean for the future of international trade. Why is Canada not at the table with our largest trading partner protecting the viability of our international supply chains and capitalizing on the opportunities of others doing the same?\nThe Chair: Before we go to the minister, one of the members has his mike still on, and I would ask that he turn it off. I am hearing background noise. The hon. minister.\nHon. Mary Ng: Mr. Chair, Canada has unprecedented access to a number of markets around the world because of the extraordinary agreements that we have made to provide access to customers in those international markets. During COVID-19, we have been working with our G20 partners. I have had two meetings with G20 trade ministers on the importance of keeping supply chains\nThe Chair: We'll go back to Mr. Hoback.\nMr. Randy Hoback: Mr. Chair, is this payback for the Prime Minister snubbing these countries at the original TPP signing?\nHon. Mary Ng: Mr. Chair, we have a CPTPP arrangement with these countries, and we are looking forward to making sure that we get Canadian businesses growing into those markets.\nMr. Randy Hoback: Mr. Chair, the U.K. will begin applying tariffs at the beginning of next year on Canadian exports such as seafood, beef and cars. These are the items that have had tariffs removed under CETA. Will the government commit to having a new trade agreement with the U.K. in place by January 1?\nHon. Mary Ng: Mr. Chair, we are monitoring the situation very carefully. The U.K., of course, is a very important trading partner for Canada. They are in discussions right now. I want to assure Canadian businesses that CETA continues to apply to our trade with the U.K. during this period while they go through Brexit.\nMr. Randy Hoback: Mr. Chair, after CUSMA, this government guaranteed to the trade committee that they would publish the objectives of any new trade agreement. When will we see these objectives published and actually have a chance to view them?\nHon. Mary Ng: Mr. Chair, we look forward to working to ensure that those objectives are published as we get into future trade discussions.\nMr. Randy Hoback: Mr. Chair, the resignation of the WTO director-general at this unprecedented time is concerning for the international trade community. Is the government committed to supporting a DG candidate who is dedicated to the massive reforms needed to get the WTO functioning again?\nHon. Mary Ng: Mr. Chair, I want to thank the hon. member for that good question. The Ottawa group, led by Canada, is working with like-minded countries on the reform of the WTO. We've been doing this work and we continue to do this work. I look forward to making sure that we are leading the way on those discussions with like-minded\nThe Chair: Mr. Hoback.\nMr. Randy Hoback: Mr. Chair, last week the President of the United States considered blocking cattle imports. Our beef producers don't need this. They need stability. Three-quarters of Canada's beef cattle exports go to the U.S. Has the government sought out and received assurances from the United States that no such action will apply to Canadian cattle?\nHon. Chrystia Freeland (Deputy Prime Minister and Minister of Intergovernmental Affairs): Mr. Chair, we have an excellent assurance of our trade with the United States, which is our new NAFTA trade agreement that we have negotiated, thanks to the unprecedented co-operation across this country. It is very important to the Canadian economy and Canadian producers.\nMr. Randy Hoback: Mr. Chair, going forward post-COVID, there are a lot things that will be changing in supply chains. What is this government doing proactively to look at opportunities in these supply chains that Canadian businesses can take advantage of?\nHon. Mary Ng: Mr. Chair, we continue to work with countries around the globe to ensure that Canada's supply chains and those global supply chains, particularly for essential goods, for agricultural products, for medical supplies, continue to remain open. We will keep doing this work.\nMr. Randy Hoback: Mr. Chair, on the agriculture side, canola farmers would like to know the status of canola going into China. Can she update the House on that status?\nHon. Marie-Claude Bibeau (Minister of Agriculture and Agri-Food): Mr.Chair, I want to assure my colleague that we are continuing to work with our industry representatives, our allies and our trading partners in China.\nThe Chair: We'll now go to Ms. McLeod.\nMrs. Cathy McLeod (KamloopsThompsonCariboo, CPC): Thank you, Mr. Chair. Senior Canadian bureaucrats received very credible reports in early January that China was procuring and hoarding PPE. As a member of cabinet, was the health minister aware?\nHon. Patty Hajdu (Minister of Health): Mr. Chair, from the very beginning of the outbreak in early January we were aware of the challenges our health sector would face, and we immediately began to work with the provinces and territories to understand what the need would be and how we could best prepare.\nMrs. Cathy McLeod: In April, the minister stated there were not enough supplies in the national emergency stockpile. Can she explain why she approved a donation of 16 tonnes of PPE for China on January 31, claiming it would not compromise our supply? She can't have it both ways. We don't have enough; we have enough and it won't compromise it.\nHon. Anita Anand (Minister of Public Services and Procurement): Mr. Chair, we are operating in a highly competitive global environment, and the reality is that we need to make sure we have multiple complementary supply chains operating at the same time, which we have been doing in the past weeks and months, to ensure our front-line health care workers have the supplies they need to keep Canadians safe. That's our priority. That's what we're working on.\nMrs. Cathy McLeod: Unfortunately, this question was directed to the health minister, referencing things she actually stated in terms of the availability of our supplies. Before the she signed off on the donationand it was the health minister who signed off on the donationdid she consult with the health ministers in the provinces and territories?\nHon. Patty Hajdu: Mr. Chair, as the member opposite knows, provinces and territories have their own stockpiles, which of course they use to prepare for incidences of outbreak and other illnesses across their jurisdictions. We've worked very closely with the provinces and territories since the beginning of the outbreak to make sure we can provide any particular additional support. In fact, of all the requests made so far, we have been able to complete them.\nMrs. Cathy McLeod: Health care workers are now having to look at modified full-face snorkels as an alternative to N95 masks. Did it not occur to the minister that our hospitals and care homes could have used that PPE she shipped out, providing a longer opportunity for them to also get procurement done?\nHon. Patty Hajdu: Mr. Chair, as the member opposite knows, the equipment that was donated when China was in its outbreak was an important donation of nearly expired or expired goods that it was in desperate need of in its effort to try to contain the virus. As the member opposite knows, we've been able to work successfully with provinces and territories to ensure they have what they need.\nMrs. Cathy McLeod: Mr. Chair, I would suggest that during February and March our hospitals would have consumed that almost-expired product very efficiently, but I want to move on to another topic. When defending the sale of 22 seniors' homes to the Chinese government, the Prime Minister stated that we have a strong regulatory regime that imposes rigorous standards. He said that this regime ensures the care our seniors get is top quality. That was in 2017. Now he states he is saddened, shocked, disappointed and angered. Was the Prime Minister completely oblivious to the risks, or was he just too anxious to please the Chinese government when he sold those 22 homes?\nHon. Patty Hajdu: Mr. Chair, the homes the member opposite is referring to are in the province of B.C., and I have to commend the province for the early work it did to protect seniors in those long-term care homes. The member opposite is trying to confuse the issue. As she knows, the review we did was entirely separate from the standards to which the province holds the care homes.\nMrs. Cathy McLeod: The Prime Minister does not have authority over seniors' homes, which he has clearly stated, but he does have authority over the act in which he approved the sale. At 18 months, government had an obligation to make sure there was compliance. Was that done?\nHon. Patty Hajdu: Mr. Chair, the long-term care homes in each province fall within the jurisdiction of their own particular act, and those provinces and territories are responsible for fulfilling the inspections required under that act.\nMrs. Cathy McLeod: Under the Investment Canada Act, the government is obligated to review the sale for compliance. Four homes had to close. Since the government approved the sale, it is complicit in the care of our seniors in this country\nHon. Navdeep Bains (Minister of Innovation, Science and Industry): Mr. Chair, I want to make it very clear that we understand how difficult this is for seniors. That is why we follow the appropriate steps, outlined under the Investment Canada Act, to make sure that any measures we take keep seniors and their well-being first and foremost.\nThe Chair: Mr.Therrien, you now have the floor.\nMr. Alain Therrien (La Prairie, BQ): Mr.Chair, during the pandemic, the government has given money to companies that don't pay a cent in tax because they use tax havens. We told the government that it didn't make sense. The government's response was that it is no big deal. During the pandemic, the government gave money to Air Canada, but Air Canada never reimbursed customers who did not get the services they paid for. We told the government that it did not make sense. The government's response was that it was no big deal. During the pandemic, the Liberal Party used the emergency wage subsidy to fund partisan activities. We told them that it did not make sense. The government responded that it was no big deal. Is the moral of the story that the government thinks that dipping into the pockets of taxpayers to spend money carelessly is no big deal?\nHon. Diane Lebouthillier (Minister of National Revenue): Mr.Chair, the fight against tax evasion is a priority for our government. We will continue to target companies that use tax evasion schemes. Let me be clear: in everything we do, we will target companies and not innocent workers. Employees are employees, no matter who they work for.\nMr. Alain Therrien: Mr.Chair, when I see that it's the Minister of National Revenue answering me, I don't feel like buying a lottery ticket. The Liberal Party used two airplanes in its last election campaign, which seems to indicate that it isn't short of money. However, the Liberals used the emergency wage subsidy. Why? Is it because they want taxpayers to fund a third airplane?\nHon. Bill Morneau: Mr.Chair, we think it's very important to protect employees across the country and in every economic sector that's experiencing a significant drop in income. That's the approach we've taken to protect people and to ensure that there will be jobs in the future. We will continue this approach.\nMr. Alain Therrien: It's especially important to protect the employees who work for the Liberals to ensure their re-election, yet the Liberal Party has raised more than $7million since the last election. Is the party in jeopardy? Can it go bankrupt?\nHon. Bill Morneau: Mr.Chair, as I said, our approach is to protect employees. We think that this principle is very important and that this approach must be maintained in order to have a better job market in the future.\nMr. Alain Therrien: Mr.Chair, we still don't know exactly how much money the Liberals took from the cookie jar. We think they may have taken as much as $1million. How many SMEs could have been saved with the $1million that the Liberals took out of the jar and took away from SMEs?\nHon. Bill Morneau: Mr.Chair, we appreciate the question. We are protecting hundreds of thousands of SMEs through the emergency wage subsidy, the Canada emergency response benefit and all our programs. We will continue this approach to help SMEs and their employees.\nMr. Alain Therrien: Mr.Chair, I will propose a choice of answers, or I won't get any. When did the government decide to use the emergency wage subsidy? Now here are three possible answers. The first possible answer is that when the Liberals brought in the emergency wage subsidy, they set parameters allowing them to use it. The second is that when the Liberals saw the Conservative Partywhich is as rich as they are, but also sanctimonious and self-righteoustake advantage of the subsidy, they thought they could do it too. The third possible answer is that the Liberals hadn't planned to use the subsidy, but they pounced on the cookie jar when they saw it, because that's what they do.\nHon. Bill Morneau: Mr.Chair, we continue to think it is very important to protect employees in every sector of the economy and across Canada. That's our approach, and I believe it's the right one to protect and preserve jobs across the country during a pandemic.\nThe Chair: We are now going to suspend the proceedings for a few seconds to allow the employees who provide support for the meeting to replace each other safely.\nThe Acting Chair (Mr. Bruce Stanton (Simcoe North, CPC)): We will now resume the discussion.  We'll continue with Ms. Khalid, the honourable member for MississaugaErin Mills.\nMs. Iqra Khalid (MississaugaErin Mills, Lib.): Thank you, Mr. Chair. I'll be splitting my time with the member for PickeringUxbridge. Mr. Chair, when the women and men of the Canadian Armed Forces stepped in to provide support to five long-term care homes in Ontario at the request of the premier, they released a report that outlined their findings in detail. Military members witnessed residents' cries for help going unanswered. They saw force-feeding. They saw bug infestations, a lack of personal protective equipment and neglect. Canadians are shaken. They are appalled by the horrific conditions outlined in the military report. Almost 1,000 seniors so far have lost their lives in long-term care homes in Ontario alone, over 25 of them in my riding of MississaugaErin Mills. These deaths could have been prevented. Can the Minister of Health please update the House on how our federal government is working with the provinces and territories to prevent further tragic occurrences from happening at long-term care homes and to ensure that our most vulnerable seniors are properly looked after and cared for?\nHon. Patty Hajdu: Mr. Chair, it's such an important question. I believe all Canadians were deeply horrified to read the details from the Canadian Armed Forces on the conditions in long-term care homes in Ontario. What's happening to seniors in Ontario is completely unacceptable. The report is very troubling. Seniors deserve to live with dignity, with respect and with safety. While long-term care is provincially regulated, we know that we need to work together. The Government of Canada stands ready to support provinces and territories as they continue to respond to this crisis. I had a very good conversation with my provincial and territorial counterparts last night about the work we can do at a national level to support their important work. We also know that seniors want to stay at home longer. That's why our historic investment of $6 billion in home care was so important. We'll continue to work with the provinces and territories to ensure that they get the care and dignity they deserve.\nThe Acting Chair (Mr. Bruce Stanton): We'll go now to Ms. O'Connell.\nMs. Jennifer O'Connell (PickeringUxbridge, Lib.): Thank you, Mr. Chair. I will sadly report that my community of Pickering has experienced the largest number of deaths at a single COVID-19 outbreak location anywhere in this country. Seventy residents at Orchard Villa long-term care home died during this pandemic. It was a devastating blow to our community. Yesterday, we received the horrific report from the Canadian Armed Forces detailing what they witnessed at Orchard Villa in Pickering, Altamont Care Community in Scarborough, Eatonville Care Centre in Etobicoke, Hawthorne Place in North York, and Holland Christian Homes' Grace Manor in Brampton. The loved ones of those who have passed away, as well as the homes' workers, have asked for a full public inquiry from the Ontario government. I know that the responsibility for these facilities falls within provincial jurisdiction, but on behalf of our communities, can the Minister of Health update us on the work she is doing to ensure that the Ontario government takes action immediately and initiates a full, independent, non-partisan public inquiry and reverses its decision to create a government-led commission that won't even start until September?\nHon. Patty Hajdu: Mr. Chair, I would say that all Canadians were shocked and horrified to hear about the conditions that existed in these particular care homes. We're so grateful to the members of the armed forces who not only improved conditions but also reported them quickly and appropriately to ensure amelioration of those conditions for those particular individuals. We also know that there are seniors all across the country who are struggling with care and with the appropriate level of care. We have to do better as a country. These are our loved ones. These are our parents and our grandparents. These are the people in our lives who have given so much to us. I stand committed to working with my provincial and territorial counterparts to ensure that we do better as a society. We know that there's a role we can play at the federal level with advice, with guidance, with support and, yes, with investments. We look forward to having those conversations about how best we can improve the care for all seniors amongst us.\nThe Acting Chair (Mr. Bruce Stanton): We'll go now to Mr. Davies from Vancouver Kingsway.\nMr. Don Davies (Vancouver Kingsway, NDP): Thank you, Mr. Chair. Canadians were horrified to hear the report yesterday from our armed forces about the appalling conditions experienced by seniors in our long-term care homes. Page after page detailed the filth, neglect, abuse and danger our seniors in care are exposed to on a daily basis. Shockingly they face injury and death through missed medications, expired medications, unsterile devices and violations of basic contagion rules to stop the spread of COVID-19. Given that evidence of possible criminal conduct was contained in the military's report, will the minister refer this matter to the RCMP for investigation immediately?\nHon. Bill Blair: Mr. Chair, thanks very much to the member for those expressions of concern, which we share. We understand in long-term care facilities both seniors and persons living with a disability face unique challenges, and the findings of this report are in fact deeply concerning and completely unacceptable. Considering the severity of this report, we promptly shared it with the Province of Ontario, and the Province of Ontario has initiated an investigation based on the report's findings. Their investigation includes alerting the province's chief coroner who has the authority to alert the police of jurisdiction. We will continue to work with the province to protect those living in long-term care facilities, and we continue to support them through the deployment of our outstanding Canadian Armed Forces and in our partnership with the Red Cross.\nMr. Don Davies: Mr. Chair, that's a shocking answer considering there's clear evidence of criminal conduct and negligence in this. That this federal government is not taking immediate steps to refer this to the nation's RCMP is unacceptable. The seniors care crisis is a national problem. COVID-19 has exposed critical vulnerabilities across Canada's entire network of long-term care facilities. Not a single province or territory currently meets the benchmark of 4.1 hours of hands-on care per day. As a result Canada has the worst record of COVID-19 deaths in long-term care among 14 comparable countries, with over 80% of Canadian fatalities occurring in these facilities. Will this government move swiftly to establish binding national standards for long-term care?\nHon. Patty Hajdu: Mr. Chair, the member opposite is exactly correct when he says that those who are hardest hit in terms of losing their lives and the negative effects of COVID are those who are living in long-term care homes. He's also correct when he indicates that COVID-19 has shown us what many of us have known for a long time, that we need to do better in long-term care and supports for seniors. As the member knows, we started those steps some four years ago or so when we began to make incredible investments in aging at home. We know that is one part of the solution, but we have to do better for those seniors who need a higher level of care. That's the work I'm doing now. I'm working with my colleagues at the provinces and territories to make sure that we come up with a solution that will truly result in better standards for all.\nMr. Don Davies: Mr. Chair, what we need is binding national standards, just like we set through the Canada Health Act in the health care sector generally. Gross fecal contamination, filthy medical equipment, insect infestations, ignoring patient cries for hourswe would never tolerate these conditions in Canada's hospitals. There's no reason to accept them in Canada's long-term care facilities. Will the minister move to bring long-term care facilities under the Canada Health Act, or similar legislation, with formal funds tied to acceptable standards of care for our seniors, just like we do for hospitals?\nHon. Patty Hajdu: Mr. Chair, the member shares the disgust and concern of so many Canadians across the country, not only those who have read the report but many of those who have struggled to provide care to elders in those long-term care homes, regardless of the province in which they live. We know we need to do better. We know that collectively, at all levels of government, we must do better for those people who cared for us and nurtured us all of those years. The member has my commitment that I will work with provinces and territories to find a solution forward to ensure that every person has the right to age with dignity and safety.\nThe Acting Chair (Mr. Bruce Stanton): Mr. Davies, you have 15 seconds for another question, a short one, and leave time for a response.\nMr. Don Davies: Thank you, Mr. Chair. These failures are the product of systemic neglect often motivated by prioritizing profit over the provision of adequate care. Does the minister agree that we should not be putting profits above the health care needs of Canada's seniors?\nHon. Patty Hajdu: Mr. Chair, I believe that, when we commit to taking care of people, we must do so with the utmost care that is required. I know that provinces and territories have a lot of work to do. So do we, at the federal level, and obviously at the local level. We must all work together to protect those people in our lives who are most vulnerable, whether they be seniors, children or others.\nThe Acting Chair (Mr. Bruce Stanton): We will now move on to Mr. Schmale, HaliburtonKawartha LakesBrock. Mr. Schmale, go ahead.\nMr. Jamie Schmale (HaliburtonKawartha LakesBrock, CPC): Thank you, Chair. According to Vaughn Palmer in an editorial in the Vancouver Sun regarding the secret Wet'suwet'en deal, Palmer writes:     The hereditary chiefs calculated the two governments would sign despite the objections from the elected chiefs. They likewise got the terms they wanted in the MOU while giving up absolutely nothing. Just as they figured governments would keep the contents secret from the public.   Can the minister describe another situation in which the federal government negotiated a secret deal of this magnitude with unelected people?\nHon. Carolyn Bennett (Minister of Crown-Indigenous Relations): I thank the member for his ongoing concern and I want to remind him that actually it is in keeping with the Supreme Court decision of 1997 that we were to now begin those conversations with the Wet'suwet'en hereditary chiefs who took the case to the Supreme Court. As we've said many times, this is not an agreement; this is an MOU that establishes the path forward for the substantive discussions towards a final agreement, which would describe the future governance and the implementation of Wet'suwet'en rights and title. It is about a shared commitment.\nMr. Jamie Schmale: Mr. Chair, if it is a shared commitment, why on the eve of the signing ceremony did the four elected chiefs denounce the hereditary chiefs for keeping them in the dark?\nHon. Carolyn Bennett: Again, it's really important that the member understand that there was a process for the hereditary chiefs to go back to their communities and discuss with them. Any agreement after the good work that will happen now would have to go back and seek the approval of all of the communities.\nMr. Jamie Schmale: Mr. Chair, the Burns Lake Band members are openly wondering if they're still a band or if the few unelected hereditary chiefs will control everything now. Minister, can you assure them that going forward you will honour their concerns and take the time to listen?\nThe Acting Chair (Mr. Bruce Stanton): I ask honourable members to still direct their questions through the chair. The honourable minister.\nHon. Carolyn Bennett: Actually, the honourable member knows that the next steps include the further and ongoing engagement by the Wet'suwet'en in their house groups and that will include the six elected chiefs of the Wet'suwet'en nation, their community members and many others. This is about going forward and making sure that any\nThe Acting Chair (Mr. Bruce Stanton): We go back to Mr. Schmale.\nMr. Jamie Schmale: Thank you, Chair. Cynthia Joseph, a chief councillor with the Hagwilget First Nation says the MOU between Ottawa, the province and the Wet'suwet'en hereditary chiefs was only shared with her community members on May 9, two days after it was published in the media. Is this part of the open and transparent government all Canadians can expect of the Prime Minister?\nHon. Carolyn Bennett: Walking the path of reconciliation means that we work with our partners and there is a way that they do the work within their communities. It is going to be an agreement to begin the work, but any final agreement is going to have to be approved by all members of the nation in terms of developing a consensus for the agreement\nThe Acting Chair (Mr. Bruce Stanton): We go back to Mr. Schmale.\nMr. Jamie Schmale: Thank you, Chair. Does the minister have any concerns regarding claims by several former female hereditary chiefs that they were stripped of their hereditary status because they didn't agree with the men?\nHon. Carolyn Bennett: Again, it is going to be really important that the work take place within the Wet'suwet'en nation to determine their future governance, to determine their way of working with Canada and to make sure\nThe Acting Chair (Mr. Bruce Stanton): We go back to Mr. Schmale.\nMr. Jamie Schmale: Thank you, Chair. For some reason it seems to be a problem to stand up for these hereditary female chiefs who had their titles taken away. Does the minister plan on recognizing band council resolutions denying the authority of hereditary chiefs to sign any future agreements without consent of the elected chiefs and the 3,000 members within the Wet'suwet'en they represent?\nHon. Carolyn Bennett: I think the member must understand that, as we begin the work, the nation will do its work and then we will come to the table to determine what the governance would be. Will it be a hybrid model like at Heiltsuk, like Ktunaxa, like some of the communities developing their constitutions, developing their laws and deciding how they will determine their own governance and that partnership with Canada?\nThe Acting Chair (Mr. Bruce Stanton): Mr.Paul-Hus.\nMr. Pierre Paul-Hus (CharlesbourgHaute-Saint-Charles, CPC): Thank you, Mr.Chair. The current restrictions on non-essential travel at the border do not prevent people from claiming refugee protection if they have family in Canada. Why is the minister refusing to allow married people to cross the border?\nHon. Bill Blair: I want to thank the honourable member for a very important question. We have heard from many constituents and members of Parliament from right across the country who are expressing concern about non-status spouses being denied entry into the country because their travel is deemed to be non-essential. I've recently been in touch with all of the provinces and territories because I think it's very important that we have their support for any changes\nThe Acting Chair (Mr. Bruce Stanton): Mr.Paul-Hus, you have the floor.\nMr. Pierre Paul-Hus: If I understand correctly, Mr.Minister, you are talking to provincial representatives, but a case like that of ChantalTremblay, for instance, is unacceptable. For two months now, she has been trying to bring her spouse to Canada, but it isn't working. Is there a way to issue a directive to border services officers that married spousesit's often marriages with Americanscan cross the border to join their spouses in Canada?\nHon. Bill Blair: Just to be very clearagain, I thank the member opposite for the opportunity to clarify thisit is never our intention to separate families, but at the same time, we have imposed appropriate and necessary restrictions on non-essential travel. Our border services officers inquire of everyone coming to that border about the nature of their travel, and for non-citizens who come to that border seeking entry into Canada, if their entry is deemed non-essential, then they exercise their discretion not to allow\nThe Acting Chair (Mr. Bruce Stanton): Mr.Paul-Hus, you have the floor.\nMr. Pierre Paul-Hus: Thank you, Mr.Chair. Information from the Canada Border Services Agency has just come out. Since March21, 425,000people have flown into Canada. Among them were 295,000Canadians, which isn't a problem. However, 100,000foreigners have entered Canada, even though the border is supposedly closed. How does the minister explain the fact that 100,000people arrived in Canada by plane?\nHon. Bill Blair: Again, I thank the member opposite for the opportunity to clarify. We have imposed very significant restrictions on non-essential travel, but of course there are circumstances where individuals come to this country and their entry into Canada is deemed essential. For example, someone who is providing medical services and coming into Canada to provide those services would be deemed essential, because there is a great need among Canadians for those services. It's dealt with on a case-by-case basis. As you can see by the numbers, we have had a very significant reduction in the travel of all non-Canadians to Canada over the past two months.\nMr. Pierre Paul-Hus: So the minister confirms that the 100,000people who arrived by air were providing a service considered essential to Canada. I'm not talking about the people who crossed the land border, but the people who came to Canada by air.\nHon. Bill Blair: What I can tell you is that at all points of entry, including our air borders, we apply the standard that the travel must be deemed essential, and that determination is utilized to see if a person is eligible to enter into the country.\nMr. Pierre Paul-Hus: We're now learning that the Correctional Service of Canada's investigation into the murder of MarylneLevesque is suspended due to the COVID-19 outbreak. Canadians aren't fooled; they know full well that it is a political decision. All the technological means are available to allow the investigation to continue. I'm proof of that today. Can the minister direct the Correctional Service of Canada to resume the investigation into the death of MarylneLevesque?\nHon. Bill Blair: Again, I thank the member for the question, because we know the concern of the people of Quebec, and the family of Ms. Levesque needs answers and deserves answers. That's why we asked the Parole Board and the Correctional Service of Canada to convene a board of investigation. Clearly, during COVID transmission, the ability to conduct that investigation and to interview all of the witnesses became extremely difficult and has been temporarily suspended, but at the very earliest opportunity we remain resolute to resume that investigation and get to the bottom of it to provide the answers that the family deserves.\nThe Acting Chair (Mr. Bruce Stanton): Mr.Paul-Hus, you have only 20seconds remaining.\nMr. Pierre Paul-Hus: Mr.Chair, victims of crime are one of the segments of the population most affected by the crisis. As we know, the government refuses to allow victims of crime to participate in parole hearings. For the first time in its history, and to add insult to injury, the government has cancelled all activities related to Victims and Survivors of Crime Week, which was to take place next week. Why is the Prime Minister turning his back on victims?\nHon. Bill Blair: Again, at the earliest days of COVID, until arrangements could be put in place, there were restrictions on victims participating. We have put the systems in place to allow victims to present their evidence virtually, either by video or by phone, to ensure that their voices are heard in these important things. We very much respect and support the role of victims in these determinations, and we're making every effort to ensure that they can participate.\nThe Acting Chair (Mr. Bruce Stanton): We'll now to Mr. Cumming, Edmonton Centre.\nMr. James Cumming (Edmonton Centre, CPC): Mr. Chair, yesterday I asked the Minister of Small Business how many business credit availability guarantees were issued by EDC, and I didn't get a number. Does she have an exact, finite, number of the guarantees today?\nHon. Mary Ng: Mr. Chair, thank you to the honourable member for that question. Our government has taken swift and immediate action to support Canadian businesses through this time. Money from this program is flowing, and businesses across the country are receiving the important support that they need.\nMr. James Cumming: How many BCAP applications have been received so far?\nHon. Mary Ng: Mr. Chair, these are large loans, and they require important due diligence and adjudication by the financial institutions. We will continue to be open and transparent as the accurate information becomes available.\nMr. James Cumming: How long does it take to be approved for a BCAP guarantee?\nHon. Mary Ng: I want to assure the member that we're going to do everything possible to support businesses and workers during this very important time.\nMr. James Cumming: How many businesses have received funding under the BCAP co-lending program since March?\nHon. Mary Ng: The lending programs, particularly the program to help small businesses, have really helped lots of businesses. Over 630,000 loans have been issued, and this is really helping those\nThe Acting Chair (Mr. Bruce Stanton): We go back to Mr. Cumming.\nMr. James Cumming: Unfortunately, lots is not an answer for the businesses that I'm trying to talk to. Can you tell me, for the CEBA changes that were recently announced, when will we be able to see people who have income through a dividend able to apply?\nHon. Mary Ng: That's a very important question, Mr. Chair. There's nothing more important to me and to our government than getting these supports out to businesses. Those small businesses that will meet the expanded CEBA criteria are working very diligently with the financial institutions to make sure that they can get access to those loans as quickly as possible.\nMr. James Cumming: Can the minister give me a day when that will happen?\nHon. Mary Ng: The financial institutions are working very hard to make sure that they can make this available to businesses.\nMr. James Cumming: When will a sole proprietor be able to go for those loans?\nHon. Mary Ng: We will work very hard and very diligently to make sure that these businesses and those sole proprietors are supported.\nMr. James Cumming: Could they go on Monday?\nHon. Mary Ng: There is nothing more important than making sure these businesses weather the difficult time of COVID-19, and our measures are\nThe Acting Chair (Mr. Bruce Stanton): We'll go back to Mr. Cumming.\nMr. James Cumming: How about Tuesday?\nHon. Mary Ng: I think we will all agree that getting support to these businesses is absolutely crucial. Our commitment is always going to be to get support to these businesses.\nMr. James Cumming: I can't get a distinct answer on any of those questions. Can you tell me how much headroom is left on the CEBA program?\nHon. Mary Ng: Today, over 630,000 businesses have received the support to do things like pay for salaries, the 25% top-up for the wage subsidy, pay for rent and pay for insurance and utilities. This is what these loans are helping our small\nMr. James Cumming: How many dollars are left in the program so businesses can have some certainty that the program will be available for some time?\nHon. Mary Ng: I think you will see that the businesses across the country that I have talked to really appreciate that the government has stepped up to help them during this difficult time. These include women with businesses, indigenous-owned businesses and those small businesses all across our communities, all across the country, that are getting the necessary help. We are going to keep\nThe Acting Chair (Mr. Bruce Stanton): We'll go back to Mr. Cumming.\nMr. James Cumming: How many dollars? It can't be that complicated. How many dollars?\nHon. Mary Ng: There are 630,000 businesses that are getting help, and thousands more businesses will be getting help with the expanded criteria. We're going to keep doing the work that we need to help our businesses across this country through this difficult time.\nMr. James Cumming: I heard from a constituent in my riding that they waited for over four hours on the portal for CECRA. Is there an issue with the portal, and if so, when will it be fixed?\nHon. Mary Ng: Making sure that businesses get the help for commercial rent support is absolutely crucial right now. We are going to endeavour to make sure that this help gets out to those small businesses. Applications have opened in a staggered way and\nThe Acting Chair (Mr. Bruce Stanton): You have time for one last short question, Mr. Cumming.\nMr. James Cumming: Finally, the Prime Minister yesterday said that a list of all organizations that have been receiving CEWS will be made public. When will that be done?\nHon. Mary Ng: We have committed to making sure that those companies taking the wage subsidy program will be listed publicly. We have committed to doing that and we will do so.\nThe Acting Chair (Mr. Bruce Stanton): We now go to Mr. d'Entremont from West Nova. Mr. d'Entremont, go ahead.\nMr. Chris d'Entremont (West Nova, CPC): Thank you very much, Mr. Chair. I have a question for the Minister of Fisheries, but I thought I would say this first. The Canadian Coast Guard is doing a search at this moment following the loss of a vessel off the coast of Newfoundland. From my community, which is a seafaring, fishing community, I just want to put my thoughts out there to the folks of Newfoundland. We are definitely thinking of them during this difficult time. My first question revolves around the lobster fishery. It's been open in Cape Breton since May 15, I believe. The weather has been good. The harvesters have been going at it every day. The price has dropped to $4.25 already. Unstable markets will probably cause it to drop even more. What is the minister doing to make sure the lobster industry survives?\nHon. Bernadette Jordan (Minister of Fisheries, Oceans and the Canadian Coast Guard): Thank you, Mr. Chair. I want to thank my colleague for his comments with regard to the tragic accident off the coast of Newfoundland and Labrador, where we saw the loss of life in a fishing accident. Of course, as coastal people, we are all in solidarity with the people of Newfoundland right now. We know that the fish and seafood sector has taken extreme hits because of COVID-19. We're working diligently to make sure we support the industry as best we can. We have made available over half a billion dollars to processors and harvesters to make sure they can weather this storm. We have made sure that the harvesters are able to access the harvester benefit as well as the grant, recognizing the unique nature of their business and how they are not able to access some of our other programs. We are continuing to monitor what is happening in the industry. We will continue to make sure we do everything we can to support the fish and seafood sector.\nMr. Chris d'Entremont: Mr. Chair, to continue along this vein for a moment, we are still looking at unstable markets for a longer period of time. At this point, processors are being selective in what they're buying. They're not buying culls and other kinds of lobsters. The plants are filling up, and harvesters are worried that they might stop buying product before the season is complete. What can the fishermen expect, or what kinds of programs can they expect, if the season goes bust?\nHon. Bernadette Jordan: Mr. Chair, we know that this is a very challenging season for our harvesters. We also know that because of the decline in markets, we've had to make accommodations for the processing sector in order to help them be better able to support the harvesters. We have put in $62.5 million, which is allowing the processors to increase capacity in their refrigeration and freezers so that they will continue to be able to purchase product. As I said earlier, we will continue to monitor the situation and make sure we do everything possible to support our harvesters. This is a very difficult\nThe Acting Chair (Mr. Bruce Stanton): We'll go back to Mr. d'Entremont.\nMr. Chris d'Entremont: Mr. Chair, I don't know whether this next question will go to the Minister of DFO or the Minister of Transport. Oakley Ryerson is a resident of West Nova. He is planning a career on the sea and wants to get his master class four. The problem is that he can't pass the eye exam. He needs full-colour vision. For those who are far-sighted or nearsighted, you just have to put on your glasses to correct it. You can actually fly airplanes. I don't know about space shuttles, but who knows? You can now wear colour-corrected lenses, but Transport Canada still does not recognize these for use. Can the Minister of Transport help Ryerson in attaining his chosen profession?\nHon. Marc Garneau (Minister of Transport): Mr. Chair, I appreciate the concern of my colleague for one of the residents in his riding. I would ask him to write to me and lay out the situation. We have medical standards with respect to a number of different kinds of transportation-related jobs for pilots, mariners and those kinds of occupations, which have to be respected. However, if he sends me the details, I will look into it personally.\nThe Acting Chair (Mr. Bruce Stanton): Mr. d'Entremont, you have another 20 to 25 seconds left.\nMr. Chris d'Entremont: Mr.Chair, the eligibility criteria for financial support include the need to demonstrate a significant loss of income during the months of March and April, yet several SMEs in the tourism industry can't qualify because their operations start with the tourist season, in late May or early June. What will the government do to help them?\nHon. Bill Morneau: Mr.Chair, before accessing the emergency wage subsidy, applicants must meet important criteria. However, as we explained last week, we will be adjusting the wage subsidy until the end of August, and we will be reviewing the criteria.\nThe Acting Chair (Mr. Bruce Stanton): We're going to go to the west coast and the member for SaanichGulf Islands. Ms. May, go ahead.\nMs. Elizabeth May: Thank you, Mr. Chair. My question is with regard to the urgent problem of mental health crises across Canada. My colleague, Jenica Atwin from Fredericton, held a press conference this morning in which she used the term echo pandemic. We will face an echo pandemic. We're already seeing increases in suicides on southern Vancouver Island. My question to the minister is this: Will we see direct funding to community mental health services as urgently requested by the Canadian Mental Health Association?\nHon. Patty Hajdu: Mr. Chair, I read the honourable member's colleague's letter just today, and I want to reassure all members that we have invested in mental health supports for Canadians, obviously before the pandemic hit but certainly since we've been living with the pandemic. I'd like to remind all members to direct their constituents to the wellnesstogether.ca website and portal. There Canadians can find online resources, as well as connections to real and alive counsellors and other professionals who can help them with their various concerns.\nMs. Elizabeth May: This question relates to another current emergency: the climate emergency. This week it was reported that the concentration of greenhouse gases reached 417 parts per million. That's not just unprecedented over thousands of years; that's unprecedented over the last one million years. The temperatures in the Arctic broke 86F, 30C in the Arctic circle. The recognized parties in the House have established standing committees to work, but not the committee on the environment. We've asked for this in negotiations. When will the recognized parties remember the June 2019 emergency resolution that we are in a climate emergency, and start making sure that we hit 2020 commitments under the Paris Agreement to improve our targets?\nHon. Marc Garneau: Mr. Chair, I appreciate my colleague's questions. I will remind her that we have committed to net-zero emissions by 2050. We've also committed to surpassing the targets that we had originally set for 2030. We realize that along with the COVID pandemic, which is the major problem that exists in the world today, there is another problem as well that affects the entire planet, and that is the problem associated with climate change. We remain committed to achieving those targets.\nMs. Elizabeth May: My next question will be for Minister Blair, but as an aside, I will say that last answer completely fails to meet the legal requirements of the Paris Agreement to file a new target this year. To save some time, Minister Blair, let's pretend to go back to the questions from my colleague MP Paul-Hus and to your last answer. This is dealt with on a case-by-case basis by CBSA agents. There are thousands of them. They are exercising personal, subjective judgment. This is not acceptable. I'm begging the minister. Could the minister please put out a directive, advice to every CBSA agent on the ground, that when a non-status entry point sees a non-status direct relativehusband, wife, child of a Canadian citizenthat relative be deemed to be entering Canada for an essential purpose?\nHon. Bill Blair: I'd like to thank the member for bringing this issue forward again. It's an important one. We have been working very hard to ensure that we do everything possible to keep families together. At the same time, we've been working with the provinces and territories, listening to the concerns of Canadians about ensuring that travel across our international border, particularly with the United States, is limited to essential travel. As I've indicated, I've had a number of important conversations and necessary conversations with our provincial and territorial partners. I believe there is a consensus on the right way forward on this, and we're working very diligently to put it in place. I want to assure the member opposite that we have given very clear direction to our CBSA officers. I believe our border services officers have been doing an extraordinary job for us in the exercise of their discretion. At the same time, they have been doing the important work of ensuring the health and safety of Canadians at our border.\nThe Acting Chair (Mr. Bruce Stanton): We're now going to Ms. Kwan for Vancouver East. Ms. Kwan, go ahead.\nMs. Jenny Kwan (Vancouver East, NDP): Four out of the five homes listed in the armed forces report were for-profit. It is painfully clear that corporate profits are being put ahead of the well-being of seniors. Will the minister admit that the for-profit model is failing our loved ones and commit to getting profits out of long-term care?\nHon. Patty Hajdu: As the member opposite notes, nobody can read that report or hear those stories without feeling absolute horror and disgust and without demanding better for the elders in our lives. As I have mentioned many times in the House, our government remains committed to working with provinces and territories to ensure that every elder person in our community can age with dignity and in safety.\nMs. Jenny Kwan: Minister, if that's the case, I will ask again. Will the minister make sure that the focus of long-term care homes is taking care of seniors and not taking care of owners' bank accounts?\nHon. Patty Hajdu: As the member will obviously know, long-term care remains in the jurisdiction of provinces and territories, and there is legislation that rules them as such. As the member also knows, we have stood by Ontario and all of the other provinces and territories throughout this outbreak. The Prime Minister has been very clear\nThe Acting Chair (Mr. Bruce Stanton): We will go back to Ms. Kwan.\nMs. Jenny Kwan: Is the minister refusing to answer the question because she agrees that profit should come before care?\nHon. Patty Hajdu: I think it's unfortunate that the member is trying to place words in my mouth. What I do agree with, though, is that long-term care needs to be reformed, and I think all provinces and territories know, and all Canadians know, that we have to do a better job.\nMs. Jenny Kwan: It's simple for the minister. She can just answer the question. Is she willing to defend for-profit care for our seniors? Is she in favour of for-profit private health care too?\nHon. Patty Hajdu: What I am willing to defend is the right for all Canadians to age with safety and dignity.\nMs. Jenny Kwan: To the minister, what is the difference? Why sell out the care of our seniors? Will she commit that she will take profit out of long-term care?\nHon. Patty Hajdu: Mr. Chair, I think the member opposite knows that the only way to actually reform long-term care is to work with provinces and territories, in fact, all levels of government, to ensure that the people who spent their lives caring for and nurturing us can end their lives with caring and nurturing\nThe Acting Chair (Mr. Bruce Stanton): We will go back to Ms. Kwan.\nMs. Jenny Kwan: I think the minister knows that what we need is national standards for seniors' care. The Revera long-term care homes are owned by the Public Sector Pension Investment Board. Since the government owns these homes, has the military been sent in there to see what's happening to seniors under their care?\nHon. Patty Hajdu: Mr. Chair, we know that it is important to work with all of the provinces and territories under whose jurisdiction it falls to protect the seniors within those care homes. That's what we've been doing since the beginning of the outbreak of the coronavirus, and that's what we'll continue to do to protect the lives of seniors and strengthen their protection. We will, as I said, Mr. Chair, work with the provinces and territories to have a longer-term plan so that all seniors can age with dignity and safety.\nMs. Jenny Kwan: The government has a clear responsibility here. What is the government doing to ensure the standards of care in these Revera homes that they own?\nHon. Patty Hajdu: Mr. Chair, as I have repeatedly said, the jurisdiction for care of long-term care homes falls within the provincial and territorial realm. However, that being said, Mr. Chair, we have been there for provinces and territories since the outbreak of the coronavirus, and as the member opposite has clearly or likely heard the Prime Minister say, we will stand with provinces and territories as all elders have the right to age with dignity\nThe Acting Chair (Mr. Bruce Stanton): We go back to Ms. Kwan.\nMs. Jenny Kwan: I didn't hear an answer, Mr. Chair, so the answer is nothing, then. Do you think that the families of the seniors in these homes want to hear those excuses about jurisdictional issues? Does the minister not think that the families want to hear that the federal government is doing all it can to care for their parents?\nThe Acting Chair (Mr. Bruce Stanton): I would remind the members to direct their questions through the chair. The honourable minister.\nHon. Patty Hajdu: Thank you, Mr. Chair. Quite frankly, I don't think that families care which level of government is responsible for caring for their elders. I think what they care about is that their elders are cared for. That's in fact what the Prime Minister believes. That's in fact what our government believes, and that's why we have willingly stepped up to say to provinces and territories that we will be there with you to make sure that all seniors in our lives have the right to age with dignity and care.\nThe Acting Chair (Mr. Bruce Stanton): We will now give the floor to Mrs.Gill, from the riding of Manicouagan. Go ahead, Mrs.Gill.\nMrs. Marilne Gill (Manicouagan, BQ): Mr.Chair, my question is for the Prime Minister who, earlier, clearly told us that the government's assistance is intended for those who are most in need and most vulnerable. I come from a riding where a lot of people make their living from the tourism industry. I don't know if the PrimeMinister read the newspapers yesterday, but in Quebec, losses to the tune of $4billion are expected until March2021 in the tourism accommodation sector alone. The service sector will lose 93,000jobs. How can I justify to my constituents the fact that a political party, which does not need it, has already seen money from the emergency wage subsidy, when people in my riding don't yet have access to it because of the seasonal nature of their work? These people haven't seen the money that is available through these programs.\nHon. Bill Morneau: We think it is very important to protect the country's employees in all sectors of the economy. Through this approach, there will be more jobs after the pandemic, and the economic situation will be better. We will continue this approach.\nMrs. Marilne Gill: Mr.Chair, this is the wrong approach. They are saying that they are protecting the jobs of the Liberal Party of Canada, which does not need the money. I'll ask a question similar to the previous one. Fishers in my riding did not qualify for the emergency wage subsidy. Another program was created for them, which isn't quite the same and doesn't really meet their needs. A government whose political wingnot the parliamentary wingdoesn't really need money takes money from the fund, but leaves fishers to make do with less generous programs that don't meet their needs. What do I tell the fishers in my riding?\nHon. Bill Morneau: Mr.Chair, we know that many sectors of the economy across the country are facing challenges. That's why we have adopted an approach with consistent criteria for all employees in all sectors. We have also introduced specific measures to help certain sectors, such as the fishing industry. We will continue our approach because we believe it's the best way to protect employees and our economy.\nMrs. Marilne Gill: Mr.Chair, I'm still not satisfied. The government is saying that the best way to proceed is to give money to the political wing of the Liberal Party of Canada, when there are people who are getting nothing. What am I supposed to tell seasonal workers, who have absolutely no assurances for their future? I can't go back to my riding and say I'm proud of the work the government is doing or our efforts in the House. It's true, the House is closed right now. I forgot. I have a very hard time accepting that the government is helping employees of the Liberal Party in preparation for the next election campaign, when communities in my region are dying because their economies revolve around a single industry. I can't tell them I'm not ashamed of what's going on as we speak.\nHon. Bill Morneau: Mr.Chair, we felt it was necessary to put emergency programs in place in response to the crisis during the pandemic. That is our approach. The emergency wage subsidy is a program that is clearly meant to ensure employees are protected and maintain their relationship with their employer. As for the Canada emergency response benefit, it means a lot to people who don't have a job. We are going to stick to our approach, which is to use consistent criteria to help all employees and all Canadians around the country struggling in any sector of the economy.\nMrs. Marilne Gill: Mr.Chair, I think the honourable Minister of Finance lives in an ivory tower. No, he is not protecting all jobs. No, he is not protecting all sectors of the economy. Once again, I will say that a party that doesn't need money has already received subsidies. However, people who need that money, people who are actually losing money or who don't know if they'll even be working this summer are getting zilch. There is absolutely no justifying that. I'd at least like to know whether the government is ashamed of what it's doing. When people have a conscience, eventually, they want to make up for their mistakes. Are the Liberals going to return that money? Is the finance minister going to help all sectors of the economy, including tourism, fisheries and seasonal industries?\nHon. Bill Morneau: Mr.Chair, I'd like to thank the member for her question. Our approach is based on consistent criteria. The emergency wage subsidy is meant for any sector of the economy where revenues have dropped by 30% or more. The measure is hugely important for organizations that are really struggling, because we can protect their workers. We are also providing the Canada emergency response benefit to other employees, meaning, those who have lost their income because of COVID-19. Consequently, we will keep up our approach to ensure we continue to fare as well as possible and the economy works well after the pandemic.\nThe Acting Chair (Mr. Bruce Stanton): Now we'll go to our last group of interventions, and that will be from Ms. Jansen in CloverdaleLangley City. Ms. Jansen, go ahead.\nMrs. Tamara Jansen (CloverdaleLangley City, CPC): Thank you, Mr. Chair. I'd like to begin with a shout-out to the brave waiters and waitresses at our local Earls restaurant and Browns Socialhouse, who have been opened again for on-site dining this week. Here in B.C. we're beginning to find our new normal, and it was great to see how small businesses have so quickly adapted their establishments to keep their workers and patrons safe while allowing people to get back to the business of living. You guys rock. Thanks for taking the lead. Mr. Chair, here in my riding I recently had contact with the mayor of Langley City who was wondering if I had any way of accessing personal protective gear, because our local firefighters were running out of stock. Then again yesterday, I spoke with one of our local homeless shelters that is also looking for PPE. Dr. Tam is telling all Canadians to wear masks in public, but I'm wondering if the Minister of Public Service and Procurement could tell us where exactly we're going to get all those masks with the current shortage.\nHon. Anita Anand: I want to be clear that our priority as a federal government has been to respond to provincial and territorial requests for PPE that goes to front-line health care workers. That is our priority, and we've been procuring goods aggressively in domestic and international markets. We are now actively also exploring ways in which we can assist broader organizations across the country with PPE needs, and that is something that I'll continue to update the House on as we go forward.\nMrs. Tamara Jansen: A Globe and Mail article revealed that government orders for N95 masks have steadily been dropping. We've gone from over 200 million ordered to 100 million, according to a federal source. Mr. Chair, the number of N95 masks ordered, as reported on the department's website, does continue to fall. Will the minister tell us why we seem to continue to struggle to supply PPE to Canadians?\nHon. Anita Anand: It is no secret that we are in a global competition for N95 masks and other supplies, so the Government of Canada's approach is to diversify supply chains internationally and build up and retool domestic industry so that we can have these supplies going forward. In terms of the numbers on our web page, we have short-term and long-term contracts in place\nThe Acting Chair (Mr. Bruce Stanton): We go back to Ms. Jansen.\nMrs. Tamara Jansen: Yes, I understand that a number of Chinese mask manufacturers have been nationalized, and products for Canadians have been confiscated by the CCP government. Is the drop in N95 orders due to, in actual fact, contracts being cancelled?\nHon. Anita Anand: On N95 masks, I would like to assure the member and the House that we have multiple contracts in place for the procurement of N95 masks, including with 3M in the United States, whose masks are crossing our border weekly over the next month.\nMrs. Tamara Jansen: That didn't quite answer my question. Have any of our orders been cancelled by the nationalization of these manufacturers in China?\nHon. Anita Anand: We have an aide in place in China. We have our embassy and other firms actively ensuring that our supplies from the manufacturing source make their way to the warehouse. Over 40 flights have come to Canada with those masks and other supplies. Our supply chains are operating despite the global environment being highly competitive.\nMrs. Tamara Jansen: We know many millions of N95 masks have arrived in Canada from China and have been substandard. What is the total number of substandard masks that have arrived?\nHon. Anita Anand: Mr. Chair, as previously explained to the House, about eight million masks did not meet spec by the Public Health Agency of Canada and have been repurposed to some extent in other areas of the system.\nMrs. Tamara Jansen: In a previous committee, the deputy minister advised us that Medicom was shoulder-tapped by the government to consider producing PPE. How many other companies did the government approach for this contract?\nHon. Anita Anand: We have operated in a very urgent way in order to procure supplies for front-line health care workers. We are now also moving to ensure that we have competitions run for the procurement of personal protective equipment. It's a multi-pronged approach, and our priority is to get supplies out to front-line health care workers in this time of crisis as quickly as possible. Thank you so much.\nThe Acting Chair (Mr. Bruce Stanton): Just before we adjourn, I think this another mark of accomplishment on behalf of the great team here at the House of Commons. There have been some great efforts, even since yesterday evening, to get this turned around for today. My compliments to all members joining us here in the House and to all members who have joined by virtual conference. The committee is now adjourned until noon tomorrow. The meeting is adjourned.", "source": "meeting_summ", "evaluation": "rouge"}
{"instructions": ["Summarize the discussion on TORRENT schedule and intermediate categorization", "What did Grad F say about his proposal?", "What did Grad F think about intermediate categories?", "Summarize the discussion on mean subtraction in SRI", "What did the professor think about echoes and reverberation?", "What did PhD C think about the signal to noise ratio?", "Summarize the meeting"], "outputs": ["The professor told the team that the TORRENT chip schedule kept getting pushed. Then, Grad F talked about his proposal, in which he was done with the section on intermediate categories. Including features from intermediate categories was a potential way of reducing error.", "Grad F explained that he was focusing on writing his proposal for his qualification exams, which was on the 25th of July. He had to write a paper and pass it around before that date.", "Grad F informed the team that he was building a system that classified intermediate categories with multi-band techniques. Then, to reduce error for phoneme recognition, the intermediate categories could be added to improve performance. The method could be replicated for large vocabulary tasks like switchboard.", "The team got an improvement on the SRI system for TI- digits and Meeting Recorder digits but near mic performance worsened. The team explored the reasons for this difference. The professor suggested getting rid of low energy sections. The team also discussed how more nuanced normalization approaches could improve task performance.", "The professor thought it was possible to reduce the effects of reverberation by removing the low-energy segments. He thought a VAD-like approach would work. This would make it so that the model was more likely to keep an echo than throw out speech.", "PhD C was skeptical of why the signal was louder after processing. PhD C suggested that the system is not too dependent on the signal level, agreeing with the professor that improvement in the model was more likely dependent on the ratio.", "The meeting began with a discussion on the TORRENT project completion being pushed for two years. Grad F then introduced intermediate categorization, which was his topic for his qualification exams. The team then discussed mean subtraction from SRI. Using it had led to an improvement in Meeting Recorder digits though near mic performance worsened. The professor points to pre-echoes as the culprit. The team continued to study differences between SRI and Aurora. The team thought it would be interesting to do the Aurora tests with the SRI system instead of the HTK. The team was also exploring the Wiener filter and VTS. The professor did not seem too excited about the VTS."], "input": "Professor B: I think for two years we were two months , uh , away from being done .\nPhD A: And what was that , Morgan ? What project ?\nProfessor B: Uh , the , uh , TORRENT chip .\nPhD A: Oh .\nProfessor B: Yeah . We were two {disfmarker} we were {disfmarker}\nPhD C: Yeah .\nProfessor B: Uh , uh , we went through it {disfmarker} Jim and I went through old emails at one point and {disfmarker} and for two years there was this thing saying , yeah , we 're {disfmarker} we 're two months away from being done . It was very {disfmarker} very believable schedules , too . I mean , we went through and {disfmarker} with the schedules {disfmarker} and we {disfmarker}\nPhD A: It was true for two years .\nProfessor B: Yeah . Oh , yeah . It was very true .\nPhD A: So , should we just do the same kind of deal where we {pause} go around and do , uh , status report {pause} kind of things ? OK . And I guess when Sunil gets here he can do his last or something . So .\nProfessor B: Yeah . So we {pause} probably should wait for him to come before we do his .\nPhD C: Mm - hmm .\nPhD A: OK . That 's a good idea .\nProfessor B: Yeah .\nGrad F: OK .\nProfessor B: Yeah .\nPhD A: Any objection ? Do y OK , M\nProfessor B: All in favor\nPhD A: Do you want to start , Morgan ? Do you have anything , or {disfmarker} ?\nProfessor B: Uh , I don't do anything . I {disfmarker} No , I mean , I {disfmarker} I 'm involved in discussions with {disfmarker} with people about what they 're doing , but I think they 're {disfmarker} since they 're here , they can talk about it themselves .\nGrad F: OK . So should I go so that , uh ,\nPhD A: Yeah . Why don't you go ahead , Barry ?\nGrad F: you 're gonna talk about Aurora stuff , per se ?\nPhD A: OK .\nGrad F: OK . Um . Well , this past week I 've just been , uh , getting down and dirty into writing my {disfmarker} my proposal . So , um {disfmarker} Mmm . I just finished a section on , uh {disfmarker} on talking about these intermediate categories that I want to classify , um , as a {disfmarker} as a middle step . And , um , I hope to {disfmarker} hope to get this , um {disfmarker} a full rough draft done by , uh , Monday so I can give it to Morgan .\nPhD A: When is your , uh , meeting ?\nGrad F: Um , my meeting\nPhD A: Yeah .\nGrad F: with , uh {disfmarker} ? Oh , oh , you mean the {disfmarker} the quals .\nPhD A: The quals . Yeah .\nGrad F: Uh , the quals are happening in July twenty - fifth .\nPhD A: Oh . Soon .\nGrad F: Yeah .\nPhD A: Uh - huh .\nGrad F: D - Day .\nPhD A: Yeah .\nGrad F: Uh - huh .\nPhD A: So , is the idea you 're going to do this paper and then you pass it out to everybody ahead of time and {disfmarker} ?\nGrad F: Right , right . So , y you write up a proposal , and give it to people ahead of time , and you have a short presentation . And , um , and then , um {disfmarker} then everybody asks you questions .\nPhD A: Hmm .\nGrad F: Yeah .\nPhD A: I remember now .\nGrad F: Yep . So , um .\nPhD A: Have you d ? I was just gonna ask , do you want to say any {disfmarker} a little bit about it ,\nGrad F: Y s\nPhD A: or {disfmarker} ? Mmm .\nGrad F: Oh . Uh , a little bit about {disfmarker} ?\nPhD A: Wh - what you 're {disfmarker} what you 're gonna {disfmarker} You said {disfmarker} you were talking about the , uh , particular features that you were looking at ,\nGrad F: Oh , the {disfmarker} the {disfmarker}\nPhD A: or {disfmarker}\nGrad F: Right . Well , I was , um , I think one of the perplexing problems is , um , for a while I was thinking that I had to come up with a complete set of intermediate features {disfmarker} in intermediate categories to {disfmarker} to classify right away . But what I 'm thinking now is , I would start with {disfmarker} with a reasonable set . Something {disfmarker} something like , um , um {disfmarker} like , uh , re regular phonetic features , just to {disfmarker} just to start off that way . And do some phone recognition . Um , build a system that , uh , classifies these , um {disfmarker} these feat uh , these intermediate categories using , uh , multi - band techniques . Combine them and do phon phoneme recognition . Look at {disfmarker} then I would look at the errors produced in the phoneme recognition and say , OK , well , I could probably reduce the errors if I included this extra feature or this extra intermediate category . That would {disfmarker} that would reduce certain confusions over other confusions . And then {disfmarker} and then {vocalsound} reiterate . Um , build the intermediate classifiers . Uh , do phoneme recognition . Look at the errors . And then postulate new {disfmarker} or remove , um , intermediate categories . And then do it again .\nPhD A: So you 're gonna use TIMIT ?\nGrad F: Um , for that {disfmarker} for that part of the {disfmarker} the process , yeah , I would use TIMIT .\nPhD A: Mm - hmm .\nGrad F: And , um , then {disfmarker} after {disfmarker} after , uh , um , doing TIMIT . Right ?\nPhD A: Mm - hmm .\nGrad F: Um , that 's {disfmarker} {vocalsound} that 's , um {disfmarker} that 's just the ph the phone recognition task .\nPhD A: Yeah .\nGrad F: Uh , I wanted to take a look at , um , things that I could model within word . So , I would mov I would then shift the focus to , um , something like Schw - Switchboard , uh , where I 'd {disfmarker} I would be able to , um {disfmarker} to model , um , intermediate categories that span across phonemes ,\nPhD A: Mm - hmm .\nGrad F: not just within the phonemes , themselves , um , and then do the same process there , um , on {disfmarker} on a large vocabulary task like Switchboard . Uh , and for that {disfmarker} for that part I would {disfmarker} I 'd use the SRI recognizer since it 's already set up for {disfmarker} for Switchboard . And I 'd run some {disfmarker} some sort of tandem - style processing with , uh , my intermediate classifiers .\nPhD A: Oh . So that 's why you were interested in getting your own features into the SRI files .\nGrad F: Yeah . That 's why I {disfmarker} I was asking about that .\nPhD A: Yeah . Yeah .\nGrad F: Yeah . Um , and I guess that 's {disfmarker} that 's it . Any {disfmarker} any questions ?\nPhD A: Sounds good . So you just have a few more weeks , huh ?\nGrad F: Um , yeah . A few more .\nPhD A: It 's about a month from now ?\nGrad F: It 's a {disfmarker} it 's a month and {disfmarker} and a week .\nPhD A: Yeah .\nGrad F: Yeah .\nPhD A: So , uh , you want to go next , Dave ? And we 'll do {disfmarker}\nGrad E: Oh . OK , sure . So , um , last week I finally got results from the SRI system about this mean subtraction approach . And , um , we {disfmarker} we got an improvement , uh , in word error rate , training on the TI - digits data set and testing on Meeting Recorder digits of , um , {vocalsound} six percent to four point five percent , um , on the n on the far - mike data using PZM F , but , um , the near - mike performance worsened , um , from one point two percent to two point four percent . And , um , wh why would that be , um , {vocalsound} considering that we actually got an improvement in near - mike performance using HTK ? And so , uh , with some input from , uh , Andreas , I have a theory in two parts . Um , first of all HTK {disfmarker} sorry , SR - the SRI system is doing channel adaptation , and so HTK wasn't . Um , so this , um {disfmarker} This mean subtraction approach will do a kind of channel {pause} normalization and so that might have given the HTK use of it a boost that wouldn't have been applied in the SRI case . And also , um , the {disfmarker} Andreas pointed out the SRI system is using more parameters . It 's got finer - grained acoustic models . So those finer - grained acoustic models could be more sensitive to the artifacts {pause} in the re - synthesized audio . Um . And me and Barry were listening to the re - synthesized audio and sometimes it seems like you get of a bit of an echo of speech in the background . And so that seems like it could be difficult for training , cuz you could have {pause} different phones {pause} lined up with a different foreground phone , {vocalsound} um , {vocalsound} depending on {pause} the timing of the echo . So , um , I 'm gonna try training on a larger data set , and then , eh , the system will have seen more examples o of these artifacts and hopefully will be more robust to them . So I 'm planning to use the Macrophone set of , um , read speech , and , um {disfmarker} Hmm .\nProfessor B: I had another thought just now , which is , uh , remember we were talking before about {disfmarker} we were talking in our meeting about , uh , this stuff that {disfmarker} some of the other stuff that Avendano did , where they were , um , getting rid of low - energy {pause} sections ? Um , uh , if you {disfmarker} if you did a high - pass filtering , as Hirsch did in {pause} late eighties to reduce some of the effects of reverberation , uh , uh , Avendano and Hermansky were arguing that , uh , perhaps one of the reasons for that working was ma may not have even been the filtering so much but the fact that when you filter a {disfmarker} an all - positive power spectrum you get some negative values , and you gotta figure out what to do with them if you 're gonna continue treating this as a power spectrum . So , what {disfmarker} what Hirsch did was , uh , set them to zero {disfmarker} set the negative values to zero . So if you imagine a {disfmarker} a waveform that 's all positive , which is the time trajectory of energy , um , and , uh , shifting it downwards , and then getting rid of the negative parts , that 's essentially throwing away the low - energy things . And it 's the low - energy parts of the speech where the reverberation is most audible . You know , you have the reverberation from higher - energy things showing up in {disfmarker} So in this case you have some artificially imposed {pause} reverberation - like thing . I mean , you 're getting rid of some of the other effects of reverberation , but because you have these non - causal windows , you 're getting these funny things coming in , uh , at n And , um , what if you did {disfmarker} ? I mean , there 's nothing to say that the {disfmarker} the processing for this re - synthesis has to be restricted to trying to get it back to the original , according to some equation . I mean , you also could , uh , just try to make it nicer .\nGrad E: Uh - huh .\nProfessor B: And one of the things you could do is , you could do some sort of VAD - like thing\nGrad E: Mm - hmm .\nProfessor B: and you actually could take very low - energy sections and set them to some {disfmarker} some , uh , very low or {disfmarker} or near zero {pause} value . I mean , uh , I 'm just saying if in fact it turns out that {disfmarker} that these echoes that you 're hearing are , uh {disfmarker}\nGrad E: Uh - huh .\nProfessor B: or pre - echoes , whichever they are {disfmarker} are {disfmarker} are , uh , part of what 's causing the problem , you actually could get rid of them .\nGrad E: Uh - huh .\nProfessor B: Be pretty simple . I mean , you do it in a pretty conservative way\nGrad E: OK .\nProfessor B: so that if you made a mistake you were more likely to {pause} keep in an echo than to throw out speech .\nGrad E: Hmm .\nPhD G: Um , what is the reverberation time {pause} like {pause} there ?\nGrad E: In thi in this room ? Uh {disfmarker}\nPhD G: On , uh , the {disfmarker} the one what {disfmarker} the s in the speech that you are {disfmarker} you are using like ?\nGrad E: Y Yeah . I {disfmarker} I {disfmarker} I {disfmarker} I don't know .\nProfessor B: So , it 's this room .\nPhD G: It 's , uh {disfmarker}\nProfessor B: It 's {disfmarker} it 's this room .\nPhD G: Oh , this room ?\nProfessor B: So {disfmarker}\nPhD G: OK .\nProfessor B: so it 's {disfmarker} these are just microphone {disfmarker} this micro close microphone and a distant microphone , he 's doing these different tests on .\nGrad F: Oh .\nProfessor B: Uh , we should do a measurement in here . I g think we never have . I think it 's {disfmarker} I would guess , uh , point seven , point eight seconds f uh , R T\nGrad F: Hmm !\nProfessor B: something like that ? But it 's {disfmarker} you know , it 's this room .\nPhD G: Mm - hmm .\nProfessor B: So .\nPhD G: OK . Mm - hmm .\nProfessor B: Uh . But the other thing is , he 's putting in {disfmarker} w I was using the word \" reverberation \" in two ways . He 's also putting in , uh , a {disfmarker} he 's taking out some reverberation , but he 's putting in something , because he has {pause} averages over multiple windows stretching out to twelve seconds , which are then being subtracted from the speech . And since , you know , what you subtract , sometimes you 'll be {disfmarker} you 'll be subtracting from some larger number and sometimes you won't . And {disfmarker}\nPhD G: Mm - hmm . Mm - hmm .\nProfessor B: So you can end up with some components in it that are affected by things that are seconds away . Uh , and if it 's a low {pause} energy compo portion , you might actually hear some {pause} funny things .\nPhD G: Yeah .\nGrad E: O o one thing , um , I noticed is that , um , the mean subtraction seems to make the PZM signals louder after they 've been re - synthesized . So I was wondering , is it possible that one reason it helped with the Aurora baseline system is {pause} just as a kind of gain control ? Cuz some of the PZM signals sound pretty quiet if you don't amplify them .\nPhD C: Mm - hmm . I don't see why {disfmarker} why your signal is louder after processing , because yo\nGrad E: Yeah . I don't know why - y , uh , either .\nPhD C: Yeah .\nProfessor B: I don't think just multiplying the signal by two would have any effect .\nPhD C: Mm - hmm .\nGrad E: Oh , OK .\nProfessor B: Yeah . I mean , I think if you really have louder signals , what you mean is that you have {pause} better signal - to - noise ratio .\nPhD C: Well , well {disfmarker}\nProfessor B: So if what you 're doing is improving the signal - to - noise ratio , then it would be better .\nPhD C: Mm - hmm .\nProfessor B: But just it being bigger if {disfmarker} with the same signal - to - noise ratio {disfmarker}\nGrad E: It w i i it wouldn't affect things .\nProfessor B: No .\nPhD C: Yeah .\nGrad E: OK .\nPhD C: Well , the system is {disfmarker} use {pause} the absolute energy , so it 's a little bit dependent on {disfmarker} on the {pause} signal level . But , not so much , I guess .\nProfessor B: Well , yeah . But it 's trained and tested on the same thing .\nPhD C: Mmm .\nProfessor B: So if the {disfmarker} if the {disfmarker} if you change {vocalsound} in both training and test , the absolute level by a factor of two , it will n have no effect .\nPhD C: Mm - hmm . Yeah .\nPhD A: Did you add {pause} this data to the training set , for the Aurora ? Or you just tested on this ?\nGrad E: Uh {disfmarker} Um . Did I w what ?\nPhD A: Well , Morgan was just saying that , uh , as long as you do it in both training and testing , it shouldn't have any effect .\nGrad E: Sorry ? Yeah .\nPhD A: But I {disfmarker} I was {pause} sort of under the impression that you just tested with this data .\nGrad E: I {disfmarker} I b\nPhD A: You didn't {pause} train it also .\nGrad E: I {disfmarker} Right . I trained on clean TI - digits . I {disfmarker} I did the mean subtraction on clean TI - digits . But I didn't {disfmarker} I 'm not sure if it made the clean ti TI - digits any louder .\nProfessor B: Oh , I see .\nGrad E: I only remember noticing it made the , um , PZM signal louder .\nProfessor B: OK . Well , I don't understand then . Yeah .\nGrad E: Huh . I don't know . If it 's {disfmarker} if it 's {disfmarker} like , if it 's trying to find a {disfmarker} a reverberation filter , it could be that this reverberation filter is making things quieter . And then if you take it out {disfmarker} that taking it out makes things louder . I mean .\nProfessor B: Uh , no . I mean , {vocalsound} uh , there 's {disfmarker} there 's nothing inherent about removing {disfmarker} if you 're really removing ,\nGrad E: Nuh - huh .\nProfessor B: uh , r uh , then I don't {pause} see how that would make it louder .\nGrad E: The mean . OK . Yeah , I see .\nProfessor B: So it might be just some {disfmarker}\nGrad E: Yeah . OK . So I should maybe listen to that stuff again .\nProfessor B: Yeah . It might just be some artifact of the processing that {disfmarker} that , uh , if you 're {disfmarker} Uh , yeah . I don't know .\nGrad E: Oh . OK .\nPhD A: I wonder if there could be something like , uh {disfmarker} for s for the PZM data ,\nPhD C: Eh\nPhD A: uh , you know , if occasionally , uh , somebody hits the table or something , you could get a spike . Uh . I 'm just wondering if there 's something about the , um {disfmarker} you know , doing the mean normalization where , uh , it {disfmarker} it could cause {pause} you to have better signal - to - noise ratio . Um .\nProfessor B: Well , you know , there is this . Wait a minute . It {disfmarker} it {disfmarker} i maybe {disfmarker} i If , um {disfmarker} Subtracting the {disfmarker} the mean log spectrum is {disfmarker} is {disfmarker} is like dividing by the spectrum . So , depending what you divide by , if your {disfmarker} if s your estimate is off and sometimes you 're {disfmarker} you 're {disfmarker} you 're getting a small number , you could make it bigger .\nPhD A: Mm - hmm .\nGrad E: Mm - hmm .\nProfessor B: So , it 's {disfmarker} it 's just a {disfmarker} a question of {disfmarker} there 's {disfmarker} It {disfmarker} it could be that there 's some normalization that 's missing , or something to make it {disfmarker}\nGrad E: Mm - hmm .\nProfessor B: Uh , y you 'd think it shouldn't be larger , but maybe in practice it is . That 's something to think about .\nGrad E: Hmm .\nProfessor B: I don't know .\nPhD C: I had a question about the system {disfmarker} the SRI system . So , {vocalsound} you trained it on TI - digits ? But except this , it 's exactly the same system as the one that was tested before and that was trained on {pause} Macrophone . Right ? So on TI - digits it gives you one point two percent error rate and on Macrophone it 's still O point eight . Uh , but is it {pause} exactly the same system ?\nGrad E: Uh . I think so .\nPhD C: Hmm .\nGrad E: If you 're talking about the Macrophone results that Andreas had about , um , a week and a half ago , I think it 's the same system .\nPhD C: Mm - hmm . So you use VTL - uh , vocal tract length normalization and , um , like MLLR transformations also ,\nGrad E: Mm - hmm .\nPhD C: and {disfmarker}\nProfessor B: I 'm sorry , was his point eight percent , er , a {disfmarker} a result on testing on Macrophone or {disfmarker} or training ?\nPhD C: all that stuff .\nGrad E: That 's {disfmarker}\nPhD C: It was {pause} training on Macrophone and testing {disfmarker} yeah , on {disfmarker} on meeting digits .\nProfessor B: Oh . So that was done already . So we were {disfmarker} Uh , and it 's point eight ? OK .\nPhD C: Mm - hmm .\nProfessor B: OK .\nPhD C: Yeah . I {disfmarker} I 've just been text {comment} testing the new {pause} Aurora front - end with {disfmarker} well , Aurora system actually {disfmarker} so front - end and HTK , um , acoustic models on the meeting digits and it 's a little bit better than the previous system . We have {disfmarker} I have two point seven percent error rate . And before with the system that was proposed , it 's what ? It was three point nine . So .\nProfessor B: Oh , that 's a lot better .\nPhD C: We are getting better .\nProfessor B: So , what {disfmarker} w ?\nPhD C: And {disfmarker}\nPhD G: With the {disfmarker} with the HTK back - end ? What we have for Aurora ?\nPhD C: Yeah . Two point seven .\nPhD G: I know in the meeting , like {disfmarker}\nPhD C: On the meeting we have two point seven .\nPhD G: Right . Oh .\nGrad F: That 's with the new IIR filters ?\nPhD C: Uh . Yeah , yeah . So , yeah ,\nGrad F: OK .\nPhD C: we have {pause} the new LDA filters , and {disfmarker} I think , maybe {disfmarker} I didn't look , but one thing that makes a difference is this DC offset compensation . Uh , eh {disfmarker} Do y did you have a look at {disfmarker} at the meet uh , meeting digits , if they have a DC component , or {disfmarker} ?\nGrad E: I {disfmarker} I didn't . No .\nPhD C: Oh .\nProfessor B: Hmm .\nPhD G: No . The DC component could be negligible . I mean , if you are {pause} recording it through a mike . I mean , any {disfmarker} all of the mikes have the DC removal {disfmarker} some capacitor sitting right in {pause} that bias it .\nProfessor B: Yeah . But this {disfmarker} uh , uh , uh , no . Because , uh , there 's a sample and hold in the A - toD. And these period these typically do have a DC offset .\nPhD G: Oh , OK .\nProfessor B: And {disfmarker} and they can be surprisingly large . It depends on the electronics .\nPhD G: Oh , so it is the digital {disfmarker} OK . It 's the A - toD that introduces the DC in .\nProfessor B: Yeah . The microphone isn't gonna pass any DC .\nPhD G: Yeah . Yeah . Yeah .\nProfessor B: But {disfmarker} but ,\nPhD G: OK .\nProfessor B: typi you know , unless {disfmarker} Actually , there are {pause} instrumentation mikes that {disfmarker} that do pass {disfmarker} go down to DC . But {disfmarker} but ,\nPhD G: Mm - hmm .\nProfessor B: uh , no , it 's the electronics . And they {disfmarker} and {disfmarker}\nPhD G: Mm - hmm .\nProfessor B: then there 's amplification afterwards . And you can get , I think it was {disfmarker} I think it was in the {pause} Wall Street Journal data that {disfmarker} that {disfmarker} I can't remember , one of the DARPA things . There was this big DC - DC offset\nPhD A: Mm - hmm .\nProfessor B: we didn't {disfmarker} we didn't know about for a while , while we were {pause} messing with it . And we were getting these terrible results . And then we were talking to somebody and they said , \" Oh , yeah . Didn't you know ? Everybody knows that . There 's all this DC offset in th \" So , yes . You can have DC offset in the data .\nPhD G: Oh , OK .\nProfessor B: Yeah .\nPhD G: OK .\nPhD A: So was that {disfmarker} was that everything , Dave ?\nGrad E: Oh . And I also , um , did some experiments {pause} about normalizing the phase . Um . So I c I came up with a web page that people can take a look at . And , um , the interesting thing that I tried was , um , Adam and Morgan had this idea , um , since my original attempts to , um , take the mean of the phase spectra over time and normalize using that , by subtracting that off , didn't work . Um , so , well , that we thought that might be due to , um , problems with , um , the arithmetic of phases . They {disfmarker} they add in this modulo two pi way and , um , there 's reason to believe that that approach of taking the mean of the phase spectrum wasn't really {pause} mathematically correct . So , {vocalsound} what I did instead is I {vocalsound} took the mean of the FFT spectrum without taking the log or anything , and then I took the phase of that , and I subtracted that phase {pause} off to normalize . But that , um , didn't work either .\nProfessor B: See , we have a different interpretation of this . He says it doesn't work . I said , I think it works magnificently , but just not for the task we intended . Uh , it gets rid of the speech .\nPhD A: What does it leave ?\nGrad F: Uh , gets rid of the speech .\nProfessor B: Uh , it leaves {disfmarker} you know , it leaves the junk . I mean , I {disfmarker} I think it 's {disfmarker} it 's tremendous .\nGrad F: Oh , wow .\nProfessor B: You see , all he has to do is go back and reverse what he did before , and he 's really got something .\nPhD A: Well , could you take what was left over and then subtract that ?\nProfessor B: Ex - exactly . Yeah , you got it .\nGrad F: Yeah .\nPhD G: Yeah .\nProfessor B: So , it 's {disfmarker} it 's a general rule .\nPhD G: Oh , it 's {disfmarker}\nProfessor B: Just listen very carefully to what I say and do the opposite . Including what I just said .\nGrad E: And , yeah , that 's everything .\nPhD A: All set ? Do you want to go , Stephane ?\nPhD C: Um . Yeah . Maybe , concerning these d still , these meeting digits . I 'm more interested in trying to figure out what 's still the difference between the SRI system and the Aurora system . And {disfmarker} Um . Yeah . So , I think I will maybe train , like , gender - dependent models , because {pause} this is also one big difference between {pause} the two systems . Um , the other differences were {pause} the fact that maybe the acoustic models of the SRI are more {disfmarker} SRI system are more complex . But , uh , Chuck , you did some experiments with this and\nPhD A: It didn't seem to help in the HTK system .\nPhD C: it was hard t to {disfmarker} to have some exper some improvement with this . Um .\nProfessor B: Well , it sounds like they also have {disfmarker} he {disfmarker} he 's saying they have all these , uh , uh , different kinds of adaptation .\nPhD C: Mm - hmm .\nProfessor B: You know , they have channel adaptation . They have speaker adaptation .\nPhD C: Yeah . Right .\nPhD A: Well , there 's also the normalization .\nProfessor B: Yeah . Yeah .\nPhD C: Yeah .\nGrad F: Yeah .\nPhD A: Like they do , um {disfmarker} I 'm not sure how they would do it when they 're working with the digits ,\nPhD C: The vocal tr\nPhD A: but , like , in the Switchboard data , there 's , um {disfmarker} conversation - side normalization for the {pause} non - C - zero components ,\nPhD C: Yeah . Yeah . This is another difference . Their normalization works like on {disfmarker} on the utterance levels .\nPhD A: Mm - hmm .\nPhD C: But we have to do it {disfmarker} We have a system that does it on - line .\nPhD A: Right .\nPhD C: So , it might be {disfmarker} it might be better with {disfmarker} it might be worse if the {pause} channel is constant ,\nPhD A: Yeah .\nPhD C: or {disfmarker} Nnn .\nPhD G: And the acoustic models are like - k triphone models or {disfmarker} or is it the whole word ?\nPhD C: SRI {disfmarker} it 's {disfmarker} it 's tr\nGrad F: SRI .\nPhD G: Yeah .\nPhD C: Yeah . I guess it 's triphones .\nPhD G: It 's triphone .\nProfessor B: I think it 's probably more than that .\nPhD C: Huh .\nProfessor B: I mean , so they {disfmarker} they have {disfmarker} I {disfmarker} I thin think they use these , uh , uh , genone things . So there 's {disfmarker} there 's these kind of , uh , uh , pooled models and {disfmarker} and they can go out to all sorts of dependencies .\nPhD G: Oh . It 's like the tied state .\nProfessor B: So .\nPhD A: Mm - hmm .\nProfessor B: They have tied states and I think {disfmarker} I {disfmarker} I {disfmarker} I don't real I 'm talk I 'm just guessing here . But I think {disfmarker} I think they {disfmarker} they don't just have triphones .\nPhD G: OK .\nProfessor B: I think they have a range of {disfmarker} of , uh , dependencies .\nPhD C: Mm - hmm .\nPhD G: Mm - hmm .\nPhD C: Mm - hmm .\nGrad F: Hmm .\nPhD C: And {disfmarker} Yeah . Well . Um . Well , the first thing I {disfmarker} that I want to do is just maybe these gender things . Uh . And maybe see with {pause} Andreas if {disfmarker} Well , I {disfmarker} I don't know {pause} how much it helps , what 's the model .\nPhD A: So {disfmarker} so the n stuff on the numbers you got , the two point seven , is that using the same training data that the SRI system used and got one point two ?\nPhD C: That 's right . So it 's the clean {pause} TI - digits training set .\nPhD A: So exact same training data ?\nPhD C: Right .\nPhD A: OK .\nPhD C: Mm - hmm . I guess you used the clean training set .\nGrad E: Right .\nPhD C: Mm - hmm .\nGrad E: For {disfmarker} with the SRI system {disfmarker}\nPhD C: Well .\nGrad E: You know , the {disfmarker} the Aurora baseline is set up with these , um {disfmarker} {vocalsound} this version of the clean training set that 's been filtered with this G - seven - one - two filter , and , um , to train the SRI system on digits S - Andreas used the original TI - digits , um , under U doctor - speech data TI - digits , which don't have this filter . But I don't think there 's any other difference .\nPhD C: Mm - hmm . Mm - hmm . Yeah .\nProfessor B: So is that {disfmarker} ? Uh , are {disfmarker} are these results comparable ? So you {disfmarker} you were getting with the , uh , Aurora baseline something like two point four percent {pause} on clean TI - digits , when , uh , training the SRI system with clean TR digits {disfmarker} {comment} TI - digits . Right ? And {disfmarker}\nGrad E: Um . Uh - huh .\nProfessor B: Yeah . And , so , is your two point seven comparable , where you 're , uh , uh , using , uh , the submitted system ?\nPhD C: Yeah . I think so .\nProfessor B: OK .\nPhD C: Yeah .\nProfessor B: So it 's {pause} about the same ,\nPhD C: Mm - hmm .\nProfessor B: maybe a little worse .\nGrad E: W w it was one {disfmarker} one point two\nPhD C: Ye\nGrad E: with the SRI system ,\nProfessor B: I 'm sorry .\nPhD C: Yeah .\nGrad E: I {disfmarker}\nPhD C: The complete SRI system is one point two .\nProfessor B: You {disfmarker} you were HTK .\nPhD C: Yeah .\nProfessor B: Right ? OK . That 's right . So {disfmarker}\nPhD C: Mm - hmm .\nProfessor B: OK , so {pause} the comparable number then , uh {pause} for what you were talking about then , since it was HTK , would be the {pause} um , two point f\nPhD C: It was four point something . Right ? The HTK system with , uh , b\nGrad E: D d\nProfessor B: Oh , right , right , right , right .\nPhD C: MFCC features {disfmarker}\nGrad E: Do you mean the b ? The baseline Aurora - two system , trained on TI - digits , tested on Meeting Recorder near , I think we saw in it today , and it was about six point six percent .\nProfessor B: Right . Right , right , right .\nPhD C: Oh .\nProfessor B: OK . Alright . So {disfmarker} He 's doing some {pause} different things .\nPhD C: So {disfmarker} Yeah . The only difference is the features , right now , between this and {disfmarker}\nProfessor B: Yes . OK , good . So they are helping .\nPhD C: Mm - hmm .\nProfessor B: That 's good to hear . Yeah .\nPhD C: They are helping . Yeah . Um . Yeah . And another thing I {disfmarker} I maybe would like to do is to {pause} just test the SRI system that 's trained on Macrophone {disfmarker} test it on , uh , the noisy TI - digits ,\nProfessor B: Yeah .\nPhD C: cuz I 'm still wondering {pause} where this {pause} improvement comes from . When you train on Macrophone , it seems better on meeting digits . But I wonder if it 's just because maybe {pause} Macrophone is acoustically closer to the meeting digits than {disfmarker} than TI - digit is , which is {disfmarker} TI - digits are very {pause} clean recorded digits\nProfessor B: Mm - hmm .\nPhD C: and {disfmarker}\nPhD A: You know , it would also be interesting to see , uh {disfmarker} to do the regular Aurora test ,\nPhD C: Uh , f s\nPhD A: um , but use the SRI system instead of HTK .\nPhD C: That 's {disfmarker} Yeah . That 's what {pause} I wanted , just , uh {disfmarker} Yeah . So , just using the SRI system , test it on {disfmarker} and test it on {pause} Aurora TI - digits . Right .\nPhD A: Why not the full Aurora , uh , test ?\nPhD C: Um . Yeah . There is this problem of multilinguality yet .\nPhD A: Mm - hmm .\nPhD C: So we don't {disfmarker}\nProfessor B: You 'd have to train the SRI system with {disfmarker} with all the different languages .\nPhD C: i i\nPhD A: Right .\nPhD C: We would have to train on {disfmarker}\nPhD A: Yeah . That 's what I mean .\nPhD C: Yeah .\nPhD A: So , like , comple\nProfessor B: It 'd be a {pause} lot of work . That 's the only thing .\nPhD C: Yeah .\nPhD A: Mmm .\nPhD C: It 's {disfmarker}\nPhD A: Well , I mean ,\nPhD C: Mmm .\nPhD A: uh , uh , I guess the work would be into getting the {disfmarker} the files in the right formats , or something . Right ? I mean {disfmarker}\nPhD C: Mm - hmm .\nPhD A: Because when you train up the Aurora system , you 're , uh {disfmarker} you 're also training on all the data .\nPhD C: That 's right .\nPhD A: I mean , it 's {disfmarker}\nPhD C: Yeah . Yeah . I see . Oh , so , OK . Right . I see what you mean .\nProfessor B: That 's true , but I think that also when we 've had these meetings week after week , oftentimes people have not done the full arrange of things\nPhD A: Mm - hmm .\nProfessor B: because {disfmarker} on {disfmarker} on whatever it is they 're trying , because it 's a lot of work , even just with the HTK .\nPhD A: Mm - hmm .\nProfessor B: So , it 's {disfmarker} it 's a good idea , but it seems like {pause} it makes sense to do some pruning\nPhD A: Mm - hmm .\nProfessor B: first with a {disfmarker} a test or two that makes sense for you ,\nPhD A: Yeah .\nProfessor B: and then {pause} take the likely candidates and go further .\nPhD A: Yeah .\nPhD C: Mm - hmm . Yeah . But , just testing on TI - digits would already give us some information {pause} about what 's going on . And {disfmarker} mm - hmm . Uh , yeah . OK . Uh , the next thing is this {disfmarker} this VAD problem that , um , um {disfmarker} So , I 'm just talking about the {disfmarker} the curves that I {disfmarker} I sent {disfmarker} {vocalsound} I sent you {disfmarker} so , whi that shows that {vocalsound} when the SNR decrease , {vocalsound} uh , the current {pause} VAD approach doesn't drop much frames {pause} for some particular noises , uh , which might be then noises that are closer to speech , uh , acoustically .\nProfessor B: I i Just to clarify something for me . I They were supp Supposedly , in the next evaluation , they 're going to be supplying us with boundaries .\nPhD C: Mm - hmm .\nProfessor B: So does any of this matter ? I mean , other than our interest in it . Uh {disfmarker}\nPhD C: Uh {disfmarker} Well . First of all , the boundaries might be , uh {disfmarker} like we would have t two hundred milliseconds or {disfmarker} before and after speech . Uh . So removing more than that might still make {pause} a difference {pause} in the results .\nProfessor B: Do we {disfmarker} ? I mean , is there some reason that we think that 's the case ?\nPhD C: And {disfmarker} No . Because we don't {disfmarker} didn't looked {pause} that much at that .\nProfessor B: Yeah .\nPhD C: But , {vocalsound} still , I think it 's an interesting problem .\nProfessor B: Oh , yeah .\nPhD C: And {disfmarker} Um . Yeah .\nProfessor B: But maybe we 'll get some insight on that when {disfmarker} when , uh , the gang gets back from Crete . Because {pause} there 's lots of interesting problems , of course .\nPhD C: Mm - hmm .\nProfessor B: And then the thing is if {disfmarker} if they really are going to have some means of giving us {pause} fairly tight , uh , boundaries , then that won't be so much the issue .\nPhD C: Yeah , yeah . Mm - hmm . Mm - hmm .\nProfessor B: Um But {vocalsound} I don't know .\nPhD G: Because w we were wondering whether that {pause} VAD is going to be , like , a realistic one or is it going to be some manual segmentation . And then , like , if {disfmarker} if that VAD is going to be a realistic one , then we can actually use their markers to shift the point around , I mean , the way we want\nProfessor B: Mm - hmm .\nPhD G: to find a {disfmarker} I mean , rather than keeping the twenty frames , we can actually move the marker to a point which we find more {pause} suitable for us .\nProfessor B: Right .\nPhD G: But if that is going to be something like a manual , uh , segmenter , then we can't {pause} use that information anymore ,\nPhD C: Mm - hmm .\nPhD G: because that 's not going to be the one that is used in the final evaluation .\nProfessor B: Right .\nPhD G: So . We don't know what is the type of {pause} {vocalsound} {pause} VAD which they 're going to provide .\nProfessor B: Yeah .\nPhD C: Yeah . And actually there 's {disfmarker} Yeah . There 's an {disfmarker} uh , I think it 's still for {disfmarker} even for the evaluation , uh , it might still be interesting to {vocalsound} work on this because {pause} the boundaries apparently that they would provide is just , {vocalsound} um , starting of speech and end of speech {pause} uh , at the utterance level . And {disfmarker} Um .\nPhD G: With some {disfmarker} some gap .\nPhD C: So {disfmarker}\nPhD G: I mean , with some pauses in the center , provided they meet that {disfmarker} whatever the hang - over time which they are talking .\nPhD C: Yeah . But when you have like , uh , five or six frames , both {disfmarker}\nPhD G: Yeah . Then the they will just fill {disfmarker} fill it up .\nPhD C: it {disfmarker} it {disfmarker} with {disfmarker}\nPhD G: I mean , th {disfmarker} Yeah .\nPhD C: Yeah .\nProfessor B: So if you could get at some of that , uh {disfmarker}\nPhD C: So {disfmarker}\nProfessor B: although that 'd be hard .\nPhD C: Yeah . It might be useful for , like , noise estimation , and a lot of other {pause} things that we want to work on .\nProfessor B: But {disfmarker} but {disfmarker} Yeah .\nPhD G: Yeah .\nProfessor B: Right . OK .\nPhD C: But {disfmarker} Mmm . Yeah . So I did {disfmarker} I just {pause} started to test {pause} putting together two VAD which was {disfmarker} was not much work actually . Um , I im re - implemented a VAD that 's very close to the , {vocalsound} um , energy - based VAD {vocalsound} that , uh , the other Aurora guys use . Um . So , which is just putting a threshold on {pause} the noise energy ,\nProfessor B: Mm - hmm .\nPhD C: and , detect detecting the first {pause} group of four frames {pause} that have a energy that 's above this threshold , and , uh , from this point , uh , tagging the frames there as speech . So it removes {vocalsound} the first silent portion {disfmarker} portion of each utterance . And it really removes it , um , still o on the noises where {pause} our MLP VAD doesn't {pause} work a lot .\nProfessor B: Mmm .\nPhD C: Uh ,\nProfessor B: Cuz I would have thought that having some kind of spectral {pause} information ,\nPhD C: and {disfmarker}\nProfessor B: uh {disfmarker} uh , you know , in the old days people would use energy and zero crossings , for instance {disfmarker} uh , would give you some {pause} better performance . Right ? Cuz you might have low - energy fricatives or {disfmarker} or , uh {pause} stop consonants , or something like that .\nPhD C: Mm - hmm .\nProfessor B: Uh .\nPhD C: Yeah . So , your point is {disfmarker} will be to u use whatever {disfmarker}\nProfessor B: Oh , that if you d if you use purely energy and don't look at anything spectral , then you don't have a good way of distinguishing between low - energy speech components and {pause} nonspeech . And , um ,\nPhD C: Mm - hmm .\nProfessor B: just as a gross generalization , most nonsp many nonspeech noises have a low - pass kind of characteristic , some sort of slope . And {disfmarker} and most , um , low - energy speech components that are unvoiced have a {disfmarker} a high - pass kind of characteristic {disfmarker}\nPhD C: Mm - hmm .\nProfessor B: an upward slope . So having some kind of a {disfmarker}\nPhD C: Yeah .\nProfessor B: uh , you know , at the beginning of a {disfmarker} of a {disfmarker} of an S sound for instance , just starting in , it might be pretty low - energy ,\nPhD C: Mm - hmm .\nProfessor B: but it will tend to have this high - frequency component . Whereas , {vocalsound} a {disfmarker} a lot of rumble , and background noises , and so forth will be predominantly low - frequency . Uh , you know , by itself it 's not enough to tell you , but it plus energy is sort of {disfmarker}\nPhD C: Yeah .\nProfessor B: it plus energy plus timing information is sort of {disfmarker}\nPhD C: Mm - hmm .\nProfessor B: I mean , if you look up in Rabiner and Schafer from like twenty - five years ago or something , that 's sort of {pause} what they were using then .\nPhD C: Mm - hmm .\nProfessor B: So it 's {disfmarker} it 's not a {disfmarker}\nPhD C: Mm - hmm .\nGrad F: Hmm .\nPhD C: So , yeah . It {disfmarker} it might be that what I did is {disfmarker} so , removes like {vocalsound} low , um , {vocalsound} uh {disfmarker} low - energy , uh , speech frames . Because {pause} the way I do it is I just {disfmarker} I just combine the two decisions {disfmarker} so , the one from the MLP and the one from the energy - based {disfmarker} with the {disfmarker} with the and {pause} operator . So , I only {pause} keep the frames where the two agree {pause} that it 's speech . So if the energy - based dropped {disfmarker} dropped low - energy speech , mmm , they {disfmarker} they are {disfmarker} they are lost . Mmm .\nProfessor B: Mm - hmm .\nPhD C: But s still , the way it 's done right now it {disfmarker} it helps on {disfmarker} on the noises where {disfmarker} it seems to help on the noises where {vocalsound} our VAD was not very {pause} good .\nProfessor B: Well , I guess {disfmarker} I mean , one could imagine combining them in different ways . But {disfmarker} but , I guess what you 're saying is that the {disfmarker} the MLP - based one has the spectral information . So .\nPhD C: Yeah . But {disfmarker} Yeah . But the way it 's combined wi is maybe done {disfmarker} Well , yeah .\nProfessor B: Well , you can imagine {disfmarker}\nPhD C: The way I use a an a \" AND \" operator is {disfmarker} So , it {disfmarker} I , uh {disfmarker}\nProfessor B: Is {disfmarker} ?\nPhD C: The frames that are dropped by the energy - based system are {disfmarker} are , uh , dropped , even if the , um , MLP decides to keep them .\nProfessor B: Right . Right . And that might not be optimal ,\nPhD C: But , yeah .\nProfessor B: but {disfmarker}\nPhD C: Mm - hmm .\nPhD A: No\nProfessor B: but {disfmarker} I mean , I guess in principle what you 'd want to do is have a {disfmarker} {vocalsound} uh , a probability estimated by each one and {disfmarker} and put them together .\nPhD C: Yeah . Mmm . M Yeah .\nPhD A: Something that {disfmarker} that I 've used in the past is , um {disfmarker} when just looking at the energy , is to look at the derivative . And you {pause} make your decision when the derivative is increasing for {pause} so many frames . Then you say that 's beginning of speech .\nPhD C: Uh - huh .\nPhD A: But , I 'm {disfmarker} I 'm trying to remember if that requires that you keep some amount of speech in a buffer . I guess it depends on how you do it . But {pause} I mean , that 's {disfmarker} that 's been a useful thing .\nProfessor B: Yeah .\nPhD C: Mm - hmm .\nGrad F: Mm - hmm .\nPhD G: Yeah . Well , every everywhere has a delay associated with it . I mean , you still have to k always keep a buffer ,\nPhD A: Mm - hmm .\nPhD G: then only make a decision because {pause} you still need to smooth the {pause} decision further .\nPhD A: Right . Right .\nPhD G: So that 's always there .\nPhD A: Yeah . OK .\nPhD C: Well , actually if I don't {disfmarker} maybe don't want to work too much of {disfmarker} on it right now . I just wanted to {disfmarker} to see if it 's {disfmarker} {vocalsound} what I observed was the re was caused by this {disfmarker} this VAD problem .\nProfessor B: Mm - hmm .\nPhD C: And it seems to be the case . Um . Uh , the second thing is the {disfmarker} this spectral subtraction . Um . Um , which I 've just started yesterday to launch a bunch of , uh , {nonvocalsound} twenty - five experiments , uh , with different , uh , values for the parameters that are used . So , it 's the Makhoul - type spectral subtraction which use {pause} an over - estimation factor . So , we substr I subtract more , {vocalsound} {vocalsound} um , {nonvocalsound} {vocalsound} noise than the noise spectra that {pause} is estimated {pause} on the noise portion of the s uh , the utterances . So I tried several , uh , over - estimation factors . And after subtraction , I also add {pause} a constant noise , and I also try different , uh , {vocalsound} noise , uh , values and we 'll see what happen .\nProfessor B: Hmm . OK .\nPhD C: Mm - hmm . Mm - hmm . But st still when we look at the , um {disfmarker} Well , it depends on the parameters that you use , but for moderate over - estimation factors and moderate noise level that you add , you st have a lot of musical noise . Um . On the other hand , when you {pause} subtract more and when you add more noise , you get rid of this musical noise but {pause} maybe you distort a lot of speech . So . Well . Mmm . Well , it {disfmarker} until now , it doesn't seem to help . But We 'll see . So the next thing , maybe I {disfmarker} what I will {pause} try to {disfmarker} to do is just {pause} to try to smooth mmm , {vocalsound} the , um {disfmarker} to smooth the d the result of the subtraction , to get rid of the musical noise , using some kind of filter , or {disfmarker}\nPhD G: Can smooth the SNR estimate , also .\nPhD C: Yeah . Right . Mmm .\nPhD G: Your filter is a function of SNR . Hmm ?\nPhD C: Yeah . So , to get something that 's {disfmarker} would be closer to {pause} what you tried to do with Wiener filtering .\nPhD G: Yeah .\nPhD C: And {disfmarker} Mm - hmm . Yeah .\nPhD G: Actually , it 's , uh {disfmarker} Uh . I don't know , it 's {disfmarker} go ahead .\nPhD C: It {disfmarker}\nPhD G: And it 's {disfmarker}\nPhD C: Maybe you can {disfmarker}\nPhD G: go ahead .\nPhD C: I think it 's {disfmarker} That 's it for me .\nPhD G: OK . So , uh {disfmarker} u th I 've been playing with this Wiener filter , like . And there are {disfmarker} there were some bugs in the program , so I was p initially trying to clear them up . Because one of the bug was {disfmarker} I was assuming that always the VAD {disfmarker} uh , the initial frames were silence . It always started in the silence state , but it wasn't for some utterances . So the {disfmarker} it wasn't estimating the noise initially , and then it never estimated , because I assumed that it was always silence .\nPhD C: Mm - hmm . So this is on SpeechDat - Car Italian ?\nPhD G: Yeah .\nPhD C: So , in some cases s there are also {disfmarker}\nPhD G: SpeechDat - Car Italian . Yeah . There 're a few cases , actually , which I found later , that there are .\nPhD C: o Uh - huh .\nPhD G: So that was one of the {pause} bugs that was there in estimating the noise . And , uh , so once it was cleared , uh , I ran a few experiments with {pause} different ways of smoothing the estimated clean speech and how t estimated the noise and , eh , smoothing the SNR also . And so the {disfmarker} the trend seems to be like , {vocalsound} uh , smoothing the {pause} current estimate of the clean speech for deriving the SNR , which is like {pause} deriving the Wiener filter , seems to be helping . Then updating it quite fast using a very small time constant . So we 'll have , like , a few results where the {disfmarker} estimating the {disfmarker} the {disfmarker} More smoothing is helping . But still it 's like {disfmarker} it 's still comparable to the baseline . I haven't got anything beyond the baseline . But that 's , like , not using any Wiener filter . And , uh , so I 'm {disfmarker} I 'm trying a few more experiments with different time constants for smoothing the noise spectrum , and smoothing the clean speech , and smoothing SNR . So there are three time constants that I have . So , I 'm just playing around . So , one is fixed in the line , like {pause} Smoothing the clean speech is {disfmarker} is helping , so I 'm not going to change it that much . But , the way I 'm estimating the noise and the way I 'm estimating the SNR , I 'm just trying {disfmarker} trying a little bit . So , that h And the other thing is , like , putting a floor on the , uh , SNR , because that {disfmarker} if some {disfmarker} In some cases the clean speech is , like {disfmarker} when it 's estimated , it goes to very low values , so the SNR is , like , very low . And so that actually creates a lot of variance in the low - energy region of the speech . So , I 'm thinking of , like , putting a floor also for the SNR so that it doesn't {pause} vary a lot in the low - energy regions . And , uh . So . The results are , like {disfmarker} So far I 've been testing only with the {pause} baseline , which is {disfmarker} which doesn't have any LDA filtering and on - line normalization . I just want to separate the {disfmarker} the contributions out . So it 's just VAD , plus the Wiener filter , plus the baseline system , which is , uh , just the spectral {disfmarker} I mean , the mel sp mel , uh , frequency coefficients . Um . And the other thing that I tried was {disfmarker} but I just {vocalsound} took of those , uh , {pause} {vocalsound} Carlos filters , which Hynek had , to see whether it really h helps or not . I mean , it was just a {disfmarker} a run to see whether it really degrades or it helps . And it 's {disfmarker} it seems to be like it 's not {vocalsound} hurting a lot by just blindly picking up one filter which is nothing but a {pause} four hertz {disfmarker} a band - pass m m filter on the cubic root of the power spectrum . So , that was the filter that Hy - uh , Carlos had . And so {disfmarker} Yeah . Just {disfmarker} just to see whether it really {disfmarker} it 's {disfmarker} it 's {disfmarker} is it worth trying or not . So , it doesn't seems to be degrading a lot on that . So there must be something that I can {disfmarker} that can be done with that type of noise compensation also , which {disfmarker} {vocalsound} I guess I would ask Carlos about that . I mean , how {disfmarker} how he derived those filters and {disfmarker} and where d if he has any filters which are derived on OGI stories , added with some type of noise which {disfmarker} what we are using currently , or something like that . So maybe I 'll {disfmarker}\nProfessor B: This is cubic root of power spectra ?\nPhD G: Yeah . Cubic root of power spectrum .\nProfessor B: So , if you have this band - pass filter , you probably get n you get negative values . Right ?\nPhD G: Yeah . And I 'm , like , floating it to z zeros right now .\nProfessor B: OK .\nPhD G: So it has , like {disfmarker} the spectrogram has , like {disfmarker} Uh , it actually , uh , enhances the onset and offset of {disfmarker} I mean , the {disfmarker} the begin and the end of the speech . So it 's {disfmarker} there seems to be , like , deep valleys in the begin and the end of , like , high - energy regions ,\nProfessor B: Mm - hmm .\nPhD G: because the filter has , like , a sort of Mexican - hat type structure .\nProfessor B: Mm - hmm .\nPhD G: So , those are the regions where there are , like {disfmarker} when I look at the spectrogram , there are those deep valleys on the begin and the end of the speech . But the rest of it seems to be , like , pretty nice .\nProfessor B: Mm - hmm .\nPhD G: So . That 's {pause} something I observe using that filter . And {disfmarker} Yeah . There are a few {disfmarker} very {disfmarker} not a lot of {disfmarker} because the filter doesn't have a {disfmarker} really a deep negative portion , so that it 's not really creating a lot of negative values in the cubic root . So , I 'll {disfmarker} I 'll s may continue with that for some w I 'll {disfmarker} I 'll {disfmarker} Maybe I 'll ask Carlos a little more about how to play with those filters , and {disfmarker} but while {pause} making this Wiener filter better . So . Yeah . That {disfmarker} that 's it , Morgan .\nProfessor B: Uh , last week you were also talking about building up the subspace {pause} stuff ?\nPhD G: Yeah . I {disfmarker} I {disfmarker} I would actually m m didn't get enough time to work on the subspace last week . It was mostly about {pause} finding those bugs and\nProfessor B: OK .\nPhD G: th you know , things , and I didn't work much on that .\nPhD A: How about you , Carmen ?\nPhD D: Well , I am still working with , eh , VTS . And , one of the things that last week , eh , say here is that maybe the problem was with the diff because the signal have different level of energy .\nProfessor B: Hmm ?\nPhD D: And , maybe , talking with Stephane and with Sunil , we decide that maybe it was interesting to {disfmarker} to apply on - line normalization before applying VTS . But then {vocalsound} we decided that that 's {disfmarker} it doesn't work absolutely , because we modified also the noise . And {disfmarker} Well , thinking about that , we {disfmarker} we then {disfmarker} we decide that maybe is a good idea . We don't know . I don't hav I don't {disfmarker} this is {disfmarker} I didn't {pause} do the experiment yet {disfmarker} to apply VTS in cepstral domain .\nProfessor B: The other thing {pause} is {disfmarker} So {disfmarker} so , in {disfmarker} i i and {disfmarker} Not {disfmarker} and C - zero would be a different {disfmarker} So you could do a different normalization for C - zero than for other things anyway . I mean , the other thing I was gonna suggest is that you could have {pause} two kinds of normalization with {disfmarker} with , uh , different time constants . So , uh , you could do some normalization {vocalsound} s uh , before the VTS , and then do some other normalization after . I don't know . But {disfmarker} but C - zero certainly acts differently than the others do ,\nPhD D: Uh .\nProfessor B: so that 's {disfmarker}\nPhD C: Mm - hmm .\nPhD D: Well , we s decide to m to {disfmarker} to obtain the new expression if we work in the cepstral domain . And {disfmarker} Well . I am working in that now ,\nProfessor B: Uh - huh .\nPhD D: but {vocalsound} I 'm not sure if that will be usefu useful . I don't know . It 's k it 's k It 's quite a lot {disfmarker} It 's a lot of work .\nProfessor B: Uh - huh .\nPhD D: Well , it 's not too much , but this {disfmarker} it 's work .\nProfessor B: Yeah .\nPhD D: And I want to know if {disfmarker} if we have some {pause} feeling that {pause} the result {disfmarker} I {disfmarker} I would like to know if {disfmarker} I don't have any feeling if this will work better than apply VTS aft in cepstral domain will work better than apply in m mel {disfmarker} in filter bank domain . I r I 'm not sure . I don't {disfmarker} I don't know absolutely nothing .\nPhD C: Mm - hmm .\nProfessor B: Yeah . Well , you 're {disfmarker} I think you 're the first one here to work with VTS , so , uh , maybe we could call someone else up who has , ask them their opinion . Uh ,\nPhD C: Mm - hmm .\nProfessor B: I don't {disfmarker} I don't have a good feeling for it . Um .\nPhD G: Pratibha .\nPhD C: Actually , the VTS that you tested before was in the log domain and so {pause} the codebook is e e kind of dependent on the {pause} level of the speech signal .\nPhD D: Yeah ?\nPhD C: And {disfmarker} So I expect it {disfmarker} If {disfmarker} if you have something that 's independent of this , I expect it to {disfmarker} it {disfmarker} to , uh , be a better model of speech .\nPhD D: To have better {disfmarker}\nPhD C: And . Well .\nProfessor B: You {disfmarker} you wouldn't even need to switch to cepstra . Right ? I mean , you can just sort of normalize the {disfmarker}\nPhD C: No . We could normali norm I mean , remove the median .\nProfessor B: Yeah . Yeah . And then you have {pause} one number which is very dependent on the level cuz it is the level ,\nPhD D: Mm - hmm .\nProfessor B: and the other which isn't .\nPhD C: Mm - hmm . Yeah . But here also we would have to be careful about removing the mean {pause} of speech and not of noise .\nPhD D: Ye\nPhD C: Because it 's like {pause} first doing general normalization\nPhD D: Yea\nPhD C: and then noise removal , which is {disfmarker}\nPhD D: Yeah . We {disfmarker} I was thinking to {disfmarker} to {disfmarker} to estimate the noise {pause} with the first frames and then apply the VAD ,\nProfessor B: Mm - hmm .\nPhD C: Mm - hmm .\nPhD D: before the on - line normalization .\nPhD C: Mm - hmm .\nPhD D: We {disfmarker} we see {disfmarker} Well , I am thinking {vocalsound} about that and working about that ,\nProfessor B: Yeah .\nPhD D: but I don't have result this week .\nProfessor B: Sure . I mean , one of the things we 've talked about {disfmarker} maybe it might be star time to start thinking about pretty soon , is as we look at the pros and cons of these different methods , how do they fit in with one another ? Because {pause} we 've talked about potentially doing some combination of a couple of them . Maybe {disfmarker} maybe pretty soon we 'll have some sense of what their {pause} characteristics are ,\nPhD D: Mm - hmm .\nProfessor B: so we can see what should be combined .\nPhD C: Mm - hmm .\nPhD A: Is that it ? OK ?\nProfessor B: OK . Why don't we read some digits ?\nPhD A: Yep . Want to go ahead , Morgan ?\nProfessor B: Sure .\nPhD A: Transcript L dash two one five .\nProfessor B: O K .", "source": "meeting_summ", "evaluation": "rouge"}
{"instructions": ["Summarize the discussion about the presentation on the prototype model.", "What were the advantages of the design for the prototype?", "What did the industrial designer recommend to do when discussing the product appearance?", "Summarize the discussion about product evaluation.", "Why did the group decide to give two points on usefulness when doing product evaluation?", "What did the project manager think of the colour and shape of the model when doing product evaluation?", "Summarize the discussion about product quotation.", "What did the user interface designer recommend to do when discussing product quotation?", "Summarize the whole meeting."], "outputs": ["With a working prototype, the user interface designer displayed the appearance and the texture of the product, which was fruit-like and spongy. As for the material, they still wanted to use titanium because it was the most modern material that they could select. Then the industrial designer gave some technical specifications on the product, including instructions on buttons, LCD display, speech recognition and location finder.", "According to the technical specifications given by the industrial designer, the product was very flexible because users could add buttons. Users could use the jog wheel to select whichever option on the LCD and do the power control. There was also an LCD control, so users could switch on the LCD display if they wanted to use LCD and use a normal button if they didn't want to use LCD. What's more, the controller had the functions of speech recognition and location finder.", "The industrial designer recommended to design several simple and perfect shapes so that users could choose the design they like. Also, they should make the colour of the LCD screen changeable to enable users to choose colours for each day depending on their mood.", "The marketing thought they needed to evaluate whether it made sense to do the project and whether the product could fulfil their requirement. So the group started to judge the design on a scale of one to seven, one being true and seven being false. The criteria were fanciness, technology, robustness, usefulness, size and weight, colour and shape, and adaptiveness. The product got an average score of two point one seven, which implied it was good.", "The basic mode of the product had only two directional buttons with which people could control the volume and change channels. Except for the two main functions, other functions were on the LCD screen and there was a jog dial controlling the cursor on the LCD screen. Therefore, the controller was very easy to use.", "The project manager didn't like the strawberry-like sensors on the top because they were not useful. Even though the marketing reminded the manager that fanciness was more important than usefulness, the manager still believed that it would be fancier if the fruit-like thing was useful.", "At first, the product components included a battery, a simple chip, a speech sensor, a single curve, titanium, two push buttons, a scroll wheel, and an LCD screen. These would cost seventeen dot eight dollars in total, which was apparently too expensive. After some discussions about battery and operations on the calculator, the group finally cut the cost down to under twelve dollars.", "The user interface designer recommended adding a hand dynamo which could produce electricity from mechanical energy so that it could provide enough energy for the device when users took the controller and pushed the buttons. The proposal was accepted by the group.", "It was the last meeting of the group and focused on detail design. First, the user interface designer displayed the appearance and the texture of the product with a working prototype. After that, the industrial designer gave some technical specifications on the product. In the product evaluation that included several criteria, the controller got an average score of two point one seven, which implied it was good. When it came to the quotation of product components, the original one was seventeen dot eight dollars, which was apparently over budget. After some discussions about battery and operations on the calculator, the group finally cut the cost down to under twelve dollars. Finally, they did some self-assessment and celebrated the completion of the project."], "input": "Project Manager: Mm .\nMarketing: So ,\nProject Manager: So , uh now {vocalsound}\nMarketing: Hi Christa . {vocalsound}\nProject Manager: it's the {disfmarker} {vocalsound} Hi Sammy . {vocalsound} It's the detail design meeting , so we're going {disfmarker} last meeting . So um , first uh Mark and Rama are going to present uh the prototype . Uh then uh Sammy will propose some uh crite cr criteria to evaluate this prototype . Then , w we {disfmarker} {vocalsound}\nUser Interface: {vocalsound} {vocalsound} Yes . {vocalsound}\nMarketing: {vocalsound} Yes . {vocalsound}\nProject Manager: {vocalsound} And then we going to do some finance to see if uh it is uh feasible\nUser Interface: And chocolate ? {vocalsound}\nProject Manager: {vocalsound} and uh at the end we will we will um evaluate ourself as a team . {vocalsound} And that's all . Okay . So first , {vocalsound} let's uh see the prototype .\nMarketing: Mm .\nIndustrial Designer: Yeah .\nProject Manager: {vocalsound}\nIndustrial Designer: Uh , here we have our prototype model .\nProject Manager: Okay . And you have some slides then ?\nUser Interface: Mm-hmm .\nIndustrial Designer: Yeah . Yeah , we have also some slides .\nProject Manager: {gap} Yeah . Mm .\nUser Interface: Yes , and place some slides .\nProject Manager: Okay . Uh so in which uh {disfmarker}\nUser Interface: Uh , participant three . {vocalsound} Prototype .\nIndustrial Designer: In {disfmarker} Yeah .\nProject Manager: Mm okay . Mm .\nIndustrial Designer: Five .\nProject Manager: {vocalsound}\nUser Interface: {vocalsound} Uh , so this is our remote control .\nIndustrial Designer: Him .\nProject Manager: {vocalsound}\nUser Interface: It's a r working prototype . You can use it now by switching all these buttons . So first , I present as we came to this perfect model ,\nProject Manager: {vocalsound}\nUser Interface: and then we'll give some technical specifications .\nMarketing: Yeah .\nProject Manager: Mm-hmm .\nUser Interface: That's {vocalsound} well {vocalsound} {vocalsound} , so that's that . Please , next slide . We analysed all the fruits\nProject Manager: {vocalsound}\nUser Interface: and contacted NASA , and uh made some {vocalsound} real good {disfmarker}\nProject Manager: MASA ? {vocalsound} {vocalsound} {vocalsound} {vocalsound} {vocalsound} {vocalsound}\nUser Interface: Yeah . If you can see this , and the stars are showing that {gap} . And um , {vocalsound} s society will accept that . For sure .\nMarketing: Mm-hmm .\nUser Interface: {vocalsound} And making some analysis of different fruits , we choose the ultimate form , ultimate colours , and uh ultimate smell of it . S please , next slide . But we still didn't want to go far from our titanium idea , 'cause it's the most of the moder the m the {gap} modern material we can p select . And it's practical . And it's still say it's for our needs , so please press something . And as I said , {vocalsound} it's perfect . {vocalsound}\nProject Manager: {vocalsound} Okay . {vocalsound} {vocalsound} {vocalsound}\nUser Interface: {vocalsound} Please press it .\nIndustrial Designer: Experience . Explanat\nUser Interface: Everyone is {gap} f really uh really glad to obtain an {disfmarker} {vocalsound} s such a r such a device .\nMarketing: Such a nice thing . {vocalsound}\nIndustrial Designer: See this {gap} . {vocalsound}\nUser Interface: So you can touch it with your hands .\nMarketing: Can I ?\nUser Interface: Sure . Yes . {vocalsound}\nIndustrial Designer: You can {disfmarker}\nMarketing: Ho-ho . {vocalsound} {vocalsound} {vocalsound} imitating flatulence] {vocalsound}\nProject Manager: What do you say ? {vocalsound}\nUser Interface: N\nMarketing: It says {vocalsound} {vocalsound}\nProject Manager: {vocalsound}\nUser Interface: {vocalsound} You must say it .\nIndustrial Designer: {vocalsound} Spongy .\nMarketing: I will uh {disfmarker}\nProject Manager: {vocalsound} One day .\nMarketing: I'll buy it . {vocalsound}\nUser Interface: Yeah . {vocalsound}\nMarketing: If I if I need so . {vocalsound}\nProject Manager: He {vocalsound} {vocalsound} {vocalsound} {vocalsound} {vocalsound}\nMarketing: Hopefully my daughter will like it . {vocalsound}\nUser Interface: Okay . Y and we got the answer . Uh , it is , yes , of course .\nMarketing: Yes , of course . Of c course . {vocalsound}\nUser Interface: {gap} , please next slide . Um , this is a prototype . You can have a look at it , and {disfmarker} That's all I wanted to say .\nMarketing: Ah .\nUser Interface: Now it's technical specification by our colleague .\nIndustrial Designer: Hmm .\nProject Manager: Hmm .\nIndustrial Designer: So {disfmarker}\nMarketing: Oh , there is {vocalsound} a button missing .\nProject Manager: {vocalsound}\nIndustrial Designer: Yeah .\nMarketing: {vocalsound} Okay . {vocalsound}\nIndustrial Designer: This this is really flexible . You can add your buttons .\nMarketing: It's in option . {vocalsound}\nIndustrial Designer: {vocalsound} Yeah . So function , mm {disfmarker}\nProject Manager: Mm-hmm .\nIndustrial Designer: {vocalsound} So , as we discussed , we have to switch on switch off whenever we want . And so , we have buttons and using L_C_D_ , or like you can use this {vocalsound} jog wheel and select which ever option on the L_C_D_ , and then do on and off . {vocalsound} Then you ha you'll have volume control . So , you you can press these buttons to increase or decrease the volume .\nProject Manager: {vocalsound}\nIndustrial Designer: And we have some L_C_D_ controls . Like , m switching the L_C_D_ display if you want to use L_C_D_ , or you don't want you can just use normal button .\nProject Manager: Mm-hmm .\nIndustrial Designer: And we have speech recognition . Here you have microphone , and then it date records your voice , and then it try to recognise .\nMarketing: Hmm .\nProject Manager: {vocalsound}\nIndustrial Designer: And it can also do the action .\nProject Manager: {vocalsound}\nIndustrial Designer: And location finder . And we want to do the location basically using speech recogniser . You can just say , where is my remote control .\nMarketing: Mm-hmm .\nIndustrial Designer: Or uh , you can just give some nickname to your remote control , like Bobby {gap} .\nProject Manager: {vocalsound} Bobby . {vocalsound} Mm-hmm .\nMarketing: {vocalsound} Hey , babe .\nIndustrial Designer: {vocalsound} And then , {vocalsound} it will say hi . {vocalsound}\nMarketing: {vocalsound} Bob . {vocalsound} Hey Bob . {vocalsound}\nIndustrial Designer: {vocalsound} Yeah , hi , and then you can use it . {vocalsound}\nMarketing: Okay ,\nProject Manager: Hmm . {vocalsound} 'Kay . {vocalsound} {vocalsound} {vocalsound} {vocalsound}\nMarketing: that's good .\nIndustrial Designer: So , {vocalsound} um our team is now fruits . Mainly strawberry . So , you can {vocalsound} have {disfmarker} {vocalsound}\nMarketing: {vocalsound} Oh , these are strawberries . {vocalsound}\nIndustrial Designer: And then you can see the look L_C_D_ and all the switches .\nProject Manager: {vocalsound} Are colourful . Yeah . {vocalsound} {vocalsound} {vocalsound}\nIndustrial Designer: {vocalsound} Material , we want to stick to titanium . {vocalsound} We will send , we want to {disfmarker} {vocalsound}\nMarketing: {vocalsound} Fruit smelling spongy titanium . {vocalsound} I didn't know it exist , but that's great .\nIndustrial Designer: Yeah , or s {vocalsound} So , we want to have {vocalsound} simple and perfect shapes , like I shown in these phones . You can have your own designs and and you can feel simple designs . {vocalsound} {vocalsound} And you can choose colours on your day for each day , or even many colours .\nMarketing: Ha .\nProject Manager: Ho-ho . That's for the L_C_D_ or for the titanium ?\nMarketing: You mean we can change the colour uh of th\nIndustrial Designer: For the L_C_D_ .\nMarketing: Yeah . Yeah okay , for the L_C_D_ .\nIndustrial Designer: With titanium it's {disfmarker} it is silver .\nMarketing: Tit titanium is {disfmarker}\nUser Interface: We are still working on titanium .\nProject Manager: Mm-mm .\nIndustrial Designer: Yeah .\nUser Interface: So , r we'll start with L_C_D_ .\nMarketing: Uh , okay .\nProject Manager: {vocalsound}\nIndustrial Designer: Mm , yeah . {vocalsound}\nUser Interface: You can ask Bob . It's Tuesday . {vocalsound}\nIndustrial Designer: Yeah .\nProject Manager: {vocalsound} Hey , you know you're theme today . {vocalsound}\nMarketing: {vocalsound} Yeah , Bob , please . {vocalsound} {gap} Tuesday colour . {vocalsound}\nIndustrial Designer: Yeah . Even you can configure your colours for its {disfmarker} the {disfmarker} depending on your mood , or s\nMarketing: Okay .\nProject Manager: Hmm .\nMarketing: Mm-hmm .\nProject Manager: {vocalsound}\nMarketing: {vocalsound} Black for Sunday . {vocalsound}\nIndustrial Designer: {vocalsound} And you can have many colours on weekends . Or {disfmarker} {vocalsound}\nProject Manager: And w wait , wh what are the strawberries for ? {vocalsound} {vocalsound} Wh wh\nIndustrial Designer: Huh ?\nMarketing: On the L_C_D_ ?\nIndustrial Designer: Ah , these are like sensors .\nMarketing: Oh .\nProject Manager: Mm-hmm . {vocalsound}\nUser Interface: {vocalsound}\nMarketing: {vocalsound} Of course .\nUser Interface: That's location sensors .\nMarketing: {vocalsound} What do you think ? {vocalsound} Strawberry sensors . {vocalsound} Very useful .\nProject Manager: Okay . {vocalsound} Strawberries .\nIndustrial Designer: So , {vocalsound}\nMarketing: {vocalsound} {vocalsound}\nIndustrial Designer: after this meeting we'll propose a party for our success for {disfmarker}\nProject Manager: {vocalsound} Ah . {vocalsound}\nMarketing: Lounge meeting . {vocalsound}\nIndustrial Designer: {vocalsound} So , if you are vegetarian or you have any options , please let us know .\nMarketing: {vocalsound}\nUser Interface: Yeah , and we can just {gap} some strawberry first . Um {disfmarker}\nIndustrial Designer: Yeah .\nProject Manager: {vocalsound} Okay . {vocalsound} Mm-hmm . {vocalsound}\nMarketing: Alright . Good . {vocalsound}\nUser Interface: Oops .\nIndustrial Designer: S\nMarketing: So , huh . Interesting . In interesting . Mm mm .\nProject Manager: {vocalsound} {vocalsound} Uh {disfmarker} {vocalsound}\nIndustrial Designer: So , any specific questions for {disfmarker}\nProject Manager: we'll see in the financial part if uh {vocalsound} all {vocalsound} {gap} {vocalsound} gets into {disfmarker}\nUser Interface: {vocalsound}\nMarketing: {vocalsound} It makes sense .\nIndustrial Designer: Yeah . {vocalsound}\nUser Interface: Let's make a party first maybe . {vocalsound} {vocalsound}\nProject Manager: {vocalsound} {vocalsound} W Who is the five uh {disfmarker} fifty millions we {vocalsound} first make a party in ?\nIndustrial Designer: Yeah . Then we can discuss {disfmarker} We can {disfmarker} {vocalsound} {vocalsound} Yeah , then we can have how much for how money is left . {vocalsound}\nMarketing: So uh , this is {disfmarker}\nProject Manager: Mm-hmm .\nMarketing: What a design .\nProject Manager: Okay . {vocalsound} Uh , so {disfmarker} Let's uh ,\nMarketing: {vocalsound} It's my turn .\nProject Manager: yeah , let's see if uh th it's meet the evaluation criterium . {vocalsound}\nMarketing: Mm-hmm . Let's see if this {disfmarker} Yeah , if you meet {vocalsound} the evaluation criterion .\nIndustrial Designer: {vocalsound} Yeah . {vocalsound}\nProject Manager: Oops .\nMarketing: {vocalsound}\nIndustrial Designer: Fudge .\nMarketing: Yeah . So , evaluation please . So . You made a very nice prototype , and um , I think , we now need altogether to try to evaluate it to see if it makes sense to do it , if it fulfils our {disfmarker} what we want to do , and things like that . So mm {disfmarker} {vocalsound} Uh , next slide , please . {vocalsound} As you know , before going and uh creating and producing these strawberry {vocalsound} uh {vocalsound} remote control , it's very important to first verify if it makes sense , if we have a chance to sell it .\nIndustrial Designer: {vocalsound} Yeah .\nMarketing: Uh , so we need to evaluate it um , try to do it in a constative way , and as much as we can . To {disfmarker} so what I propose is that we are going to to have this scale from one to seven . One meaning that , ye yes uh it fulfils uh the the criterion , whatever it is . And seven meaning , no it doesn't fulfil at all . And we're all l going to list all the criterion . I'm going to go to that next slide ,\nProject Manager: Okay .\nMarketing: and together try to evaluate this according to this criterion and from one to seven . And then we are just going to have an average , which will give us the value of our uh remote control . So , maybe we can have a look at the criteria ?\nIndustrial Designer: Fancy .\nMarketing: So these are the criterion uh I'm {disfmarker} I thought were important . Of course , this can be discussed , but let's let's see , so let's vote . So we have fancy here and we have the scale from one to seven with four in the middle .\nProject Manager: Mm-hmm .\nIndustrial Designer: Huh .\nMarketing: So ,\nIndustrial Designer: Yeah , what's is really {disfmarker}\nMarketing: what do you think , is it fancy ? {vocalsound}\nIndustrial Designer: Uh , it's really {disfmarker} {vocalsound}\nProject Manager: Uh , I think that fancy , we can say it is fancy . {vocalsound} {vocalsound}\nMarketing: {vocalsound} It is very very fancy . Or have you ever seen something like that ? {vocalsound}\nProject Manager: {vocalsound} Oh . I am not the d the only one choosing , yeah .\nMarketing: Yeah , of course .\nProject Manager: Uh what do you think ?\nMarketing: What do you think ?\nUser Interface: Feel the weight .\nMarketing: Is it {disfmarker} The weight is later .\nIndustrial Designer: Yeah . Oh .\nUser Interface: Really . {vocalsound}\nProject Manager: Uh-huh . {vocalsound}\nMarketing: {vocalsound} Now {vocalsound} we're {disfmarker} {vocalsound}\nUser Interface: Okay .\nMarketing: We're on the fanciness now . I think it's quite fancy .\nIndustrial Designer: Yeah , yeah .\nProject Manager: Yeah . Yeah .\nIndustrial Designer: We can give at least five or six , seven .\nMarketing: It's uh {disfmarker} Yeah , so {disfmarker} No it's it's one .\nProject Manager: It's in the other {gap} .\nIndustrial Designer: Oh , {gap} Oh . So {disfmarker} Oh , okay . Yeah , okay . Oh , okay . So {disfmarker}\nMarketing: Yeah , o one means it's , yes , a very fancy and seven mean no at all .\nProject Manager: Mm . {vocalsound}\nMarketing: So it's one or two .\nProject Manager: Two . Let's say two , yeah .\nIndustrial Designer: M maybe two .\nMarketing: What do you think ? Two ?\nUser Interface: Two . Two .\nMarketing: Okay . So here , two . Up .\nIndustrial Designer: Technology .\nMarketing: Then we have uh technology .\nIndustrial Designer: Yeah . Um {disfmarker}\nMarketing: So , what about technology ? We have uh we have speech recognition , we have location based {gap} ,\nIndustrial Designer: And we have L_C_D_ .\nMarketing: we have L_C_D_ .\nProject Manager: Change colour of t\nIndustrial Designer: So you change colours .\nMarketing: Change colour , I mean that's very {disfmarker}\nIndustrial Designer: Useful .\nProject Manager: Yeah , I think it's a {disfmarker}\nMarketing: Quite\nUser Interface: Yeah , yeah , yeah .\nMarketing: d I think it's a one for that , at least .\nProject Manager: Yeah . Yeah .\nUser Interface: Yeah . Uh {disfmarker}\nIndustrial Designer: Yeah , yeah . It's silly .\nMarketing: At least a one , yeah .\nProject Manager: Mm-mm . {vocalsound} {vocalsound} {vocalsound}\nMarketing: Robustness , uh-huh .\nIndustrial Designer: Uh , still we need to cha {vocalsound}\nMarketing: {vocalsound} So {vocalsound} let's suppose my daughter take it and um {vocalsound} {disfmarker} and through it away .\nProject Manager: {vocalsound} Um {disfmarker}\nMarketing: Do you think it makes sense that it's going to live again ? Uh , maybe not the prototype .\nProject Manager: The strawberries {vocalsound}\nIndustrial Designer: Yeah , it {disfmarker} {vocalsound}\nProject Manager: Oh . {vocalsound}\nMarketing: {vocalsound} Let's try . {vocalsound} {vocalsound} Oh my god . {vocalsound}\nIndustrial Designer: Maybe strawberry .\nMarketing: Okay , we just lost one strawberry .\nUser Interface: No .\nIndustrial Designer: Oh .\nMarketing: So {disfmarker} {vocalsound}\nUser Interface: No . How can I say this .\nMarketing: Not at all ?\nIndustrial Designer: Yeah , we can easily plug it .\nUser Interface: It's still it's still working , and your daughter got a bonus .\nMarketing: It is {disfmarker} Yeah . {vocalsound} Yeah .\nUser Interface: {vocalsound} A strawberry .\nMarketing: So it's not so bad .\nProject Manager: Mm-mm .\nIndustrial Designer: Yeah , yeah .\nMarketing: I um uh I would say three .\nProject Manager: Yeah . But it's too {gap} .\nIndustrial Designer: Yeah .\nProject Manager: It's um robust , yeah .\nMarketing: Yeah , that does make sense , yeah ?\nIndustrial Designer: Useful ?\nMarketing: Useful . {vocalsound} Well , so the question is does it have uh the minimum requirement of re remote control ?\nIndustrial Designer: Yeah , {gap} {disfmarker}\nMarketing: So I don't know . These buttons are uh {disfmarker} It not clear .\nProject Manager: Oh , yeah , lets me try .\nMarketing: But you have at least uh next produce .\nProject Manager: Yeah .\nIndustrial Designer: Yeah .\nProject Manager: What is uh next , please ?\nIndustrial Designer: Yeah , channel . I this is volume control and channel changes . These are the main {disfmarker}\nMarketing: Uh , it depends on the {disfmarker}\nProject Manager: And you can uh do di two sites ?\nMarketing: Okay .\nIndustrial Designer: You {disfmarker}\nProject Manager: Yeah .\nIndustrial Designer: Yeah . Yeah , and you can do on L_C_D_ using these going to scrolling all the option .\nProject Manager: Okay , also .\nIndustrial Designer: So if you don't want {disfmarker}\nMarketing: So but , for instance , because the L_C_D_ is not uh touch control , touch screen , you cannot go to channel twenty five directly .\nIndustrial Designer: Yeah , um {disfmarker} yeah .\nProject Manager: You can , by using the {disfmarker}\nUser Interface: You can .\nIndustrial Designer: Yeah .\nMarketing: Directly .\nUser Interface: You go {disfmarker} you {disfmarker}\nProject Manager: You c push here the the {disfmarker}\nUser Interface: So , the basic mode {disfmarker}\nProject Manager: yeah . {vocalsound}\nUser Interface: Yeah . So that's simple . The basic mode is uh you got just two buttons and a jog dial .\nMarketing: Yeah .\nUser Interface: With two buttons , you do this like uh volume up , volume down .\nMarketing: Oh , it's a jog dial , okay .\nUser Interface: Or if you go to the site , it's channel up channel down .\nIndustrial Designer: And channel .\nMarketing: Uh-huh . Okay .\nUser Interface: And if you want to make to s twenty-five , you push on this .\nMarketing: Yeah .\nUser Interface: You select twenty , you select five .\nIndustrial Designer: You can select .\nMarketing: {vocalsound} Okay .\nUser Interface: That's it .\nIndustrial Designer: Yeah mm .\nMarketing: It's much longer than that that being two two five , no ?\nUser Interface: No .\nMarketing: Don't you think so ? May {disfmarker} not {disfmarker} okay , we can go . That's uh {disfmarker} You're right .\nIndustrial Designer: Yeah , yeah , yeah . Y you need to like press two and five and {disfmarker} Yeah .\nMarketing: That's {disfmarker} it's less uh {disfmarker} Yeah . But it's it's nice , because people anyway don't go there .\nIndustrial Designer: Yeah , yeah . Yeah mm .\nMarketing: But {disfmarker} {vocalsound} So what do you think for it , usefulness ?\nIndustrial Designer: So , d Yeah , we need to address {disfmarker} we want {disfmarker}\nMarketing: Seems to be useful . {vocalsound}\nIndustrial Designer: we only address two main functions here and the other functions will be on L_C_D_ . So\nProject Manager: {vocalsound} Let me understand well ,\nIndustrial Designer: so {disfmarker}\nProject Manager: because I'm not sure {disfmarker} that's for {disfmarker} that this one are b d uh two dir directional button .\nMarketing: Both . Yeah . Yeah .\nUser Interface: Yeah . Yeah .\nIndustrial Designer: Yeah .\nProject Manager: Yeah .\nIndustrial Designer: Yeah . Up .\nMarketing: Up down or left right . Yeah .\nProject Manager: Yeah . And which {disfmarker} what is that ?\nUser Interface: It's a jog dial for controlling the cursor on the L_C_D_ screen .\nIndustrial Designer: This is jog wheel .\nMarketing: That {disfmarker}\nProject Manager: Okay , okay . It's a kind {disfmarker} Oh , okay okay . {vocalsound}\nUser Interface: Like , selecting the menus .\nIndustrial Designer: Yeah . Um , {vocalsound} see in L_C_D_ , like you will have blocks and you select which one .\nMarketing: Cool .\nProject Manager: Oh oh okay , great .\nMarketing: I would say then uh {disfmarker} {gap}\nProject Manager: Now it's looks us useful .\nIndustrial Designer: Yeah . Yeah .\nMarketing: Two or three ?\nProject Manager: Yeah .\nMarketing: Two or three ?\nIndustrial Designer: Two , maybe . {vocalsound}\nMarketing: Two .\nProject Manager: {vocalsound} Yeah .\nMarketing: Okay , two . {vocalsound} {vocalsound} So size and weight .\nIndustrial Designer: Yeah , yeah . {gap}\nMarketing: Is it the the the effective size and weight that the {disfmarker} Is it uh real size , real weight ? Or {disfmarker} Because it {disfmarker}\nIndustrial Designer: Yeah , it's {disfmarker} size al almost {gap} {disfmarker}\nMarketing: Size is going to be that , yeah ?\nIndustrial Designer: Yeah , because it is {disfmarker}\nMarketing: Uh , and and {disfmarker}\nIndustrial Designer: The weight will be bit lighter . We will s We use titanium .\nUser Interface: Sure ,\nProject Manager: Mm-mm .\nUser Interface: without titanium alloy , it's going to be light .\nIndustrial Designer: Yeah . Yeah . Yeah .\nMarketing: It's going to be lighter ,\nProject Manager: {vocalsound}\nUser Interface: Of course .\nMarketing: because this seems to be very heavy f I mean ,\nIndustrial Designer: Heavy . Yeah .\nMarketing: for my daughter , for instance .\nProject Manager: Mm-hmm . {vocalsound} {vocalsound}\nIndustrial Designer: Yeah .\nMarketing: {vocalsound} Not sure if uh {vocalsound} she can use it . {vocalsound}\nIndustrial Designer: But sides {disfmarker} uh , the sides should be okay . {gap} . Yeah\nMarketing: So , should be okay .\nIndustrial Designer: mm .\nMarketing: Up to three for that ,\nProject Manager: Mm-mm .\nMarketing: because I'm {disfmarker} haven't seen the weight so I must not uh {disfmarker}\nUser Interface: Okay . Okay .\nProject Manager: {vocalsound}\nIndustrial Designer: Oh .\nMarketing: Colour and shape .\nProject Manager: {vocalsound} Uh-oh . {vocalsound}\nMarketing: Well , so colour , it seems that we have the several colours for the L_C_D_ .\nIndustrial Designer: Yeah .\nProject Manager: Yeah .\nMarketing: But um , it's not very clear what is the colour of the sh the sh {vocalsound} the case .\nProject Manager: {vocalsound} Yeah .\nIndustrial Designer: The case is silver titanium , no ?\nMarketing: It's a {disfmarker} it's going to be titanium . Okay , okay .\nProject Manager: Yeah , it's {gap} .\nIndustrial Designer: Yeah .\nMarketing: That's nice .\nProject Manager: Let's imagine .\nMarketing: {vocalsound} I think it's good . Okay .\nProject Manager: {vocalsound} And what about the strawberries on the top ? {vocalsound} I'm not convince . {vocalsound} But maybe I'm not trendy . But , uh {disfmarker}\nMarketing: Yahoo . {vocalsound} {vocalsound} Well y you know , it's this uh fruit and vegetable year .\nIndustrial Designer: Oh . Yeah , yeah . Yeah .\nProject Manager: Yeah , but uh {vocalsound} uh they're not useful .\nMarketing: So {disfmarker} {vocalsound}\nProject Manager: I I mean it {disfmarker} that's uh {disfmarker}\nIndustrial Designer: {vocalsound} So maybe , I think {disfmarker}\nMarketing: Uh , I think usefulness is m as as I rem um just have to remind you that usefulness is much less important than fanciness .\nProject Manager: Mm-hmm .\nIndustrial Designer: Yeah .\nProject Manager: Yep .\nIndustrial Designer: Yeah , well {disfmarker}\nMarketing: Whether it's fancy or not now , it {disfmarker} we have to decide .\nProject Manager: Hmm .\nIndustrial Designer: Yeah . Um {disfmarker}\nMarketing: But this\nProject Manager: I would have m uh i found more fancy that the fruits are useful .\nMarketing: If it's {disfmarker} Uh-huh . So , that they will {disfmarker} that maybe the fruit may be here instead . {vocalsound}\nProject Manager: Yeah .\nIndustrial Designer: Yeah , well then it's bit difficult to use . Not like this d We're just giving the fruit for more fanciness and more attraction , too .\nProject Manager: Mm-hmm . But the n {vocalsound} Yeah .\nIndustrial Designer: So , maybe think we can have rubber or some sponges , stuff for strawberries and different colours .\nProject Manager: Mm .\nIndustrial Designer: So it's {disfmarker}\nMarketing: So , it seems we are not so clear on the shape uh {disfmarker}\nIndustrial Designer: Even {disfmarker}\nProject Manager: No , I'm not sure uh why {disfmarker}\nIndustrial Designer: These buttons {disfmarker}\nProject Manager: uh if it was like this {disfmarker}\nIndustrial Designer: {gap} But it looks really {vocalsound} not really good .\nProject Manager: I It's {gap} n {vocalsound} no , it's not fancy any more .\nIndustrial Designer: I mean , the f Yeah . So these are kind of rubber things . Even if you lose one you can just put whatever .\nProject Manager: Okay .\nUser Interface: And {disfmarker}\nIndustrial Designer: Even we can provide many different colours or different fruits , and {disfmarker}\nProject Manager: Uh-huh . And different routes . Okay , I see what {disfmarker}\nUser Interface: Moreover , moreover it covers it covers all the end goals . Even if it is , you know , it's very rounded ,\nIndustrial Designer: Yeah .\nUser Interface: but still you got some rubber fruit here , and it's completely uh completely secure to leave it uh with children and that .\nIndustrial Designer: Yeah .\nProject Manager: Okay , so you you you feel like it's something uh a protection for the remote control .\nIndustrial Designer: Yeah . Yeah . Yeah . Yeah , we've {disfmarker} yeah we have sensors here and so here and here ,\nProject Manager: Also .\nIndustrial Designer: so we just {disfmarker} Yeah , so even if you don't put , it works . But this is really fancy . {gap}\nProject Manager: Okay .\nMarketing: I suggested three .\nProject Manager: Okay . {vocalsound}\nMarketing: Because uh , everybody s doesn't seem to be convince ,\nUser Interface: Okay . Okay .\nMarketing: although it's quite {disfmarker}\nIndustrial Designer: Yeah .\nMarketing: You have good arguments .\nIndustrial Designer: Yeah .\nMarketing: But {disfmarker}\nProject Manager: Okay . {vocalsound} {vocalsound}\nMarketing: And uh the last one is adaptive . This is not r maybe not as important as the other one , {vocalsound}\nIndustrial Designer: Yeah .\nMarketing: but uh can we adapt it to each each personal use ?\nUser Interface: Sure , sure , just look at it . {vocalsound} It's full adaptable . {vocalsound}\nMarketing: {vocalsound} Great .\nProject Manager: {vocalsound} Wow , that's a {disfmarker} {vocalsound}\nMarketing: {vocalsound} Fully adaptable .\nUser Interface: Yeah , you can fit it into your palm , you know .\nMarketing: That's {disfmarker} Yeah . {vocalsound} So you can fit into your palm , okay .\nProject Manager: Yea\nIndustrial Designer: Yeah . {vocalsound}\nMarketing: That {disfmarker}\nIndustrial Designer: You can {disfmarker}\nMarketing: What else can we need ?\nIndustrial Designer: Yeah . {vocalsound}\nMarketing: You {disfmarker} Do you think you are gonna be able to do that with ti titanium as well ?\nProject Manager: Yeah , it's fudge titanium . {vocalsound} You know .\nMarketing: {vocalsound} It's fudge , yeah , yeah .\nProject Manager: Right , yeah . {vocalsound} And uh {disfmarker} {vocalsound}\nUser Interface: Mm , {gap} {disfmarker}\nMarketing: Yeah , fruit titanium , yeah . Well , I if if this is {disfmarker} if you are ready to do that , then I think it deserves a one . {vocalsound}\nIndustrial Designer: Yeah . {vocalsound}\nProject Manager: Okay . {vocalsound} Let's go for one . {vocalsound}\nMarketing: {vocalsound} Okay .\nIndustrial Designer: Yeah .\nMarketing: Now we have to do the average . {vocalsound}\nIndustrial Designer: Three , three , six , eight , eleven .\nMarketing: {vocalsound} Who is good in math ? {vocalsound}\nUser Interface: It's two point one seven .\nMarketing: Okay . {vocalsound} Two point one seven . That's nice . Two point one seven out of seven .\nIndustrial Designer: Hmm .\nMarketing: I think we have a good good thing .\nProject Manager: Yeah .\nMarketing: Well , that's all I had to say about the evaluation .\nProject Manager: So it's a good evaluation .\nMarketing: So {disfmarker} It seems to be good , yeah .\nProject Manager: Yeah . Mm .\nIndustrial Designer: Yeah mm .\nMarketing: We have uh {disfmarker}\nIndustrial Designer: Yeah , two one one seven , we have . So {disfmarker}\nMarketing: Yeah .\nProject Manager: Mm-mm .\nMarketing: Yeah . Okay . Thanks .\nProject Manager: {vocalsound} Okay . So now , it has to fulfil the {vocalsound} financial criterium ?\nMarketing: {vocalsound}\nIndustrial Designer: Financi\nMarketing: Ah-ha .\nProject Manager: So , I have an {disfmarker} Here . Um {disfmarker}\nMarketing: {vocalsound} {vocalsound}\nIndustrial Designer: Energy .\nMarketing: So so how many batteries do we need ?\nIndustrial Designer: Uh , we use bat One battery .\nMarketing: One battery ?\nProject Manager: Okay ,\nIndustrial Designer: Yep .\nProject Manager: so two .\nMarketing: Good . Why two ?\nIndustrial Designer: Oh , we just need one , I guess .\nMarketing: {vocalsound} Say no . No , ne never install .\nProject Manager: Uh-huh . {vocalsound}\nMarketing: Two batteries or one ?\nProject Manager: {vocalsound} Oh .\nIndustrial Designer: No , number is one . We need only one battery .\nProject Manager: Yeah yeah ,\nMarketing: Only one .\nProject Manager: but the price is two . Oh , number .\nMarketing: No , no . But no , no . No , no way .\nProject Manager: Sorry sorry sorry . I'm sorry .\nUser Interface: No , uh you just {disfmarker}\nIndustrial Designer: Number , number .\nUser Interface: Number . Yeah .\nProject Manager: Yeah . Yeah . Oh .\nMarketing: Yeah . You never use uh Excel ? {vocalsound}\nProject Manager: No , never . {vocalsound}\nUser Interface: How {disfmarker}\nMarketing: Good . {vocalsound}\nUser Interface: What what's the limit ? {vocalsound}\nProject Manager: {vocalsound} H {vocalsound}\nMarketing: {vocalsound} It's twelve bucks .\nUser Interface: Uh , it's it's okay that I don't know , 'cause uh it's not my field . Twelve bucks . Okay ,\nMarketing: Twelve bucks .\nUser Interface: now {disfmarker} Mm-hmm .\nMarketing: Twelve and a half , I think .\nUser Interface: Check that number also . {vocalsound}\nIndustrial Designer: So we {disfmarker}\nMarketing: Okay . {vocalsound} Okay , electronics .\nIndustrial Designer: We have sample chip .\nMarketing: So {disfmarker}\nIndustrial Designer: Uh , like simple chip , yeah .\nMarketing: It's a simple chip ?\nIndustrial Designer: So , yeah .\nMarketing: Simple chip , okay . One .\nIndustrial Designer: Yeah . Four buttons at least .\nMarketing: Okay .\nProject Manager: Okay . {vocalsound}\nIndustrial Designer: And then we have the t sample speaker sensor for speech recognition . {vocalsound}\nProject Manager: And for the {disfmarker} One also .\nIndustrial Designer: Yeah , one to one .\nMarketing: One or two ? One ?\nIndustrial Designer: Yeah , one .\nMarketing: Okay . So the case , which one uh is it in the end ?\nIndustrial Designer: Yeah , I think we will go for a single curve , no ?\nMarketing: Let's do a single curve .\nIndustrial Designer: Oh , is {gap} {disfmarker}\nUser Interface: It's it's flat .\nIndustrial Designer: {vocalsound} Oh . {vocalsound} Oh , okay .\nMarketing: It's flat , and curved .\nProject Manager: I thought you can curve\nUser Interface: It's flat .\nProject Manager: {vocalsound} {gap} somebody . {vocalsound}\nUser Interface: {vocalsound} But it is flat ,\nMarketing: It's curvable . {vocalsound}\nUser Interface: you {disfmarker} Look . It's curvable , but it's not curved . {vocalsound}\nMarketing: Maybe there is a supplement for that {gap} , no ?\nProject Manager: Mm-hmm .\nMarketing: It's only {gap} curve ?\nProject Manager: Oh see , I I think {vocalsound} that the the price is this one .\nMarketing: Okay , let's go .\nIndustrial Designer: Yeah . {vocalsound}\nMarketing: {vocalsound} This {disfmarker} Okay ,\nProject Manager: Yeah , yeah .\nMarketing: you d {vocalsound}\nProject Manager: Don't chip on me .\nMarketing: We tried , we tried .\nProject Manager: {vocalsound} {vocalsound} {vocalsound}\nUser Interface: Oh , okay .\nIndustrial Designer: Oh . Titanium .\nMarketing: So , what is it ? T titanium ?\nProject Manager: Mm-hmm .\nUser Interface: Mm .\nMarketing: Mm , that's expensive .\nProject Manager: {vocalsound} Mm-mm .\nMarketing: Mm-hmm .\nUser Interface: Mm .\nProject Manager: {vocalsound} Yeah . {vocalsound} But she wanted u the {vocalsound} fudge titanium .\nMarketing: Okay . {vocalsound}\nIndustrial Designer: Yeah , well {disfmarker}\nMarketing: {vocalsound} Let's stick to s titan .\nProject Manager: I think it's five , but {disfmarker} {vocalsound} you don't say {gap} . {vocalsound}\nMarketing: Special colour ?\nUser Interface: Well , n Why three ?\nIndustrial Designer: No , only one , no ?\nMarketing: No because uh {disfmarker}\nProject Manager: Mm .\nUser Interface: Why three ?\nProject Manager: Oh , sorry . Again , I'm {disfmarker} {gap} {disfmarker} See it .\nIndustrial Designer: Um {disfmarker}\nMarketing: Yeah . {vocalsound}\nProject Manager: Special colour ,\nIndustrial Designer: Interface .\nProject Manager: or it's only on the {disfmarker}\nMarketing: Oh .\nIndustrial Designer: Yes , in L_C_D_ display .\nProject Manager: Yeah , but {vocalsound} there is no {vocalsound} colour here .\nIndustrial Designer: Ok Yeah , an Yeah .\nProject Manager: So I put it here .\nIndustrial Designer: Push-button .\nMarketing: So the L_C_D_ {disfmarker}\nProject Manager: How many push-button ?\nIndustrial Designer: Scro\nProject Manager: Three or two ?\nIndustrial Designer: Uh , two .\nMarketing: Two .\nProject Manager: Is there {disfmarker} The scroll-wheel , okay .\nIndustrial Designer: Yeah .\nMarketing: Yeah . {vocalsound}\nIndustrial Designer: One scroll wheel {vocalsound} .\nMarketing: It's going to be expensive . {vocalsound} {vocalsound}\nIndustrial Designer: One L_C_D_ displayed .\nProject Manager: Okay . Um {disfmarker} That's that's not {disfmarker}\nMarketing: That's all ?\nProject Manager: We choose this one , and not this one .\nIndustrial Designer: Yeah .\nMarketing: No . Oh , I think , no it's {disfmarker}\nIndustrial Designer: Yeah , it's cheaper .\nMarketing: Uh , is it a scroll wheel and pe push button , th this centre one ?\nProject Manager: Or only a scroll-wheel .\nIndustrial Designer: Yeah . Only scroll wheel .\nMarketing: Or only only scroll wheel , okay .\nIndustrial Designer: Yeah mm . So {disfmarker}\nProject Manager: {vocalsound} You try to s {vocalsound}\nMarketing: {vocalsound} You are trying to make make up {disfmarker} {vocalsound} make us up .\nProject Manager: No , no , no .\nIndustrial Designer: It's already {disfmarker}\nProject Manager: {vocalsound} Because {vocalsound} how do you do to {vocalsound} y select ?\nIndustrial Designer: {vocalsound} Ah .\nMarketing: No , but you select with the two d the other two buttons ,\nProject Manager: Yeah , I mean you you go on the location with your scroll wheel\nIndustrial Designer: Y ye\nMarketing: no ? That's true .\nProject Manager: and then you {disfmarker}\nIndustrial Designer: Yeah .\nMarketing: Yeah .\nIndustrial Designer: Then it automatically {disfmarker} we can just do like you feel , it goes . And it will activate {disfmarker}\nMarketing: Yeah .\nProject Manager: Stay longer . Okay .\nMarketing: It should stay . Yeah .\nProject Manager: Oops . {vocalsound}\nIndustrial Designer: Um , plus , yeah , it's {disfmarker} price is really {disfmarker} {vocalsound}\nProject Manager: Okay , okay . Um {disfmarker}\nIndustrial Designer: Special colours , yeah .\nProject Manager: Mm-hmm .\nUser Interface: For buttons .\nIndustrial Designer: Okay .\nUser Interface: No ,\nIndustrial Designer: Yeah , buttons and strawberries .\nUser Interface: buttons just normal .\nIndustrial Designer: Yeah . Special form .\nProject Manager: You you have all of these , no ?\nMarketing: {vocalsound} She's very hard on this . {vocalsound}\nProject Manager: {vocalsound} Mm maybe n not this one but {disfmarker}\nMarketing: Special colour ? Yeah . No . Special material ?\nUser Interface: That's for buttons .\nIndustrial Designer: Uh , we have titan\nUser Interface: But buttons are standard .\nMarketing: Yeah , buttons are the standard buttons . Yeah . It's only buttons , these .\nProject Manager: Yeah , so {disfmarker}\nMarketing: Nothing special .\nIndustrial Designer: Yeah .\nMarketing: Okay . So we are at seventeen dot eight .\nProject Manager: Not special colours an interest in ?\nMarketing: No , the colour is in the L_C_D_ .\nProject Manager: {vocalsound} And buttons are not colourised ? They are m\nIndustrial Designer: Mm , hmm ,\nMarketing: I no .\nIndustrial Designer: I think uh because you can just go for a good colours .\nMarketing: We can just use this red .\nIndustrial Designer: Yeah , and uh {disfmarker}\nMarketing: {vocalsound} It's {disfmarker} {vocalsound}\nProject Manager: Boo-hoo . {vocalsound} It's already too expensive . {vocalsound} Apparently .\nIndustrial Designer: Yeah .\nMarketing: So what is {disfmarker} Are we supposed to cut things out now ?\nProject Manager: Yeah . Mm .\nMarketing: Uh , until we get twelve fifty .\nProject Manager: Mm-hmm . Mm . {vocalsound}\nIndustrial Designer: Oh . {vocalsound}\nProject Manager: {vocalsound} So think of what we can cut uh here . {vocalsound}\nMarketing: {vocalsound} Well , if I look at what is the most expensive things , uh it's the L_C_D_\nIndustrial Designer: Sample speaker .\nMarketing: and the speaker .\nIndustrial Designer: Yeah .\nProject Manager: Apparently , we have to choose one or the other . {vocalsound}\nIndustrial Designer: Yeah .\nMarketing: Yeah . Yeah .\nUser Interface: Well , as you may know there's some research done in the field of producing energy from mechanical eng , I mean , producing electricity from mechanical energy . So , the point is that when you take device and push the button , you produce enough energy\nProject Manager: But you don't need a battery ?\nUser Interface: to make electricity . Yeah , that you don't need a battery . So , it's something like hand dynamo robot . A real high-tech version of it .\nMarketing: Mm-hmm .\nProject Manager: But um\nMarketing: So that would {disfmarker}\nProject Manager: it's like the hand dynamo , no ?\nIndustrial Designer: Maybe the jog wheel can be like kind of hand\nMarketing: So , but if we select the hand dynamo it's okay , we only {disfmarker}\nIndustrial Designer: {gap} is {disfmarker}\nMarketing: We we win one .\nUser Interface: Okay ,\nIndustrial Designer: Yeah .\nMarketing: That's already that .\nProject Manager: Uh it's a it's a beginning .\nMarketing: Okay , let's do that .\nProject Manager: Okay .\nUser Interface: Why not .\nIndustrial Designer: Yeah .\nUser Interface: Let's do that .\nProject Manager: So {disfmarker} One here and here .\nIndustrial Designer: Yeah , just remo\nProject Manager: 'Kay .\nUser Interface: And I propose to {disfmarker}\nIndustrial Designer: S\nUser Interface: So uh , about chips . Advanced chip on print , right ?\nProject Manager: Mm-hmm .\nUser Interface: So , put minus one there , please . {vocalsound}\nProject Manager: {vocalsound} Mm .\nMarketing: {vocalsound} I'm not sure if this is legal .\nIndustrial Designer: Yeah .\nProject Manager: {vocalsound} That's right . {vocalsound}\nUser Interface: Why not ?\nIndustrial Designer: Uh , no .\nUser Interface: And ?\nMarketing: And ?\nProject Manager: M maybe minus uh three , no ? {vocalsound}\nIndustrial Designer: Yeah .\nMarketing: No . {vocalsound}\nUser Interface: So , was there result ?\nIndustrial Designer: No , no . It's not {disfmarker}\nMarketing: Okay , let's see .\nProject Manager: {vocalsound} Mm-hmm . Mm .\nUser Interface: Let's have a look .\nIndustrial Designer: It's not changing , no ?\nUser Interface: Why ?\nIndustrial Designer: It {disfmarker} you don't\nMarketing: Yeah , yeah , yeah , if {disfmarker} Click somewhere , you'll see features .\nUser Interface: Oops .\nMarketing: Yes , it does .\nProject Manager: {vocalsound} {vocalsound} So {disfmarker} {vocalsound} {vocalsound}\nMarketing: Maybe put minus two , so it looks uh {vocalsound} more reasonable . {vocalsound}\nUser Interface: Yeah . Why not .\nMarketing: Yeah , anyway {disfmarker}\nProject Manager: Oh , sorry .\nUser Interface: Minus .\nMarketing: No , minus two .\nProject Manager: Mm-hmm .\nMarketing: Nobody will know .\nProject Manager: Mm . {vocalsound}\nMarketing: {vocalsound} It's not recorded , is it ?\nUser Interface: Good .\nMarketing: {vocalsound} Okay , we're on time .\nProject Manager: {vocalsound} Okay . {vocalsound}\nMarketing: Good .\nIndustrial Designer: So now on , we can increase our {disfmarker} {vocalsound} Still you have two more . {vocalsound}\nProject Manager: Oh , we can put uh a hand dynamo and a battery if you want .\nIndustrial Designer: Maybe we can use it for our party .\nProject Manager: {vocalsound} Oh .\nUser Interface: And a battery and a battery , yeah .\nIndustrial Designer: Yeah .\nProject Manager: Both its it's cool . {vocalsound}\nIndustrial Designer: Yeah , yeah .\nMarketing: No , now we are exp exceeding I think .\nUser Interface: Now it's fancy ,\nProject Manager: Mm .\nUser Interface: let's add one instead of two . {vocalsound}\nIndustrial Designer: Yeah , that {disfmarker}\nMarketing: It {disfmarker} Is it ? {vocalsound}\nProject Manager: {vocalsound} Yeah , yeah y\nIndustrial Designer: {vocalsound}\nMarketing: I think we're exceeding now .\nIndustrial Designer: No , but point five point three .\nMarketing: We have to remove the {disfmarker}\nIndustrial Designer: Okay .\nMarketing: Uh , it's better . I think they are counting uh {disfmarker}\nProject Manager: Yeah . Mm . It's maximum\nIndustrial Designer: Is really strict ?\nMarketing: We would prefer ,\nProject Manager: and don't have to {disfmarker} Yeah , yeah .\nIndustrial Designer: Oh .\nMarketing: yeah . Maximum is maximum .\nProject Manager: Uh {disfmarker}\nIndustrial Designer: Oh yeah .\nMarketing: So , remove one of them . Yeah . Okay . Okay , we're uh on target .\nProject Manager: Uh , mm-mm . Yeah . Mm . Okay . Mm . So {vocalsound} target reached . {vocalsound}\nMarketing: {vocalsound} I'm just curious to see this\nIndustrial Designer: {vocalsound} Ho {vocalsound}\nMarketing: uh {disfmarker} {vocalsound} my {disfmarker} {vocalsound} address chip on print .\nProject Manager: {vocalsound} It's um English uh {vocalsound} {disfmarker} Yeah . {vocalsound}\nMarketing: Trick {vocalsound} . Uh , I would say it's the Russian trick , but\nProject Manager: {vocalsound} Yeah , but uh {gap} is uh English . So {disfmarker}\nMarketing: {vocalsound} {disfmarker} Anyway {disfmarker} {vocalsound} No ,\nIndustrial Designer: Oh . Uh {disfmarker}\nProject Manager: Mm . {vocalsound} {vocalsound} {vocalsound} {vocalsound}\nUser Interface: Well , I don't know .\nMarketing: they may have some their origins , strange origins {disfmarker}\nUser Interface: I don't know . I am not sure who was programming this calculator , you know . 'Cause uh {disfmarker} I wonder if we put A_ or B_ somewhere instead of a number .\nProject Manager: Mm , let's try .\nMarketing: {vocalsound} No , no , no .\nIndustrial Designer: {vocalsound} And we can discuss all these things in our party .\nMarketing: Let's finish this meeting instead . {vocalsound}\nProject Manager: {vocalsound} Okay . {vocalsound} I save it uh {disfmarker}\nMarketing: What else ?\nProject Manager: Okay , so next mm {disfmarker} {vocalsound}\nMarketing: No .\nProject Manager: No , that's yours .\nMarketing: This is right .\nProject Manager: Sorry .\nMarketing: Okay ,\nProject Manager: 'Kay .\nMarketing: so finance , that's done . Are the cost under twelve ?\nProject Manager: {vocalsound}\nIndustrial Designer: Mm yeah , very much .\nMarketing: Yes . Project evaluation , good . {vocalsound}\nProject Manager: Okay . So now {disfmarker}\nUser Interface: Next slide .\nProject Manager: {vocalsound}\nMarketing: Project process .\nProject Manager: {vocalsound} We have to make um {disfmarker} {vocalsound}\nMarketing: Safe uh asse uh safe assessment .\nProject Manager: Yeah . Yeah . Mm . See mm how {disfmarker} {vocalsound} Are we a good team ? Mm . {vocalsound}\nUser Interface: Okay .\nMarketing: Yeah , I think we've listened to everybody .\nProject Manager: Mm-hmm .\nMarketing: Everybody could say what they thought .\nProject Manager: Mm .\nMarketing: And uh {disfmarker}\nProject Manager: Is there enough room for creativity ?\nUser Interface: Yeah , yeah .\nIndustrial Designer: {vocalsound} Yeah , yeah .\nProject Manager: Mm . And you . {vocalsound}\nUser Interface: Yeah .\nMarketing: Yeah . When we see the results , there is no doubt there {disfmarker} {vocalsound}\nIndustrial Designer: Yeah , it's really {disfmarker}\nProject Manager: Mm . {vocalsound} Oh . {vocalsound} Okay . {vocalsound} Well , project evaluation .\nMarketing: {vocalsound} Maybe a lack of leadership ? {vocalsound}\nProject Manager: {vocalsound}\nIndustrial Designer: {vocalsound} Yeah .\nUser Interface: M maybe not , huh ?\nMarketing: Team-work , very strong , I would say .\nIndustrial Designer: Yeah , our team-work is really strong .\nMarketing: Team-work , no problem . Means . Whiteboard , digital pens .\nIndustrial Designer: Oh , we still {gap} , I guess .\nUser Interface: What was the {disfmarker} Oh yeah , what was good ? Everything . What was bad ?\nMarketing: Yeah , I think white-board is useful . Digital pens , useful .\nIndustrial Designer: Hmm .\nMarketing: New ideas found ?\nProject Manager: {vocalsound} So , you say , is there sheep ? {vocalsound}\nMarketing: Yeah .\nProject Manager: {vocalsound} Luck . {vocalsound} Okay . So luck , but good . {vocalsound}\nMarketing: But uh {disfmarker}\nProject Manager: Which imply good uh team performance .\nMarketing: Yeah ,\nProject Manager: {gap} {gap} {vocalsound}\nUser Interface: Yeah . A good leader , you know , a good leader is somewhere in the shade and {gap} {disfmarker}\nMarketing: but uh then I I mus That's true . And there's uh one very important point .\nIndustrial Designer: Don't really .\nMarketing: We're on time .\nProject Manager: Mm-hmm .\nIndustrial Designer: Yeah . And we also {disfmarker}\nMarketing: Meetings finish when they have to or even before .\nProject Manager: {vocalsound} {vocalsound}\nIndustrial Designer: Mm . We made {disfmarker} Mm . {vocalsound}\nMarketing: The {disfmarker} for meeting it's uh one of the most important thing .\nUser Interface: Of course . Uh {disfmarker}\nProject Manager: Okay . Mm . {vocalsound}\nUser Interface: Not to waste time , that's important .\nMarketing: Yeah . Yeah , we have other {vocalsound} uh remote controls to create . {vocalsound}\nUser Interface: We need time f\nIndustrial Designer: Hmm .\nProject Manager: {vocalsound} Okay . {gap} {vocalsound}\nIndustrial Designer: {vocalsound} Ah , we got new idea , speech recognition , location finding . New materials , new s uh this fancy strawberry design .\nProject Manager: A lot of uh {disfmarker}\nUser Interface: New materials .\nMarketing: Mm . {vocalsound} {gap} .\nProject Manager: {vocalsound} Yeah , uh new ways of doing financial {disfmarker} {vocalsound}\nMarketing: Mm , yeah . Hey ,\nIndustrial Designer: {vocalsound} And new tricks . {vocalsound}\nMarketing: just wondering if my uh {disfmarker} what about the the pink {disfmarker} {vocalsound} the pinkness of that uh\nProject Manager: Mm . Mm . They're working on um pink titanium . {vocalsound}\nMarketing: {gap} . They are working on a {disfmarker}\nIndustrial Designer: {vocalsound} Ah , very {gap} .\nMarketing: Okay , good .\nProject Manager: {vocalsound} {vocalsound}\nUser Interface: Budget .\nMarketing: I think we are great .\nIndustrial Designer: Yeah .\nMarketing: There's no no other words for that . {vocalsound} {vocalsound} We are probably the best .\nUser Interface: Alright .\nProject Manager: Mm yeah . Yeah ,\nMarketing: Real Reaction is uh\nProject Manager: we're really nice .\nMarketing: {disfmarker} Yeah . Yeah .\nProject Manager: Yeah . Mm . {vocalsound} Okay .\nMarketing: {vocalsound} Finished ?\nProject Manager: I think it's {disfmarker}\nMarketing: Ah , celebration . Are the costs within the budget ?\nProject Manager: Yeah . Uh {disfmarker}\nMarketing: Of course they are . Yeah .\nIndustrial Designer: Yeah .\nProject Manager: {vocalsound} How {disfmarker}\nUser Interface: Okay .\nMarketing: {vocalsound} Is the project evaluated ?\nProject Manager: Yeah .\nUser Interface: Yeah , it is .\nIndustrial Designer: Yeah , yeah ,\nMarketing: Yes , it is . {vocalsound}\nIndustrial Designer: it's {disfmarker}\nProject Manager: Mm . {vocalsound}\nIndustrial Designer: We got two {disfmarker}\nUser Interface: So , we see , we can even forecast . {gap} they propose us like celebration , everything ,\nIndustrial Designer: Good score .\nUser Interface: we could forecast it , right ?\nMarketing: To whom ? To the whole our company ?\nProject Manager: I'm the one , {vocalsound} proposing the celebration .\nIndustrial Designer: {vocalsound} Oh , okay . {vocalsound}\nProject Manager: {vocalsound} Of course ,\nUser Interface: You ? It was you .\nProject Manager: you know I'm the program manager . {vocalsound}\nUser Interface: Okay .\nMarketing: So , let's celebrate . Uh {disfmarker} {vocalsound} {vocalsound}\nProject Manager: Mm-hmm .\nIndustrial Designer: So where we will go now ?\nProject Manager: {vocalsound} {vocalsound} Ah um ,\nIndustrial Designer: Uh , ye\nProject Manager: I think it's finish .\nMarketing: {vocalsound} I think the meeting {gap} {disfmarker}\nIndustrial Designer: Will go to Italian restaurant , or {disfmarker}\nMarketing: The meeting is over at least .\nProject Manager: Yeah . Mm .\nIndustrial Designer: Ah , okay .\nMarketing: So , we have to go out . {vocalsound}\nIndustrial Designer: We can decide .\nProject Manager: Mm-mm .\nUser Interface: {vocalsound} Okay .\nIndustrial Designer: Yeah .\nProject Manager: {vocalsound} And we go to the party . {vocalsound}\nIndustrial Designer: Yeah .\nMarketing: Yeah , yeah , yeah .\nIndustrial Designer: Thank you .\nProject Manager: {gap} thank you to you . Mm .", "source": "meeting_summ", "evaluation": "rouge"}
{"instructions": ["What was concluded on semantic specification?", "Please describe the semantic specification", "How would the mental spaces operate?", "What is the description of the domains in the mental spaces?", "What was the meeting about?"], "outputs": ["The revised semantic specification and construction formalism are more stable than the previous versions. In the latter, we find both construction types and meaning types along with formal considerations like verb subcategorization, or the ones a \"directed motion\" construction would dictate.", "The semantic specification, on the other hand, is split into three levels: \"scenario\" is a list of schemas and bindings between them, which describes the current event in terms of Source-Path-Goal, Container, etc.; \"referent\" is about the entities in the discourse and includes grammatical information and pointers to the ontology; \"discourse segment\" comprises utterance-specific things.", "Mental spaces can be tackled with mechanisms that can also deal with context issues (time, space etc.): creating a base space and rules of interaction with other interconnected spaces. However, the complexity of these mechanisms has to be bound as well: it is necessary to define the range of constructions to be studied. ", "Given the domains currently used (tourist, child language learning), some features, like speaker attitude, are not of equal importance at this stage. On the other hand, it was decided for the inheritance between constructions to be left out for now, as the notation can be rendered more elegant later on.", "The revised semantic specification and construction formalism are more stable than the previous versions. Semantic constraints also come into play. The semantic specification, on the other hand, is split into three levels: \"scenario\" is a list of schemas and bindings between them, which describes the current event in terms of Source-Path-Goal, Container, etc.; \"referent\" is about the entities in the discourse and includes grammatical information and pointers to the ontology; \"discourse segment\" comprises utterance-specific things. Apart from the presentation, JavaBayes can now run through the modified web page of the project."], "input": "Grad B: what things to talk about .\nGrad F: I 'm {disfmarker} What ? Really ? Oh , that 's horrible ! Disincentive !\nGrad A: OK , we 're recording .\nGrad F: Hello ?\nGrad B: Check check {pause} check check .\nGrad D: Uh , yeah .\nGrad F: Hello ? Which am I ?\nProfessor C: Oh right .\nGrad B: Alright . Good .\nGrad F: Channel fi OK . OK . Are you doing something ? OK , then I guess I 'm doing something . So , um , So basically the result of m much thinking since the last time we met , um , but not as much writing , um , is a sheet that I have a lot of , like , thoughts and justification of comments on but I 'll just pass out as is right now . So , um , here . If you could pass this around ? And there 's two things . And so one on one side is {disfmarker} on one side is a sort of the revised sort of updated semantic specification .\nGrad D: Um {disfmarker} The {disfmarker} wait .\nGrad F: And the other side is , um , sort of a revised construction formalism .\nGrad E: This is just one sheet , right ?\nGrad D: Ah ! Just one sheet .\nGrad F: It 's just one sheet .\nGrad D: OK .\nGrad F: It 's just a {disfmarker} Nothing else .\nGrad D: Front , back .\nGrad F: Um , Enough to go around ? OK . And in some ways it 's {disfmarker} it 's {disfmarker} it 's very similar to {disfmarker} There are very few changes in some ways from what we 've , um , uh , b done before but I don't think everyone here has seen all of this . So , uh , I 'm not sure where to begin . Um , as usual the disclaimers are there are {disfmarker} all these things are {disfmarker} it 's only slightly more stable than it was before .\nGrad E: Mm - hmm .\nGrad F: And , um , after a little bit more discussion and especially like Keith and I {disfmarker} I have more linguistic things to settle in the next few days , um , it 'll probably change again some more .\nGrad E: Yeah .\nGrad F: Um , maybe I will {disfmarker} let 's start b let 's start on number two actually on the notation , um , because that 's , I 'm thinking , possibly a little more familiar to , um {disfmarker} to people . OK , so the top block is just sort of a {disfmarker} sort of abstract nota it 's sort of like , um , listings of the kinds of things that we can have . And certain things that have , um , changed , have changed back to this . There {disfmarker} there 's been a little bit of , um , going back and forth . But basically obviously all constructions have some kind of name . I forgot to include that you could have a type included in this line .\nProfessor C: What I was gonna {disfmarker} Right .\nGrad F: So something like , um {disfmarker} Well , there 's an example {disfmarker} the textual example at the end has clausal construction . So , um , just to show it doesn't have to be beautiful It could be , you know , simple old text as well . Um , there are a couple of {disfmarker} Uh , these three have various ways of doing certain things . So I 'll just try to go through them . So they could all have a type at the beginning . Um , and then they say the key word construction\nProfessor C: Oh , I see .\nGrad F: and they have some name .\nProfessor C: So {disfmarker} so the current syntax is if it s if there 's a type it 's before construct\nGrad F: Yeah , right .\nProfessor C: OK , that 's fine .\nGrad F: OK , and then it has a block that is constituents . And as usual I guess all the constructions her all the examples here have only , um , tsk {comment} one type of constituent , that is a constructional constituent . I think that 's actually gonna turn out to m be certainly the most common kind . But in general instead of the word \" construct \" , th here you might have \" meaning \" or \" form \" as well . OK ? So if there 's some element that doesn't {disfmarker} that isn't yet constructional in the sense that it maps form and meaning . OK , um , the main change with the constructs which {disfmarker} each of which has , um , the key word \" construct \" and then some name , and then some type specification , is that it 's {disfmarker} it 's pro it 's often {disfmarker} sometimes the case in the first case here that you know what kind of construction it is . So for example whatever I have here is gonna be a form of the word \" throw \" , or it 's gonna be a form of the word , you know , I don't know , \" happy \" , or something like that . Or , you know , some it 'll be a specific word or maybe you 'll have the type . You 'll say \" I need a p uh spatial relation phrase here \" or \" I need a directional specifier here \" . So - uh you could have a j a actual type here . Um , or you could just say in the second case that you only know the meaning type . So a very common example of this is that , you know , in directed motion , the first person to do something should be an agent of some kind , often a human . Right ? So if I {disfmarker} you know , the um , uh , run down the street then I {disfmarker} I {disfmarker} I run down the street , it 's typed , uh , \" I \" , meaning category is what 's there . The {disfmarker} the new kind is this one that is sort of a pair and , um , sort of skipping fonts and whatever . The idea is that sometimes there are , um , general constructions that you know , that you 're going to need . It 's {disfmarker} it 's the equivalent of a noun phrase or a prepositional phrase , or something like that there .\nGrad E: Mm - hmm .\nGrad F: And usually it has formal um , considerations that will go along with it .\nProfessor C: Mm - hmm .\nGrad F: And then uh , you might know something much more specific depending on what construction you 're talking about , about what meaning {disfmarker} what specific meaning you want . So the example again at the bottom , which is directed motion , you might need a nominal expression to take the place of , you know , um , \" the big th \" , you you know , \" the big {disfmarker} the tall dark man \" , you know , \" walked into the room \" .\nGrad E: Mm - hmm .\nGrad F: But because of the nature of this particular construction you know not just that it 's nominal of some kind but in particular , that it 's some kind of animate nominal , and which will apply just as well to like , you know , a per you know , a simple proper noun or to some complicated expression . Um , so I don't know if the syntax will hold but something that gives you a way to do both constructional and meaning types . So . OK , then I don't think the , {comment} um {disfmarker} at least {disfmarker} Yeah . {comment} None of these examples have anything different for formal constraints ? But you can refer to any of the , um , sort of available elements and scope , right ? which here are the constructs , {comment} to say something about the relation . And I think i if you not if you compare like the top block and the textual block , um , we dropped like the little F subscript . The F subscripts refer to the \" form \" piece of the construct .\nProfessor C: Good .\nGrad F: And I think that , um , in general it 'll be unambiguous . Like if you were giving a formal constraint then you 're referring to the formal pole of that . So {disfmarker} so by saying {disfmarker} if I just said \" Name one \" then that means name one formal and we 're talking about formal struc {comment} Which {disfmarker} which makes sense . Uh , there are certain times when we 'll have an exception to that , in which case you could just indicate \" here I mean the meaningful for some reason \" . Right ? Or {disfmarker} Actually it 's more often that , only to handle this one special case of , you know , \" George and Jerry walk into the room in that order \" .\nGrad E: Mm - hmm .\nGrad F: So we have a few funny things where something in the meaning might refer to something in the form . But {disfmarker} but s we 're not gonna really worry about that for right now and there are way We can be more specific if we have to later on . OK , and so in terms of the {disfmarker} the relations , you know , as usual they 're before and ends . I should have put an example in of something that isn't an interval relation but in form you might also have a value binding . You know , you could say that , um , you know , \" name - one dot \" , t you know , \" number equals \" , you know , a plural or something like that .\nGrad E: Mm - hmm .\nGrad F: There are certain things that are attribute - value , similar to the bindings below but I mean they 're just {disfmarker} us usually they 're going to be value {disfmarker} value fillers , right ? OK , and then again semantic constraints here are just {disfmarker} are just bindings . There was talk of changing the name of that . And Johno and I {disfmarker} I {disfmarker} you {disfmarker} you and I can like fight about that if you like ? but about changing it to \" semantic {pause} n effects \" , which I thought was a little bit too order - biased\nGrad B: Well {disfmarker} Th\nGrad F: and \" semantic bindings \" , which I thought might be too restrictive in case we don't have only bindings . And so it was an issue whether constraints {disfmarker} um , there were some linguists who reacted against \" constraints \" , saying , \" oh , if it 's not used for matching , then it shouldn't be called a constraint \" . But I think we want to be uncommitted about whether it 's used for matching or not . Right ? Cuz there are {disfmarker} I think we thought of some situations where it would be useful to use whatever the c bindings are , for actual , you know , sort of like modified constraining purposes .\nProfessor C: Well , you definitely want to de - couple the formalism from the parsing strategy . So that whether or not it 's used for matching or only for verification , I {disfmarker}\nGrad E: Yeah .\nGrad F: Yeah , yeah . It 's used shouldn't matter , right ? Mm - hmm .\nProfessor C: s For sure . I mean , I don't know what , uh , term we want to use\nGrad F: Mm - hmm .\nProfessor C: but we don't want to {disfmarker}\nGrad F: Yeah , uh , there was one time when {disfmarker} when Hans explained why \" constraints \" was a misleading word for him .\nProfessor C: Yep .\nGrad F: And I think the reason that he gave was similar to the reason why Johno thought it was a misleading term , which was just an interesting coincidence . Um , but , uh {disfmarker} And so I was like , \" OK , well both of you don't like it ?\nProfessor C: It 's g it 's gone .\nGrad F: Fine , we can change it \" . But I {disfmarker} I {disfmarker} I 'm starting to like it again .\nGrad B: But {disfmarker}\nGrad F: So that that 's why {disfmarker} {comment} That 's why I 'll stick with it .\nGrad A: Well , you know what ?\nGrad F: So {disfmarker}\nGrad A: If you have an \" if - then \" phrase , do you know what the \" then \" phrase is called ?\nProfessor C: Th\nGrad F: What ? Con - uh , a consequent ?\nGrad A: Yeah .\nGrad F: Yeah , but it 's not an \" if - then \" .\nGrad A: No , but {disfmarker}\nProfessor C: I know . Anyway , so the other {disfmarker} the other strategy you guys could consider is when you don't know what word to put , you could put no word ,\nGrad F: Mm - hmm .\nProfessor C: just meaning . OK ? And the then let {disfmarker}\nGrad E: Yeah .\nGrad F: Yeah , that 's true .\nGrad B: So that 's why you put semantic constraints up top and meaning bindings down {disfmarker} down here ?\nGrad F: Oh , oops ! No . That was just a mistake of cut and paste from when I was going with it .\nGrad B: OK .\nProfessor C: OK .\nGrad F: So , I 'm sorry . I didn't mean {disfmarker} that one 's an in unintentional .\nGrad B: So this should be semantic and {disfmarker}\nGrad F: Sometimes I 'm intentionally inconsistent\nGrad B: \nGrad F: cuz I 'm not sure yet . Here , I actually {disfmarker} it was just a mistake .\nGrad B: Th - so this definitely should be \" semantic constraints \" down at the bottom ?\nGrad E: Sure .\nGrad F: Yeah .\nGrad B: OK .\nGrad F: Well , unless I go with \" meaning \" but i I mean , I kind of like \" meaning \" better than \" semantic \"\nGrad B: Or {disfmarker}\nProfessor C: Oh , whatever .\nGrad F: but I think there 's {pause} vestiges of other people 's biases .\nProfessor C: Or {disfmarker} wh That - b\nGrad F: Like {disfmarker}\nProfessor C: Right . Minor {disfmarker} min problem {disfmarker}\nGrad F: Minor point .\nProfessor C: OK .\nGrad E: Extremely .\nGrad F: OK , um , so I think the middle block doesn't really give you any more information , ex than the top block . And the bottom block similarly only just illus you know , all it does is illustrate that you can drop the subscripts and {disfmarker} and that you can drop the , um {disfmarker} uh , that you can give dual types . Oh , one thing I should mention is about \" designates \" . I think I 'm actually inconsistent across these as well . So , um , strike out the M subscript on the middle block .\nProfessor C: Mm - hmm .\nGrad F: So basically now , um , this is actually {disfmarker} this little change actually goes along with a big linguistic change , which is that \" designates \" isn't only something for the semantics to worry about now .\nProfessor C: Good .\nGrad F: So we want s \" designates \" to actually know one of the constituents which acts like a head in some respects but is sort of , um , really important for say composition later on . So for instance , if some other construction says , you know , \" are you of type {disfmarker} is this part of type whatever \" , um , the \" designates \" tells you which sort of part is the meaning part . OK , so if you have like \" the big red ball \" , you know , you wanna know if there 's an object or a noun . Well , ball is going to be the designated sort of element of that kind of phrase .\nGrad E: Mmm .\nGrad F: Um , there is a slight complication here which is that when we talk about form it 's useful sometimes to talk about , um {disfmarker} to talk about there also being a designated object and we think that that 'll be the same one , right ? So the ball is the head of the phrase , \" the r the {disfmarker} \" , um , \" big red ball \" , and the entity denoted by the word \" ball \" is sort of the semantic head in some ways of {disfmarker} of this sort of , um , in interesting larger element .\nProfessor C: A a and the {disfmarker} Yeah . And there 's {disfmarker} uh there 's ca some cases where the grammar depends on some form property of the head . And {disfmarker} and this enables you to get that , if I understand you right .\nGrad E: Yeah .\nGrad F: Mm - hmm .\nGrad E: Yeah .\nGrad F: Right , right .\nGrad E: That 's the idea .\nProfessor C: Yeah yeah .\nGrad E: Yeah .\nGrad F: And , uh , you might be able to say things like if the head has to go last in a head - final language , you can refer to the head as a p the , you know {disfmarker} the formal head as opposed to the rest of the form having to be at the end of that decision .\nProfessor C: Right .\nGrad F: So that 's a useful thing so that you can get some internal structural constraints in .\nProfessor C: OK , so that all looks good . Let me {disfmarker} Oh , w Oh . I don't know . Were you finished ?\nGrad F: Um , there was a list of things that isn't included but you {disfmarker} you can {disfmarker} you can ask a question . That might @ @ it .\nProfessor C: OK . So , i if I understand this the {disfmarker} aside from , uh , construed and all that sort of stuff , the {disfmarker} the differences are mainly that , {vocalsound} we 've gone to the possibility of having form - meaning pairs for a type\nGrad F: Mm - hmm .\nProfessor C: or actually gone back to ,\nGrad F: Right .\nProfessor C: if we go back far enough {disfmarker}\nGrad F: Well , except for their construction meaning , so it 's not clear that , uh {disfmarker} Well , right now it 's a c uh contr construction type and meaning type . So I don't know what a form type is .\nProfessor C: Oh , I see . Yeah , yeah , yeah . I 'm sorry , you 're right .\nGrad F: Yeah .\nProfessor C: A construction type . Uh , that 's fine . But it , um {disfmarker}\nGrad F: Right . A well , and a previous , um , you know , version of the notation certainly allowed you to single out the meaning bit by it . So you could say \" construct of type whatever designates something \" .\nProfessor C: Yeah .\nGrad F: But that was mostly for reference purposes , just to refer to the meaning pole . I don't think that it was often used to give an extra meaning const type constraint on the meaning , which is really what we want most of the time I think .\nProfessor C: Mm - hmm .\nGrad F: Um , I {disfmarker} I don't know if we 'll ever have a case where we actually h if there is a form category constraint , you could imagine having a triple there that says , you know {disfmarker} that 's kind of weird .\nProfessor C: No , no , no , I don't think so . I think that you 'll {disfmarker} you 'll do fine .\nGrad E: I {disfmarker}\nProfessor C: In fact , these are , um , as long as {disfmarker} as Mark isn't around , these are form constraints . So a nominal expression is {disfmarker} uh , the fact that it 's animate , is semantic . The fact that it 's n uh , a nominal expression I would say on most people 's notion of {disfmarker} of f you know , higher form types , this i this is one .\nGrad F: Mm - hmm .\nGrad E: Yeah .\nGrad F: Right , right .\nProfessor C: And I think that 's just fine .\nGrad E: Yeah , yeah .\nGrad F: Which is fine , yeah .\nProfessor C: Yeah .\nGrad E: It 's {disfmarker} that now , um , I 'm mentioned this , I {disfmarker} I don't know if I ever explained this but the point of , um , I mentioned in the last meeting , {comment} the point of having something called \" nominal expression \" is , um , because it seems like having the verb subcategorize for , you know , like say taking as its object just some expression which , um , designates an object or designates a thing , or whatever , um , that leads to some syntactic problems basically ? So you wanna , you know {disfmarker} you sort of have this problem like \" OK , well , I 'll put the word \" , uh , let 's say , the word \" dog \" , you know . And that has to come right after the verb\nGrad F: Mm - hmm .\nGrad E: cuz we know verb meets its object . And then we have a construction that says , oh , you can have \" the \" preceding a noun . And so you 'd have this sort of problem that the verb has to meet the designatum .\nProfessor C: Right .\nGrad E: And you could get , you know , \" the kicked dog \" or something like that , meaning \" kicked the dog \" .\nProfessor C: Right .\nGrad E: Um , so you kind of have to let this phrase idea in there\nProfessor C: That I {disfmarker} I have no problem with it at all .\nGrad E: but {disfmarker} It - it\nProfessor C: I think it 's fine .\nGrad E: Yeah .\nGrad F: Yeah . Right , n s you may be {disfmarker} you may not be like everyone else in {disfmarker} in Berkeley ,\nGrad E: Yeah . Yeah .\nGrad F: but that 's OK .\nGrad E: I mean , we {disfmarker} we {disfmarker} we sort of thought we were getting away with , uh {disfmarker} with , a p\nGrad F: Uh , we don't mind either , so {disfmarker}\nGrad E: I mean , this is not reverting to the X - bar theory of {disfmarker} of phrase structure .\nProfessor C: Right .\nGrad E: But , uh ,\nGrad F: Right .\nGrad E: I just know that this is {disfmarker} Like , we didn't originally have in mind that , uh {disfmarker} that verbs would subcategorize for a particular sort of form .\nGrad F: Mm - hmm .\nProfessor C: But they do .\nGrad E: Um , but they does .\nGrad F: Well , there 's an alternative to this\nGrad E: At least in English .\nGrad F: which is , um {disfmarker} The question was did we want directed motion ,\nProfessor C: Yeah .\nGrad F: which is an argument structure construction {disfmarker}\nProfessor C: Mm - hmm .\nGrad E: Yeah .\nGrad F: did we want it to worry about , um , anything more than the fact that it , you know , has semantic {disfmarker} You know , it 's sort of frame - based construction . So one option that , you know , Keith had mentioned also was like , well if you have more abstract constructions such as subject , predicate , basically things like grammatical relations ,\nGrad E: Mm - hmm .\nGrad F: those could intersect with these in such a way that subject , predicate , or subject , predicate , subject , verb , ob you know , verb object would require that those things that f fill a subject and object are NOM expressions .\nProfessor C: Right .\nGrad F: And that would be a little bit cleaner in some way . But you know , for now , I mean ,\nProfessor C: Yeah . But it {disfmarker} y y it 's {disfmarker} yeah , just moving it {disfmarker} moving the c the cons the constraints around .\nGrad F: uh , you know . M moving it to another place , right .\nGrad E: Yeah .\nProfessor C: OK , so that 's {disfmarker}\nGrad F: But there does {disfmarker} basically , the point is there has to be that constraint somewhere , right ?\nProfessor C: Right .\nGrad F: So , yeah .\nProfessor C: And so that was the {disfmarker}\nGrad F: Robert 's not happy now ?\nGrad A: No !\nGrad F: Oh , OK .\nProfessor C: OK , and sort of going with that is that the designatum also now is a pair .\nGrad F: Yes .\nProfessor C: Instead of just the meaning .\nGrad F: Mm - hmm .\nProfessor C: And that aside from some terminology , that 's basically it .\nGrad F: Right .\nProfessor C: I just want to b I 'm {disfmarker} I 'm asking .\nGrad E: Mm - hmm .\nGrad F: Yep .\nGrad E: Yeah .\nGrad F: Yeah , um , the un sort of the un - addressed questions in this , um , definitely would for instance be semantic constraints we talked about .\nProfessor C: Yeah .\nGrad F: Here are just bindings but , right ? we might want to introduce mental spaces {disfmarker} You know , there 's all these things that we don't {disfmarker}\nProfessor C: The whole {disfmarker} the mental space thing is clearly not here .\nGrad F: Right ? So there 's going to be some extra {disfmarker} you know , definitely other notation we 'll need for that which we skip for now .\nGrad E: Mm - hmm .\nProfessor C: By the way , I do want to get on that as soon as Robert gets back .\nGrad F: Uh Yeah .\nProfessor C: So , uh , the {disfmarker} the mental space thing .\nGrad F: OK .\nProfessor C: Um , obviously , {vocalsound} construal is a b is a b is a big component of that\nGrad E: Mm - hmm .\nProfessor C: so this probably not worth trying to do anything till he gets back . But sort of as soon as he gets back I think um , we ought to {disfmarker}\nGrad F: Mm - hmm . Mm - hmm .\nGrad E: So what 's the {disfmarker} what 's the time frame ? I forgot again when you 're going away for how long ?\nGrad A: Just , uh , as a {disfmarker} sort of a mental bridge , I 'm not {disfmarker} I 'm skipping fourth of July . So , uh , {vocalsound} right afterwards I 'm back .\nGrad E: OK . OK .\nGrad F: What ? You 're missing like the premier American holiday ? What 's the point of spending a year here ?\nGrad A: Uh , I 've had it often enough .\nGrad F: So , anyway .\nGrad B: Well he w he went to college here .\nGrad F: Oh , yeah , I forgot . Oops . {comment} Sorry .\nProfessor C: Yeah .\nGrad F: OK .\nProfessor C: And furthermore it 's well worth missing .\nGrad F: Not in California .\nGrad E: Yes .\nGrad F: Yeah , that 's true . I like {disfmarker} I {disfmarker} I like spending fourth of July in other countries , {vocalsound} whenever I can .\nProfessor C: Right .\nGrad F: Um {disfmarker}\nProfessor C: OK , so that 's great .\nGrad F: Construal , OK , so {disfmarker} Oh , so there was one question that came out . I hate this thing . Sorry . Um , which is , so something like \" past \" which i you know , we think is a very simple {disfmarker} uh , we 've often just stuck it in as a feature ,\nProfessor C: Right . Right .\nGrad F: you know , \" oh , {pause} this event takes place before speech time \" , {comment} OK , is what this means . Um , it 's often thought of as {disfmarker} it is also considered a mental space ,\nProfessor C: Right .\nGrad F: you know , by , you know , lots of people around here .\nProfessor C: Right .\nGrad F: So there 's this issue of well sometimes there are really exotic explicit space builders that say \" in France , blah - blah - blah \" ,\nGrad E: Mm - hmm .\nGrad F: and you have to build up {disfmarker} you ha you would imagine that would require you , you know , to be very specific about the machinery , whereas past is a very conventionalized one and we sort of know what it means but it {disfmarker} we doesn't {disfmarker} don't necessarily want to , you know , unload all the notation every time we see that it 's past tense .\nProfessor C: Right .\nGrad F: So , you know , we could think of our {disfmarker} uh , just like X - schema \" walk \" refers to this complicated structure , past refers to , you know , a certain configuration of this thing with respect to it .\nProfessor C: I think that 's exactly right .\nGrad F: So {disfmarker} so we 're kind of like having our cake and eating it {disfmarker}\nProfessor C: Yeah .\nGrad F: you know , having it both ways , right ?\nProfessor C: Yeah . {pause} No , I think {disfmarker} I think that i we 'll have to see how it works out when we do the details\nGrad F: So , i i Mm - hmm .\nProfessor C: but my intuition would be that that 's right .\nGrad F: Mm - hmm . Yeah , OK .\nGrad A: Do you want to do the same for space ?\nGrad F: Wha - sorry ?\nGrad A: Space ?\nGrad F: Space ?\nGrad A: Here ? Now ?\nGrad F: Oh , oh , oh , oh , instead of just time ?\nGrad A: Mm - hmm .\nGrad F: Yeah , yeah , yeah . Same thing . So there are very conventionalized like deictic ones , right ? And then I think for other spaces that you introduce , you could just attach y whatever {disfmarker}\nGrad A: Hmm .\nGrad F: You could build up an appropriately {disfmarker} uh , appropriate structure according to the l the sentence .\nProfessor C: Yeah .\nGrad A: Hmm , well this {disfmarker} this basically would involve everything you can imagine to fit under your C dot something {disfmarker}\nGrad E: N\nGrad A: you know , where {disfmarker} where it 's contextually dependent ,\nGrad F: Yeah . Right .\nGrad A: \" what is now , what was past ,\nGrad F: Mm - hmm .\nGrad A: what is in the future , where is this , what is here , what is there , what is {disfmarker} \"\nGrad F: Mm - hmm . Yeah . So time and space . Um , we 'll {disfmarker} we 'll get that on the other side a little , like very minimally . There 's a sort of there 's a slot for setting time and setting place .\nProfessor C: Good .\nGrad F: And you know , you could imagine for both of those are absolute things you could say about the time and place , and then there are many in more interestingly , linguistically anyway , {comment} there are relative things that , you know , you relate the event in time and space to where you are now . If there 's something a lot more complicated like , or so {disfmarker} hypothetical or whatever , then you have to do your job ,\nGrad E: Mm - hmm .\nGrad F: like or somebody 's job anyway .\nGrad E: Yeah .\nGrad F: I 'm gonna point to {disfmarker} at random .\nGrad E: Yeah . I mean , I 'm {disfmarker} I 'm s curious about how much of the mental {disfmarker} I mean , I 'm not sure that the formalism , sort of the grammatical side of things , {comment} is gonna have that much going on in terms of the mental space stuff . You know , um , basically all of these so - called space builders that are in the sentence are going to sort of {disfmarker} I think of it as , sort of giving you the coordinates of , you know {disfmarker} assuming that at any point in discourse there 's the possibility that we could be sort of talking about a bunch of different world scenarios , whatever , and the speaker 's supposed to be keeping track of those . The , um {disfmarker} the construction that you actually get is just gonna sort of give you a cue as to which one of those that you 've already got going , um , you 're supposed to add structure to .\nGrad F: Mm - hmm .\nGrad E: So \" in France , uh , Watergate wouldn't have hurt Nixon \" or something like that . Um , well , you say , \" alright , I 'm supposed to add some structure to my model of this hypothetical past France universe \" or something like that . The information in the sentence tells you that much but it doesn't tell you like exactly what it {disfmarker} what the point of doing so is . So for example , depending on the linguistic con uh , context it could be {disfmarker} like the question is for example , what does \" Watergate \" refer to there ? Does it , you know {disfmarker} does it refer to , um {disfmarker} if you just hear that sentence cold , the assumption is that when you say \" Watergate \" you 're referring to \" a Watergate - like scandal as we might imagine it happening in France \" . But in a different context , \" oh , you know , if Nixon had apologized right away it wouldn't {disfmarker} you know , Watergate wouldn't have hurt him so badly in the US and in France it wouldn't have hurt him at all \" . Now we 're s now that \" Watergate \" {disfmarker} we 're now talking about the real one ,\nGrad F: They 're real , right .\nGrad E: and the \" would \" sort of {disfmarker} it 's a sort of different dimension of hypothe - theticality , right ? We 're not saying {disfmarker} What 's hypothetical about this world .\nGrad F: I see {disfmarker} right .\nGrad E: In the first case , hypothetically we 're imagining that Watergate happened in France .\nGrad F: Hmm .\nGrad E: In the second case we 're imagining hypothetically that Nixon had apologized right away\nGrad F: Mm - hmm .\nGrad E: or something . Right ?\nGrad F: Right .\nGrad E: So a lot of this isn't happening at the grammatical level .\nProfessor C: Correct .\nGrad E: Uh , um , and so {disfmarker}\nGrad F: Mm - hmm .\nGrad E: I don't know where that sits then ,\nGrad A: Hmm .\nGrad E: sort of the idea of sorting out what the person meant .\nGrad F: It seems like , um , the grammatical things such as the auxiliaries that you know introduce these conditionals , whatever , give you sort of the {disfmarker} the most basi\nGrad E: Mm - hmm .\nGrad F: th those we {disfmarker} I think we can figure out what the possibilities are , right ?\nGrad E: Mm - hmm .\nGrad F: There are sort of a relatively limited number . And then how they interact with some extra thing like \" in France \" or \" if such - and - such \" , that 's like there are certain ways that they c they can {disfmarker}\nGrad E: Yeah .\nGrad F: You know , one is a more specific version of the general pattern that the grammat grammar gives you .\nGrad E: Yeah .\nGrad F: I think . But , you know , whatever ,\nProfessor C: Yeah , in the short run all we need is a enough mechanism on the form side to get things going .\nGrad F: we {disfmarker} we 're {disfmarker}\nGrad E: Mm - hmm . Yeah .\nProfessor C: Uh , I {disfmarker} uh , you {disfmarker} you {disfmarker}\nGrad E: But the whole point of {disfmarker} the whole point of what Fauconnier and Turner have to say about , uh , mental spaces , and blending , and all that stuff is that you don't really get that much out of the sentence . You know , there 's not that much information contained in the sentence . It just says , \" Here . Add this structure to this space . \" and exactly what that means for the overall ongoing interpretation is quite open . An individual sentence could mean a hundred different things depending on , quote , \" what the space configuration is at the time of utterance \" .\nGrad F: Mm - hmm . Mm - hmm .\nGrad E: And so somebody 's gonna have to be doing a whole lot of work but not me , I think .\nProfessor C: Well {disfmarker} I think that 's right . Oh , I {disfmarker} yeah , I , uh , uh {disfmarker} I think that 's {disfmarker} Not k I th I don't think it 's completely right . I mean , in fact a sentence examples you gave in f did constrain the meaning b the form did constrain the meaning ,\nGrad E: Yeah .\nProfessor C: and so , um , it isn't , uh {disfmarker}\nGrad E: Sure , but like what {disfmarker} what was the point of saying that sentence about Nixon and France ? That is not {disfmarker} there is nothing about that in the {disfmarker} in the sentence really .\nGrad F: That 's OK . We usually don't know the point of the sentence at all .\nGrad E: Yeah .\nGrad F: But we know what it 's trying to say .\nProfessor C: Yeah .\nGrad E: Y yeah .\nGrad F: We {disfmarker} we know that it 's {disfmarker} what predication it 's setting up .\nProfessor C: But {disfmarker} but {disfmarker} bottom line , I agree with you ,\nGrad E: Yeah .\nGrad F: That 's all .\nProfessor C: that {disfmarker} that {disfmarker} that we 're not expecting much out of the , uh f\nGrad E: Yeah .\nGrad F: Purely linguistic cues , right ?\nProfessor C: uh , the purely form cues , yeah .\nGrad F: So .\nProfessor C: And , um {disfmarker} I mean , you 're {disfmarker} you 're the linguist\nGrad F: Mmm .\nProfessor C: but , uh , it seems to me that th these {disfmarker} we {disfmarker} we {disfmarker} you know , we 've talked about maybe a half a dozen linguistics theses in the last few minutes or something .\nGrad E: Yeah , yeah .\nProfessor C: Yeah , I mean {disfmarker}\nGrad E: Yeah . Oh , yeah .\nProfessor C: uh , I {disfmarker} I mean , that {disfmarker} that 's my feeling that {disfmarker} that these are really hard uh , problems that decide exactly what {disfmarker} what 's going on .\nGrad E: Mm - hmm . Yeah . Yeah .\nProfessor C: OK .\nGrad F: OK , so , um , one other thing I just want to point out is there 's a lot of confusion about the terms like \" profile , designate , focus \" , et cetera , et cetera .\nProfessor C: Uh , right , right , right .\nGrad E: Mm - hmm .\nGrad F: Um , for now I 'm gonna say like \" profile \" 's often used {disfmarker} like two uses that come to mind immediately . One is in the traditional like semantic highlight of one element with respect to everything else . So \" hypotenuse \" , you profiled this guy against the background of the {pause} right t right triangle .\nGrad E: Mm - hmm .\nGrad F: OK . And the second use , um , is in FrameNet. It 's slightly different . Oh , I was asking Hans about this . They use it to really mean , um , this {disfmarker} in a frame th this is {disfmarker} the profiles on the {disfmarker} these are the ones that are required . So they have to be there or expressed in some way . Which {disfmarker} which {disfmarker} I 'm not saying one and two are mutually exclusive but they 're {disfmarker} they 're different meanings .\nProfessor C: Right .\nGrad E: Mm - hmm .\nGrad F: So the closest thing {disfmarker} so I was thinking about how it relates to this notation . For us , um {disfmarker} OK , so how is it {disfmarker}\nProfessor C: Does that {disfmarker} Is that really what they mean in {disfmarker} in {disfmarker}\nGrad F: so \" designate \" {disfmarker} FrameNet ?\nProfessor C:  I didn't know that .\nGrad F: FrameNet ? Yeah , yeah . I {disfmarker} I mean , I {disfmarker} I was a little bit surprised about it too .\nProfessor C: Yeah .\nGrad F: I knew that {disfmarker} I thought that that would be something like {disfmarker} there 's another term that I 've heard for that thing\nProfessor C: Right , OK .\nGrad F: but they {disfmarker} I mean {disfmarker} uh , well , at least Hans says they use it that way . And {disfmarker}\nProfessor C: Well , I 'll check .\nGrad F: and may maybe he 's wrong . Anyway , so I think the {disfmarker} the \" designate \" that we have in terms of meaning is really the \" highlight this thing with respect to everything else \" . OK ?\nProfessor C: Right .\nGrad F: So this is what {disfmarker} what it means . But the second one seems to be useful but we might not need a notation for it ? We don't have a notation for it but we might want one . So for example we 've talked about if you 're talking about the lexical item \" walk \" , you know it 's an action . Well , it also has this idea {disfmarker} it carries along with it the idea of an actor or somebody 's gonna do the walking . Or if you talk about an adjective \" red \" , it carries along the idea of the thing that has the property of having color red . So we used to use the notation \" with \" for this\nProfessor C: Right .\nGrad F: and I think that 's closest to their second one . So I d don't yet know , I have no commitment , as to whether we need it . It might be {disfmarker} it 's the kind of thing that w a parser might want to think about whether we require {disfmarker} you know , these things are like it 's semantically part of it {disfmarker}\nProfessor C: N no , no . Well , uh , th critically they 're not required syntactically . Often they 're pres presu presupposed and all that sort of stuff .\nGrad F: Right . Right , right . Yeah , um , definitely . So , um , \" in \" was a good example . If you walk \" in \" , like well , in what ?\nProfessor C: Right , there 's {disfmarker}\nGrad F: You know , like you have to have the {disfmarker} {comment} So {disfmarker} so it 's only semantically is it {disfmarker} it is still required , say , by simulation time though\nProfessor C: Right .\nGrad F: to have something . So it 's that {disfmarker} I meant the idea of like that {disfmarker} the semantic value is filled in by sim simulation . I don't know if that 's something we need to spa to {disfmarker} to like say ever as part of the requirement ? {disfmarker} or the construction ? or not . We 'll {disfmarker} we 'll again defer .\nProfessor C: Or {disfmarker} I mean , or {disfmarker} or , uh so the {disfmarker}\nGrad F: Have it construed ,\nProfessor C: Yeah , yeah .\nGrad F: is that the idea ? Just point at Robert . Whenever I 'm confused just point to him .\nProfessor C: Right . It 's {disfmarker} it 's his thesis , right ?\nGrad F: You tell me .\nProfessor C: Anyway ,\nGrad F: OK .\nProfessor C: right , yeah , w this is gonna be a b you 're right , this is a bit of in a mess and we still have emphasis as well , or stress , or whatever .\nGrad F: OK , well we 'll get , uh uh , I {disfmarker} we have thoughts about those as well .\nProfessor C: Yeah . Great .\nGrad F: Um , the I w I would just s some of this is just like my {disfmarker} you know , by fiat . I 'm going to say , this is how we use these terms . I don't - you know , there 's lots of different ways in the world that people use it .\nProfessor C: I {disfmarker} that 's fine .\nGrad E: Yeah .\nGrad F: I think that , um , the other terms that are related are like focus and stress .\nProfessor C: Mm - hmm .\nGrad F: So , s I think that the way I {disfmarker} we would like to think , uh , I think is focus is something that comes up in , I mean , lots of {disfmarker} basically this is the information structure .\nProfessor C: Mm - hmm .\nGrad F: OK , it 's like {disfmarker} uh , it 's not {disfmarker} it might be that there 's a syntactic , uh , device that you use to indicate focus or that there are things like , you know , I think Keith was telling me , {comment} things toward the end of the sentence , post - verbal , tend to be the focused {disfmarker} focused element ,\nGrad E: Mmm .\nGrad F: the new information . You know , if I {disfmarker} \" I walked into the room \" , you {disfmarker} tend to think that , whatever , \" into the room \" is sort of like the more focused kind of thing .\nGrad E: Mm - hmm . Yeah .\nGrad F: And when you , uh , uh , you have stress on something that might be , you know , a cue that the stressed element , or for instance , the negated element is kind of related to information structure . So that 's like the new {disfmarker} the sort of like import or whatever of {disfmarker} of this thing . Uh , so {disfmarker} so I think that 's kind of nice to keep \" focus \" being an information structure term . \" Stress \" {disfmarker} I th and then there are different kinds of focus that you can bring to it . So , um , like \" stress \" , th stress is kind of a pun on {disfmarker} you might have like {disfmarker} whatever , like , um , accent kind of stress .\nGrad E: Mm - hmm .\nGrad F: And that 's just a {disfmarker} uh , w we 'll want to distinguish stress as a form device . You know , like , oh , high volume or whatever .\nGrad E: Yeah .\nGrad F: Um , t uh , and distinguish that from it 's effect which is , \" Oh , the kind of focus we have is we 're emphasizing this value often as opposed to other values \" , right ? So focus carries along a scope . Like if you 're gonna focus on this thing and you wanna know {disfmarker} it sort of evokes all the other possibilities that it wasn't .\nGrad E: Mm - hmm .\nGrad F: Um , so my classic {disfmarker} my now - classic example of saying , \" Oh , he did go to the meeting ? \" ,\nGrad E: Yeah .\nGrad F: that was my way of saying {disfmarker} as opposed to , you know , \" Oh , he didn't g \" or \" There was a meeting ? \"\nGrad E: Yeah .\nGrad F: I think that was the example that was caught on by the linguists immediately .\nGrad E: Yeah .\nGrad F: And so , um , the {disfmarker} like if you said he {disfmarker} you know , there 's all these different things that if you put stress on a different part of it then you 're , c focusing , whatever , on , uh {disfmarker}\nGrad E: Mm - hmm .\nGrad F: \" he walked to the meeting \" as opposed to \" he ran \" , or \" he did walk to the meeting \" as opposed to \" he didn't walk \" . You know ,\nGrad E: Mm - hmm .\nGrad F: so we need to have a notation for that which , um , I think that 's still in progress . So , sort of I 'm still working it out . But it did {disfmarker} one {disfmarker} one implication it does f have for the other side , which we 'll get to in a minute is that I couldn't think of a good way to say \" here are the possible things that you could focus on \" , cuz it seems like any entity in any sentence , you know , or any meaning component of anyth you know {disfmarker} all the possible meanings you could have , any of them could be the subject of focus .\nProfessor C: Mmm .\nGrad F: But I think one {disfmarker} the one thing you can schematize is the kind of focus , right ? So for instance , you could say it 's the {disfmarker} the tense on this as opposed to , um , the {disfmarker} the action . OK . Or it 's {disfmarker} uh , it 's an identity thing or a contrast with other things , or stress this value as opposed to other things . So , um , it 's {disfmarker} it is kind of like a profile {disfmarker} profile - background thing but I {disfmarker} I can't think of like the limited set of possible meanings that you would {disfmarker} that you would focu\nGrad E: Light up with focus , yeah .\nGrad F: light {disfmarker} highlight as opposed to other ones . So it has some certain complications for the , uh , uh {disfmarker} later on . Li - I mean , uh , the best thing I can come up with is that information has a list of focused elements . For instance , you {disfmarker} Oh , one other type that I forgot to mention is like query elements and that 's probably relevant for the like \" where is \" , you know , \" the castle \" kind of thing ?\nGrad E: Mm - hmm .\nGrad F: Because you might want to say that , um , location or cert certain WH words bring {disfmarker} you know , sort of automatically focus in a , you know , \" I don't know the identity of this thing \" kind of way on certain elements . So . OK . Anyway . So that 's onl there are {disfmarker} there are many more things that are uncl that are sort of like a little bit unstable about the notation but it 's most {disfmarker} I think it 's {disfmarker} this is , you know , the current {disfmarker} current form . Other things we didn't {vocalsound} totally deal with , um ,\nGrad E: Oh , there 's a bunch .\nGrad F: well , we 've had a lot of other stuff that Keith and I have them working on in terms of like how you deal with like an adjective .\nGrad E: Yeah .\nGrad F: You know , a {disfmarker} a nominal expression .\nGrad E: Yeah .\nGrad F: And , um , I mean , we should have put an example of this and we could do that later .\nGrad E: Yeah .\nGrad F: But I think the not inherently like the general principles still work though , that , um , we can have constructions that have sort of constituent structure in that there is like , you know , for instance , one {disfmarker} Uh , you know , they {disfmarker} they have constituents , right ? So you can like nest things when you need to , but they can also overlap in a sort of flatter way . So if you don't have like a lot of grammar experience , then like this {disfmarker} this might , you know , be a little o opaque . But , you know , we have the {pause} properties of dependency grammars and some properties of constituents {disfmarker} constituent - based grammar . So that 's {disfmarker} I think that 's sort of the main thing we wanted to aim for\nGrad E: Mm - hmm .\nGrad F: and so far it 's worked out OK .\nProfessor C: Good .\nGrad F: So . OK .\nGrad A: I can say two things about the f\nGrad F: Yes .\nGrad A: Maybe you want to forget stress . This {disfmarker} my f\nGrad F: As a word ?\nGrad A: No , as {disfmarker} as {disfmarker} Just don't {disfmarker} don't think about it .\nGrad F: As a {disfmarker} What 's that ?\nGrad A: If {disfmarker}\nGrad F: Sorry .\nGrad A: canonically speaking you can {disfmarker} if you look at a {disfmarker} a curve over sentence , you can find out where a certain stress is and say , \" hey , that 's my focus exponent . \"\nGrad E: Right .\nGrad F: Mm - hmm .\nGrad A: It doesn't tell you anything what the focus is . If it 's just that thing ,\nGrad F: Mm - hmm . Or the constituent that it falls in .\nGrad A: a little bit more or the whole phrase .\nGrad E: Mm - hmm .\nGrad A: Um {disfmarker}\nGrad F: You mean t forget about stress , the form cue ?\nGrad A: The form bit\nGrad E: Yeah .\nGrad A: because , uh , as a form cue , um , not even trained experts can always {disfmarker} well , they can tell you where the focus exponent is sometimes .\nGrad F: OK .\nGrad A: And that 's also mostly true for read speech . In {disfmarker} in real speech , um , people may put stress . It 's so d context dependent on what was there before , phrase ba breaks , um , restarts .\nGrad F: Yeah . Mm - hmm .\nGrad A: It 's just , um {disfmarker} it 's absurd . It 's complicated .\nGrad F: OK ,\nGrad A: And all {disfmarker}\nGrad E: Yeah , I mean , I {disfmarker} I 'm sort of inclined to say let 's worry about specifying the information structure focus of the sentence\nGrad F: I believe you , yeah .\nGrad E: and then ,\nGrad F: Mm - hmm . Ways that you can get it come from th\nGrad E: hhh , {comment} the phonology component can handle actually assigning an intonation contour to that .\nGrad F: right .\nGrad E: You know , I mean , later on we 'll worry about exactly how {disfmarker}\nGrad A: Or {disfmarker} or map from the contour to {disfmarker} to what the focus exponent is .\nGrad E: y Yeah . Exactly .\nGrad F: Mm - hmm .\nGrad E: But figure out how the {disfmarker}\nGrad A: But , uh , if you don't know what you 're {disfmarker} what you 're focus is then you 're {disfmarker} you 're hopeless - uh - ly lost anyways ,\nGrad E: Yeah .\nGrad F: Right . That 's fine , yeah . Mm - hmm .\nGrad A: and the only way of figuring out what that is , {vocalsound} is , um , by sort of generating all the possible alternatives to each focused element , decide which one in that context makes sense and which one doesn't .\nGrad F: Mm - hmm .\nGrad A: And then you 're left with a couple three . So , you know , again , that 's something that h humans can do ,\nGrad F: Mm - hmm .\nGrad A: um , but far outside the scope of {disfmarker} of any {disfmarker} anything . So . You know . It 's {disfmarker}\nGrad F: OK . Well , uh , yeah , I wouldn't have assumed that it 's an easy problem in {disfmarker} in absence of all the oth\nGrad A: u u\nGrad F: you need all the other information I guess .\nGrad A: But it 's {disfmarker} it 's {disfmarker} what it {disfmarker} uh , it 's pretty easy to put it in the formalism , though . I mean , because\nGrad F: Yeah .\nGrad A: you can just say whatever stuff , \" i is the container being focused or the {disfmarker} the entire whatever , both , and so forth . \"\nGrad F: Mm - hmm , mm - hmm .\nGrad E: Mm - hmm .\nGrad F: Yeah . Exactly . So the sort of effect of it is something we want to be able to capture .\nProfessor C: Yeah , so b b but I think the poi I 'm not sure I understand but here 's what I th think is going on . That if we do the constructions right when a particular construction matches , it {disfmarker} the fact that it matches , does in fact specify the focus .\nGrad F: W uh , I 'm not sure about that .\nProfessor C: OK .\nGrad F: Or it might limit {disfmarker} it cert certainly constrains the possibilities of focus .\nProfessor C: Uh {disfmarker} k uh , at at the very least it constrai\nGrad F: I think that 's {disfmarker} that 's , th that 's certainly true . And depending on the construction it may or may not f specify the focus , right ?\nProfessor C: Oh , uh , for sure , yes . There are constrai yeah , it 's not every {disfmarker} but there are constructions , uh , where you t explicitly take into account those considerations\nGrad F: Yeah . Mm - hmm .\nProfessor C: that you need to take into account in order to decide which {disfmarker} what is being focused .\nGrad F: Mm - hmm .\nGrad A: Mm - hmm . So we talked about that a little bit this morning . \" John is on the bus , not Nancy . \"\nGrad F: Mm - hmm .\nGrad A: So that 's {disfmarker} focuses on John .\nProfessor C: Right .\nGrad F: Hmm .\nGrad A: \" John is on the bus and not on the train . \"\nGrad F: Mm - hmm .\nGrad A: \" John is on the bus \" versus \" John is on the train . \"\nProfessor C: Right .\nGrad F: Right .\nGrad A: And \" John is on the bus \" versus \" was \" , and e\nGrad F: Is on . \" John is on the bus \" . Yeah . Yeah .\nGrad A: \" it 's the bu \" so e\nProfessor C: Right . Yeah , all {disfmarker} all of those .\nGrad A: All of these\nProfessor C: Yeah .\nGrad F: Right .\nGrad A: and will we have {disfmarker} u is it all the same constructions ? Just with a different foc focus constituent ?\nGrad F: Yeah , I would say that argument structure in terms of like the main like sort of ,\nGrad A: Mm - hmm .\nGrad F: I don't know {disfmarker} the fact that you can get it without any stress and you have some {disfmarker} whatever is predicated anyway should be the same set of constructions . So that 's why I was talking about overlapping constructions . So , then you have a separate thing that picks out , you know , stress on something relative to everything else .\nProfessor C: Yeah . So , the question is actually {disfmarker}\nGrad E: Mm - hmm .\nProfessor C: oh , I 'm sorry ,\nGrad F: And it would {disfmarker}\nProfessor C: go ahead ,\nGrad F: yeah ,\nProfessor C: finish .\nGrad F: and it w and that would have to {disfmarker} uh it might be ambiguous as , uh , whether it picks up that element , or the phrase , or something like that . But it 's still is limited possibility .\nGrad A: Hmm .\nGrad F: So that should , you know , interact with {disfmarker} it should overlap with whatever other construction is there .\nGrad A: Yeah .\nProfessor C: S s the question is , do we have a way on the other page , uh , when we get to the s semantic side , of saying what the stressed element was , or stressed phrase , or something .\nGrad F: Mm - hmm . Well , so that 's why I was saying how {disfmarker} since I couldn't think of an easy like limited way of doing it , um , all I can say is that information structure has a focused slot\nProfessor C: Right .\nGrad F: and I think that should be able to refer to {disfmarker}\nProfessor C: So that 's down at the bottom here when we get over there . OK .\nGrad F: Yeah , and , infer {disfmarker} and I don't have {disfmarker} I don't have a great way or great examples\nProfessor C: I 'll - I 'll wait . OK .\nGrad F: but I think that {disfmarker} something like that is probably gonna be , uh , more {disfmarker} more what we have to do .\nGrad A: Hmm .\nProfessor C: OK .\nGrad F: But , um ,\nGrad A: So\nGrad F: OK , that was one comment . And you had another one ?\nGrad A: Yeah , well the {disfmarker} once you know what the focus is the {disfmarker} everything else is background . How about \" topic - comment \" that 's the other side of information .\nGrad F: How about what ?\nGrad A: Topic - comment .\nGrad F: Yeah , so that was the other thing . And so I didn't realize it before . It 's like , \" oh ! \" It was an epiphany that it {disfmarker} you know , topic and focus are a contrast set . So topic is {disfmarker} Topic - focused seems to me like , um , background profile , OK , or a landmark trajector , or some something like that . There 's {disfmarker} there 's definitely , um , that kind of thing going on .\nGrad A: Mmm .\nGrad F: Now I don't know whether {disfmarker} I n I don't have as many great examples of like topic - indicating constructions on like focus , right ? Um , topic {disfmarker} it seems kind of {disfmarker} you know , I think that might be an ongoing kind of thing .\nGrad A: Mm - hmm .\nGrad E: Japanese has this though . You know .\nGrad F: Topic marker ?\nGrad A: Yeah .\nGrad E: Yeah , that 's what \" wa \" is , uh , just to mark which thing is the topic .\nGrad F: Mm - hmm .\nGrad E: It doesn't always have to be the subject .\nGrad F: Mm - hmm . Right . So again , information structure has a topic slot . And , you know , I stuck it in thinking that we might use it .\nGrad A: Mm - hmm .\nGrad F: Um , I think I stuck it in .\nProfessor C: Yep , it 's there .\nGrad F: Um , and one thing that I didn't do consistently , um , is {disfmarker} when we get there , is like indicate what kind of thing fits into every role . I think I have an idea of what it should be but th you know , so far we 've been getting away with like either a type constraint or , um , you know , whatever . I forg it 'll be a frame . You know , it 'll be {disfmarker} it 'll be another predication or it 'll be , um , I don't know , some value from {disfmarker} from some something , some variable and scope or something like that , or a slot chain based on a variable and scope . OK , so well that 's {disfmarker} should we flip over to the other side officially then ?\nGrad A: Mm - hmm , hmm .\nGrad E: OK , side one .\nGrad F: I keep , uh , like , pointing forward to it . Yeah . Now we 'll go back to s OK , so this doesn't include something which mi mi may have some effect on {disfmarker} on it , which is , um , the discourse situation context record , right ? So I didn't {disfmarker} I {disfmarker} I meant just like draw a line and like , you know , you also have , uh , some tracking of what was going on .\nProfessor C: Right .\nGrad F: And sort of {disfmarker} this is a big scale comment before I , you know , look into the details of this . But for instance you could imagine instead of having {disfmarker} I {disfmarker} I changed the name of {disfmarker} um it used to be \" entities \" . So you see it 's \" scenario \" , \" referent \" and \" discourse segment \" . And \" scenario \" is essentially what kind of {disfmarker} what 's the basic predication , what event happened . And actually it 's just a list of various slots from which you would draw {disfmarker} draw in order to paint your picture , a bunch of frames , bi and bindings , right ? Um , and obviously there are other ones that are not included here , general cultural frames and general like , uh , other action f\nGrad E: Mm - hmm .\nGrad F: you know , specific X - schema frames . OK , whatever . The middle thing used to be \" entities \" because you could imagine it should be like really a list where here was various information . And this is intended to be grammatically specifiable information about a referent {disfmarker} uh , you know , about some entity that you were going to talk about . So \" Harry walked into the room \" , \" Harry \" and \" room \" , you know , the room {disfmarker} th but they would be represented in this list somehow . And it could also have for instance , it has this category slot . Um , it should be either category or in or instance . Basically , it could be a pointer to ontology . So that everything you know about this could be {disfmarker} could be drawn in . But the important things for grammatical purposes are for {disfmarker} things like number , gender , um {disfmarker} ki the ones I included here are slightly arbitrary but you could imagine that , um , you need to figure out wheth if it 's a group whether , um , some event is happening , linear time , linear spaces , like , you know , are {disfmarker} are they doing something serially or is it like , um , uh I 'm {disfmarker} I 'm not sure . Because this partly came from , uh , Talmy 's schema and I 'm not sure we 'll need all of these actually . But {disfmarker} Um , and then the \" status \" I used was like , again , in some languages , you know , like for instance in child language you might distinguish between different status . So , th the {disfmarker} the big com and {disfmarker} and finally \" discourse segment \" is about {vocalsound} sort of speech - act - y information structure - y , like utterance - specific kinds of things . So the comment I was going to make about , um , changing entity {disfmarker} the entity 's block to reference is that {vocalsound} you can imagine your discourse like situation context , you have a set of entities that you 're sort of referring to . And you might {disfmarker} that might be sort of a general , I don't know , database of all the things in this discourse that you could refer to . And I changed to \" reference \" cuz I would say , for a particular utterance you have particular referring expressions in it . And those are the ones that you get information about that you stick in here . For instance , I know it 's going to be plural . I know it 's gonna be feminine or something like that . And {disfmarker} and these could actually just point to , you know , the {disfmarker} the ID in my other list of enti active entities , right ? So , um , uh , th there 's {disfmarker} there 's all this stuff about discourse status . We 've talked about . I almost listed \" discourse status \" as a slot where you could say it 's active . You know , there 's this , um , hierarchy {disfmarker} uh there 's a schematization of , you know , things can be active or they can be , um , accessible , inaccessible .\nGrad E: Yeah .\nGrad F: It was the one that , you know , Keith , um , emailed to us once , to some of us , not all of us . And the thing is that that {disfmarker} I noticed that that , um , list was sort of discourse dependent . It was like in this particular set , s you know , instance , it has been referred to recently or it hasn't been ,\nGrad E: Yeah .\nGrad F: or this is something that 's like in my world knowledge but not active .\nProfessor C: This {disfmarker} Uh {disfmarker} yeah , well there {disfmarker} there seems to be context properties .\nGrad F: So .\nProfessor C: Yeah .\nGrad F: Yeah , they 're contex and for instance , I used to have a location thing there but actually that 's a property of the situation . And it 's again , time , you know {disfmarker} at cert certain points things are located , you know , near or far from you\nProfessor C: Well , uh , uh , this is recursive\nGrad F: and {disfmarker}\nProfessor C: cuz until we do the uh , mental space story , we 're not quite sure {disfmarker} {comment} Th - th\nGrad F: Yeah .\nProfessor C: which is fine . We 'll just {disfmarker} we 'll j\nGrad F: Yeah , yeah . So some of these are , uh {disfmarker}\nProfessor C: we just don't know yet .\nGrad F: Right . So I {disfmarker} so for now I thought , well maybe I 'll just have in this list the things that are relevant to this particular utterance , right ? Everything else here is utterance - specific . Um , and I left the slot , \" predications \" , open because you can have , um , things like \" the guy I know from school \" .\nGrad E: Mm - hmm .\nGrad F: Or , you know , like your referring expression might be constrained by certain like unbounded na amounts of prep you know , predications that you might make . And it 's unclear whether {disfmarker} I mean , you could just have in your scenario , \" here are some extra few things that are true \" , right ?\nGrad E: Mm - hmm .\nGrad F: And then you could just sort of not have this slot here . Right ? You 're {disfmarker} but {disfmarker} but it 's used for identification purposes .\nProfessor C: Right .\nGrad E: Yeah .\nGrad F: So it 's {disfmarker} it 's a little bit different from just saying \" all these things are true from my utterance \" .\nGrad E: Yeah .\nGrad F: Um .\nGrad E: Right , \" this guy I know from school came for dinner \" does not mean , um , \" there 's a guy , I know him from school , and he came over for dinner \" . That 's not the same effect .\nGrad F: Yeah , it 's a little bit {disfmarker} it 's a little bit different . Right ? So {disfmarker} Or maybe that 's like a restrictive , non - restrictive {disfmarker}\nGrad E: Yeah .\nGrad F: you know , it 's like it gets into that kind of thing for {disfmarker} um , but maybe I 'm mixing , you know {disfmarker} this is kind of like the final result after parsing the sentence .\nGrad E: Mm - hmm .\nGrad F: So you might imagine that the information you pass to , you know {disfmarker} in identifying a particular referent would be , \" oh , some {disfmarker} \" you know , \" it 's a guy and it 's someone I know from school \" .\nGrad E: Yeah .\nGrad F: So maybe that would , you know , be some intermediate structure that you would pass into the disc to the , whatever , construal engine or whatever , discourse context , to find {disfmarker} you know , either create this reference ,\nGrad E: Mm - hmm .\nGrad F: in which case it 'd be created here , and {disfmarker} you know , so {disfmarker} so you could imagine that this might not {disfmarker} So , uh , I 'm uncommitted to a couple of these things .\nGrad A: But {disfmarker} to make it m precise at least in my mind , uh , it 's not precise .\nGrad F: Um .\nGrad A: So \" house \" is gender neuter ? In reality\nGrad F: Um , it could be in {disfmarker}\nGrad A: or in {disfmarker}\nProfessor C: Semantically .\nGrad A: semantically .\nGrad F: semantically , yeah . Yeah .\nGrad A: So {disfmarker}\nGrad F: So it uh , uh , a table . You know , a thing that c doesn't have a gender . So . Uh , it could be that {disfmarker} I mean , maybe you 'd {disfmarker} maybe not all these {disfmarker} I mean , I wou I would say that I tried to keep slots here that were potentially relevant to most {disfmarker} most things .\nGrad A: No , just to make sure that we {disfmarker} everybody that 's {disfmarker} completely agreed that it {disfmarker} it has nothing to do with , uh , form .\nGrad F: Yeah . OK , that is semantic as opposed to {disfmarker} Yeah . Yeah . That 's right . Um .\nGrad A: Then \" predications \" makes sense to {disfmarker} to have it open for something like , uh , accessibility or not .\nGrad F: S so again {disfmarker} Open to various things .\nGrad A: Yeah .\nGrad F: Right . OK , so . Let 's see . So maybe having made that big sca sort of like large scale comment , should I just go through each of these slots {disfmarker} uh , each of these blocks , um , a little bit ?\nGrad E: Sure .\nGrad F: Um , mostly the top one is sort of image schematic . And just a note , which was that , um {disfmarker} s so when we actually ha so for instance , um , some of them seem more inherently static , OK , like a container or sort of support - ish . And others are a little bit seemingly inherently dynamic like \" source , path , goal \" is often thought of that way or \" force \" , or something like that . But in actual fact , I think that they 're intended to be sort of neutral with respect to that . And different X - schemas use them in a way that 's either static or dynamic . So \" path \" , you could just be talking about the path between this and this .\nGrad E: Mmm .\nGrad F: And you know , \" container \" that you can go in and out . All of these things . And so , um , I think this came up when , uh , Ben and I were working with the Spaniards , um , the other day {disfmarker} the \" Spaniettes \" , as we {vocalsound} called them {disfmarker} um , to decide like how you want to split up , like , s image schematic contributions versus , like , X - schematic contributions . How do you link them up . And I think again , um , it 's gonna be something in the X - schema that tells you \" is this static or is this dynamic \" . So we definitely need {disfmarker} that sort of aspectual type gives you some of that . Um , that , you know , is it , uh , a state or is it a change of state , or is it a , um , action of some kind ?\nGrad A: Uh , i i i is there any meaning to when you have sort of parameters behind it and when you don't ?\nGrad F: Uh . Yeah .\nGrad A: Just means {disfmarker}\nGrad F: Oh , oh ! You mean , in the slot ?\nGrad A: Mm - hmm .\nGrad F: Um , no , it 's like X - sc it 's {disfmarker} it 's like I was thinking of type constraints but X - schema , well it obviously has to be an X - schema . \" Agent \" , I mean , the {disfmarker} the performer of the X - schema , that s depends on the X - schema . You know , and I {disfmarker} in general it would probably be , you know {disfmarker}\nGrad E: So the difference is basically whether you thought it was obvious what the possible fillers were .\nGrad F: Yeah , basically .\nGrad A: Mm - hmm .\nGrad E: OK .\nGrad F: Um , \" aspectual type \" probably isn't obvious but I should have {disfmarker} So , I just neglected to stick something in . \" Perspective \" , \" actor \" , \" undergoer \" , \" observer \" , um ,\nGrad B: Mmm .\nGrad F: I think we 've often used \" agent \" , \" patient \" , obser\nGrad E: \" Whee ! \" That 's that one , right ?\nGrad F: Yeah , exactly . {vocalsound} Exactly . Um , and so one nice thing that , uh , we had talked about is this example {comment} of like , if you have a passive construction then one thing it does is ch you know {disfmarker} definitely , it is one way to {disfmarker} for you to , you know , specifically take the perspective of the undergoing kind of object . And so then we talked about , you know , whether well , does that specify topic as well ? Well , maybe there are other things . You know , now that it 's {disfmarker} subject is more like a topic . And now that , you know {disfmarker} Anyway . So . Sorry . I 'm gonna trail off on that one cuz it 's not that f important right now .\nProfessor C: N now , for the moment we just need the ability to l l write it down if {disfmarker} if somebody figured out what the rules were .\nGrad F: Um , To know how {disfmarker} Yeah . Yeah . Exactly .\nProfessor C: Yeah .\nGrad F: Um , some of these other ones , let 's see . So , uh , one thing I 'm uncertain about is how polarity interacts .\nProfessor C: Mm - hmm .\nGrad F: So polarity , uh , is using for like action did not take place for instance . So by default it 'll be like \" true \" , I guess , you know , if you 're specifying events that did happen . You could imagine that you skip out this {disfmarker} you know , leave off this polarity , you know , not {disfmarker} don't have it here . And then have it part of the speech - act in some way .\nProfessor C: Mm - hmm .\nGrad F: There 's some negation . But the reason why I left it in is cuz you might have a change of state , let 's say , where some state holds and then some state doesn't hold , and you 're just talking , you know {disfmarker} if you 're trying to have the nuts and bolts of simulation you need to know that , you know , whatever , the holder doesn't and {disfmarker}\nProfessor C: No , I th I think at this lev which is {disfmarker} it should be where you have it .\nGrad F: OK , it 's {disfmarker} so it 's {disfmarker} it 's {disfmarker} it 's fine where it is .\nProfessor C: I mean , how you get it may {disfmarker} may in will often involve the discourse\nGrad F: So , OK . May come from a few places .\nProfessor C: but {disfmarker} but {disfmarker} by the time you 're simulating you sh y you should know that .\nGrad F: Right . Right .\nGrad E: So , {vocalsound} I 'm still just really not clear on what I 'm looking at . The \" scenario \" box , like , what does that look like for an example ? Like , not all of these things are gonna be here .\nGrad F: Yeah .\nProfessor C: Correct .\nGrad E: This is just basically says\nGrad F: Mm - hmm . It 's a grab bag of {disfmarker}\nGrad E: \" part of what I 'm going to hand you is a whole bunch of s uh , schemas , image , and X - schemas . Here are some examples of the sorts of things you might have in there \" .\nGrad F: So that 's exactly what it is .\nGrad E: OK .\nGrad F: And for a particular instance which I will , you know , make an example of something , is that you might have an instance of container and path , let 's say , as part of your , you know , \" into \" you know , definition .\nGrad E: Mm - hmm . Mm - hmm .\nGrad F: So you would eventually have instances filled in with various {disfmarker} various values for all the different slots .\nGrad E: Mm - hmm .\nGrad F: And they 're bound up in , you know , their bindings and {disfmarker} and {disfmarker} and values .\nProfessor C: W it c\nGrad E: OK . Do you have to say about the binding in your {disfmarker} is there a slot in here for {disfmarker} that tells you how the bindings are done ?\nProfessor C: No , no , no . I {disfmarker} let 's see , I think we 're {disfmarker} we 're not {disfmarker} I don't think we have it quite right yet . So , uh , what this is ,\nGrad E: OK .\nProfessor C: let 's suppose for the moment it 's complete . OK , uh , then this says that when an analysis is finished , the whole analysis is finished , {comment} you 'll have as a result , uh , some s resulting s semspec for that utterance in context ,\nGrad E: OK . Mm - hmm .\nProfessor C: which is made up entirely of these things and , uh , bindings among them . And bindings to ontology items .\nGrad E: Mm - hmm .\nProfessor C: So that {disfmarker} that the who that this is the tool kit under whi out of which you can make a semantic specification .\nGrad E: Mm - hmm . Mm - hmm .\nProfessor C: So that 's A . But B , which is more relevant to your life , is this is also the tool kit that is used in the semantic side of constructions .\nGrad E: OK . Mm - hmm .\nProfessor C: So this is an that anything you have , in the party line , {comment} anything you have as the semantic side of constructions comes , from pieces of this {disfmarker} ignoring li\nGrad E: OK .\nProfessor C: I mean , in general , you ignore lots of it .\nGrad E: Right .\nProfessor C: But it 's got to be pieces of this along with constraints among them .\nGrad E: OK .\nProfessor C: Uh , so that the , you know , goal of the , uh uh , \" source , path , goal \" has to be the landmark of the conta you know , the interior of this container .\nGrad E: Mm - hmm .\nProfessor C: Or whate whatever .\nGrad E: Yeah .\nProfessor C: So those constraints appear in constructions\nGrad E: Mm - hmm .\nProfessor C: but pretty much this is the full range of semantic structures available to you .\nGrad E: OK .\nGrad F: Except for \" cause \" , that I forgot . But anyway , there 's som some kind of causal structure for composite events .\nGrad E: Yeah .\nProfessor C: OK , good . Let 's {disfmarker} let 's mark that . So we need a c\nGrad F: Uh , I mean , so it gets a little funny . These are all {disfmarker} so far these structures , especially from \" path \" and on down , these are sort of relatively familiar , um , image schematic kind of slots . Now with \" cause \" , uh , the fillers will actually be themselves frames . Right ?\nProfessor C: Right .\nGrad E: Mm - hmm .\nGrad F: So you 'll say , \" event one causes event B {disfmarker}\nProfessor C: And {disfmarker} and {disfmarker} and {disfmarker} and this {disfmarker} this {disfmarker} this again may ge our , um {disfmarker} and we {disfmarker} and {disfmarker} and , of course , worlds .\nGrad F: uh , event two \" , and {disfmarker}\nGrad E: Mm - hmm .\nGrad F: Yeah . So that 's , uh these are all implicitly one {disfmarker} within , uh within one world . Um , even though saying that place takes place , whatever . Uh , if y if I said \" time \" is , you know , \" past \" , that would say \" set that this world \" , you know , \" somewhere , before the world that corresponds to our current speech time \" .\nGrad E: Mm - hmm . Mm - hmm . Yeah .\nGrad F: So . But that {disfmarker} that {disfmarker} that 's sort of OK . The {disfmarker} the {disfmarker} within the event it 's st it 's still one world . Um . Yeah , so \" cause \" and {disfmarker} Other frames that could come in {disfmarker} I mean , unfortunately you could bring in say for instance , um , uh , \" desire \" or something like that ,\nGrad E: Mm - hmm .\nGrad F: like \" want \" . And actually there is right now under \" discourse segments \" , um , \" attitude \" ?\nGrad E: Mm - hmm .\nGrad F: \" Volition \" ? could fill that . So there are a couple things where I like , \" oh , I 'm not sure if I wanted to have it there\nGrad E: Well that 's {disfmarker}\nGrad F: or {disfmarker} \" Basically there was a whole list of {disfmarker} of possible speaker attitudes that like say Talmy listed . And , like , well , I don't {disfmarker} you know , it was like \" hope , wish . desire \" ,\nProfessor C: Right .\nGrad E: Uh - huh .\nGrad F: blah - blah - blah . And it 's like , well , I feel like if I wanted to have an extra meaning {disfmarker} I don't know if those are grammatically marked in the first place . So {disfmarker} They 're more lexically marked , right ?\nGrad E: Mmm .\nGrad F: At least in English . So if I wanted to I would stick in an extra frame in my meaning , saying , e so th it 'd be a hierarchical frame them , right ? You know , like \" Naomi wants {disfmarker} wants su a certain situation and that situation itself is a state of affairs \" .\nProfessor C: S right . So {disfmarker} so , \" want \" itself can be {disfmarker} {pause} i i i i i\nGrad F: u Can be just another frame that 's part of your {disfmarker}\nProfessor C: Well , and it i basically it 's an action . In {disfmarker} in our s in our {disfmarker} in our {disfmarker}\nGrad F: Yeah . Situation . {comment} Right , right .\nProfessor C: in {disfmarker} in our {disfmarker} in our s terminology , \" want \" can be an action and \" what you want \" is a world .\nGrad F: Mm - hmm .\nGrad B: Hmm .\nProfessor C: So that 's {disfmarker} I mean , it 's certainly one way to do it .\nGrad F: Mmm .\nProfessor C: Yeah , there {disfmarker} there are other things .\nGrad E: Mm - hmm .\nProfessor C: Causal stuff we absolutely need . Mental space we need .\nGrad F: Mm - hmm .\nProfessor C: The context we need . Um , so anyway , Keith {disfmarker} So is this comfortable to you that , uh , once we have this defined , it is your tool kit for building the semantic part of constructions .\nGrad E: Mm - hmm .\nProfessor C: And then when we combine constructions semantically , the goal is going to be to fill out more and more of the bindings needed in order to come up with the final one .\nGrad E: Mm - hmm .\nProfessor C: And that 's the wh and {disfmarker} and I mean , that {disfmarker} according to the party line , that 's the whole story .\nGrad E: Yeah . Mm - hmm . Yeah . Um . y Right . That makes sense . So I mean , there 's this stuff in the {disfmarker} off in the scenario , which just tells you how various {disfmarker} what schemas you 're using and they 're {disfmarker} how they 're bound together . And I guess that some of the discourse segment stuff {disfmarker} is that where you would sa\nGrad F: Mm - hmm .\nGrad E: I mean , that 's {disfmarker} OK , that 's where the information structure is which sort of is a kind of profiling on different parts of , um , of this .\nGrad F: Right . Exactly .\nGrad E: I mean , what 's interesting is that the information structure stuff {disfmarker} Hmm . There 's almost {disfmarker} I mean , we keep coming back to how focus is like this {disfmarker} this , uh , trajector - landmark thing .\nGrad F: Yeah .\nGrad E: So if I say , um , You know , \" In France it 's like this \" . You know , great , we 've learned something about France but the fact is that utterances of that sort are generally used to help you draw a conclusion also about some implicit contrast , like \" In France it 's like this \" . And therefore you 're supposed to say , \" Boy , life sure {disfmarker} \"\nGrad F: Right .\nGrad E: You know , \" in France kids are allowed to drink at age three \" . And w you 're {disfmarker} that 's not just a fact about France . You also conclude something about how boring it is here in the U S . Right ?\nGrad F: Right , right .\nProfessor C: Right .\nGrad E: And so {disfmarker}\nGrad F: S so I would prefer not to worry about that for right now\nGrad E: OK .\nGrad F: and to think that there are , um ,\nGrad E: That comes in and , uh {disfmarker}\nGrad F: discourse level constructions in a sense , topic {disfmarker} topic - focus constructions that would say , \" oh , when you focus something \" then {disfmarker}\nGrad E: Mm - hmm . Yeah .\nGrad F: just done the same way {disfmarker} just actually in the same way as the lower level . If you stressed , you know , \" John went to the {disfmarker} \" , you know , \" the bar \" whatever , you 're focusing that\nGrad E: Mm - hmm .\nGrad F: and a in a possible inference is \" in contrast to other things \" .\nGrad E: Yeah .\nGrad F: So similarly for a whole sentence , you know , \" in France such - and - such happens \" .\nGrad E: Yeah . Yeah , yeah .\nGrad F: So the whole thing is sort of like again implicitly as opposed to other things that are possible .\nGrad E: Yeah .\nGrad A: Uh , just {disfmarker} just , uh , look {disfmarker} read uh even sem semi formal Mats Rooth .\nGrad F: I mean {disfmarker} Yeah .\nGrad A: If you haven't read it . It 's nice .\nGrad F: Uh - huh .\nGrad A: And just pick any paper on alternative semantics .\nGrad F: Uh - huh .\nGrad E: OK .\nGrad A: So that 's his {disfmarker} that 's the best way of talking about focus , is I think his way .\nGrad E: OK , what was the name ?\nGrad A: Mats . MATS . Rooth .\nGrad E: OK .\nGrad A: I think two O 's , yes , TH .\nGrad E: OK .\nGrad A: I never know how to pronounce his name because he 's sort of ,\nProfessor C: S Swede ?\nGrad A: uh , he is Dutch\nProfessor C: Dutch ?\nGrad A: and , um {disfmarker} but very confused background I think .\nProfessor C: Oh , Dutch .\nGrad E: Yeah .\nProfessor C: Uh - huh .\nGrad A: So {pause} and , um ,\nGrad E: Mats Gould .\nGrad A: And sadly enough he also just left the IMS in Stuttgart . So he 's not there anymore .\nGrad E: Hmm .\nGrad A: But , um {disfmarker} I don't know where he is right now but alternative semantics is {disfmarker} if you type that into an , uh , uh , browser or search engine you 'll get tons of stuff .\nGrad E: OK . OK . OK , thanks .\nGrad A: And what I 'm kind of confused about is {disfmarker} is what the speaker and the hearer is {disfmarker} is sort of doing there .\nGrad F: So for a particular segment it 's really just a reference to some other entity again in the situation , right ? So for a particular segment the speaker might be you or might be me .\nGrad A: Yeah .\nGrad F: Um , hearer is a little bit harder . It could be like multiple people . I guess that {disfmarker} that {disfmarker} that {disfmarker} that 's not very clear from here {disfmarker}\nGrad A: Yeah , but you {disfmarker} Don't we ultimately want to handle that analogously to the way we handle time and place ,\nGrad F: I mean , that 's not allowed here .\nGrad A: because \" you \" , \" me \" , \" he \" , \" they \" , you know , \" these guys \" , all these expressions , nuh , are in {disfmarker} in much the same way contextually dependent as \" here , \" and \" now , \" and \" there \" {disfmarker}\nGrad F: Mm - hmm .\nProfessor C: Now , this is {disfmarker} this is assuming you 've already solved that .\nGrad F: Ye - yeah .\nProfessor C: So it 's {disfmarker} it 's Fred and Mary ,\nGrad F: So th\nProfessor C: so the speaker would be Fred and the {disfmarker}\nGrad A: Ah !\nGrad F: Right , so the constructions might {disfmarker} of course will refer , using pronouns or whatever .\nGrad A: Mm - hmm .\nGrad F: In which case they have to check to see , uh , who the , uh , speaker in here wa in order to resolve those . But when you actually say that \" he walked into {disfmarker} \" , whatever , um , the \" he \" will refer to a particular {disfmarker} You {disfmarker} you will already have figured who \" he \" or \" you \" , mmm , or \" I \" , maybe is a bett better example , who \" I \" refers to . Um , and then you 'd just be able to refer to Harry , you know , in wherever that person {disfmarker} whatever role that person was playing in the event .\nGrad A: Mmm . That 's up at the reference part .\nGrad F: Yeah , yeah .\nGrad A: And down there in the speaker - hearer part ?\nGrad F: S so , that 's {disfmarker} I think that 's just {disfmarker} n for instance , Speaker is known from the situation , right ? You 're {disfmarker} when you hear something you 're told who the speaker is {disfmarker} I mean , you know who the speaker is . In fact , that 's kind of constraining how {disfmarker} in some ways you know this before you get to the {disfmarker} you fill in all the rest of it . I think .\nProfessor C: Mmm .\nGrad F: I mean , how else would you um {disfmarker}\nGrad A: You know , uh , uh , it 's {disfmarker} the speaker may {disfmarker} in English is allowed to say \" I . \"\nProfessor C: Yeah . Well , here {disfmarker}\nGrad A: Uh , among the twenty - five percent most used words .\nGrad F: Yeah . Right .\nGrad A: But wouldn't the \" I \" then set up the {disfmarker} the s s referent {disfmarker} that happens to be the speaker this time\nGrad F: Mm - hmm .\nGrad A: and not \" they , \" whoever they are .\nGrad F: Right , right .\nGrad A: Or \" you \" {disfmarker}\nGrad F: So {disfmarker}\nGrad A: much like the \" you \" could n\nGrad F: S so {disfmarker} OK , so I would say ref under referent should be something that corresponds to \" I \" . And maybe each referent should probably have a list of way whatever , the way it was referred to . So that 's \" I \" but , uh , uh , should we say it {disfmarker} it refers to , what ? Uh , if it were \" Harry \" it would refer to like some ontology thing . If it were {disfmarker} if it 's \" I \" it would refer to the current speaker , OK , which is given to be like , you know , whoever it is .\nGrad A: Well , not {disfmarker} not always . I mean , so there 's \" and then he said , I w \" Uh - huh .\nProfessor C: Uh {disfmarker}\nGrad F: \" I \" within the current world .\nGrad A: Yeah .\nProfessor C: Yeah . That 's right . So {disfmarker} so again , this {disfmarker} uh , this {disfmarker} this is gonna to get us into the mental space stuff\nGrad F: Yeah , yeah , yeah , yeah .\nProfessor C: and t because you know , \" Fred said that Mary said {disfmarker} \" , and whatever .\nGrad E: Mmm .\nGrad F: Mm - hmm .\nProfessor C: And {disfmarker} and so we 're , uh gonna have to , um , chain those as well .\nGrad A: Mm - hmm . Twhhh - whhh . But {disfmarker}\nGrad F: Mm - hmm . So this entire thing is inside a world ,\nProfessor C: Right . Right .\nGrad F: not just like the top part .\nProfessor C: I {disfmarker} I think , uh {disfmarker}\nGrad F: That 's {disfmarker}\nGrad A: Mm - hmm .\nProfessor C: Except s it 's {disfmarker} it 's trickier than that because um , the reference for example {disfmarker} So he where it gets really tricky is there 's some things ,\nGrad F: Yeah .\nProfessor C: and this is where blends and all terribl So , some things which really are meant to be identified and some things which aren't .\nGrad F: Yeah . Right .\nProfessor C: And again , all we need for the moment is some way to say that .\nGrad F: Right . So I thought of having like {disfmarker} for each referent , having the list of {disfmarker} of the things t with which it is identified . You know , which {disfmarker} which , uh you know , you {disfmarker} you {disfmarker} you {disfmarker}\nProfessor C: You could do that .\nGrad F: for instance , um {disfmarker} So , I guess , it sort of depends on if it is a referring exp if it 's identifiable already or it 's a new thing .\nGrad E: Mm - hmm .\nGrad F: If it 's a new thing you 'd have to like create a structure or whatever . If it 's an old thing it could be referring to , um , usually w something in a situation , right ? Or something in ontology .\nProfessor C: uh - huh .\nGrad F: So , there 's a you know , whatever , it c it could point at one of these .\nProfessor C: I just had a {disfmarker} I just had an {disfmarker} an idea that would be very nice if it works .\nGrad F: For what ?\nProfessor C: Uh , uh , uh , I haven't told you what it is yet .\nGrad F: If it works .\nProfessor C: This was my build - up .\nGrad F: Mm - hmm . Mmm .\nProfessor C: An i an idea that would be nice i\nGrad F: Yeah . OK , we 're crossing our fingers .\nProfessor C: Right .\nGrad B: So we 're building a mental space , good .\nProfessor C: If it worked . Yeah .\nGrad F: OK .\nProfessor C: Right , it was a space builder . Um , we might be able to handle context in the same way that we handle mental spaces because , uh , you have somewhat the same things going on of , uh , things being accessible or not .\nGrad F: Mm - hmm .\nProfessor C: And so , i\nGrad F: Yep .\nProfessor C: it c it {disfmarker} it , uh I think if we did it right we might be able to get at least a lot of the same structure .\nGrad F: Use the same {disfmarker} {comment} Yep .\nProfessor C: So that pulling something out of a discourse context is I think similar to other kinds of , uh , mental space phenomena .\nGrad B: I see .\nGrad F: Mm - hmm . And {disfmarker} And {disfmarker}\nProfessor C: Uh , I 've {disfmarker} I 've {disfmarker} I 've never seen anybody write that up but maybe they did . I don't know . That may be all over the literature .\nGrad F: Yeah .\nGrad E: There 's things like ther you know , there 's all kinds of stuff like , um , in {disfmarker} I think I mentioned last time in Czech if you have a {disfmarker} a verb of saying then\nGrad F: So {disfmarker} so by default {disfmarker}\nGrad E: um , you know , you say something like {disfmarker} or {disfmarker} or I was thinking you can say something like , \" oh , I thought , uh , you are a republican \" or something like that . Where as in English you would say , \" I thought you were \" .\nProfessor C: Right .\nGrad E: Um , you know , sort of the past tense being copied onto the lower verb doesn't happen there , so you have to say something about , you know , tense is determined relative to current blah - blah - blah .\nGrad F: Mm - hmm .\nGrad E: Same things happens with pronouns .\nGrad F: Mm - hmm .\nGrad E: There 's languages where , um , if you have a verb of saying then , ehhh , where {disfmarker} OK , so a situation like \" Bob said he was going to the movies \" , where that lower subject is the same as the person who was saying or thinking , you 're actually required to have \" I \" there .\nGrad F: Mm - hmm .\nProfessor C: Mm - hmm .\nGrad E: Um , and it 's sort of in an extended function {disfmarker}\nProfessor C: So we would have it be in quotes in English .\nGrad E: Yeah .\nGrad B: Right .\nGrad E: But it 's not perceived as a quotative construction .\nGrad F: Right .\nProfessor C: Yeah .\nGrad E: I mean , it 's been analyzed by the formalists as being a logophoric pronoun , um which means a pronoun which refers back to the person who is speaking or that sort of thing , right ?\nProfessor C: OK .\nGrad F: Oh , right . Yeah , that makes sense .\nGrad E: Um , but {disfmarker} uh , that happens to sound like the word for \" I \" but is actually semantically unrelated to it .\nGrad F: Oh , no !\nProfessor C: Oh , good , I love the formali\nGrad E: Um ,\nGrad F: Really ?\nGrad E: Yeah . {vocalsound} Yeah .\nGrad F: You 're kidding .\nGrad E: There 's a whole book which basically operates on this assumption . Uh , Mary Dalrymple , uh , this book , a ninety - three book on , uh on pronoun stuff .\nGrad F: No , that 's horrible . OK . That 's horrible . {comment} OK .\nGrad E: Well , yeah . And then the same thing for ASL where , you know , you 're signing and someone says something . And then , you know , so \" he say \" , and then you sort of do a role shift . And then you sign \" I , this , that , and the other \" .\nGrad F: Uh - huh .\nGrad E: And you know , \" I did this \" . That 's also been analyzed as logophoric and having nothing to do with \" I \" . And the role shift thing is completely left out and so on . So , I mean , the point is that pronoun references , uh , you know , sort of ties in with all this mental space stuff and so on , and so forth .\nGrad F: Uh - huh .\nGrad E: And so , yeah , I mean {disfmarker}\nGrad F: Yeah .\nProfessor C: So that {disfmarker} that d that does sound like it 's co consistent with what we 're saying , yeah .\nGrad E: Right . Yeah .\nGrad F: OK , so it 's kind of like the unspecified mental spaces just are occurring in context . And then when you embed them sometimes you have to pop up to the h you know , depending on the construction or the whatever , um , you {disfmarker} you {disfmarker} you 're scope is {disfmarker} m might extend out to the {disfmarker} the base one .\nGrad E: Mm - hmm .\nProfessor C: Mm - hmm .\nGrad E: Yeah .\nGrad F: It would be nice to actually use the same , um , mechanism since there are so many cases where you actually need it 'll be one or the other .\nGrad E: Yeah .\nGrad F: It 's like , oh , actually , it 's the same {disfmarker} same operation .\nProfessor C: Oh , OK , so this {disfmarker} this is worth some thought .\nGrad F: So .\nGrad E: It 's like {disfmarker} it 's like what 's happening {disfmarker} that , yeah , what what 's happening , uh , there is that you 're moving the base space or something like that , right ?\nGrad F: Yeah , yeah .\nGrad E: So that 's {disfmarker} that 's how Fauconnier would talk about it . And it happens diff under different circumstances in different languages .\nGrad F: Mm - hmm .\nGrad E: And so ,\nGrad F: Mm - hmm .\nGrad E: um , things like pronoun reference and tense which we 're thinking of as being these discourse - y things actually are relative to a Bayes space which can change .\nGrad F: Mm - hmm ,\nGrad E: And we need all the same machinery .\nGrad F: right .\nGrad A: Mm - hmm .\nGrad F: Robert .\nProfessor C: Well , but , uh , this is very good actually\nGrad E: Schade .\nProfessor C: cuz it {disfmarker} it {disfmarker} it {disfmarker} to the extent that it works , it y\nGrad F: Ties it all into it .\nProfessor C: it {disfmarker} it ties together several of {disfmarker} of these things .\nGrad F: Yeah . Yep .\nGrad A: Mm - hmm . Mm - hmm . And I 'm sure gonna read the transcript of this one . So . But the , uh , {disfmarker} {vocalsound} But it 's too bad that we don't have a camera . You know , all the pointing is gonna be lost .\nGrad E: Yeah .\nGrad F: Oh , yeah .\nGrad B: Well every time Nancy giggles it means {disfmarker} it means that it 's your job .\nGrad F: Yeah , that 's why I said \" point to Robert \" , {vocalsound} when I did it .\nGrad A: Uh . Yeah . Mmm , isn't {disfmarker} I mean , I 'm {disfmarker} I was sort of dubious why {disfmarker} why he even introduces this sort of reality , you know , as your basic mental space and then builds up {disfmarker}\nGrad E: Mm - hmm .\nGrad A: d doesn't start with some {disfmarker} because it 's so obvi it should be so obvious , at least it is to me , {comment} that whenever I say something I could preface that with \" I think . \" Nuh ?\nGrad E: Yeah .\nGrad A: So there should be no categorical difference between your base and all the others that ensue .\nGrad E: Yeah .\nProfessor C: No , but there 's {disfmarker} there 's a Gricean thing going on there , that when you say \" I think \" you 're actually hedging .\nGrad E: Yeah , I mean {disfmarker}\nGrad F: Mmm . It 's like I don't totally think {disfmarker}\nProfessor C: Right .\nGrad E: Yeah . Y\nGrad F: I mostly think , uh {disfmarker}\nGrad A: Yeah , it 's {disfmarker} Absolutely .\nGrad E: Yeah , it 's an {disfmarker} it 's an evidential . It 's sort of semi - grammaticalized . People have talked about it this way . And you know , you can do sort of special things . You can , th put just the phrase \" I think \" as a parenthetical in the middle of a sentence and so on , and so forth .\nGrad A: Yeah .\nGrad E: So {disfmarker}\nGrad F: Actually one of the child language researchers who works with T Tomasello studied a bunch of these constructions and it was like it 's not using any kind of interesting embedded ways just to mark , you know , uncertainty or something like that .\nGrad E: Yeah .\nGrad F: So .\nGrad A: Yeah , but about linguistic hedges , I mean , those {disfmarker} those tend to be , um , funky anyways because they blur {disfmarker}\nProfessor C: So we don't have that in here either do we ?\nGrad E: Yeah .\nGrad F: Hedges ?\nProfessor C: Yeah , yeah .\nGrad F: Hhh , {comment} I {disfmarker} there used to be a slot for speaker , um , it was something like factivity . I couldn't really remember what it meant\nGrad E: Yeah .\nGrad F: so I took it out .\nGrad E: Um .\nGrad F: But it 's something {disfmarker}\nGrad E: Well we were just talking about this sort of evidentiality and stuff like that , right ?\nGrad F: we {disfmarker} we were talking about sarcasm too , right ? Oh , oh .\nGrad E: I mean ,\nGrad F: Oh , yeah , yeah , right .\nGrad E: that 's what I think is , um , sort of telling you what percent reality you should give this\nProfessor C: So we probably should .\nGrad F: Yeah .\nGrad A: Mm - hmm .\nGrad E: or the , you know {disfmarker}\nProfessor C: Confidence or something like that .\nGrad E: Yeah , and the fact that I 'm , you know {disfmarker} the fact maybe if I think it versus he thinks that might , you know , depending on how much you trust the two of us or whatever ,\nGrad F: Yeah .\nGrad A: Uh great word in the English language is called \" about \" .\nGrad E: you know {disfmarker}\nGrad A: If you study how people use that it 's also {disfmarker}\nGrad F: What 's the word ?\nGrad A: \" about . \" It 's about {disfmarker}\nProfessor C: About .\nGrad A: clever .\nProfessor C: Oh , that {disfmarker} in that use of \" about \" , yeah .\nGrad F: Oh , oh , oh , as a hedge .\nGrad E: Yeah .\nProfessor C: And I think {disfmarker} And I think {pause} y if you want us to spend a pleasant six or seven hours you could get George started on that .\nGrad E: He wrote a paper about thirty - five years ago on that one .\nGrad B: I r I read that paper ,\nProfessor C: Yeah .\nGrad B: the hedges paper ? I read some of that paper actually .\nGrad E: Yeah .\nProfessor C: Yeah .\nGrad E: Would you believe that that paper lead directly to the development of anti - lock brakes ?\nGrad F: What ?\nProfessor C: No .\nGrad E: Ask me about it later I 'll tell you how . When we 're not on tape .\nGrad F: I 'd love to know .\nGrad B: Oh , man .\nGrad F: So , and {disfmarker} and I think , uh , someone had raised like sarcasm as a complication at some point .\nProfessor C: There 's all that stuff . Yeah , let 's {disfmarker} I {disfmarker} I don't {disfmarker} I think {disfmarker}\nGrad F: And we just won't deal with sarcastic people .\nProfessor C: Yeah , I mean {disfmarker}\nGrad E: I don't really know what like {disfmarker} We {disfmarker} we don't have to care too much about the speaker attitude , right ? Like there 's not so many different {disfmarker} hhh , {comment} I don't know , m\nGrad F: Certainly not as some {disfmarker} Well , they 're intonational markers I think for the most part .\nGrad E: Yeah .\nGrad F: I don't know too much about the like grammatical {disfmarker}\nGrad E: I just mean {disfmarker} There 's lots of different attitudes that {disfmarker} that the speaker could have and that we can clearly identify , and so on , and so forth .\nGrad F: Yeah .\nGrad E: But like what are the distinctions among those that we actually care about for our current purposes ?\nProfessor C: Right . Right , so , uh , this {disfmarker} this raises the question of what are our current purposes .\nGrad F: Mm - hmm .\nProfessor C: Right ?\nGrad E: Oh , shoot .\nGrad F: Oh , yeah , do we have any ?\nGrad E: Here it is three - fifteen already .\nGrad A: Mmm . Yeah .\nProfessor C: Uh , so , um , I {disfmarker} I don't know the answer but {disfmarker} but , um , it does seem that , you know , this is {disfmarker} this is coming along . I think it 's {disfmarker} it 's converging . It 's {disfmarker} as far as I can tell there 's this one major thing we have to do which is the mental {disfmarker} the whole s mental space thing . And then there 's some other minor things .\nGrad F: Mm - hmm .\nProfessor C: Um , and we 're going to have to s sort of bound the complexity . I mean , if we get everything that anybody ever thought about you know , w we 'll go nuts .\nGrad E: Yeah .\nProfessor C: So we had started with the idea that the actual , uh , constraint was related to this tourist domain and the kinds of interactions that might occur in the tourist domain , assuming that people were being helpful and weren't trying to d you know , there 's all sorts of {disfmarker} God knows , irony , and stuff like {disfmarker} which you {disfmarker} isn't probably of much use in dealing with a tourist guide .\nGrad E: Yeah .\nProfessor C: Yeah ?\nGrad E: Yeah .\nProfessor C: Uh .\nGrad F: M mockery .\nProfessor C: Right . Whatever . So y uh , no end of things th that {disfmarker} that , you know , we don't deal with .\nGrad A: But it {disfmarker}\nProfessor C: And {disfmarker}\nGrad A: i isn't that part easy though\nProfessor C: Go ahead .\nGrad A: because in terms of the s simspec , it would just mean you put one more set of brack brackets around it , and then just tell it to sort of negate whatever the content of that is in terms of irony\nGrad E: Yeah .\nProfessor C: N no .\nGrad F: Mmm .\nGrad A: or {disfmarker}\nProfessor C: No .\nGrad E: Right .\nGrad F: Maybe .\nProfessor C: No .\nGrad F: Yeah , in model theory cuz the semantics is always like \" speaker believes not - P \" , you know ?\nProfessor C: Right .\nGrad F: Like \" the speaker says P and believes not - P \" .\nGrad E: We have a theoretical model of sarcasm now .\nGrad F: But {disfmarker}\nProfessor C: Right .\nGrad E: Yeah , right , I mean .\nProfessor C: No , no .\nGrad F: Right , right , but ,\nProfessor C: Anyway , so {disfmarker} so , um , I guess uh , let me make a proposal on how to proceed on that , which is that , um , it was Keith 's , uh , sort of job over the summer to come up with this set of constructions . Uh , and my suggestion to Keith is that you , over the next couple weeks , n\nGrad E: Mmm .\nProfessor C: don't try to do them in detail or formally but just try to describe which ones you think we ought to have .\nGrad E: OK .\nProfessor C: Uh , and then when Robert gets back we 'll look at the set of them .\nGrad E: OK .\nProfessor C: Just {disfmarker} just sort of , you know , define your space .\nGrad E: Yeah , OK .\nProfessor C: And , um , so th these are {disfmarker} this is a set of things that I think we ought to deal with .\nGrad E: Yeah .\nProfessor C: And then we 'll {disfmarker} we 'll {disfmarker} we 'll go back over it and w people will {disfmarker} will give feedback on it .\nGrad E: OK .\nProfessor C: And then {disfmarker} then we 'll have a {disfmarker} at least initial spec of {disfmarker} of what we 're actually trying to do .\nGrad E: Yeah .\nProfessor C: And that 'll also be useful for anybody who 's trying to write a parser .\nGrad E: Mm - hmm .\nProfessor C: Knowing uh {disfmarker}\nGrad E: In case there 's any around .\nGrad F: If we knew anybody like that .\nProfessor C: Right , \" who might want \" et cetera . So , uh {disfmarker}\nGrad E: OK .\nProfessor C: So a and we get this {disfmarker} this , uh , portals fixed and then we have an idea of the sort of initial range . And then of course Nancy you 're gonna have to , uh , do your set of {disfmarker} but you have to do that anyway .\nGrad F: For the same , yeah , data . Yeah , mm - hmm .\nProfessor C: So {disfmarker} so we 're gonna get the w we 're basically dealing with two domains , the tourist domain and the {disfmarker} and the child language learning .\nGrad B: Mmm .\nProfessor C: And we 'll see what we need for those two . And then my proposal would be to , um , not totally cut off more general discussion but to focus really detailed work on the subset of things that we 've {disfmarker} we really want to get done .\nGrad E: Mm - hmm .\nProfessor C: And then as a kind of separate thread , think about the more general things and {disfmarker} and all that .\nGrad E: Mm - hmm . Mm - hmm .\nGrad A: Well , I also think the detailed discussion will hit {disfmarker} you know , bring us to problems that are of a general nature and maybe even {disfmarker}\nProfessor C: Uh , without doubt . Yeah .\nGrad F: Yeah .\nGrad A: even suggest some solutions .\nProfessor C: But what I want to do is {disfmarker} is {disfmarker} is to {disfmarker} to constrain the things that we really feel responsible for .\nGrad A: Yeah . Mmm .\nProfessor C: So that {disfmarker} that we say these are the things we 're really gonna try do by the end of the summer\nGrad E: Mm - hmm .\nProfessor C: and other things we 'll put on a list of {disfmarker} of research problems or something , because you can easily get to the point where nothing gets done because every time you start to do something you say , \" oh , yeah , but what about this case ? \"\nGrad E: Mm - hmm .\nProfessor C: This is {disfmarker} this is called being a linguist .\nGrad A: Mmm .\nGrad E: Yeah .\nProfessor C: And , uh ,\nGrad E: Basically .\nGrad F: Or me .\nProfessor C: Huh ?\nGrad F: Or me . Anyways {disfmarker}\nGrad B: There 's that quote in Jurafsky and Martin where {disfmarker} where it goes {disfmarker} where some guy goes , \" every time I fire a linguist the performance of the recognizer goes up . \"\nProfessor C: Right .\nGrad F: Yeah .\nGrad E: Exactly .\nProfessor C: Right . But anyway . So , is {disfmarker} is that {disfmarker} does that make sense as a , uh {disfmarker} a general way to proceed ?\nGrad F: Sure , yeah .\nGrad E: Yeah , yeah , we 'll start with that , just figuring out what needs to be done then actually the next step is to start trying to do it .\nProfessor C: Exactly right .\nGrad A: Mmm .\nGrad E: Got it .\nGrad A: Mmm .\nGrad E: OK .\nGrad A: We have a little bit of news , uh , just minor stuff . The one big {disfmarker}\nGrad B: Ooo , can I ask a {disfmarker}\nGrad E: You ran out of power .\nGrad A: Huh ?\nGrad B: Can I ask a quick question about this side ?\nGrad A: Yeah .\nGrad F: Yes .\nGrad B: Is this , uh {disfmarker} was it intentional to leave off things like \" inherits \" and {disfmarker}\nGrad F: Oops . Um ,\nGrad E: No .\nGrad F: not really {disfmarker} just on the constructions , right ?\nGrad B: Yeah , like constructions can inherit from other things ,\nGrad F: Um ,\nGrad B: am I right ?\nGrad F: yeah .\nGrad B: Yeah .\nGrad F: I didn't want to think too much about that for {disfmarker} for now .\nGrad B: OK .\nProfessor C: Yeah .\nGrad F: So , uh , maybe it was subconsciously intentional .\nProfessor C: Yeah , uh {disfmarker} yeah .\nGrad E: Um , yeah , there should be {disfmarker} I {disfmarker} I wanted to s find out someday if there was gonna be some way of dealing with , uh , if this is the right term , multiple inheritance ,\nProfessor C: Mm - hmm .\nGrad E: where one construction is inheriting from , uh from both parents ,\nGrad F: Uh - huh . Yep .\nGrad E: uh , or different ones , or three or four different ones .\nProfessor C: Yeah . So let me {disfmarker}\nGrad E: Cuz the problem is that then you have to {disfmarker}\nGrad F: Yeah .\nGrad E: which of {disfmarker} you know , which are {disfmarker} how they 're getting bound together .\nGrad F: Refer to {pause} them .\nProfessor C: Yeah , right , right , right . Yeah , yeah , yeah .\nGrad F: Yeah , and {disfmarker} and there are certainly cases like that . Even with just semantic schemas we have some examples .\nProfessor C: Right .\nGrad F: So , and we 've been talking a little bit about that anyway .\nProfessor C: Yeah . So what I would like to do is separate that problem out .\nGrad F: Inherits .\nProfessor C: So um ,\nGrad E: OK .\nProfessor C: my argument is there 's nothing you can do with that that you can't do by just having more constructions .\nGrad E: Yeah , yes .\nProfessor C: It 's uglier and it d doesn't have the deep linguistic insights and stuff .\nGrad E: That 's right .\nProfessor C: Uh ,\nGrad E: But whatever .\nProfessor C: Right .\nGrad E: Yeah , no , no , no no .\nGrad F: Uh , those are over rated .\nGrad E: No , by all means ,\nProfessor C: And so I {disfmarker} what I 'd like to do is {disfmarker} is in the short run focus on getting it right .\nGrad E: right . Uh , sure .\nProfessor C: And when we think we have it right then saying , \" aha ! ,\nGrad E: Yeah .\nProfessor C: can we make it more elegant ? \"\nGrad E: Yeah , that 's {disfmarker}\nProfessor C: Can {disfmarker} can we , uh {disfmarker} What are the generalizations , and stuff ?\nGrad E: Yeah . Connect the dots . Yeah .\nProfessor C: But rather than try to guess a inheritance structure and all that sort of stuff before we know what we 're doing .\nGrad E: Yep . Yeah .\nProfessor C: So I would say in the short run we 're not gonna b\nGrad E: Yeah .\nProfessor C: First of all , we 're not doing them yet at all . And {disfmarker} and it could be that half way through we say , \" aha ! , we {disfmarker} we now see how we want to clean it up . \"\nGrad E: Mm - hmm .\nProfessor C: Uh , and inheritance is only one {disfmarker} I mean , that 's one way to organize it but there are others . And it may or may not be the best way .\nGrad E: Yeah .\nGrad A: Mmm .\nProfessor C: I 'm sorry , you had news .\nGrad A: Oh , just small stuff . Um , thanks to Eva on our web site we can now , if you want to run JavaBayes , uh , you could see {disfmarker} get {disfmarker} download these classes . And then it will enable you {disfmarker} she modified the GUI so it has now a m a m a button menu item for saving it into the embedded JavaBayes format .\nGrad D: Mm - hmm .\nGrad B: Mmm .\nGrad A: So that 's wonderful .\nProfessor C: Great .\nGrad A: And , um and she , a You tested it out . Do you want to say something about that , that it works , right ? With the {disfmarker}\nGrad D: I was just checking like , when we wanna , um , get the posterior probability of , like , variables . You know how you asked whether we can , like , just observe all the variables like in the same list ? You can't .\nGrad A: Uh - huh .\nGrad D: You have to make separate queries every time .\nGrad A: OK , that 's {disfmarker} that 's a bit unfortunate\nGrad D: So {disfmarker} Yeah .\nGrad A: but for the time being it 's {disfmarker} it 's {disfmarker} it 's fine to do it {disfmarker}\nGrad D: You just have to have a long list of , you know , all the variables .\nGrad A: Yeah . But uh {disfmarker}\nGrad D: Basically .\nGrad F: Uh , all the things you want to query , you just have to like ask for separately .\nGrad D: Yeah , yeah .\nGrad A: Well that 's {disfmarker} probably maybe in the long term that 's good news because it forces us to think a little bit more carefully how {disfmarker} how we want to get an out output . Um , but that 's a different discussion for a different time . And , um , I don't know . We 're really running late , so I had , uh , an idea yesterday but , uh , I don't know whether we should even start discussing .\nProfessor C: W what {disfmarker} Yeah , sure , tell us what it is .\nGrad A: Um , the construal bit that , um , has been pointed to but hasn't been , um , made precise by any means , um , may w may work as follows . I thought that we would , uh {disfmarker} that the following thing would be in incredibly nice and I have no clue whether it will work at all or nothing . So that 's just a tangent , a couple of mental disclaimers here . Um , imagine you {disfmarker} you write a Bayes - net , um {disfmarker}\nGrad F: Bayes ?\nGrad A: Bayes - net ,\nGrad F: OK .\nGrad A: um , completely from scratch every time you do construal . So you have nothing . Just a white piece of paper .\nProfessor C: Mmm , right .\nGrad A: You consult {disfmarker} consult your ontology which will tell you a bunch of stuff , and parts , and properties , uh - uh - uh\nGrad F: Grout out the things that {disfmarker} that you need .\nProfessor C: Right .\nGrad A: then y you 'd simply write , uh , these into {disfmarker} onto your {disfmarker} your white piece of paper . And you will get a lot of notes and stuff out of there . You won't get {disfmarker} you won't really get any C P T 's , therefore we need everything that {disfmarker} that configures to what the situation is , IE , the context dependent stuff . So you get whatever comes from discourse but also filtered . Uh , so only the ontology relevant stuff from the discourse plus the situation and the user model .\nGrad F: Mm - hmm .\nGrad A: And that fills in your CPT 's with which you can then query , um , the {disfmarker} the net that you just wrote and find out how thing X is construed as an utterance U . And the embedded JavaBayes works exactly like that , that once you {disfmarker} we have , you know , precise format in which to write it , so we write it down . You query it . You get the result , and you throw it away . And the {disfmarker} the nice thing about this idea is that you don't ever have to sit down and think about it or write about it . You may have some general rules as to how things can be {disfmarker} can be construed as what , so that will allow you to craft the {disfmarker} the {disfmarker} the initial notes . But it 's {disfmarker} in that respect it 's completely scalable . Because it doesn't have any prior , um , configuration . It 's just you need an ontology of the domain and you need the context dependent modules . And if this can be made to work at all , {vocalsound} that 'd be kind of funky .\nProfessor C: Um , it sounds to me like you want P R\nGrad A: P R Ms - uh , PRM I mean , since you can unfold a PRM into a straightforward Bayes - net {disfmarker}\nProfessor C: Beca - because it {disfmarker} b because {disfmarker} No , no , you can't . See the {disfmarker} the critical thing about the PRM is it gives these relations in general form . So once you have instantiated the PRM with the instances and ther then you can {disfmarker} then you can unfold it .\nGrad A: Then you can . Mm - hmm , yeah . No , I was m using it generic . So , uh , probabilistic , whatever , relational models . Whatever you write it . In {disfmarker}\nProfessor C: Well , no , but it matters a lot because you {disfmarker} what you want are these generalized rules about the way things relate , th that you then instantiate in each case .\nGrad A: And then {disfmarker} then instantiate them . That 's ma maybe the {disfmarker} the way {disfmarker} the only way it works .\nProfessor C: Yeah , and that 's {disfmarker}\nGrad A: \nProfessor C: Yeah , that 's the only way it could work . I {disfmarker} we have a {disfmarker} our local expert on P R uh , but my guess is that they 're not currently good enough to do that . But we 'll {disfmarker} we 'll have to see .\nGrad A: But , uh ,\nProfessor C: Uh {disfmarker} Yes . This is {disfmarker} that 's {disfmarker} that would be a good thing to try . It 's related to the Hobbs abduction story in that you th you throw everything into a pot and you try to come up with the , uh {disfmarker}\nGrad A: Except there 's no {disfmarker} no theorem prover involved .\nGrad F: Best explanation .\nProfessor C: No , there isn't a theorem prover but there {disfmarker} but {disfmarker} but the , um , The cove the {disfmarker} the P R Ms are like rules of inference and you 're {disfmarker} you 're coupling a bunch of them together .\nGrad A: Mm - hmm , yeah .\nProfessor C: And then ins instead of proving you 're trying to , you know , compute the most likely . Uh {disfmarker} Tricky . But you {disfmarker} yeah , it 's a good {disfmarker} it 's a {disfmarker} it 's a good thing to put in your thesis proposal .\nGrad A: What 's it ?\nProfessor C: So are you gonna write something for us before you go ?\nGrad A: Yes . Um .\nProfessor C: Oh , you have something .\nGrad A: In the process thereof , or whatever .\nProfessor C: OK . So , what 's {disfmarker} what {disfmarker} when are we gonna meet again ?\nGrad F: When are you leaving ?\nGrad A: Fri - uh ,\nGrad F: Thursday , Friday ?\nGrad A: Thursday 's my last day here .\nGrad D: Fri\nProfessor C: Yeah .\nGrad F: OK .\nGrad A: So {disfmarker} I would suggest as soon as possible . Do you mean by we , the whole ben gang ?\nProfessor C: N no , I didn't mean y just the two of us . We {disfmarker} obviously we can {disfmarker} we can do this . But the question is do you want to , for example , send the little group , uh , a draft of your thesis proposal and get , uh , another session on feedback on that ? Or {disfmarker}\nGrad A: We can do it Th - Thursday again . Yeah .\nGrad E: Fine with me . Should we do the one PM time for Thursday since we were on that before or {disfmarker} ?\nGrad A: Sure .\nGrad E: OK .\nProfessor C: Alright .\nGrad D: Hmm .\nGrad A: Thursday at one ? I can also maybe then sort of run through the , uh {disfmarker} the talk I have to give at EML which highlights all of our work .\nProfessor C: OK .\nGrad A: And we can make some last minute changes on that .\nProfessor C: OK .\nGrad B: You can just give him the abstract that we wrote for the paper .\nProfessor C: That - that 'll tell him exactly what 's going on . Yeah , that {disfmarker} Alright .\nGrad F: Can we do {disfmarker} can we do one - thirty ?\nGrad A: No .\nGrad F: Oh , you already told me no .\nGrad A: But we can do four .\nGrad F: One , OK , it 's fine . I can do one . It 's fine . It 's fine .\nGrad A: One or four . I don't care .\nGrad E: To me this is equal . I don't care .\nGrad A: If it 's equal for all ? What should we do ?\nGrad F: Yeah , it 's fine .\nGrad A: Four ?\nGrad F: Fine . Yeah {disfmarker} no , no , no , uh , I don't care . It 's fine .\nGrad A: It 's equal to all of us , so you can decide one or four .\nGrad B: The pressure 's on you Nancy .\nGrad A: Liz actually said she likes four because it forces the Meeting Recorder people to cut , you know {disfmarker} the discussions short .\nGrad F: OK . OK , four .\nGrad E: Well , if you insist , then .\nGrad F: OK ? OK . I am .", "source": "meeting_summ", "evaluation": "rouge"}
{"instructions": ["Summarize the discussion on detecting important linguistic features", "What did the professor think about clustering?", "What did the professor think about positional parameters?", "Summarize the discussion on improving the back recognizer for the Aurora task", "How did PhD B approach the back-end of the Aurora recognizer?", "What did the professor think about improving the back recognizer for the Aurora task?", "Summarize the meeting"], "outputs": ["The team wanted to understand how they could combine different linguistic features to make a more robust recognition model. They were running experiments to figure out what the good features were. The team also entertained the possibility of clustering them, which would add to the robustness.", "The professor was not too excited about clustering. He thought that the team could identify the bands that were the most promising and weigh them more highly in the model. As it stood, the model was using all bands with equal strength.", "The professor recounted that the person who worked with positional parameters, Mark Randolph, is at Motorola. He explained that his model consisted of many continuous variables and that heading in that direction would become a research project in and of itself.", "PhD B was conducting an experiment to improve the backend performance of the Aurora recognizer. The goal was recognizing the HTK system by challenging the canonical paradigm.", "PhD B focused on Italian and experimented with the number of states for different words. PhD B thought training for each case may improve performance by accounting for the difference in variance.", "The Professor thought that the experiments were pretty simple, so computational power was not really a problem. He also thought that it would be okay to increase the states from six to nine.", "The meeting began with the team catching up the professor, who had missed the previous meeting. Then, the team moved onto talking about echo cancelling techniques. They were trying to get the voice of other people from the primary person's microphone. Then, the team discussed how they could improve the performance on the Aurora task by playing around with the model. The team ended the meeting with various comments on different topics."], "input": "Professor A:  Am I on ? I guess so . Radio two . Hmm . Radio two .\nGrad E: Hello ?\nProfessor A: Wow .\nGrad E: Mm - hmm . Hi ?\nPhD B: Blow into it , it works really well .\nGrad F: Channel B .\nProfessor A: People say the strangest things when their microphones are on .\nPhD D: Channel four . Test .\nPhD C: Uh - oh .\nPhD D: OK .\nPhD C: Radio four .\nGrad E: Hello ?\nProfessor A: So everybody everybody 's on ?\nPhD D: Today 's\nProfessor A: Yeah . So y you guys had a {disfmarker} a meeting with uh {disfmarker} with Hynek which I unfortunately had to miss . Um and uh somebody\nPhD C: Mmm .\nProfessor A: eh e and uh I guess Chuck you weren't there either , so the uh\nPhD B: I was there .\nProfessor A: Oh you were there ?\nPhD B: With Hynek ?\nProfessor A: Yeah .\nPhD B: Yeah .\nProfessor A: So everybody knows what happened except me . OK . {vocalsound} Maybe somebody should tell me .\nPhD C: Oh yeah . Alright . Well . Uh first we discussed about some of the points that I was addressing in the mail I sent last week .\nProfessor A: Uh - huh .\nPhD C: So . Yeah . About the um , well {disfmarker} the downsampling problem .\nProfessor A: Yeah .\nPhD C: Uh and about the f the length of the filters and {disfmarker} Yeah .\nProfessor A: What was the {disfmarker} w what was the downsampling problem again ?\nPhD C: So we had {disfmarker}\nProfessor A: I forget .\nPhD C: So the fact that there {disfmarker} there is no uh low - pass filtering before the downsampling . Well .\nProfessor A: Uh - huh .\nPhD C: There is because there is LDA filtering but that 's perhaps not uh the best w m\nProfessor A: Depends what it 's frequency characteristic is , yeah .\nPhD C: Well . Mm - hmm .\nProfessor A: So you could do a {disfmarker} you could do a stricter one .\nPhD D: System on\nProfessor A: Maybe . Yeah .\nPhD C: Yeah . So we discussed about this , about the um {disfmarker}\nProfessor A: Was there any conclusion about that ?\nPhD C: Uh \" try it \" . Yeah .\nProfessor A: I see .\nPhD C: I guess .\nProfessor A: Yeah . So again this is th this is the downsampling {vocalsound} uh of the uh {disfmarker} the feature vector stream\nPhD C: Uh .\nProfessor A: and um Yeah I guess the {disfmarker} the uh LDA filters they were doing do have um {vocalsound} uh let 's see , so the {disfmarker} the {disfmarker} the feature vectors are calculated every ten milliseconds so uh the question is how far down they are at fifty {disfmarker} fifty hertz . Uh . {vocalsound} Um .\nPhD C: Yeah . Mm - hmm .\nProfessor A: Sorry at twenty - five hertz since they 're downsampling by two . So . Does anybody know what the frequency characteristic is ?\nPhD C: We don't have yet\nProfessor A: Oh OK .\nPhD C: um {vocalsound} So , yeah .\nProfessor A: OK .\nPhD C: We should have a look first at , perhaps , {vocalsound} the modulation spectrum .\nProfessor A: Yeah .\nPhD C: Um . So there is this , there is the um length of the filters . Um . {vocalsound} {vocalsound} So the i this idea of trying to find filters with shorter delays . Um . We started to work with this .\nProfessor A: Hmm - hmm .\nPhD C: Mmm . And the third point um {vocalsound} {vocalsound} was the um , yeah , {vocalsound} the on - line normalization where , well , the recursion f recursion for the mean estimation {vocalsound} is a filter with some kind of delay\nProfessor A: Yeah .\nPhD C: and that 's not taken into account right now . Um . Yeah . And there again , yeah . For this , the conclusion of Hynek was , well , \" we can try it but {disfmarker} \"\nProfessor A: Uh - huh .\nPhD C: Um .\nProfessor A: Try {disfmarker} try what ?\nPhD C: So try to um {vocalsound} {vocalsound} um take into account the delay of the recursion for the mean estimation .\nProfessor A: OK .\nPhD C: Mmm . And this {disfmarker} we 've not uh worked on this yet . Um , yeah . And so while discussing about these {disfmarker} these LDA filters , some i issues appeared , like well , the fact that if we look at the frequency response of these filters it 's uh , well , we don't know really what 's the important part in the frequency response and there is the fact that {vocalsound} in the very low frequency , these filters don't {disfmarker} don't really remove a lot . {vocalsound} compared to the {disfmarker} to the uh standard RASTA filter . Uh and that 's probably a reason why , yeah , on - line normalization helps because it {disfmarker} it ,\nProfessor A: Right .\nPhD C: yeah , it removed this mean . Um . Yeah , but perhaps everything could {disfmarker} should be {disfmarker} could be in the filter , I mean , uh the {disfmarker} the mean normalization and {disfmarker} Yeah . So . Yeah . So basically that was {disfmarker} that 's {vocalsound} all we discussed about . We discussed about {vocalsound} good things to do also uh well , generally good stuff {vocalsound} to do for the research .\nProfessor A: Mm - hmm .\nPhD C: And this was this LDA uh tuning perhaps and {vocalsound} Hynek proposed again to his uh TRAPS , so .\nProfessor A: OK .\nPhD C: Yeah ,\nProfessor A: I mean I g I guess the key thing for me is {disfmarker} is figuring out how to better coordinate between the two sides\nPhD C: um .\nProfessor A: cuz {disfmarker} because um\nPhD C: Mm - hmm .\nProfessor A: uh I was talking with Hynek about it later and the {disfmarker} the {disfmarker} sort of had the sense sort of that {disfmarker} that neither group of people wanted to {disfmarker} to bother the other group too much . And {disfmarker} and I don't think anybody is , you know , closed in in their thinking or are unwilling to talk about things but I think that {vocalsound} you were sort of waiting for them to {vocalsound} tell you that they had something for you and {disfmarker} and that {disfmarker} and expected that they would do certain things and they were sor they didn't wanna bother you\nPhD C: Mm - hmm .\nProfessor A: and {vocalsound} they were sort of waiting for you and {disfmarker} and {disfmarker} and uh we ended up with this thing where they {disfmarker} they were filling up all of the possible latency themselves , and they just had hadn't thought of that . So . Uh . {vocalsound} {vocalsound} {vocalsound} {vocalsound} {vocalsound} I mean it 's true that maybe {disfmarker} maybe no one really thought about that {disfmarker} that this latency thing would be such a {disfmarker} a strict issue\nPhD C: Yeah . Well , but . Yeah . Yeah . Well {disfmarker}\nProfessor A: in {disfmarker} in uh {disfmarker} the other {disfmarker}\nPhD C: Yeah I don't know what happened really , but\nProfessor A: Yeah .\nPhD C: I guess it 's {disfmarker} it 's also so uh the time constraints . Because , {vocalsound} well , we discussed about that {disfmarker} about this problem and they told us \" well , we will do all that 's possible to have enough space for a network \" but then , yeah , perhaps they were too short with the time and\nProfessor A: Then they couldn't . I see .\nPhD C: uh yeah . But there was also problem {disfmarker} perhaps a problem of communication . So , yeah . Now we will try to {disfmarker}\nProfessor A: Just talk more .\nPhD C: Yeah , slikes and send mails .\nProfessor A: Yeah .\nPhD C: u s o o Yeah .\nProfessor A: Yeah .\nPhD C: Uh . OK .\nProfessor A: So there 's um {disfmarker} Alright . Well maybe we should just uh I mean you 're {disfmarker} you 're bus other than that you folks are busy doing all the {disfmarker} all the things that you 're trying that we talked about before right ? And this {disfmarker} machines are busy and {vocalsound} you 're busy\nPhD C: Yeah .\nProfessor A: and\nPhD C: Basically .\nProfessor A: Yeah . OK . Oh .\nPhD C: Um .\nProfessor A: Let 's {disfmarker} let 's , I mean , I think that as {disfmarker} as we said before that one of the things that we 're imagining is that uh there {disfmarker} there will be {vocalsound} uh in the system we end up with there 'll be something to explicitly uh uh do something about noise\nPhD C: Mm - hmm .\nProfessor A: in addition to the uh other things that we 're talking about and that 's probably the best thing to do . And there was that one email that said that {vocalsound} it sounded like uh uh things looked very promising up there in terms of uh I think they were using Ericsson 's {vocalsound} approach or something and {vocalsound} in addition to {disfmarker} They 're doing some noise removal thing , right ?\nPhD C: Yeah , yeah . So yeah we 're {disfmarker} will start to do this also .\nProfessor A: Yeah .\nPhD C: Uh so Carmen is just looking at the Ericsson {disfmarker} Ericsson code .\nPhD D: Yeah . We modif\nProfessor A: Mm - hmm .\nPhD C: And\nPhD D: Yeah , I modified it {disfmarker} well , modifying {disfmarker} {vocalsound} I studied Barry 's sim code , more or less . to take @ @ the first step the spectral subtraction . and we have some {disfmarker} the feature for Italian database and we will try with this feature with the filter to find the result .\nProfessor A: Mm - hmm . Mm - hmm .\nPhD D: But we haven't result until this moment .\nProfessor A: Yeah , sure .\nPhD D: But well , we are working in this also\nProfessor A: Yeah .\nPhD D: and maybe try another type of spectral subtraction , I don't {disfmarker}\nProfessor A: When you say you don't have a result yet you mean it 's {disfmarker} it 's just that it 's in process or that you {disfmarker} {vocalsound} it finished and it didn't get a good result ?\nPhD D: No . No , no n we have n we have do the experiment only have the feature {disfmarker} the feature but the experiment have\nPhD C: Yeah .\nPhD D: we have not make the experiment\nProfessor A: Oh . OK .\nPhD D: and maybe will be good result or bad result , we don't know .\nProfessor A: Yeah . Yeah .\nPhD C: Yeah .\nProfessor A: OK . So um I suggest actually now we {disfmarker} we {disfmarker} we sorta move on and {disfmarker} and hear what 's {disfmarker} what 's {disfmarker} what 's happening in {disfmarker} in other areas like {vocalsound} what 's {disfmarker} what 's happening with your {vocalsound} investigations {vocalsound} about echos and so on .\nGrad F: Oh um Well um I haven't started writing the test yet , I 'm meeting with Adam today\nProfessor A: Mm - hmm .\nGrad F: um and he 's going t show me the scripts he has for um {vocalsound} {vocalsound} running recognition on mee Meeting Recorder digits .\nProfessor A: Mm - hmm .\nGrad F: Uh {vocalsound} I also um {vocalsound} {vocalsound} haven't got the code yet , I haven't asked Hynek for {disfmarker} for the {disfmarker} for his code yet . Cuz I looked at uh Avendano 's thesis and {vocalsound} I don't really understand what he 's doing yet but it {disfmarker} {vocalsound} it {disfmarker} it sounded like um {vocalsound} the channel normalization part {vocalsound} um of his thesis um {vocalsound} was done in a {disfmarker} a bit of I don't know what the word is , a {disfmarker} a bit of a rough way um {vocalsound} it sounded like he um he {disfmarker} he {disfmarker} it {disfmarker} it wasn't really fleshed out and maybe he did something that was {vocalsound} interesting for the test situation but I {disfmarker} I 'm not sure if it 's {vocalsound} what I 'd wanna use so I have to {disfmarker} I have to read it more , I don't really understand what he 's doing yet .\nProfessor A: OK . Yeah I haven't read it in a while so I 'm not gonna be too much help unless I read it again ,\nPhD D: It 's my\nPhD C: Oh yeah ?\nPhD D: I know this is mine here .\nProfessor A: so . OK . Um . {vocalsound} The um {disfmarker} so you , and then {vocalsound} you 're also gonna be doing this echo cancelling between the {disfmarker} the close mounted and the {disfmarker} {vocalsound} and the {disfmarker} the {disfmarker} the {disfmarker} what we 're calling a cheating experiment uh of sorts between the distant {disfmarker}\nGrad F: Uh I I 'm ho Right . Well {disfmarker} {vocalsound} or I 'm hoping {disfmarker} I 'm hoping Espen will do it .\nProfessor A: Ah ! OK .\nGrad F: Um\nProfessor A: F um\nGrad F: u\nProfessor A: Delegate . That 's good . It 's good to delegate .\nGrad F: I {disfmarker} I think he 's at least planning to do it for the cl close - mike cross - talk and so maybe I can just take whatever setup he has and use it .\nProfessor A: Great . Great . Yeah actually um he should uh I wonder who else is I think maybe it 's Dan Ellis is going to be doing uh a different cancellation . Um . {vocalsound} One of the things that people working in the meeting task wanna get at is they would like to have cleaner {vocalsound} close - miked recordings . So uh this is especially true for the lapel but even for the close {disfmarker} close - miked uh cases um we 'd like to be able to have {vocalsound} um other sounds from other people and so forth removed from {disfmarker} So when someone isn't speaking you 'd like the part where they 're not speaking to actually be {disfmarker} So {vocalsound} what they 're talking about doing is using ec uh echo cancellation - like techniques . It 's not really echo but {vocalsound} uh just um uh taking the input from other mikes and using uh {vocalsound} uh a uh {disfmarker} {vocalsound} an adaptive filtering approach to remove the effect of that uh other speech . So . Um what was it , there was {disfmarker} there was some {disfmarker} some {disfmarker} some point where {vocalsound} eh uh Eric or somebody was {disfmarker} was speaking and he had lots of {vocalsound} silence in his channel and I was saying something to somebody else uh {vocalsound} which was in the background and it was not {disfmarker} it was recognizing my words , which were the background speech {vocalsound} on the close {disfmarker} {vocalsound} close mike .\nGrad F: Hmm .\nPhD B: Oh the {disfmarker} What we talked about yesterday ?\nProfessor A: Yes .\nPhD B: Yeah that was actually my {disfmarker} I was wearing the {disfmarker} I was wearing the lapel and you were sitting next to me ,\nProfessor A: Oh you {disfmarker} it was you I was Yeah .\nPhD B: and I only said one thing but you were talking and it was picking up all your words .\nProfessor A: Yeah . Yeah . So they would like clean channels . Uh and for that {disfmarker} mmm uh {disfmarker} that purpose uh they 'd like to pull it out . So I think {disfmarker} {vocalsound} I think Dan Ellis or somebody who was working with him was going to uh work on that . So . OK . Right ? Um . {vocalsound} And uh I don't know if we 've talked lately about the {disfmarker} the plans you 're developing that we talked about this morning uh I don't remember if we talked about that last week or not , but {vocalsound} maybe just a quick reprise of {disfmarker} of what we were saying this morning .\nGrad E: OK .\nProfessor A: Uh .\nGrad E: Um . {comment} So continuing to um extend\nPhD B: What about the stuff that um Mirjam has been doing ? And {disfmarker} and S Shawn , yeah . Oh . So they 're training up nets to try to recognize these acoustic features ? I see .\nProfessor A: But that 's uh uh all {disfmarker} that 's {disfmarker} is a {disfmarker} a certainly relevant {comment} {vocalsound} uh study and , you know , what are the features that they 're finding . We have this problem with the overloading of the term \" feature \" so\nPhD B: Yeah .\nProfessor A: uh {vocalsound} what are the variables , what we 're calling this one , what are the variables that they 're found {disfmarker} finding useful\nPhD C: Hmm .\nProfessor A: um for {disfmarker}\nPhD B: And their {disfmarker} their targets are based on canonical mappings of phones to acoustic f features .\nProfessor A: Right . And that 's certainly one thing to do and we 're gonna try and do something more f more fine than that but uh um so um So I guess you know what , I was trying to remember some of the things we were saying , do you ha still have that {disfmarker} ? Yeah .\nGrad E: Oh yeah .\nProfessor A: There 's those {vocalsound} {pause} that uh yeah , some of {disfmarker} some of the issues we were talking about was in j just getting a good handle on {disfmarker} on uh {vocalsound} what \" good features \" are and {disfmarker}\nPhD B: What does {disfmarker} what did um Larry Saul use for {disfmarker} it was the sonorant uh detector , right ? How did he {disfmarker} H how did he do that ? Wh - what was his detector ? Mm - hmm . Mm - hmm . Oh , OK . Mm - hmm . So how did he combine all these features ? What {disfmarker} what r mmm classifier did he Hmm . Oh right . You were talking about that , yeah . I see .\nProfessor A: And the other thing you were talking about is {disfmarker} is {disfmarker} is where we get the targets from . So I mean , there 's these issues of what are the {disfmarker} what are the variables that you use and do you combine them using the soft \" AND - OR \" or you do something , you know , more complicated um and then the other thing was so where do you get the targets from ? The initial thing is just the obvious that we 're discussing is starting up with phone labels {vocalsound} from somewhere and then uh doing the transformation . But then the other thing is to do something better and eh w why don't you tell us again about this {disfmarker} this database ? This is the {disfmarker}\nPhD B: Hmm !\nProfessor A: And then tell them to talk naturally ? Yeah , yeah .\nPhD B: Pierced tongues and Yeah . You could just mount it to that and they wouldn't even notice . Weld it . Zzz .\nProfessor A: Maybe you could go to these parlors and {disfmarker} and you could , you know {disfmarker} you know have {disfmarker} have , you know , reduced rates if you {disfmarker} {vocalsound} if you can do the measurements .\nPhD B: Yeah . I That 's right . You could {disfmarker} what you could do is you could sell little rings and stuff with embedded you know , transmitters in them and things\nProfessor A: Yeah . Yeah , be cool and help science .\nPhD B: and Yeah .\nProfessor A: OK .\nPhD B: Hmm ! There 's a bunch of data that l around , that {disfmarker} people have done studies like that w way way back right ? I mean {vocalsound} I can't remember where {disfmarker} uh Wisconsin or someplace that used to have a big database of {disfmarker} Yeah . I remember there was this guy at A T - andT , Randolph ? or r What was his name ? Do you remember that guy ? Um , {vocalsound} {vocalsound} researcher at A T - andT a while back that was studying , trying to do speech recognition from these kinds of features . I can't remember what his name was . Dang . Now I 'll think of it . That 's interesting .\nProfessor A: Do you mean eh {disfmarker} but you {disfmarker} I mean {disfmarker} Mar\nPhD C: Well he was the guy {disfmarker} the guy that was using {disfmarker}\nProfessor A: you mean when was {disfmarker} was Mark Randolph there , or {disfmarker} ?\nPhD B: Mark Randolph .\nProfessor A: Yeah he 's {disfmarker} he 's {disfmarker} he 's at Motorola now .\nPhD B: Oh is he ?\nProfessor A: Yeah .\nPhD B: Oh OK .\nProfessor A: Yeah .\nPhD B: Yeah .\nPhD C: Is it the guy that was using the pattern of pressure on the tongue or {disfmarker} ?\nPhD B: I can't remember exactly what he was using , now . But I know {disfmarker} I just remember it had to do with you know {vocalsound} uh positional parameters\nPhD C: What {disfmarker} Yeah .\nPhD B: and trying to m you know do speech recognition based on them .\nPhD C: Mm - hmm .\nProfessor A: Yeah . So the only {disfmarker} the only uh hesitation I had about it since , I mean I haven't see the data is it sounds like it 's {disfmarker} it 's {vocalsound} continuous variables and a bunch of them . And so\nPhD B: Hmm .\nProfessor A: I don't know how complicated it is to go from there {disfmarker} What you really want are these binary {pause} labels , and just a few of them . And maybe there 's a trivial mapping if you wanna do it and it 's e but it {disfmarker} I {disfmarker} I {disfmarker} I worry a little bit that this is a research project in itself , whereas um {vocalsound} if you did something instead that {disfmarker} like um having some manual annotation by {vocalsound} uh you know , linguistics students , this would {disfmarker} there 'd be a limited s set of things that you could do a as per our discussions with {disfmarker} with John before\nPhD B: Mm - hmm .\nProfessor A: but the things that you could do , like nasality and voicing and a couple other things you probably could do reasonably well .\nPhD B: Mm - hmm .\nProfessor A: And then there would {disfmarker} it would really be uh this uh uh binary variable . Course then , that 's the other question is do you want binary variables . So . I mean the other thing you could do is {vocalsound} boot trying to {disfmarker} to uh get those binary variables and take the continuous variables from {vocalsound} uh the uh {vocalsound} uh the data itself there , but I {disfmarker} I 'm not sure {disfmarker}\nPhD B: Could you cluster the {disfmarker} just do some kind of clustering ?\nProfessor A: Guess you could , yeah .\nPhD B: Bin them up into different categories and {disfmarker}\nProfessor A: Yeah . So anyway that 's {disfmarker} that 's uh {disfmarker} that 's another whole direction that cou could be looked at . Um . {vocalsound} Um . {vocalsound} I mean in general it 's gonna be {disfmarker} for new data that you look at , it 's gonna be hidden variable because we 're not gonna get everybody sitting in these meetings to {vocalsound} wear the pellets and {disfmarker} Um . So .\nGrad E: Right . Right .\nPhD B: So you 're talking about using that data to get uh instead of using canonical mappings of phones .\nGrad E: Right .\nPhD B: So you 'd use that data to give you sort of what the {disfmarker} {vocalsound} the true mappings are for each phone ?\nGrad E: Mm - hmm .\nPhD B: I see .\nGrad E: Mm - hmm .\nProfessor A: Yeah . So wh yeah , where this fits into the rest in {disfmarker} in my mind , I guess , is that um {vocalsound} we 're looking at different ways that we can combine {vocalsound} uh different kinds of {disfmarker} of rep front - end representations {vocalsound} um in order to get robustness under difficult or even , you know , typical conditions . And part of it , this robustness , seems to come from {vocalsound} uh multi - stream or multi - band sorts of things and Saul seems to have {vocalsound} a reasonable way of looking at it , at least for one {disfmarker} {vocalsound} {vocalsound} one um articulatory feature . The question is is can we learn from that {vocalsound} to change some of the other methods we have , since {disfmarker} I mean , one of the things that 's nice about what he had I thought was that {disfmarker} that it {disfmarker} it um {disfmarker} the decision about how strongly to train the different pieces is based on uh a {disfmarker} a reasonable criterion with hidden variables rather than {vocalsound} um just assuming {vocalsound} that you should train e e every detector uh with equal strength {vocalsound} towards uh it being this phone or that phone . Right ? So it {disfmarker} so um {vocalsound} he 's got these um uh uh\nPhD B: Hmm .\nProfessor A: he \" AND 's \" between these different {vocalsound} features . It 's a soft \" AND \" , I guess but in {disfmarker} in principle {vocalsound} you {disfmarker} you wanna get a strong concurrence of all the different things that indicate something and then he \" OR 's \" across the different {disfmarker} soft \" OR 's \" across the different uh {vocalsound} multi - band channels . And um {vocalsound} the weight yeah , the target for the training of the \" AND \" {disfmarker} \" AND ' ed \" things {vocalsound} is something that 's kept {vocalsound} uh as a hidden variable , and is learned with EM . Whereas what we were doing is {disfmarker} is uh {vocalsound} taking {vocalsound} the phone target and then just back propagating from that\nPhD B: So he doesn't have {disfmarker}\nProfessor A: which means that it 's {disfmarker} {vocalsound} it 's uh i It could be for instance {vocalsound} that for a particular point in the data {vocalsound} you don't want to um uh train a particular band {disfmarker} train the detectors for a particular band . You {disfmarker} you wanna ignore {vocalsound} that band , cuz that 's a {disfmarker} Ban - band is a noisy {disfmarker} noisy measure .\nPhD B: Mm - hmm .\nProfessor A: And we don't {disfmarker} We 're {disfmarker} we 're still gonna try to train it up . In our scheme we 're gonna try to train it up to do as well {disfmarker} well as it can at predicting . Uh . Maybe that 's not the right thing to do .\nPhD B: So he doesn't have to have truth marks or {disfmarker} Ho\nGrad E: F right , and uh he doesn't have to have hard labels .\nProfessor A: Well at the {disfmarker} at the tail end , yeah , he has to know what 's {disfmarker} where it 's sonorant . But he 's {disfmarker} but what he 's - but what he 's not training up {disfmarker} uh what he doesn't depend on as truth is\nGrad E: Right . For the full band .\nProfessor A: um I guess one way of describing would be if {disfmarker} if a sound is sonorant is it sonorant in this band ? Is it sonorant in that band ?\nGrad E: Right .\nProfessor A: Is it sonorant in that band ? i It 's hard to even answer that what you really mean is that the whole sound is sonorant . So\nPhD B: Mm - hmm . OK .\nProfessor A: then it comes down to , you know , to what extent should you make use of information from particular band {vocalsound} towards making your decision . And um {vocalsound} uh we 're making in a sense sort of this hard decision that you should {disfmarker} you should use everything {vocalsound} uh with {disfmarker} with uh equal strength .\nPhD B: I see .\nProfessor A: And uh because in the ideal case we would be going for posterior probabilities , if we had {vocalsound} uh enough data to really get posterior probabilities and if the {disfmarker} if we also had enough data so that it was representative of the test data then we would in fact be doing the right thing to train everything as hard as we can . But um this is something that 's more built up along an idea of robustness from {disfmarker} from the beginning and so you don't necessarily want to train everything up towards the {disfmarker}\nPhD B: So where did he get his {disfmarker} uh his tar his uh high - level targets about what 's sonorant and what 's not ?\nGrad E: From uh canonical mappings {comment} um at first\nPhD B: OK .\nProfessor A: Yeah .\nGrad E: and then it 's unclear um eh\nPhD B: Using TIMIT ? or using {disfmarker}\nGrad E: using TIMIT\nPhD B: Uh - huh .\nGrad E: right , right .\nProfessor A: Yeah .\nGrad E: And then uh he does some fine tuning um for um special cases . Yeah .\nProfessor A: Yeah . I mean we ha we have a kind of {vocalsound} iterative training because we do this embedded Viterbi , uh so there is some something that 's suggested , based on the data but it 's {disfmarker} it 's not {disfmarker} I think it s doesn't seem like it 's quite the same , cuz of this {disfmarker} cuz then whatever {vocalsound} that alignment is , it 's that for all {disfmarker} all bands .\nPhD B: Mm - hmm .\nProfessor A: Well no , that 's not quite right , we did actually do them separate {disfmarker} tried to do them separately so that would be a little more like what he did . Um . But it 's still {vocalsound} not quite the same because then it 's {disfmarker} it 's um setting targets based on where you would say {vocalsound} the sound begins in a particular band . Where he 's s this is not a labeling per se . Might be closer I guess if we did a {vocalsound} soft {disfmarker} soft target uh {vocalsound} uh embedded {vocalsound} neural net training like we 've done a few times uh {vocalsound} f the forward um {disfmarker} do the forward calculations to get the gammas and train on those . Mmm . Uh what 's next ?\nPhD B: I could say a little bit about w stuff I 've been playing with .\nProfessor A: Oh . You 're playing ?\nPhD B: I um Huh ?\nProfessor A: You 're playing ?\nPhD B: Yes , I 'm playing . Um {vocalsound} so I wanted to do this experiment to see um {vocalsound} uh what happens if we try to uh improve the performance of the back - end recognizer for the Aurora task and see how that affects things . And so I had this um {disfmarker} I think I sent around last week a {disfmarker} {vocalsound} this plan I had for an experiment , this matrix where {vocalsound} I would take the um {disfmarker} the original um the original system . So there 's the original system trained on the mel cepstral features and then com and then uh optimize the b HTK system and run that again . So look at the difference there and then uh do the same thing for {vocalsound} the ICSI - OGI front - end .\nProfessor A: What {disfmarker} which test set was this ?\nPhD B: This is {disfmarker} that I looked at ?\nProfessor A: Mm - hmm .\nPhD B: Uh I 'm looking at the Italian right now .\nProfessor A: Mm - hmm .\nPhD B: So as far as I 've gotten is I 've uh {vocalsound} been able to go through from beginning to end the um full HTK {vocalsound} system for the Italian data and got the same results that um {disfmarker} that uh {vocalsound} Stephane had . So um I started looking {disfmarker} to {disfmarker} and now I 'm {disfmarker} I 'm sort of lookin at the point where I wanna know what should I change in the HTK back - end in order to try to {disfmarker} uh to improve it . So . One of the first things I thought of was the fact that they use {vocalsound} the same number of states for all of the models\nProfessor A: Mm - hmm .\nPhD B: and so I went on - line and I uh found a pronunciation dictionary for Italian digits\nProfessor A: Mm - hmm .\nPhD B: and just looked at , you know , the number of phones in each one of the digits . Um you know , sort of the canonical way of setting up a {disfmarker} an HMM system is that you use {vocalsound} um three states per phone and um {vocalsound} so then the {disfmarker} the total number of states for a word would just be , you know , the number of phones times three . And so when I did that for the Italian digits , I got a number of states , ranging on the low end from nine to the high end , eighteen . Um . {vocalsound} Now you have to really add two to that because in HTK there 's an initial null and a final null so when they use {vocalsound} uh models that have eighteen states , there 're really sixteen states . They 've got those initial and final null states . And so um {vocalsound} {vocalsound} their guess of eighteen states seems to be pretty well matched to the two longest words of the Italian digits , the four and five {vocalsound} which um , according to my , you know , sort of off the cuff calculation , should have eighteen states each .\nProfessor A: Mm - hmm .\nPhD B: And so they had sixteen . So that 's pretty close . Um {vocalsound} {vocalsound} but for the {disfmarker} most of the words are sh much shorter . So the majority of them wanna have nine states . And so theirs are s sort of twice as long . So {vocalsound} my guess {disfmarker} uh And then if you {disfmarker} I {disfmarker} I printed out a confusion matrix um {vocalsound} uh for the well - matched case , and it turns out that the longest words are actually the ones that do the best . So my guess about what 's happening is that {vocalsound} you know , if you assume a fixed {disfmarker} the same amount of training data for each of these digits and a fixed length model for all of them but the actual words for some of them are half as long you really um have , you know , half as much training data for those models . Because if you have a long word and you 're training it to eighteen states , {vocalsound} {vocalsound} uh you 've got {disfmarker} you know , you 've got the same number of Gaussians , you 've gotta train in each case ,\nProfessor A: Mm - hmm .\nPhD B: but for the shorter words , you know , the total number of frames is actually half as many .\nProfessor A: Mm - hmm .\nPhD B: So {vocalsound} it could be that , you know , for the short words there 's {disfmarker} because you have so many states , you just don't have enough data to train all those Gaussians . So um I 'm going to try to um create more word - specific {vocalsound} um uh prototype H M Ms to start training from .\nProfessor A: Yeah , I mean , it 's not at all uncommon you do worse on long word on short words than long words anyway just because you 're accumulating more evidence for the {disfmarker} for the longer word ,\nPhD B: Mm - hmm .\nProfessor A: but .\nPhD B: Yeah so I 'll {disfmarker} I 'll , the next experiment I 'm gonna try is to just um you know create {vocalsound} uh models that seem to be more w matched to my guess about how long they should be .\nProfessor A: Mm - hmm .\nPhD B: And as part of that um I wanted to see sort of how the um {disfmarker} how these models were coming out , you know , what w {vocalsound} when we train up uh th you know , the model for \" one \" , which wants to have nine states , you know , what is the {disfmarker} uh what do the transition probabilities look like {disfmarker} in the self - loops , {comment} look like in {disfmarker} in those models ? And so I talked to Andreas and he explained to me how you can {vocalsound} calculate the expected duration of an HMM just by looking at the transition matrix\nProfessor A: Mm - hmm .\nPhD B: and so I wrote a little Matlab script that calculates that and so I 'm gonna sort of print those out for each of the words to see what 's happening , you know , how these models are training up ,\nProfessor A: Mm - hmm . Mm - hmm .\nPhD B: you know , the long ones versus the short ones . I d I did {disfmarker} quickly , I did the silence model and {disfmarker} {vocalsound} and um that 's coming out with about one point two seconds as its average duration and the silence model 's the one that 's used at the beginning and the end of each of the {vocalsound} string of digits .\nProfessor A: Wow . Lots of silence .\nPhD B: Yeah , yeah . And so the S P model , which is what they put in between digits , I {disfmarker} I haven't calculated that for that one yet , but um . So they basically {disfmarker} their {disfmarker} {vocalsound} their model for a whole digit string is silence {vocalsound} digit , SP , digit , SP blah - blah - blah and then silence at the end . And so .\nProfessor A: Are the SP 's optional ? I mean skip them ?\nPhD B: I have to look at that , but I 'm not sure that they are . Now the one thing about the S P model is really it only has a single s emitting state to it .\nProfessor A: Mm - hmm .\nPhD B: So if it 's not optional , you know , it 's {disfmarker} it 's not gonna hurt a whole lot\nProfessor A: I see .\nPhD B: and it 's tied to the center state of the silence model so it 's not its own {disfmarker} um It doesn't require its own training data ,\nProfessor A: Mm - hmm .\nPhD B: it just shares that state .\nProfessor A: Mm - hmm .\nPhD B: So it , I mean , it 's pretty good the way that they have it set up , but um i So I wanna play with that a little bit more . I 'm curious about looking at , you know {vocalsound} how these models have trained and looking at the expected durations of the models and I wanna compare that in the {disfmarker} the well - matched case f to the unmatched case , and see if you can get an idea of {disfmarker} just from looking at the {vocalsound} durations of these models , you know , what what 's happening .\nProfessor A: Yeah , I mean , I think that uh , as much as you can , it 's good to d sort of not do anything really tricky .\nPhD B: Mm - hmm .\nProfessor A: Not do anything that 's really finely tuned , but just sort of eh you know you t you i z\nPhD B: Yeah .\nProfessor A: The premise is kind of you have a {disfmarker} a good person look at this for a few weeks and what do you come up with ?\nPhD B: Mm - hmm . Mm - hmm .\nProfessor A: And uh\nPhD B: And Hynek , when I wa told him about this , he had an interesting point , and that was th um {vocalsound} the {disfmarker} the final models that they end up training up have I think probably something on the order of six Gaussians per state . So they 're fairly , you know , hefty models . And Hynek was saying that well , probably in a real application , {vocalsound} you wouldn't have enough compute to handle models that are very big or complicated . So in fact what we may want are simpler models .\nProfessor A: Could be .\nPhD B: And compare how they perform to that . But {vocalsound} you know , it depends on what the actual application is and it 's really hard to know what your limits are in terms of how many Gaussians you can have .\nProfessor A: Right . And that , I mean , at the moment that 's not the limitation , so .\nPhD B: Mm - hmm .\nProfessor A: I mean , I {disfmarker} I {disfmarker} I {disfmarker} what I thought you were gonna say i but which I was thinking was um where did six come from ? Probably came from the same place eighteen came from . You know , so .\nPhD B: Yeah . Right .\nProfessor A: Uh {vocalsound} that 's another parameter , right ? that {disfmarker} that maybe , you know , uh {disfmarker} you really want three or nine or {disfmarker}\nPhD B: Yeah , yeah . Well one thing {disfmarker} I mean , if I {disfmarker} if {disfmarker} if I start um reducing the number of states for some of these shorter models {vocalsound} that 's gonna reduce the total number of Gaussians .\nProfessor A: Right .\nPhD B: So in a sense it 'll be a simpler system .\nProfessor A: Yeah . Yeah . But I think right now again the idea is doing just very simple things\nPhD B: Yeah .\nProfessor A: how much better can you make it ? And um since they 're only simple things there 's nothing that you 're gonna do that is going to blow up the amount of computation\nPhD B: Mm - hmm .\nProfessor A: um so\nPhD B: Right . Right .\nProfessor A: if you found that nine was better than six that would be O K , I think , actually .\nPhD B: Mm - hmm .\nProfessor A: Doesn't have to go down .\nPhD B: Yeah . I really wasn't even gonna play with that part of the system yet ,\nProfessor A: Mm - hmm , OK .\nPhD B: I was just gonna change the {disfmarker} the t\nProfessor A: Yeah , just work with the models , yeah .\nPhD B: yeah , just look at the length of the models and just see what happens .\nProfessor A: Yeah .\nPhD B: So .\nProfessor A: Cool . OK . So uh {vocalsound} what 's uh I guess your plan for {disfmarker} You {disfmarker} you {disfmarker} you guys ' plan for the next {disfmarker} next week is {vocalsound} just continue on these {disfmarker} these same things we 've been talking about for Aurora and\nPhD C: Yeah , I guess we can try to {vocalsound} have some kind of new baseline for next week perhaps . with all these minor things {vocalsound} {vocalsound} modified . And then do other things , play with the spectral subtraction , and {vocalsound} retry the MSG and things like that .\nProfessor A: Yeah . Yeah . Yeah we {disfmarker} we have a big list .\nPhD C: Big list ?\nProfessor A: You have a big list of {disfmarker} {vocalsound} of things to do . So . Well that 's good . I think {vocalsound} that after all of this uh um confusion settles down in another {disfmarker} some point a little later next year there will be some sort of standard and it 'll get out there and {vocalsound} hopefully it 'll have some effect from something {vocalsound} that {disfmarker} {vocalsound} that has uh been done by our group of people but uh e even if it doesn't there 's {disfmarker} {vocalsound} there 's go there 'll be standards after that . So .\nPhD B: Does anybody know how to um {vocalsound} run Matlab sort of in batch mode like you c send it {vocalsound} s a bunch of commands to run and it gives you the output . Is it possible to do that ?\nGrad E: I {disfmarker} I think uh Mike tried it\nPhD B: Yeah ?\nGrad E: and he says it 's impossible so he went to Octave .\nPhD B: Octave .\nGrad E: Octave is the um UNIX clone of {disfmarker} of Matlab which you can batch .\nPhD B: Ah ! OK . Great . Thanks .\nGrad E: Yeah .\nPhD B: I was going crazy trying to do that .\nProfessor A: Huh .\nGrad E: Yeah .\nPhD C: What is Octave so ? It 's a free software ?\nGrad E: What 's that ? Uh , Octave ?\nPhD C: Yeah .\nGrad E: Yeah it 's {disfmarker} it 's {disfmarker} it 's free . I think we have it here {comment} r running somewhere .\nPhD B: Great !\nGrad E: Yeah .\nPhD C: And it does the same syntax and everything eh like Matlab , or {disfmarker} ?\nGrad E: Um {vocalsound} {comment} i it 's a little behind , it 's the same syntax but it 's a little behind in that {comment} Matlab went to these like um you can have cells and you can {disfmarker} you can {comment} uh implement object - oriented type things with Matlab . Uh Octave doesn't do that yet , so I think you , Octave is kinda like Matlab um four point something or .\nPhD B: If it 'll do like a lot of the basic matrix and vector stuff\nGrad E: The basic stuff , right .\nPhD B: that 's perfect .\nGrad E: Yeah .\nPhD B: Great !\nProfessor A: OK , guess we 're done .\nGrad E: OK .\nGrad F: Well , although by the way .", "source": "meeting_summ", "evaluation": "rouge"}
{"instructions": ["Summarize the discussion about the current XML format to link up different components in data", "What did F think about the current XML format to link up different components in data?", "What did A think about the current XML format to link up different components in data?", "Summarize the discussion about the disadvantages of ATLAS and other options", "What did C think about the disadvantages of ATLAS and other options?", "What did F think about the disadvantages of ATLAS and other options?", "Summarize the whole meeting"], "outputs": ["C developed an XML format that links together utterances based on time tags, essentially creating a lattice. The XML format would be divided into many sections, each with its own ID and timeline tag. The XML format could be modified to deal with smaller linguistic units since that would only entail changing the timestamps. Despite being easy to use, the format was not efficient for smaller linguistic units, like phones. It would work for word units, at best.", "F was concerned about how the time labels would adjust to smaller phonetic units. F inquired if the time boundaries could be changed by propagating new information throughout the XML. F thought that they could configure different XML files to deal with different units, but it would lead to large file sizes.", "A had seen an example of this kind of XML format before. A thought that the time boundaries were nicely handled but believed that smaller linguistic units would drain too much memory. It was essentially like a lattice, in his opinion. Though, A did not seem too concerned with dealing with smaller linguistic units since the problem would not be encountered frequently.", "Since the team is familiar with Perl and a flat file format is easier, it was suggested that the cost of learning a new framework, like ATLAS, might be too high. It was suggested that ATLAS be used for the external file representation initially, and if it seems suitable, then it should be adopted in its entirety. P files were also discussed but the problem with them was that they could still get pretty big.", "C thought that other options have a big learning curve, which should be taken into account, and that a flat format works well. A flat file format may not be fast, but everyone can handle it. C believed that quick and dirty solutions should be balanced with long-term infrastructural solutions. For instance, Perl can be paired with external representations of ATLAS files to create a working system. C also suggested that alternatives to P files might be interesting too, though the disadvantage would, once again, be the learning curve.", "F wanted to ensure that prosodic features could be dealt with at the level of small linguistic units. F proposed that they be attached to the word or segment level with the option of extracting smaller units. This would allow the team to keep what they have without starting over.", "Meeting participants wanted to agree upon a standard database to link up different components of the transcripts. The current idea was to use an XML script, but it quickly seemed that other options, like a pfile or ATLAS, are more suitable. The reason being that they would make it easier to deal with different linguistic units, like frames and utterances. Eventually, the team was skeptical of using something that would be hard to learn, like ATLAS. Nonetheless, they wanted to explore their options. The meeting finished with some discussion about handling annotations."], "input": "Grad C: Yeah , we had a long discussion about how much w how easy we want to make it for people to bleep things out . So {disfmarker} Morgan wants to make it hard .\nPhD D: It {disfmarker} it doesn't {disfmarker}\nGrad C: Did {disfmarker} did {disfmarker} did it {disfmarker} ? I didn't even check yesterday whether it was moving .\nPhD D: It didn't move yesterday either when I started it .\nGrad C: So .\nPhD D: So I don't know if it doesn't like both of us {disfmarker}\nGrad C: Channel three ? Channel three ?\nPhD D: You know , I discovered something yesterday on these , um , wireless ones .\nGrad B: Channel two .\nGrad C: Mm - hmm ?\nPhD D: You can tell if it 's picking up {pause} breath noise and stuff .\nGrad C: Yeah , it has a little indicator on it {disfmarker} on the AF .\nPhD D: Mm - hmm . So if you {disfmarker} yeah , if you breathe under {disfmarker} breathe and then you see AF go off , then you know {pause} it 's p picking up your mouth noise .\nPhD F: Oh , that 's good . Cuz we have a lot of breath noises .\nGrad C: Yep . Test .\nPhD F: In fact , if you listen to just the channels of people not talking , it 's like \" @ @ \" . It 's very disgust\nGrad C: What ? Did you see Hannibal recently or something ?\nPhD F: Sorry . Exactly . It 's very disconcerting . OK . So , um ,\nGrad C: \nPhD F: I was gonna try to get out of here , like , in half an hour , um , cuz I really appreciate people coming , and {vocalsound} the main thing that I was gonna ask people to help with today is {pause} to give input on what kinds of database format we should {pause} use in starting to link up things like word transcripts and annotations of word transcripts , so anything that transcribers or discourse coders or whatever put in the signal , {vocalsound} with time - marks for , like , words and phone boundaries and all the stuff we get out of the forced alignments and the recognizer . So , we have this , um {disfmarker} I think a starting point is clearly the {disfmarker} the channelized {pause} output of Dave Gelbart 's program , which Don brought a copy of ,\nGrad C: Yeah . Yeah , I 'm {disfmarker} I 'm familiar with that . I mean , we {disfmarker} I sort of already have developed an XML format for this sort of stuff .\nPhD F: um , which {disfmarker}\nPhD D: Can I see it ?\nGrad C: And so the only question {disfmarker} is it the sort of thing that you want to use or not ? Have you looked at that ? I mean , I had a web page up .\nPhD F: Right . So ,\nGrad C: So {disfmarker}\nPhD F: I actually mostly need to be able to link up , or {disfmarker} I it 's {disfmarker} it 's a question both of what the representation is and {disfmarker}\nGrad C: You mean , this {disfmarker} I guess I am gonna be standing up and drawing on the board .\nPhD F: OK , yeah . So you should , definitely .\nGrad C: Um , so {disfmarker} so it definitely had that as a concept . So tha it has a single time - line ,\nPhD F: Mm - hmm .\nGrad C: and then you can have lots of different sections , each of which have I Ds attached to it , and then you can refer from other sections to those I Ds , if you want to . So that , um {disfmarker} so that you start with {disfmarker} with a time - line tag . \" Time - line \" . And then you have a bunch of times . I don't e I don't remember exactly what my notation was ,\nPhD A: Oh , I remember seeing an example of this .\nGrad C: but it {disfmarker}\nPhD F: Right , right .\nPhD A: Yeah .\nGrad C: Yeah , \" T equals one point three two \" , uh {disfmarker} And then I {disfmarker} I also had optional things like accuracy , and then \" ID equals T one , uh , one seven \" . And then , {nonvocalsound} I also wanted to {disfmarker} to be i to be able to not specify specifically what the time was and just have a stamp .\nPhD F: Right .\nGrad C: Yeah , so these are arbitrary , assigned by a program , not {disfmarker} not by a user . So you have a whole bunch of those . And then somewhere la further down you might have something like an utterance tag which has \" start equals T - seventeen , end equals T - eighteen \" . So what that 's saying is , we know it starts at this particular time . We don't know when it ends .\nPhD F: OK .\nGrad C: Right ? But it ends at this T - eighteen , which may be somewhere else . We say there 's another utterance . We don't know what the t time actually is but we know that it 's the same time as this end time .\nPhD A: Mmm .\nGrad C: You know , thirty - eight , whatever you want .\nPhD A: So you 're essentially defining a lattice .\nGrad C: OK . Yes , exactly .\nPhD A: Yeah .\nGrad C: And then , uh {disfmarker} and then these also have I Ds . Right ? So you could {disfmarker} you could have some sort of other {disfmarker} other tag later in the file that would be something like , um , oh , I don't know , {comment} uh , {nonvocalsound} \" noise - type equals {nonvocalsound} door - slam \" . You know ? And then , uh , {nonvocalsound} you could either say \" time equals a particular time - mark \" or you could do other sorts of references . So {disfmarker} or {disfmarker} or you might have a prosody {disfmarker} \" Prosody \" right ? D ? T ? D ? T ? T ?\nPhD F: It 's an O instead of an I , but the D is good .\nGrad C: You like the D ? That 's a good D .\nPhD F: Yeah .\nGrad C: Um , you know , so you could have some sort of type here , and then you could have , um {disfmarker} the utterance that it 's referring to could be U - seventeen or something like that .\nPhD F: OK . So , I mean , that seems {disfmarker} that seems g great for all of the encoding of things with time and ,\nGrad C: Oh , well .\nPhD F: um {disfmarker} I {disfmarker} I guess my question is more , uh , what d what do you do with , say , a forced alignment ?\nPhD A: How - how\nPhD F: I mean you 've got all these phone labels , and what do you do if you {disfmarker} just conceptually , if you get , um , transcriptions where the words are staying but the time boundaries are changing , cuz you 've got a new recognition output , or s sort of {disfmarker} what 's the , um , sequence of going from the waveforms that stay the same , the transcripts that may or may not change , and then the utterance which {disfmarker} where the time boundaries that may or may not change {disfmarker} ?\nPhD A: Oh , that 's {disfmarker} That 's actually very nicely handled here because you could {disfmarker} you could {disfmarker} all you 'd have to change is the , {vocalsound} um , time - stamps in the time - line without {disfmarker} without , uh , changing the I Ds .\nPhD F: Um . And you 'd be able to propagate all of the {disfmarker} the information ?\nGrad C: Right . That 's , the who that 's why you do that extra level of indirection . So that you can just change the time - line .\nPhD A: Except the time - line is gonna be huge . If you say {disfmarker}\nGrad C: Yes .\nPhD F: Yeah ,\nPhD A: suppose you have a phone - level alignment .\nPhD F: yeah , especially at the phone - level .\nPhD A: You 'd have {disfmarker} you 'd have {disfmarker}\nPhD F: The {disfmarker} we {disfmarker} we have phone - level backtraces .\nGrad C: Yeah , this {disfmarker} I don't think I would do this for phone - level . I think for phone - level you want to use some sort of binary representation\nPhD F: Um {disfmarker}\nGrad C: because it 'll be too dense otherwise .\nPhD F: OK . So , if you were doing that and you had this sort of companion , uh , thing that gets called up for phone - level , uh , what would that look like ?\nPhD A: Why\nGrad C: I would use just an existing {disfmarker} an existing way of doing it .\nPhD F: How would you {disfmarker} ?\nPhD A: Mmm . But {disfmarker} but why not use it for phone - level ?\nPhD F: H h\nPhD A: It 's just a matter of {disfmarker} it 's just a matter of it being bigger . But if you have {disfmarker} you know , barring memory limitations , or uh {disfmarker} I w I mean this is still the m\nGrad C: It 's parsing limitations . I don't want to have this text file that you have to read in the whole thing to do something very simple for .\nPhD A: Oh , no . You would use it only {pause} for {pause} purposes where you actually want the phone - level information , I 'd imagine .\nPhD F: So you could have some file that configures how much information you want in your {disfmarker} in your XML or something .\nGrad C: Right . I mean , you 'd {disfmarker} y\nPhD F: Um ,\nPhD A: You {disfmarker}\nGrad C: I {disfmarker} I am imagining you 'd have multiple versions of this depending on the information that you want .\nPhD F: cuz th it does get very bush with {disfmarker} Right .\nGrad C: Um , I 'm just {disfmarker} what I 'm wondering is whether {disfmarker} I think for word - level , this would be OK .\nPhD F: Yeah .\nGrad C: For word - level , it 's alright .\nPhD F: Yeah . Definitely .\nPhD A: Mm - hmm .\nGrad C: For lower than word - level , you 're talking about so much data that I just {disfmarker} I don't know . I don't know if that {disfmarker}\nPhD F: I mean , we actually have {disfmarker} So , one thing that Don is doing , is we 're {disfmarker} we 're running {disfmarker} For every frame , you get a pitch value ,\nPhD D: Lattices are big , too .\nPhD F: and not only one pitch value but different kinds of pitch values\nGrad C: Yeah , I mean , for something like that I would use P - file\nPhD F: depending on {disfmarker}\nGrad C: or {disfmarker} or any frame - level stuff I would use P - file .\nPhD F: Meaning {disfmarker} ?\nGrad C: Uh , that 's a {disfmarker} well , or something like it . It 's ICS uh , ICSI has a format for frame - level representation of features . Um .\nPhD F: OK . That you could call {disfmarker} that you would tie into this representation with like an ID .\nGrad C: Right . Right . Or {disfmarker} or there 's a {disfmarker} there 's a particular way in XML to refer to external resources .\nPhD F: And {disfmarker} OK .\nGrad C: So you would say \" refer to this external file \" . Um , so that external file wouldn't be in {disfmarker}\nPhD F: So that might {disfmarker} that might work .\nPhD D: But what {disfmarker} what 's the advantage of doing that versus just putting it into this format ?\nGrad C: More compact , which I think is {disfmarker} is better .\nPhD D: Uh - huh .\nGrad C: I mean , if you did it at this {disfmarker}\nPhD F: I mean these are long meetings and with {disfmarker} for every frame ,\nGrad C: You don't want to do it with that {disfmarker} Anything at frame - level you had better encode binary\nPhD F: um {disfmarker}\nGrad C: or it 's gonna be really painful .\nPhD A: Or you just compre I mean , I like text formats . Um , b you can always , uh , G - zip them , and , um , you know , c decompress them on the fly if y if space is really a concern .\nPhD D: Yeah , I was thi I was thinking the advantage is that we can share this with other people .\nGrad C: Well , but if you 're talking about one per frame , you 're talking about gigabyte - size files . You 're gonna actually run out of space in your filesystem for one file .\nPhD F: These are big files . These are really {disfmarker} I mean {disfmarker}\nGrad C: Right ? Because you have a two - gigabyte limit on most O Ss .\nPhD A: Right , OK . I would say {disfmarker} OK , so frame - level is probably not a good idea . But for phone - level stuff it 's perfectly {disfmarker}\nPhD F: And th it 's {disfmarker}\nPhD A: Like phones , or syllables , or anything like that .\nPhD F: Phones are every five frames though , so . Or something like that .\nPhD A: But {disfmarker} but {disfmarker} but most of the frames are actually not speech . So , you know , people don't {disfmarker} v Look at it , words times the average {disfmarker} The average number of phones in an English word is , I don't know , {comment} five maybe ?\nPhD F: Yeah , but we actually {disfmarker}\nPhD A: So , look at it , t number of words times five . That 's not {disfmarker} that not {disfmarker}\nPhD F: Oh , so you mean pause phones take up a lot of the {disfmarker} long pause phones .\nPhD A: Exactly .\nGrad C: Yep .\nPhD A: Yeah .\nPhD F: Yeah . OK . That 's true . But you do have to keep them in there . Y yeah .\nGrad C: So I think it {disfmarker} it 's debatable whether you want to do phone - level in the same thing .\nPhD F: OK .\nGrad C: But I think , a anything at frame - level , even P - file , is too verbose .\nPhD F: OK . So {disfmarker}\nGrad C: I would use something tighter than P - files .\nPhD F: Do you {disfmarker} Are you familiar with it ?\nGrad C: So .\nPhD F: I haven't seen this particular format ,\nPhD A: I mean , I 've {disfmarker} I 've used them .\nPhD F: but {disfmarker}\nPhD A: I don't know what their structure is .\nPhD F: OK .\nPhD A: I 've forgot what the str\nPhD D: But , wait a minute , P - file for each frame is storing a vector of cepstral or PLP values ,\nGrad C: It 's whatever you want , actually .\nPhD D: right ? Right .\nGrad C: So that {disfmarker} what 's nice about the P - file {disfmarker} It {disfmarker} i Built into it is the concept of {pause} frames , utterances , sentences , that sort of thing , that structure . And then also attached to it is an arbitrary vector of values . And it can take different types .\nPhD F: Oh .\nGrad C: So it {disfmarker} th they don't all have to be floats . You know , you can have integers and you can have doubles , and all that sort of stuff .\nPhD F: So that {disfmarker} that sounds {disfmarker} that sounds about what I w\nGrad C: Um . Right ? And it has a header {disfmarker} it has a header format that {pause} describes it {pause} to some extent . So , the only problem with it is it 's actually storing the {pause} utterance numbers and the {pause} frame numbers in the file , even though they 're always sequential . And so it does waste a lot of space .\nPhD A: Hmm .\nGrad C: But it 's still a lot tighter than {disfmarker} than ASCII . And we have a lot of tools already to deal with it .\nPhD F: You do ? OK . Is there some documentation on this somewhere ?\nGrad C: Yeah , there 's a ton of it . Man - pages and , uh , source code , and me .\nPhD F: OK , great . So , I mean , that sounds good . I {disfmarker} I was just looking for something {disfmarker} I 'm not a database person , but something sort of standard enough that , you know , if we start using this we can give it out , other people can work on it ,\nGrad C: Yeah , it 's not standard .\nPhD F: or {disfmarker} {comment} Is it {disfmarker} ?\nGrad C: I mean , it 's something that we developed at ICSI . But , uh {disfmarker}\nPhD F: But it 's {pause} been used here\nGrad C: But it 's been used here\nPhD F: and people 've {disfmarker}\nGrad C: and {disfmarker} and , you know , we have a {pause} well - configured system that you can distribute for free , and {disfmarker}\nPhD D: I mean , it must be the equivalent of whatever you guys used to store feat your computed features in , right ?\nPhD F: OK .\nPhD A: Yeah , th we have {disfmarker} Actually , we {disfmarker} we use a generalization of the {disfmarker} the Sphere format .\nPhD D: Mmm .\nPhD A: Um , but {disfmarker} Yeah , so there is something like that but it 's , um , probably not as sophist\nGrad C: Well , what does H T K do for features ?\nPhD D: And I think there 's {disfmarker}\nGrad C: Or does it even have a concept of features ?\nPhD A: They ha it has its own {disfmarker} I mean , Entropic has their own feature format that 's called , like , S - SD or some so SF or something like that .\nPhD F: Yeah .\nGrad C: I 'm just wondering , would it be worth while to use that instead ?\nPhD D: Yeah .\nPhD A: Hmm ?\nPhD F: Yeah . Th - this is exactly the kind of decision {disfmarker} It 's just whatever {disfmarker}\nPhD D: But , I mean , people don't typically share this kind of stuff , right ?\nPhD A: Right .\nGrad C: They generate their own .\nPhD D: I mean {disfmarker} Yeah .\nPhD F: Actually , I {disfmarker} I just {disfmarker} you know , we {disfmarker} we 've done this stuff on prosodics and three or four places have asked for those prosodic files , and we just have an ASCII , uh , output of frame - by - frame .\nGrad C: Ah , right .\nPhD F: Which is fine , but it gets unwieldy to go in and {disfmarker} and query these files with really huge files .\nGrad C: Right .\nPhD F: I mean , we could do it . I was just thinking if there 's something that {disfmarker} where all the frame values are {disfmarker}\nGrad C: And a and again , if you have a {disfmarker} if you have a two - hour - long meeting , that 's gonna {disfmarker}\nPhD F: Hmm ? They 're {disfmarker} they 're fair they 're quite large .\nGrad C: Yeah , I mean , they 'd be emo enormous .\nPhD F: And these are for ten - minute Switchboard conversations ,\nGrad C: Right .\nPhD F: and {disfmarker} So it 's doable , it 's just that you can only store a feature vector at frame - by - frame and it doesn't have any kind of ,\nPhD D: Is {disfmarker} is the sharing part of this a pretty important {pause} consideration\nPhD F: um {disfmarker}\nPhD D: or does that just sort of , uh {disfmarker} a nice thing to have ?\nPhD F: I {disfmarker} I don't know enough about what we 're gonna do with the data . But I thought it would be good to get something that we can {disfmarker} that other people can use or adopt for their own kinds of encoding . And just , I mean we have to use some we have to make some decision about what to do .\nGrad C: Yeah .\nPhD F: And especially for the prosody work , what {disfmarker} what it ends up being is you get features from the signal , and of course those change every time your alignments change . So you re - run a recognizer , you want to recompute your features , um , and then keep the database up to date .\nGrad C: Right .\nPhD F: Or you change a word , or you change a {vocalsound} utterance boundary segment , which is gonna happen a lot . And so I wanted something where {pause} all of this can be done in a elegant way and that if somebody wants to try something or compute something else , that it can be done flexibly . Um , it doesn't have to be pretty , it just has to be , you know , easy to use , and {disfmarker}\nGrad C: Yeah , the other thing {disfmarker} We should look at ATLAS , the NIST thing ,\nPhD F: Oh .\nPhD A: Mmm .\nGrad C: and see if they have anything at that level .\nPhD F: Uh {disfmarker}\nGrad C: I mean , I 'm not sure what to do about this with ATLAS , because they chose a different route . I chose something that {disfmarker} Th - there are sort of two choices . Your {disfmarker} your file format can know about {disfmarker} know that you 're talking about language {pause} and speech , which is what I chose , and time , or your file format can just be a graph representation . And then the application has to impose the structure on top . So what it looked like ATLAS chose is , they chose the other way , which was their file format is just nodes and links , and you have to interpret what they mean yourself .\nPhD F: And why did you not choose that type of approach ?\nGrad C: Uh , because I knew that we were doing speech , and I thought it was better if you 're looking at a raw file to be {disfmarker} t for the tags to say \" it 's an utterance \" , as opposed to the tag to say \" it 's a link \" .\nPhD F: OK . OK .\nGrad C: So , but {disfmarker}\nPhD F: But other than that , are they compatible ? I mean , you could sort of {disfmarker}\nGrad C: Yeah , they 're reasonably compatible .\nPhD F: I mean , you {disfmarker} you could {disfmarker}\nPhD D: You could probably translate between them .\nGrad C: Yep .\nPhD F: Yeah , that 's w So ,\nGrad C: So , well , the other thing is if we choose to use ATLAS , which maybe we should just do , we should just throw this out before we invest a lot of time in it .\nPhD F: OK . I don't {disfmarker} So this is what the meeting 's about ,\nGrad C: Yeah .\nPhD F: just sort of how to {disfmarker} Um , cuz we need to come up with a database like this just to do our work . And I actually don't care , as long as it 's something useful to other people , what we choose .\nGrad C: Yeah .\nPhD F: So maybe it 's {disfmarker} maybe oth you know , if {disfmarker} if you have any idea of how to choose , cuz I don't .\nGrad C: The only thing {disfmarker} Yeah .\nPhD A: Do they already have tools ?\nGrad C: I mean , I {disfmarker} I chose this for a couple reasons . One of them is that it 's easy to parse . You don't need a full XML parser . It 's very easy to just write a Perl script {pause} to parse it .\nPhD A: As long as uh each tag is on one line .\nGrad C: Exactly . Exactly . Which I always do .\nPhD F: And you can have as much information in the tag as you want , right ?\nGrad C: Well , I have it structured . Right ? So each type tag has only particular items that it can take .\nPhD F: Can you {disfmarker} But you can add to those structures if you {disfmarker}\nGrad C: Sure . If you have more information . So what {disfmarker} What NIST would say is that instead of doing this , you would say something like \" link {nonvocalsound} start equals , um , you know , some node ID ,\nPhD F: Yeah . So {disfmarker}\nGrad C: end equals some other node ID \" , and then \" type \" would be \" utterance \" .\nPhD A: Hmm .\nGrad C: You know , so it 's very similar .\nPhD F: So why would it be a {disfmarker} a waste to do it this way if it 's similar enough that we can always translate it ?\nPhD D: It probably wouldn't be a waste . It would mean that at some point if we wanted to switch , we 'd just have to translate everything .\nGrad C: Write a translator . But it se Since they are developing a big {disfmarker}\nPhD F: But it {disfmarker} but that sounds {disfmarker}\nPhD D: But that 's {disfmarker} I don't think that 's a big deal .\nPhD F: As long as it is {disfmarker}\nGrad C: they 're developing a big infrastructure . And so it seems to me that if {disfmarker} if we want to use that , we might as well go directly to what they 're doing , rather than {disfmarker}\nPhD A: If we want to {disfmarker} Do they already have something that 's {disfmarker} that would be useful for us in place ?\nPhD D: Yeah . See , that 's the question . I mean , how stable is their {disfmarker} Are they ready to go ,\nGrad C: The {disfmarker} I looked at it {disfmarker}\nPhD D: or {disfmarker} ?\nGrad C: The last time I looked at it was a while ago , probably a year ago , uh , when we first started talking about this .\nPhD D: Hmm .\nGrad C: And at that time at least {vocalsound} it was still not very {pause} complete . And so , specifically they didn't have any external format representation at that time . They just had the sort of conceptual {pause} node {disfmarker} uh , annotated transcription graph , which I really liked . And that 's exactly what this stuff is based on . Since then , they 've developed their own external file format , which is , uh , you know , this sort of s this sort of thing . Um , and apparently they 've also developed a lot of tools , but I haven't looked at them . Maybe I should .\nPhD A: We should {disfmarker} we should find out .\nPhD F: I mean , would the tools {disfmarker} would the tools run on something like this , if you can translate them anyway ?\nGrad C: Um , th what would {disfmarker} would {disfmarker} would {disfmarker} what would worry me is that maybe we might miss a little detail\nPhD A: It 's a hassle\nPhD F: I mean , that {disfmarker} I guess it 's a question that {disfmarker}\nPhD A: if {disfmarker}\nPhD F: uh , yeah .\nGrad C: that would make it very difficult to translate from one to the other .\nPhD F: OK .\nPhD A: I {disfmarker} I think if it 's conceptually close , and they already have or will have tools that everybody else will be using , I mean , {vocalsound} it would be crazy to do something s you know , separate that {disfmarker}\nPhD F: OK .\nGrad C: Yeah , we might as well . Yep .\nPhD F: Yeah .\nGrad C: So I 'll {disfmarker} I 'll take a closer look at it .\nPhD F: Actually , so it 's {disfmarker} that {disfmarker} that would really be the question , is just what you would feel is in the long run the best thing .\nGrad C: And {disfmarker} Right .\nPhD F: Cuz {vocalsound} once we start , sort of , doing this I don't {disfmarker} we don't actually have enough time to probably have to rehash it out again\nGrad C: The {disfmarker} Yep . The other thing {disfmarker} the other way that I sort of established this was as easy translation to and from the Transcriber format .\nPhD F: and {disfmarker} s Right .\nGrad C: Um ,\nPhD F: Right .\nGrad C: but {disfmarker}\nPhD F: I mean , I like this . This is sort of intuitively easy to actually r read ,\nGrad C: Yep .\nPhD F: as easy it could {disfmarker} as it could be . But , I suppose that {pause} as long as they have a type here that specifies \" utt \" , um ,\nGrad C: It 's almost the same .\nPhD F: it 's {disfmarker} yeah , close enough that {disfmarker}\nGrad C: The {disfmarker} the {disfmarker} the {disfmarker} the point is {disfmarker} with this , though , is that you can't really add any supplementary information . Right ? So if you suddenly decide that you want {disfmarker}\nPhD F: You have to make a different type .\nGrad C: Yeah . You 'd have to make a different type .\nPhD F: So {disfmarker} Well , if you look at it and {disfmarker} Um , I guess in my mind I don't know enough {disfmarker} Jane would know better , {comment} about the {pause} types of annotations and {disfmarker} and {disfmarker} But I imagine that those are things that would {disfmarker} well , you guys mentioned this , {comment} that could span any {disfmarker} it could be in its own channel , it could span time boundaries of any type ,\nGrad C: Right .\nPhD F: it could be instantaneous , things like that . Um , and then from the recognition side we have backtraces at the phone - level .\nGrad C: Right .\nPhD F: If {disfmarker} if it can handle that , it could handle states or whatever . And then at the prosody - level we have frame {disfmarker} sort of like cepstral feature files ,\nGrad C: Yep .\nPhD F: uh , like these P - files or anything like that . And that 's sort of the world of things that I {disfmarker} And then we have the aligned channels , of course ,\nGrad C: Right .\nPhD A: It seems to me you want to keep the frame - level stuff separate .\nPhD F: and {disfmarker} Yeah .\nPhD A: And then {disfmarker}\nPhD F: I {disfmarker} I definitely agree and I wanted to find actually a f a nicer format or a {disfmarker} maybe a more compact format than what we used before .\nGrad C: Right .\nPhD F: Just cuz you 've got {vocalsound} ten channels or whatever and two hours of a meeting . It 's {disfmarker} it 's a lot of {disfmarker}\nGrad C: Huge .\nPhD A: Now {disfmarker} now how would you {disfmarker} how would you represent , um , multiple speakers in this framework ? Were {disfmarker} You would just represent them as {disfmarker}\nGrad C: Um ,\nPhD A: You would have like a speaker tag or something ?\nGrad C: there 's a spea speaker tag up at the top which identifies them and then each utt the way I had it is each turn or each utterance , {comment} I don't even remember now , had a speaker ID tag attached to it .\nPhD A: Mm - hmm . OK .\nGrad C: And in this format you would have a different tag , which {disfmarker} which would , uh , be linked to the link . So {disfmarker} so somewhere else you would have another thing {pause} that would be ,\nPhD F: Yeah .\nGrad C: um {disfmarker} Let 's see , would it be a node or a link ? Um {disfmarker} And so {disfmarker} so this one would have , um , an ID is link {disfmarker} {comment} link seventy - four or something like that .\nPhD A: Mm - hmm .\nGrad C: And then somewhere up here you would have a link that {disfmarker} that , uh , you know , was referencing L - seventy - four and had speaker Adam .\nPhD A: Is i ?\nGrad C: You know , or something like that .\nPhD F: Actually , it 's the channel , I think , that {disfmarker}\nPhD A: Well , channel or speaker or whatever .\nPhD F: I mean , w yeah , channel is what the channelized output out\nPhD A: It doesn't {disfmarker}\nGrad C: This isn't quite right .\nPhD A: Right .\nGrad C: I have to look at it again .\nPhD F: Yeah , but {disfmarker}\nPhD A: But {disfmarker} but {disfmarker} so how in the NIST format do we express {vocalsound} a hierarchical relationship between , um , say , an utterance and the words within it ? So how do you {pause} tell {pause} that {pause} these are the words that belong to that utterance ?\nGrad C: Um , you would have another structure lower down than this that would be saying they 're all belonging to this ID .\nPhD A: Mm - hmm .\nPhD D: So each thing refers to the {pause} utterance that it belongs to .\nGrad C: Right . And then each utterance could refer to a turn ,\nPhD D: So it 's {disfmarker} it 's not hi it 's sort of bottom - up .\nGrad C: and each turn could refer to something higher up .\nPhD F: And what if you actually have {disfmarker} So right now what you have as utterance , um , the closest thing that comes out of the channelized is the stuff between the segment boundaries that the transcribers put in or that Thilo put in , which may or may not actually be , like , a s it 's usually not {disfmarker} um , the beginning and end of a sentence , say .\nGrad C: Well , that 's why I didn't call it \" sentence \" .\nPhD F: So , right . Um , so it 's like a segment or something .\nGrad C: Yeah .\nPhD F: So , I mean , I assume this is possible , that if you have {disfmarker} someone annotates the punctuation or whatever when they transcribe , you can say , you know , from {disfmarker} for {disfmarker} from the c beginning of the sentence to the end of the sentence , from the annotations , this is a unit , even though it never actually {disfmarker} i It 's only a unit by virtue of the annotations {pause} at the word - level .\nGrad C: Sure . I mean , so you would {disfmarker} you would have yet another tag .\nPhD F: And then that would get a tag somehow .\nGrad C: You 'd have another tag which says this is of type \" sentence \" .\nPhD F: OK . OK .\nGrad C: And , what {disfmarker}\nPhD F: But it 's just not overtly in the {disfmarker}\nPhD A: OK .\nPhD F: Um , cuz this is exactly the kind of {disfmarker}\nPhD A: So {disfmarker}\nPhD F: I think that should be {pause} possible as long as the {disfmarker} But , uh , what I don't understand is where the {disfmarker} where in this type of file {pause} that would be expressed .\nGrad C: Right . You would have another tag somewhere . It 's {disfmarker} well , there 're two ways of doing it .\nPhD F: S so it would just be floating before the sentence or floating after the sentence without a time - mark .\nGrad C: You could have some sort of link type {disfmarker} type equals \" sentence \" , and ID is \" S - whatever \" . And then lower down you could have an utterance . So the type is \" utterance \" {disfmarker} equals \" utt \" . And you could either say that {disfmarker} No . I don't know {disfmarker}\nPhD A: So here 's the thing .\nGrad C: I take that back .\nPhD A: Um {disfmarker}\nGrad C: Can you {disfmarker} can you say that this is part of this ,\nPhD F: See , cuz it 's {disfmarker}\nPhD A: Hhh .\nPhD F: it 's {disfmarker}\nPhD D: You would just have a r\nPhD F: S\nGrad C: or do you say this is part of this ? I think {disfmarker}\nPhD D: You would refer up to the sentence .\nPhD F: But they 're {disfmarker}\nPhD A: Well , the thing {disfmarker}\nPhD F: they 're actually overlapping each other , sort of .\nGrad C: So {disfmarker}\nPhD A: the thing is that some something may be a part of one thing for one purpose and another thing of another purpose .\nGrad C: Right .\nPhD A: So f\nPhD F: You have to have another type then , I guess .\nPhD A: s Um , well , s let 's {disfmarker} let 's ta so let 's {disfmarker}\nGrad C: Well , I think I 'm {disfmarker} I think w I had better look at it again\nPhD F: Yeah .\nPhD A: so {disfmarker}\nGrad C: because I {disfmarker} I 'm {disfmarker}\nPhD F: OK . OK .\nPhD A: y So for instance @ @ {comment} sup\nGrad C: There 's one level {disfmarker} there 's one more level of indirection that I 'm forgetting .\nPhD A: Suppose you have a word sequence and you have two different segmentations of that same word sequence . f Say , one segmentation is in terms of , um , you know , uh , sentences . And another segmentation is in terms of , um , {vocalsound} I don't know , {comment} prosodic phrases . And let 's say that they don't {pause} nest . So , you know , a prosodic phrase may cross two sentences or something .\nGrad C: Right .\nPhD A: I don't know if that 's true or not but {vocalsound} let 's as\nPhD F: Well , it 's definitely true with the segment .\nPhD A: Right .\nPhD F: That 's what I {disfmarker} exactly what I meant by the utterances versus the sentence could be sort of {disfmarker}\nPhD A: Yeah . So , you want to be s you want to say this {disfmarker} this word is part of that sentence and this prosodic phrase .\nPhD F: Yeah .\nPhD A: But the phrase is not part of the sentence\nPhD F: Yeah .\nPhD A: and neither is the sentence part of the phrase .\nPhD F: Right .\nGrad C: I I 'm pretty sure that you can do that , but I 'm forgetting the exact level of nesting .\nPhD A: So , you would have to have {vocalsound} two different pointers from the word up {disfmarker} one level up , one to the sent\nGrad C: So {disfmarker} so what you would end up having is a tag saying \" here 's a word , and it starts here and it ends here \" .\nPhD A: Right .\nGrad C: And then lower down you would say \" here 's a prosodic boundary and it has these words in it \" . And lower down you 'd have \" here 's a sentence ,\nPhD A: Right .\nPhD F: An - Right .\nGrad C: and it has these words in it \" .\nPhD F: So you would be able to go in and say , you know , \" give me all the words in the bound in the prosodic phrase\nGrad C: Yep .\nPhD F: and give me all the words in the {disfmarker} \" Yeah .\nGrad C: So I think that 's {disfmarker} that would wor\nPhD F: Um , OK .\nGrad C: Let me look at it again .\nPhD A: Mm - hmm . The {disfmarker} the o the other issue that you had was , how do you actually efficiently extract , um {disfmarker} find and extract information in a structure of this type ?\nPhD F: OK .\nGrad C: So .\nPhD F: That 's good .\nPhD A: So you gave some examples like {disfmarker}\nPhD F: Well , uh , and , I mean , you guys might {disfmarker} I don't know if this is premature because I suppose once you get the representation you can do this , but the kinds of things I was worried about is ,\nPhD A: No , that 's not clear .\nPhD F: uh {disfmarker}\nPhD A: I mean , yeah , you c sure you can do it ,\nPhD F: Well , OK . So i if it {disfmarker}\nPhD A: but can you do it sort of l l you know , it {disfmarker}\nPhD F: I I mean , I can't do it , but I can {disfmarker} um ,\nPhD A: y y you gotta {disfmarker} you gotta do this {disfmarker} you {disfmarker} you 're gonna want to do this very quickly\nGrad C: Well {disfmarker}\nPhD A: or else you 'll spend all your time sort of searching through very {vocalsound} complex data structures {disfmarker}\nPhD F: Right . You 'd need a p sort of a paradigm for how to do it . But an example would be \" find all the cases in which Adam started to talk while Andreas was talking and his pitch was rising , Andreas 's pitch \" . That kind of thing .\nGrad C: Right . I mean , that 's gonna be {disfmarker} Is the rising pitch a {pause} feature , or is it gonna be in the same file ?\nPhD F: Well , the rising pitch will never be {pause} hand - annotated . So the {disfmarker} all the prosodic features are going to be automatically {disfmarker}\nGrad C: But the {disfmarker} I mean , that 's gonna be hard regardless ,\nPhD F: So they 're gonna be in those {disfmarker}\nGrad C: right ? Because you 're gonna have to write a program that goes through your feature file and looks for rising pitches .\nPhD A: Yeah .\nPhD F: So {disfmarker} Right . So normally what we would do is we would say \" what do we wanna assign rising pitch to ? \" Are we gonna assign it to words ? Are we gonna just assign it to sort of {disfmarker} when it 's rising we have a begin - end rise representation ? But suppose we dump out this file and we say , uh , for every word we just classify it as , w you know , rise or fall or neither ?\nGrad C: OK . Well , in that case you would add that to this {pause} format\nPhD F: OK .\nGrad C: r\nPhD F: So we would basically be sort of , um , taking the format and enriching it with things that we wanna query in relation to the words that are already in the file ,\nGrad C: Right .\nPhD F: and then querying it .\nPhD A: You want sort of a grep that 's {disfmarker} that works at the structural {disfmarker} on the structural representation .\nPhD F: OK .\nGrad C: You have that . There 's a {pause} standard again in XML , specifically for searching XML documents {disfmarker} structured X - XML documents , where you can specify both the content and the structural position .\nPhD A: Yeah , but it 's {disfmarker} it 's not clear that that 's {disfmarker} That 's relative to the structure of the XML document ,\nPhD F: If {disfmarker}\nPhD A: not to the structure of what you 're representing in the document .\nGrad C: You use it as a tool . You use it as a tool , not an end - user . It 's not an end - user thing .\nPhD A: Right .\nGrad C: It 's {disfmarker} it 's {disfmarker} you would use that to build your tool to do that sort of search .\nPhD A: Right . Be Because here you 're specifying a lattice .\nPhD F: Uh {disfmarker}\nPhD A: So the underlying {disfmarker} that 's the underlying data structure . And you want to be able to search in that lattice .\nPhD F: But as long as the {disfmarker}\nGrad C: It 's a graph , but {disfmarker}\nPhD A: That 's different from searching through the text .\nPhD F: But it seems like as long as the features that {disfmarker}\nGrad C: Well , no , no , no . The whole point is that the text and the lattice are isomorphic . They {pause} represent each other {pause} completely .\nPhD A: Um {disfmarker}\nGrad C: So that {disfmarker} I mean th\nPhD F: That 's true if the features from your acoustics or whatever that are not explicitly in this are at the level of these types .\nPhD A: Hhh .\nPhD F: That {disfmarker} that if you can do that {disfmarker}\nGrad C: Yeah , but that 's gonna be the trouble no matter what . Right ? No matter what format you choose , you 're gonna have the trou you 're gonna have the difficulty of relating the {disfmarker} the frame - level features {disfmarker}\nPhD F: That 's right . That 's true . That 's why I was trying to figure out what 's the best format for this representation .\nGrad C: Yep .\nPhD F: And it 's still gonna be {disfmarker}\nPhD A: Hmm .\nPhD F: it 's still gonna be , uh , not direct .\nGrad C: Right .\nPhD F: You know , it {disfmarker} Or another example was , you know , uh , where in the language {disfmarker} where in the word sequence are people interrupting ? So , I guess that one 's actually easier .\nPhD D: What about {disfmarker} what about , um , the idea of using a relational database to , uh , store the information from the XML ? So you would have {disfmarker} XML basically would {disfmarker} Uh , you {disfmarker} you could use the XML to put the data in , and then when you get data out , you put it back in XML . So use XML as sort of the {disfmarker} the transfer format ,\nGrad C: Transfer .\nPhD D: uh , but then you store the data in the database , which allows you to do all kinds of {pause} good search things in there .\nGrad C: The , uh {disfmarker} One of the things that ATLAS is doing is they 're trying to define an API which is independent of the back store ,\nPhD F: Huh .\nGrad C: so that , uh , you could define a single API and the {disfmarker} the storage could be flat XML files or a database .\nPhD D: Mm - hmm .\nGrad C: My opinion on that is for the s sort of stuff that we 're doing , {comment} I suspect it 's overkill to do a full relational database , that , um , just a flat file and , uh , search tools I bet will be enough .\nPhD A: But {disfmarker}\nGrad C: But that 's the advantage of ATLAS , is that if we actually take {disfmarker} decide to go that route completely and we program to their API , then if we wanted to add a database later it would be pretty easy .\nPhD D: Mm - hmm . Mm - hmm .\nPhD F: It seems like the kind of thing you 'd do if {disfmarker} I don't know , if people start adding all kinds of s bells and whistles to the data . And so that might be {disfmarker} I mean , it 'd be good for us to know {disfmarker} to use a format where we know we can easily , um , input that to some database if other people are using it .\nGrad C: Yep .\nPhD F: Something like that .\nGrad C: I guess I 'm just a little hesitant to try to go whole hog on sort of the {disfmarker} the whole framework that {disfmarker} that NIST is talking about , with ATLAS and a database and all that sort of stuff ,\nPhD F: So {disfmarker}\nGrad C: cuz it 's a big learning curve , just to get going .\nPhD D: Hmm .\nPhD A: Hmm .\nGrad C: Whereas if we just do a flat file format , sure , it may not be as efficient but everyone can program in Perl and {disfmarker} and use it .\nPhD F: OK .\nGrad C: Right ?\nPhD A: But this is {disfmarker}\nGrad C: So , as opposed to {disfmarker}\nPhD A: I {disfmarker} I 'm still , um , {vocalsound} not convinced that you can do much at all on the text {disfmarker} on the flat file that {disfmarker} that {disfmarker} you know , the text representation . e Because the text representation is gonna be , uh , not reflecting the structure of {disfmarker} of your words and annotations . It 's just {disfmarker} it 's {disfmarker}\nGrad C: Well , if it 's not representing it , then how do you recover it ? Of course it 's representing it .\nPhD A: No . You {disfmarker} you have to {disfmarker} what you have to do is you have to basically {disfmarker}\nGrad C: That 's the whole point .\nPhD A: Y yeah . You can use Perl to read it in and construct a internal representation that is essentially a lattice . But , the {disfmarker} and then {disfmarker}\nGrad C: OK .\nPhD D: Yeah .\nGrad C: Well , that was a different point .\nPhD A: Right .\nGrad C: Right ? So what I was saying is that {disfmarker}\nPhD A: But that 's what you 'll have to do . Bec - be\nGrad C: For Perl {disfmarker} if you want to just do Perl . If you wanted to use the structured XML query language , that 's a different thing . And it 's a set of tools {vocalsound} that let you specify given the D - DDT {disfmarker} DTD of the document , um , what sorts of structural searches you want to do . So you want to say that , you know , you 're looking for , um , a tag within a tag within a particular tag that has this particular text in it , um , and , uh , refers to a particular value . And so the point isn't that an end - user , who is looking for a query like you specified , wouldn't program it in this language . What you would do is , someone would build a tool that used that as a library . So that they {disfmarker} so that you wouldn't have to construct the internal representations yourself .\nPhD F: Is a {disfmarker} See , I think the kinds of questions , at least in the next {disfmarker} to the end of this year , are {disfmarker} there may be a lot of different ones , but they 'll all have a similar nature . They 'll be looking at either a word - level prosodic , uh , an {disfmarker} a value ,\nGrad C: Mm - hmm .\nPhD F: like a continuous value , like the slope of something . But you know , we 'll do something where we {disfmarker} some kind of data reduction where the prosodic features are sort o uh , either at the word - level or at the segment - level ,\nGrad C: Right .\nPhD F: or {disfmarker} or something like that . They 're not gonna be at the phone - level and they 're no not gonna be at the frame - level when we get done with sort of giving them simpler shapes and things . And so the main thing is just being able {disfmarker} Well , I guess , the two goals . Um , one that Chuck mentioned is starting out with something that we don't have to start over , that we don't have to throw away if other people want to extend it for other kinds of questions ,\nGrad C: Right .\nPhD F: and being able to at least get enough , uh , information out on {disfmarker} where we condition the location of features on information that 's in the kind of file that you {pause} put up there . And that would {disfmarker} that would do it ,\nGrad C: Yeah . I think that there are quick and dirty solutions ,\nPhD F: I mean , for me .\nGrad C: and then there are long - term , big - infrastructure solutions . And so {vocalsound} we want to try to pick something that lets us do a little bit of both .\nPhD F: In the between , right . And especially that the representation doesn't have to be thrown away ,\nGrad C: Um {disfmarker} Right .\nPhD F: even if your tools change .\nGrad C: And so it seems to me that {disfmarker} I mean , I have to look at it again to see whether it can really do what we want , but if we use the ATLAS external file representation , um , it seems like it 's rich enough that you could do quick tools just as I said in Perl , and then later on if we choose to go up the learning curve , we can use the whole ATLAS inter infrastructure ,\nPhD F: Yeah . I mean , that sounds good to me .\nGrad C: which has all that built in .\nPhD F: I {disfmarker} I don't {disfmarker} So if {disfmarker} if you would l look at that and let us know what you think .\nGrad C: Sure .\nPhD F: I mean , I think we 're sort of guinea pigs , cuz I {disfmarker} I want to get the prosody work done but I don't want to waste time , you know , getting the {disfmarker}\nPhD A: Oh , maybe {disfmarker}\nPhD F: Yeah ?\nPhD A: um {disfmarker}\nGrad C: Well , I wouldn't wait for the formats , because anything you pick we 'll be able to translate to another form .\nPhD A: Well {disfmarker} Ma well , maybe you should actually look at it yourself too to get a sense of what it is you 'll {disfmarker} you 'll be dealing with ,\nPhD F: OK .\nPhD A: because , um , you know , Adam might have one opinion but you might have another , so\nGrad B: Yeah .\nPhD F: Yeah , definitely .\nPhD A: I think the more eyes look at this the better .\nPhD F: Especially if there 's , e um {disfmarker} you know , if someone can help with at least the {disfmarker} the setup of the right {disfmarker}\nGrad C: Hi , Jane .\nPhD F: Oh , hi .\nPhD A: Mmm .\nPhD F: the right representation , then , i you know , I hope it won't {disfmarker} We don't actually need the whole full - blown thing to be ready ,\nGrad C: Can you {disfmarker} Oh , well .\nPhD F: so . Um , so maybe if you guys can look at it and sort of see what ,\nGrad B: Yeah .\nGrad C: Sure .\nPhD F: um {disfmarker} I think we 're {disfmarker} we 're {disfmarker} {vocalsound} we 're actually just {disfmarker}\nGrad C: We 're about done .\nPhD F: yeah ,\nGrad B: Hmm .\nPhD F: wrapping up , but , um {disfmarker} Yeah , sorry , it 's a uh short meeting , but , um {disfmarker} Well , I don't know . Is there anything else , like {disfmarker} I mean that helps me a lot ,\nGrad C: Well , I think the other thing we might want to look at is alternatives to P - file .\nPhD F: but {disfmarker}\nGrad C: I mean , th the reason I like P - file is I 'm already familiar with it , we have expertise here , and so if we pick something else , there 's the learning - curve problem . But , I mean , it is just something we developed at ICSI .\nPhD A: Is there an {disfmarker} is there an IP - API ?\nGrad C: And so {disfmarker} Yeah .\nPhD A: OK .\nGrad C: There 's an API for it . And , uh ,\nPhD A: There used to be a problem that they get too large ,\nGrad C: a bunch of libraries , P - file utilities .\nPhD A: and so {pause} basically the {disfmarker} uh the filesystem wouldn't {disfmarker}\nGrad C: Well , that 's gonna be a problem no matter what . You have the two - gigabyte limit on the filesystem size . And we definitely hit that with Broadcast News .\nPhD A: Maybe you could extend the API to , uh , support , uh , like splitting up , you know , conceptually one file into smaller files on disk so that you can essentially , you know , have arbitrarily long f\nGrad C: Yep . Most of the tools can handle that .\nPhD A: Yeah .\nGrad C: So that we didn't do it at the API - level . We did it at the t tool - level . That {disfmarker} that {disfmarker} most {disfmarker} many of them can s you can specify several P - files and they 'll just be done sequentially .\nPhD A: OK .\nGrad C: So .\nPhD F: So , I guess , yeah , if {disfmarker} if you and Don can {disfmarker} if you can show him the P - file stuff and see .\nGrad C: Sure .\nPhD F: So this would be like for the F - zero {disfmarker}\nGrad B: True .\nGrad C: I mean , if you do \" man P - file \" or \" apropos P - file \" , you 'll see a lot .\nGrad B: I 've used the P - file , I think . I 've looked at it at least , briefly , I think when we were doing s something .\nPhD A: What does the P stand for anyway ?\nGrad C: I have no idea .\nGrad B: Oh , in there .\nGrad C: I didn't de I didn't develop it . You know , it was {disfmarker} I think it was Dave Johnson . So it 's all part of the Quicknet library . It has all the utilities for it .\nPhD A: No , P - files were around way before Quicknet . P - files were {disfmarker} were around when {disfmarker} w with , um , {vocalsound} RAP .\nGrad C: Oh , were they ?\nPhD D: Mm - hmm .\nPhD A: Right ?\nPhD F: It 's like the history of ICSI .\nPhD A: You worked with P - files .\nGrad C: Mm - hmm .\nPhD F: Like {disfmarker}\nPhD D: No .\nPhD A: I worked with P - files .\nPhD F: Yeah ?\nPhD D: I don't remember what the \" P \" is , though .\nPhD A: No .\nGrad C: But there are ni they 're {disfmarker} The {pause} Quicknet library has a bunch of things in it to handle P - files ,\nPhD A: Yeah .\nGrad C: so it works pretty well .\nPhD A: \nPhD F: And that isn't really , I guess , as important as the {disfmarker} the main {disfmarker} I don't know what you call it , the {disfmarker} the main sort of word - level {disfmarker}\nGrad C: Neither do I .\nPhD D: Probably stands for \" Phil \" . Phil Kohn .\nGrad C: It 's a Phil file ?\nPhD D: Yeah . That 's my guess .\nPhD F: Huh . OK . Well , that 's really useful . I mean , this is exactly the kind of thing that I wanted to settle . Um , so {disfmarker}\nGrad C: Yeah , I 've been meaning to look at the ATLAS stuff again anyway .\nPhD F: Great .\nGrad C: So , just keep {disfmarker}\nPhD F: Yeah . I guess it 's also sort of a political deci I mean , if {disfmarker} if you feel like that 's a community that would be good to tie into anyway , then it 's {disfmarker} sounds like it 's worth doing .\nGrad C: Yeah , I think it {disfmarker} it w\nPhD A: j I think there 's {disfmarker}\nGrad C: And , w uh , as I said , I {disfmarker} what I did with this stuff {disfmarker} I based it on theirs . It 's just they hadn't actually come up with an external format yet . So now that they have come up with a format , it doesn't {disfmarker} it seems pretty reasonable to use it .\nPhD A: Mmm .\nGrad C: But let me look at it again .\nPhD F: OK , great .\nGrad C: As I said , that {disfmarker}\nPhD F: Cuz we actually can start {disfmarker}\nGrad C: There 's one level {disfmarker} there 's one more level of indirection and I 'm just blanking on exactly how it works . I gotta look at it again .\nPhD F: I mean , we can start with , um , I guess , this input from Dave 's , which you had printed out , the channelized input . Cuz he has all of the channels , you know , with the channels in the tag and stuff like that .\nGrad C: Yeah , I 've seen it .\nPhD F: So that would be i directly ,\nGrad C: Yep . Easy {disfmarker} easy to map .\nPhD F: um {disfmarker} Yeah . And so then it would just be a matter of getting {disfmarker} making sure to handle the annotations that are , you know , not at the word - level and , um , t to import the\nGrad B: Where are those annotations coming from ?\nPhD F: Well , right now , I g Jane would {disfmarker} {vocalsound} would {disfmarker}\nGrad C: Mm - hmm .\nPhD F: Yeah .\nPostdoc E: Are you talking about the overlap a annotations ?\nPhD F: Yeah , any kind of annotation {pause} that , like , isn't already there . Uh , you know , anything you can envision .\nPostdoc E: Yeah . So what I was imagining was {disfmarker} um , so Dave says we can have unlimited numbers of green ribbons . And so put , uh , a {disfmarker} a green ribbon on for an overlap code . And since we w we {disfmarker} I {disfmarker} I think it 's important to remain flexible regarding the time bins for now . And so it 's nice to have {disfmarker} However , you know , you want to have it , uh , time time uh , located in the discourse . So , um , if we {disfmarker} if we tie the overlap code to the first word in the overlap , then you 'll have a time - marking . It won't {disfmarker} it 'll be independent of the time bins , however these e evolve , shrink , or whatever , increase , or {disfmarker} Also , you could have different time bins for different purposes . And having it tied to the first word in an overlap segment is unique , uh , you know , anchored , clear . And it would just end up on a separate ribbon .\nGrad C: Right .\nPostdoc E: So the overlap coding is gonna be easy with respect to that . You look puzzled .\nPhD D: I {disfmarker} I just {disfmarker} I don't quite understand what these things are .\nPostdoc E: OK .\nPhD D: Uh .\nPostdoc E: What , the codes themselves ?\nPhD D: Well , th overlap codes .\nPostdoc E: Or the {disfmarker} ?\nPhD D: I 'm not sure what that @ @ {disfmarker}\nGrad C: Well , I mean , is that {disfmarker}\nPhD D: It probably doesn't matter .\nPostdoc E: Well , we don't have to go into the codes .\nGrad C: I mean , it doesn't .\nPhD D: No , I d\nPostdoc E: We don't have to go into the codes .\nGrad C: I mean , that {disfmarker} not for the topic of this meeting .\nPostdoc E: But let me just {disfmarker} No . W the idea is just to have a separate green ribbon , you know , and {disfmarker} and {disfmarker} and let 's say that this is a time bin . There 's a word here . This is the first word of an overlapping segment of any length , overlapping with any other , uh , word {disfmarker} uh , i segment of any length . And , um , then you can indicate that this here was perhaps a ch a backchannel , or you can say that it was , um , a usurping of the turn , or you can {disfmarker} you know , any {disfmarker} any number of categories . But the fact is , you have it time - tagged in a way that 's independent of the , uh , sp particular time bin that the word ends up in . If it 's a large unit or a small unit , or\nPhD A: Mm - hmm .\nPostdoc E: we sh change the boundaries of the units , it 's still unique and {disfmarker} and , uh , fits with the format ,\nPhD F: Right .\nPostdoc E: flexible , all that .\nPhD A: Um , it would be nice {disfmarker} um , eh , gr this is sort of r regarding {disfmarker} uh , uh it 's related but not directly germane to the topic of discussion , but , when it comes to annotations , um , you often find yourself in the situation where you have {pause} different annotations {pause} of the same , say , word sequence . OK ?\nPostdoc E: Yeah .\nPhD A: And sometimes the word sequences even differ slightly because they were edited s at one place but not the other .\nPostdoc E: Yeah .\nPhD A: So , once this data gets out there , some people might start annotating this for , I don't know , dialogue acts or , um , you know , topics or what the heck . You know , there 's a zillion things that people might annotate this for . And the only thing that is really sort of common among all the versi the various versions of this data is the word sequence , or approximately .\nPostdoc E: Yep .\nPhD F: Or the time .\nPhD A: Or the times . But , see , if you 'd annotate dialogue acts , you don't necessarily want to {disfmarker} or topics {disfmarker} you don't really want to be dealing with time - marks .\nPhD F: I guess .\nPhD A: You 'd {disfmarker} it 's much more efficient for them to just see the word sequence , right ?\nPhD F: Mm - hmm .\nPhD A: I mean , most people aren't as sophisticated as {disfmarker} as we are here with , you know , uh , time alignments and stuff . So {disfmarker} So the {disfmarker} the {disfmarker} the point is {disfmarker}\nGrad C: Should {disfmarker} should we mention some names on the people who are n ?\nPhD A: Right . So , um , the p my point is that {pause} you 're gonna end up with , uh , word sequences that are differently annotated . And {pause} you want some tool , uh , that is able to sort of merge these different annotations back into a single , uh , version . OK ? Um , and we had this problem very massively , uh , at SRI when we worked , uh , a while back on , {vocalsound} uh {disfmarker} well , on dialogue acts as well as , uh , you know , um , what was it ? uh ,\nPhD F: Well , all the Switchboard in it .\nPhD A: utterance types . There 's , uh , automatic , uh , punctuation and stuff like that .\nPhD F: Yeah .\nPhD A: Because we had one set of {pause} annotations that were based on , uh , one version of the transcripts with a particular segmentation , and then we had another version that was based on , uh , a different s slightly edited version of the transcripts with a different segmentation . So , {vocalsound} we had these two different versions which were {disfmarker} you know , you could tell they were from the same source but they weren't identical . So it was extremely hard {vocalsound} to reliably merge these two back together to correlate the information from the different annotations .\nGrad C: Yep . I {disfmarker} I don't see any way that file formats are gonna help us with that .\nPhD A: No .\nGrad C: It 's {disfmarker} it 's all a question of semantic .\nPhD A: No . But once you have a file format , I can imagine writing {disfmarker} not personally , but someone writing a tool that is essentially an alignment tool , um , that mediates between various versions ,\nPhD F: Mm - hmm .\nGrad C: Yeah .\nPhD A: and {disfmarker} uh , sort of like th uh , you know , you have this thing in UNIX where you have , uh , diff .\nGrad C: Diff .\nPhD F: W - diff or diff .\nPhD A: There 's the , uh , diff that actually tries to reconcile different {disfmarker} two diffs f {comment} based on the same original .\nPhD F: Yeah .\nPostdoc E: Is it S - diff ?\nGrad C: Yep .\nPostdoc E: Mmm .\nPhD A: Something like that , um , but operating on these lattices that are really what 's behind this {disfmarker} uh , this annotation format .\nGrad C: Yep .\nPhD A: So {disfmarker}\nGrad C: There 's actually a diff library you can use {pause} to do things like that that {disfmarker} so you have different formats .\nPhD F: You could definitely do that with the {disfmarker}\nPhD A: So somewhere in the API you would like to have like a merge or some {disfmarker} some function that merges two {disfmarker} two versions .\nGrad C: Yeah , I think it 's gonna be very hard . Any sort of structured anything when you try to merge is really , really hard\nPhD A: Right .\nGrad C: because you ha i The hard part isn't the file format . The hard part is specifying what you mean by \" merge \" .\nPhD A: Is {disfmarker} Exactly .\nGrad C: And that 's very difficult .\nPhD F: But the one thing that would work here actually for i that is more reliable than the utterances is the {disfmarker} the speaker ons and offs . So if you have a good ,\nGrad C: But this is exactly what I mean , is that {disfmarker} that the problem i\nPhD F: um {disfmarker} Yeah . You just have to know wha what to tie it to .\nGrad C: Yeah , exactly . The problem is saying \" what are the semantics ,\nPhD F: And {disfmarker}\nGrad C: what do you mean by \" merge \" ? \"\nPhD F: Right , right .\nPhD A: Right . So {disfmarker} so just to let you know what we {disfmarker} where we kluged it by , uh , doing {disfmarker} uh , by doing {disfmarker} Hhh .\nGrad C: So .\nPhD A: Both were based on words , so , bo we have two versions of the same words intersp you know , sprinkled with {disfmarker} with different tags for annotations .\nGrad C: And then you did diff .\nPhD A: And we did diff . Exactly !\nGrad C: Yeah , that 's just what I thought .\nPhD A: And that 's how {disfmarker}\nGrad C: That 's just wh how I would have done it .\nPhD A: Yeah . But , you know , it had lots of errors and things would end up in the wrong order , and so forth . Uh , so , um , if you had a more {disfmarker}\nGrad C: Yep .\nPhD A: Uh , it {disfmarker} it was a kluge because it was basically reducing everything to {disfmarker} uh , to {disfmarker} uh , uh , to textual alignment .\nGrad C: A textual {disfmarker}\nPhD A: Um , so {disfmarker}\nPhD F: But , d isn't that something where whoever {disfmarker} if {vocalsound} {disfmarker} if the people who are making changes , say in the transcripts , cuz this all happened when the transcripts were different {disfmarker} ye um , if they tie it to something , like if they tied it to the acoustic segment {disfmarker} if they {disfmarker} You know what I mean ? Then {disfmarker} Or if they tied it to an acoustic segment and we had the time - marks , that would help .\nGrad C: Yep .\nPhD F: But the problem is exactly as Adam said , that you get , you know , y you don't have that information or it 's lost in the merge somehow ,\nPostdoc E: Well , can I ask one question ?\nPhD F: so {disfmarker}\nPostdoc E: It {disfmarker} it seems to me that , um , we will have o an official version of the corpus , which will be only one {disfmarker} one version in terms of the words {disfmarker} where the words are concerned . We 'd still have the {disfmarker} the merging issue maybe if coding were done independently of the {disfmarker}\nPhD A: And you 're gonna get that\nPostdoc E: But {disfmarker} but {disfmarker}\nPhD A: because if the data gets out , people will do all kinds of things to it . And , uh , s you know , several years from now you might want to look into , um , the prosody of referring expressions . And someone at the university of who knows where has annotated the referring expressions . So you want to get that annotation and bring it back in line with your data .\nGrad C: Right .\nPhD A: OK ?\nGrad C: But unfortunately they 've also hand - edited it .\nPostdoc E: OK , then {disfmarker}\nPhD F: But they 've also {disfmarker} Exactly . And so that 's exactly what we should {disfmarker} somehow when you distribute the data , say that {disfmarker} you know , that {disfmarker} have some way of knowing how to merge it back in and asking people to try to do that .\nPhD A: Yeah .\nGrad C: Yep .\nPhD A: Right .\nPostdoc E: Well , then the {disfmarker}\nPhD D: What 's {disfmarker} what 's wrong with {pause} doing times ? I {disfmarker}\nPostdoc E: I agree . That was what I was wondering .\nPhD F: Uh , yeah , time is the {disfmarker}\nGrad C: Well ,\nPostdoc E: Time is unique . You were saying that you didn't think we should {disfmarker}\nPhD F: Time is passing !\nPhD A: Time {disfmarker} time {disfmarker} times are ephemeral .\nPostdoc E: Andreas was saying {disfmarker} Yeah .\nGrad C: what if they haven't notated with them , times ?\nPhD F: Yeah . He {disfmarker} he 's a language modeling person , though .\nPhD A: Um {disfmarker}\nGrad C: So {disfmarker} so imagine {disfmarker} I think his {disfmarker} his example is a good one . Imagine that this person who developed the corpus of the referring expressions didn't include time .\nPhD A: Mm - hmm . Yeah .\nGrad C: He included references to words .\nPostdoc E: Ach !\nPhD A: Yeah .\nGrad C: He said that at this word is when {disfmarker} when it happened .\nPostdoc E: Well , then {disfmarker}\nPhD A: Or she .\nGrad C: Or she .\nPostdoc E: But then couldn't you just indirectly figure out the time {pause} tied to the word ?\nPhD F: But still they {disfmarker} Exactly .\nGrad C: Sure . But what if {disfmarker} what if they change the words ?\nPhD F: Yeah .\nPostdoc E: Not {disfmarker} Well , but you 'd have some anchoring point . He couldn't have changed all the words .\nPhD D: But can they change the words without changing the time of the word ?\nGrad C: Sure . But they could have changed it a little . The {disfmarker} the point is , that {disfmarker} that they may have annotated it off a word transcript that isn't the same as our word transcript , so how do you merge it back in ? I understand what you 're saying .\nPhD A: Mmm . Mm - hmm .\nGrad C: And I {disfmarker} I guess the answer is , um , it 's gonna be different every time . It 's j it 's just gonna be {disfmarker}\nPostdoc E: Yeah .\nPhD F: Yeah .\nGrad C: I it 's exactly what I said before ,\nPhD F: You only know the boundaries of the {disfmarker}\nGrad C: which is that \" what do you mean by \" merge \" ? \" So in this case where you have the words and you don't have the times , well , what do you mean by \" merge \" ? If you tell me what you mean , I can write a program to do it .\nPhD F: Right . Right . You can merge at the level of the representation that the other person preserved and that 's it .\nGrad C: Right . And that 's about all you can do .\nPhD F: And beyond that , all you know is {disfmarker} is relative ordering and sometimes even that is wrong .\nGrad C: So {disfmarker} so in {disfmarker} so in this one you would have to do a best match between the word sequences ,\nPhD F: So .\nPhD A: Mm - hmm .\nGrad C: extract the times f from the best match of theirs to yours , and use that .\nPhD F: And then infer that their time - marks are somewhere in between .\nGrad C: Right .\nPhD F: Yeah , exactly .\nPostdoc E: But it could be that they just {disfmarker} uh , I mean , it could be that they chunked {disfmarker} they {disfmarker} they lost certain utterances and all that stuff ,\nGrad C: Right , exactly . So it could get very , very ugly .\nPostdoc E: or {disfmarker}\nPhD F: Definitely .\nPostdoc E: Yeah .\nPhD F: Definitely . Alright .\nPostdoc E: That 's interesting .\nPhD F: Well , I guess , w I {disfmarker} I didn't want to keep people too long and Adam wanted t people {disfmarker} I 'll read the digits . If anyone else offers to , that 'd be great . And\nPhD A: Ah , well .\nGrad C: Yeah .\nPhD F: if not , I guess {disfmarker}\nPhD A: For th for the {disfmarker} {nonvocalsound} for the benefit of science we 'll read the digits .\nGrad C: More digits , the better . OK , this is\nPhD F: Thanks {disfmarker} thanks a lot . It 's really helpful . I mean , Adam and Don {nonvocalsound} will sort of meet and I think that 's great . Very useful . Go next .\nPhD D: Scratch that .\nPostdoc E: O three\nGrad C: Oh , right .", "source": "meeting_summ", "evaluation": "rouge"}
{"instructions": ["Summarize the discussion of group warming and the introduction to the new remote control project.", "What did Project Manager recommend to do after introducing the design steps and why?", "Summarize the discussion of specific designing requirements of the new remote control.", "What did Project Manager\u2019s think of the water-proof design when discussing the designing requirements of the new remote control?", "What did the conferees think of the solution to water-proof and shock-proof technical demands when discussing the designing requirements of the new remote control?", "What did Industrial Designer and Project Manager think of the remote tracking method when discussing the designing requirements of the new remote control?", "Summarize the whole meeting."], "outputs": ["Mutual greeting heralded the beginning of the meeting and the goal of the new remote control project was introduced by Project Manager to the conferees as to win over competitive products by being original, trendy and user-friendly. Then Project Manager continued with the introduction of the design process, which was divided into three main parts\u2014functional design, conceptual design and desired design that respectively focused on the user-related technical functions, desirable user interface and different trends involved, and specific implementation and choice-detailing process of conceptual design.", "Project Manager recommended a drawing activity of conferees\u2019 favourite animals with the aim of inspiring and contributing to the design process of the remote control.", "Given the customer demand and conferees personal experiences, several designing requirements were proposed during the discussion. The remote control was decided to be adaptable to multiple devices with few buttons, be able to be lighted in the dark and held in hand, and be both water-proof and shock-proof along with a whistle tracking system, based on which advantage over competitors might well be gained at the price of a rising production cost.", "Considering the product originality, Project Manager believed that a water-proof remote control could be used in the bath conveniently while saving the customer\u2019s need to purchase an extra plastic cover. Therefore, originality and competitiveness might be gained over competitive products.", "Conferees agreed that the remote control could be sold with optional plastic protection and water-proof box for customers to choose.", "Industrial Designer first recommended adding a special beeping button on the TV set to remind users of where the remote controls were, but the plan was deemed impractical concerning TV sets that were not designed by them. Then Project Manager suggested whistle tracking and was approved by all the conferees as an original improvement.", "This meeting was primarily concerned with the design process and specific designing requirements of the remote control. Project Manager first introduced the goal of the new remote control project as to be original, trendy and user-friendly so as to bear an advantage over competitive products. Then three steps of the design process were respectively introduced and explained by Project Manager, and drawings of favourite animals then followed as an imagination-inspiring activity. According to Project Manager, the fifty-million-Euro financial objective of the project would be achieved at a production cost lower than 12.5 Euros and a twofold selling price. Competitiveness-endowing requirements for remote control design were then proposed and carefully discussed."], "input": "User Interface: {gap}\nProject Manager: {vocalsound}\nUser Interface: {vocalsound} How do you wear this thing ?\nProject Manager: Hmm . Mm mm mm . {vocalsound}\nUser Interface: Not too many cables and stuff .\nMarketing: {gap}\nUser Interface: {vocalsound} {vocalsound}\nProject Manager: {vocalsound}\nUser Interface: {vocalsound} Original . {vocalsound}\nProject Manager: {vocalsound} Is recorded ? Okay ? Okay so welcome everyone . So we are here for the kickoff meeting of uh the process of designing a new remote control . So I will first start with a warm welcome opening {vocalsound} stuff ,\nUser Interface: {vocalsound}\nProject Manager: then uh we will uh see what will be uh our product and what will be the different step we will have to design it . And uh then we will uh discuss if we have few ideas and we will uh end uh by uh dispatching the different task you will be {disfmarker} you will have to fulfil to complete this process . So {disfmarker}\nUser Interface: Uh . Just one thing . Uh , you said twenty-five minutes , but I have something else to do uh , so gotta have another meeting uh soon ,\nProject Manager: {vocalsound}\nUser Interface: so maybe you could hurry up a bit {disfmarker}\nProject Manager: {vocalsound} sorry ?\nUser Interface: It's true . I have another meeting so if you could uh {disfmarker}\nProject Manager: You have another meeting soon ?\nUser Interface: Yeah .\nProject Manager: So you have to be quick .\nIndustrial Designer: {vocalsound}\nUser Interface: Yeah , for the lawnmower project .\nProject Manager: Okay .\nUser Interface: Okay .\nProject Manager: So the the goal is to have a remote control so to have an advantage over our competitors we have to be original , we have to be trendy and we have to also try to be user-friendly .\nUser Interface: {vocalsound}\nProject Manager: So uh the design step will be divided in three uh main points . First it will be the functional design . Third is the conceptual design and then is the desired design . So the functional design is to identify the main user needs , the technical function the remote control should fulfil . And then we will move to f conceptual design where we'll specify the different component involved , what kind of user interf interface we want and what are the different uh trend in user interface and stuff like that .\nIndustrial Designer: {vocalsound}\nProject Manager: And then the desired devi design will consist in uh specifically implementing {vocalsound} and detailing the choice we've uh made in the second point . So I will now ask you which is very important for the design of a new remote control for to uh each of us to to draw uh your favourite animal on the white board .\nUser Interface: {vocalsound} What an original idea .\nProject Manager: {vocalsound} Do you have any idea of which animal you want to show us ? {vocalsound}\nUser Interface: Orangutan .\nProject Manager: Okay {vocalsound} that's good .\nIndustrial Designer: {vocalsound}\nUser Interface: {vocalsound}\nIndustrial Designer: No no n\nProject Manager: {vocalsound} n n {gap}\nUser Interface: Can I give you the\nProject Manager: You should {disfmarker}\nUser Interface: {disfmarker} no ? But I don't have to say anything . When I'm drawing the orangutan .\nProject Manager: {vocalsound} {vocalsound} If you want to react uh about this wonderful drawing uh {vocalsound} I'll let you uh comment .\nUser Interface: {vocalsound} {vocalsound}\nIndustrial Designer: {vocalsound}\nMarketing: {vocalsound}\nUser Interface: It's an abstract drawing of an orangutan .\nProject Manager: Okay it's an abstract drawing .\nUser Interface: Yes .\nProject Manager: I think it's nice and original . {vocalsound}\nIndustrial Designer: {vocalsound} You should write y the name I think . {vocalsound}\nMarketing: {vocalsound}\nUser Interface: I don't have a red colour . Usually orangutans have red hair so this is a very important but I don't have red pen , so {disfmarker}\nProject Manager: Okay .\nUser Interface: {vocalsound} Yes .\nProject Manager: You want to draw something Christine ? {vocalsound}\nMarketing: {vocalsound} {vocalsound}\nUser Interface: {vocalsound}\nMarketing: Okay uh sorry . You have to imagine a little bit {vocalsound} um .\nProject Manager: {vocalsound}\nMarketing: This {disfmarker}\nProject Manager: Of course your animal is recorded so it's not lost . {vocalsound}\nMarketing: {vocalsound} Sorry too {vocalsound} uh .\nUser Interface: Yes . I know .\nProject Manager: {vocalsound}\nMarketing: {vocalsound}\nUser Interface: {vocalsound}\nIndustrial Designer: {vocalsound}\nMarketing: {vocalsound}\nUser Interface: {vocalsound}\nProject Manager: Is this uh {disfmarker}\nUser Interface: Wha what is this strange beast ?\nMarketing: Is it beautiful ? {vocalsound}\nProject Manager: {vocalsound}\nIndustrial Designer: {vocalsound}\nUser Interface: Is it a monster ?\nProject Manager: {vocalsound}\nMarketing: Do you know ? It's a cat .\nUser Interface: It's a cat ?\nIndustrial Designer: {vocalsound}\nMarketing: {vocalsound} Isn't it ? {vocalsound}\nUser Interface: I thought these things did not exist .\nProject Manager: {vocalsound}\nMarketing: {vocalsound} Yes yes\nIndustrial Designer: Me {vocalsound}\nMarketing: is it {disfmarker} like that .\nUser Interface: Ah yeah {vocalsound}\nIndustrial Designer: Ah yeah . Yeah .\nMarketing: Is it better ?\nProject Manager: Ah okay it's pretty . {vocalsound}\nMarketing: {vocalsound} Okay .\nProject Manager: {vocalsound} Okay it's your cat . {vocalsound}\nMarketing: {vocalsound} It's my cat .\nUser Interface: Does have a name ?\nMarketing: {vocalsound} Yeah . {vocalsound}\nIndustrial Designer: {vocalsound}\nMarketing: The name is Caramel .\nUser Interface: Caramel . Ah-ha .\nIndustrial Designer: Caramel .\nMarketing: Yeah . {vocalsound}\nProject Manager: Okay . Olivier , do you want to {vocalsound}\nIndustrial Designer: {vocalsound} And you {vocalsound} {vocalsound} I think I'm too short for the cables . {vocalsound}\nMarketing: {vocalsound}\nProject Manager: {vocalsound} Okay I go , but next time you'll do something I'm sure . {vocalsound} {vocalsound} I'm a bit short on cable .\nUser Interface: Next time I concentrate .\nIndustrial Designer: {vocalsound}\nProject Manager: Okay . So what could I draw ? {vocalsound} Maybe I can draw like a very simplified cow . {vocalsound} I don't know if it looks like a cow {vocalsound}\nUser Interface: He looks like a bong .\nMarketing: {vocalsound}\nIndustrial Designer: {vocalsound}\nProject Manager: Like a what ? {vocalsound}\nUser Interface: Okay . Sorry . No .\nIndustrial Designer: Quite squarey .\nUser Interface: Scary ?\nProject Manager: {gap} {vocalsound}\nIndustrial Designer: He also . {vocalsound}\nMarketing: {vocalsound}\nProject Manager: I dunno it it looks more like a donkey in fact {vocalsound} I would say .\nUser Interface: {vocalsound}\nMarketing: {vocalsound}\nUser Interface: {vocalsound} I I think we will be finished this uh {disfmarker}\nIndustrial Designer: Mm .\nProject Manager: Okay so I hope that it helps you uh in the process of designing a remote control .\nUser Interface: Is it for uh for putting a {disfmarker} for logos , no .\nProject Manager: {vocalsound} Okay .\nUser Interface: {vocalsound} That's {disfmarker}\nProject Manager: Let's move on . So {disfmarker} Here the uh financial objective of our project . That is to say to to have a production cost lower than twelve point five Euros and have a selling price of twice that price t in order to target a profe profit of uh fifty uh million Euros .\nUser Interface: I is there a matter for a new remote control ?\nProject Manager: {vocalsound} Yeah if it's trendy , original I d fulfil the user needs .\nUser Interface: Is it uh a single device remote control or is it a multi-device remote control ?\nProject Manager: We have to discuss that point .\nUser Interface: Ah\nProject Manager: On {disfmarker}\nUser Interface: this is not defined at all ?\nProject Manager: yeah you you can suggest points like this . So what what {disfmarker}\nUser Interface: Ah , okay .\nProject Manager: so we have to decide for example if it can control one device or multiple . So what's {disfmarker} what are your ideas about that ?\nUser Interface: {vocalsound}\nProject Manager: Maybe I can have the {disfmarker} your opinion from the marketing side ?\nUser Interface: Well uh do we sell other stuff ? Uh if if we bundle the remote control with something uh to sell then it could be a single device , otherwise it could be programmable one otherwise who would buy a remote control from us .\nProject Manager: Okay , so if it selled uh by its own i it it would rather be for multiple device .\nUser Interface: Yeah .\nProject Manager: {vocalsound} Do you agree ?\nIndustrial Designer: Mm-hmm .\nProject Manager: Yeah . So maybe it should be for multiple devices . And uh do you have any ideas um of uh design ideas or any uh uh technical requirement we we should uh fulfil ?\nIndustrial Designer: {vocalsound} I think we shouldn't have too many b for my part . I think {disfmarker}\nUser Interface: No , I couldn I cannot fi think of any requirements right now . {vocalsound}\nIndustrial Designer: If we don't have so many buttons could be nice .\nProject Manager: {vocalsound} Few buttons . Okay .\nUser Interface: {vocalsound}\nProject Manager: And do you have it also to be {disfmarker} to be lighted in order to be used in the dark ? Might be a good idea .\nIndustrial Designer: {vocalsound} Yeah .\nProject Manager: Okay . And do you have any um any uh idea of the trend {disfmarker} the trend in domain , what it shouldn't {disfmarker} it should look like , or things like that ?\nIndustrial Designer: {vocalsound} Something which is not squarey maybe uh , not a box .\nUser Interface: Mm .\nProject Manager: With rou okay . Like for {disfmarker} okay .\nUser Interface: Something like that , least fits in your hand .\nProject Manager: Okay .\nUser Interface: {vocalsound} Yeah .\nIndustrial Designer: Yeah .\nUser Interface: The basic requirement .\nProject Manager: So . Fit in your hand , yeah .\nUser Interface: {vocalsound} Only a buck .\nProject Manager: And also it have , i it may be {vocalsound} it may be important for the remote control to be uh {disfmarker} To , to resist to various shocks that can happen if it fall .\nUser Interface: {vocalsound}\nIndustrial Designer: Mm-hmm .\nUser Interface: Waterproof . {vocalsound}\nProject Manager: {vocalsound} Water-proof as well .\nIndustrial Designer: {vocalsound} And I think we should have a device {disfmarker}\nProject Manager: Maybe it is original because you can uh use it in your uh {disfmarker} in your bath whereas the others can't .\nUser Interface: {vocalsound}\nMarketing: {vocalsound}\nProject Manager: Maybe water-proof would be very original .\nIndustrial Designer: Sorry . {gap}\nMarketing: {vocalsound}\nProject Manager: Havin having a water-proof remote control so that the people can uh use it in their bath .\nUser Interface: Mm .\nProject Manager: That could be uh {disfmarker}\nUser Interface: B it seems uh so , but uh if you don't have an waterproof remote control it means you can just cover it with some plastic and you can sort of f\nProject Manager: Yeah but , it is still something uh you have to buy and that is um not maybe very {disfmarker}\nUser Interface: And , and that's one of the {disfmarker} that's one of the shock {disfmarker} I mean there are people that have a remote control and they are worried that it's going to break and they put some extra plastic around it .\nProject Manager: Yeah , mayb B\nUser Interface: That's people {gap} they actually do it themselves .\nProject Manager: But maybe we can bulk it with uh already this plastic thing and uh the waterproof uh stuff as well .\nIndustrial Designer: Yeah . {gap} directly .\nUser Interface: I it will look a bulky in that case .\nProject Manager: Yeah . Maybe we can sell uh all that together , so so plastic protection and uh and a waterproof box as well .\nIndustrial Designer: Yeah .\nProject Manager: That might be good uh track to follow .\nUser Interface: Like as an optional thing .\nProject Manager: Optional or selled with it ?\nIndustrial Designer: {vocalsound} And I I think we should have something , most of the time I I lose my remote control .\nProject Manager: Yeah .\nIndustrial Designer: We should have s uh special bu button on the T_V_ to make the remote control beeping .\nProject Manager: Maybe we can have uh {disfmarker} But we don't design the T_V_ .\nMarketing: {vocalsound}\nProject Manager: Maybe we can have uh something you whistle and uh the remote control uh beep .\nIndustrial Designer: Ah yeah .\nMarketing: {vocalsound}\nUser Interface: Barks .\nIndustrial Designer: Yeah . {vocalsound}\nProject Manager: Yeah , barks , yeah .\nIndustrial Designer: {vocalsound} Barks .\nProject Manager: So we can uh have a whistle uh remote control ?\nIndustrial Designer: Yeah . Yeah whistle .\nProject Manager: I don't know , whistle-able ? {vocalsound} Th\nIndustrial Designer: Whistle tracking . {vocalsound}\nProject Manager: {vocalsound} Whistle tracking yeah . Whistle tracking remote control . That's a good idea , that's very original and that's can uh improve .\nUser Interface: {vocalsound} That's that's quite cool , but uh of course we {disfmarker} you don't normally need uh any audio uh recording stuff on your remote control right ?\nProject Manager: Yeah d d uh .\nUser Interface: So i it's just going to add t to the cost .\nProject Manager: Yeah but s still we have to mm we have to {vocalsound} have an advantage over our competitors . I think this is a good advantage .\nUser Interface: {vocalsound} It's cool . I think I like the idea , but I'm not sure about the what you ,\nProject Manager: Yeah . We have to ask {disfmarker}\nUser Interface: who is giving {disfmarker} who's giving who's giving our budget . Who's {disfmarker}\nProject Manager: Yeah . We have to ask the quest of that's uh design to the uh Industrial um Designer .\nUser Interface: Yeah . Yeah .\nIndustrial Designer: Yeah . {vocalsound} yeah {vocalsound}\nProject Manager: {vocalsound} Which is you .\nUser Interface: 'Kay . {vocalsound}\nProject Manager: {vocalsound} Okay so try to find that for next meeting . {vocalsound}\nIndustrial Designer: Okay . {vocalsound}\nProject Manager: Okay . So next meeting is in thirty minutes or so uh . {vocalsound} Don't pani .\nIndustrial Designer: {vocalsound} Don't panic . {vocalsound}\nProject Manager: So so I will ask the Industrial Designer to find out more about this industrial design so any working {disfmarker} any working function we have discussed .\nIndustrial Designer: Mm-hmm .\nProject Manager: So then I will ask the User Interf Interface Designer to to think about the point we discussed like the number of buttons , the the fact that is lighted or not , things like that , and what would be convenient for the user .\nUser Interface: Mm-hmm .\nProject Manager: And also um {vocalsound} I will ask the Market Expert to uh try to find out what are the absolute requirements , what is absolutely needed in a remote control uh for the user . So . And then uh I will uh just ask you to think about that and uh look at your mail because you will receive uh some good advice soon . {vocalsound}\nUser Interface: Mm .\nProject Manager: So . Thank you I think that's all for this point .\nUser Interface: Good .\nIndustrial Designer: Mm-hmm .\nUser Interface: {vocalsound}\nMarketing: Thank you {vocalsound}\nUser Interface: Uh , so we come back in five minutes ? Half an hour .\nProject Manager: Anyway you will receive some messages . {vocalsound} Be careful . You eat it ? Does it move uh ? Okay , but I don't know if it uh is still correctly uh {disfmarker} We'll see .\nIndustrial Designer: Ah . {gap}", "source": "meeting_summ", "evaluation": "rouge"}
{"instructions": ["How did the group discussed about the possible environmental-friendly material?", "How did the group hold their views towards multi-functional and single-functional product?", "What was the most prioritized functional requirement of their remote control?", "What did they discussed about buttons as a function?", "What other functions that customers would be willing to pay more for?", "What other points did the product manager and the marketing specialist raise about functions of the product?", "Summarize the group's decision on colour and logo of the product.", "What did they finalize on the product?", "What did the group discussed about the portability of the remote control?", "What did the group discussed about the fluorescent button on the remote control?", "How did the fluorescent buttons related to the humanitarian design of the product?", "What was the idea of personalization and how was it not so feasible?", "Summarize the whole meeting."], "outputs": ["The industrial designer suggested that when taking environmental impact into consideration, the product could switch to a more environmental-friendly material. This type of material was made up of specific alloys of metals which have a shape memory, and it also allowed recycling. Hence, the product manager lifted out the point that the company could recycle the old remote controls from customers and take down the usable parts to make new remote controls. Even though the team liked the idea, the product manager also raised his concern towards the financial budget. In the end they agreed to discuss further about how they could achieve the idea by not exceeding the budget.", "The user interface designer suggested two options of making the remote control functional. One way was to make it multi-functional, so as to be used for several entertainment devices. Another way was to make it single-functional, which could be used specifically for the television. The entire group preferred the product to be single-functional. It is because making an original design was more obtainable, and it would be more profitable as it would be more simplistic. They had to make it compatible with different brands of devices to sell internationally.", "The marketing specialist did some research and the marking specialist stressed on the topic of appearance. To combine with the company\u2019s motto, the marketing specialist believed in providing the international market with fashionable remote controls. And the statistics also showed that eighty percent of users would spend more money when a remote control would look fancy. Hence customers would spend more money on a fancy-looking remote control.", "It was discovered by the marketing specialist that people liked to switch channels, thus they had to make a more durable button. The marketing specialist counted the times of usage of every button on the remote control, and wanted to make a user-friendly banner to include all the buttons in. When including the buttons, they took in consideration the relevance and disadvantaged people as well.", "The marketing specialist discovered that since a button would be too troublesome, a large percentage of the public would also like to pay for voice recognition on the remote controls. However, the project manager raised certain limitations of voice recognition function, and it also clashed with the intention of designing a simple product.", "The marketing specialist suggested a LCD screen could be installed. The industrial designer thought it would be good to link with the teletext function. Also, the marketing specialist raised points about the target age group. In their assumption, a teenager would not be willing to pay for an expensive remote control, whereas the elder age group would be more willing. The group reached a consensus on catering the product to the age group of early twenties.", "The project manager mentioned that they would love to incorporate the company`s logo and colour into the product design, but it did not necessarily need to be the same colour. Since there was not a plan about which specific colour and logo to use, the industrial designer initiated the colour yellow and it was adopted.", "Firstly, the team decided that the target functions of the remote control would just be for the television. Secondly, they removed functions that were previously discussed, such as teletext, LCD screen and voice recognition. Particularly for the teletext function, they were removing it because they were reaching out to an international crowd and some countries did have such things as teletext. They kept the alarm idea because it was not expensive to actualize.", "The group agreed on making it small, but the findability was a problem. The user interface designer suggested that since the remote control was only linked to one TV set, it could stick to somewhere. And in order to reduce the size, the user interface designer further suggested that the remote control could charge within the socket, so it could obtain electricity which was provided from the TV`s power source.", "The group liked the fluorescent idea. The user interface designer suggested that since fluorescent lights lost their brightness after a certain time, the group could make this function tactile. They decided to make this function into little arrows that could be felt. They further debated on whether to use a battery to provide power or to use a naturally fluorescent material.", "The group wanted the lighting up to be a faint glow, so that it would not cause a sudden explosion of light in a dim environment. At the same time, the glowing buttons would be made in the shape of numbers so that the vision-impaired people would be taken care of. Meanwhile, they wished the glow was in neon style so that they could implement the company's colour in it and make it trendy.", "The marketing specialist threw out the idea of making the remote control cover changeable and personalized. The marketing specialist further suggested that they could incorporate the TV theme elements such as Bart Simpson into the cover. However, it might raise a question about copyright issues so they decided to delay the discussion.", "The meeting mainly discussed the design of functions and the appearances. On function wise, the group had a little argument whether to make the product multi-functional or single functional. In the end they went with single-functional because it was more focused and affordable. They also removed some of the functions being discussed such as LCD screen, teletext and voice recognition, because they wanted to stick with a simplistic design. On design wise, the group finalized on the colour yellow as their product appearance and they chose illuminated buttons as one of their highlights. They also included some humanitarian factors into the design."], "input": "User Interface: {vocalsound}\nIndustrial Designer: Okay . {vocalsound} Yeah . That's okay . That's okay .\nMarketing: {vocalsound}\nIndustrial Designer: Okay .\nProject Manager: Am I starting now ? Anytime ? Oh sorry . 'Kay , um . Alright , welcome back fro to the second meeting . And um I hope you had a productive last thirty minutes .\nUser Interface: {vocalsound}\nProject Manager: Um , and um , I'll be taking minutes on this one , and um {disfmarker} Being hooked up to the PowerPoint for this meeting isn't very necessary for uh myself , because it'll be more about uh , what you guys are bringing to the meeting today . Um , so , the first presentation we'll be looking at is Poppy's presentation . And , um {disfmarker} So , sorry ? So , um , take it away Poppy .\nIndustrial Designer: Okay . Um , do I need to {disfmarker} {gap}\nProject Manager: It's , it's plugged in . So , um {disfmarker}\nIndustrial Designer: plugged in .\nUser Interface: F_ eight , w . Function F_ eight .\nIndustrial Designer: F_ okay . Function F_ eight . Sorry about this guys .\nProject Manager: No problem .\nUser Interface: {gap}\nIndustrial Designer: 'Kay . {gap} is on . Right . {gap} Okay . I will take this time just to apologise .\nUser Interface: {vocalsound}\nIndustrial Designer: I , I only , uh , received my emails later on . 'Cause I was too busy carried away doing my own thing ,\nMarketing: {vocalsound}\nIndustrial Designer: which is not obviously not a very good part of a team-working thing .\nUser Interface: {vocalsound}\nIndustrial Designer: But there we go .\nProject Manager: I'm sure it's fine .\nIndustrial Designer: Um , so I was looking at how we're going to go about the working design , and what we actually need to do , and what the remote control needs to do . And it needs to um allow a person to have a portable desi device , so they can control the television from wherever they are . They don't need to actually manually touch the television set . So , it gives them much more flexibility , and allows them to be where they want to be . Um , from {disfmarker} Uh , on a functional side of things , we found out that wh from our previous meeting , we decided that there're certain points that will make our product unique . Um , one is the visibility in the dark , which was um Genevieve's idea . So we need to think about how we could bring this in um technically . And we could use illuminated buttons , which we are all familiar with when we're using a mobile phone , or um something fam familiar . A automatically , um lights up at first touch . Or we could use fluorescent materials which would just um take in the light during the day , and then as soon as they go off they would glow in the dark . Um , also we could use um an alarm . So if we lost the um remote control , perhaps there could be a button on the television set itself , which you could press , and then an alarm from the handset would sound where it was , hopefully in the room . Maybe behind a cushion or somewhere .\nProject Manager: {vocalsound}\nUser Interface: {vocalsound}\nIndustrial Designer: Um , so that would work . Um , oop . Go back there . Um , another thing I think we d missed out on on the last meeting was the fact that we should consider the environmental impact of our design . Um , from previous researches I've carried out on other projects , um we've learnt about smart materials where um um specific alloys of metals have a shape memory .\nUser Interface: {vocalsound}\nMarketing: {vocalsound}\nIndustrial Designer: So they can be heated and um and cooled , and they change the shape of um the metal . So , for example , a screw that's holding something together could expand and it would force all the components apart . So um , the benefits of this for our product would be that when it came to the end of its product life , if it was heated , um everything would spring apart . So , all the um individual components could be easily separated , and then some could be reused , some could be recycled , and I think that would be very important for products now . Especially 'cause there's much uh responsibility for all the um companies who are coming up with like new designs . 'Cause all , we all know that our resources are being limited , and we have to be very environmentally conscious .\nProject Manager: Right , um , one question . This , um , self-destructible uh metal , it allows for recycling materials ?\nIndustrial Designer: Yeah .\nProject Manager: So that , um , someone could have this product for as long as they felt that they wanted it , and then once they contribute it , then that company can break down the part , the parts better ?\nIndustrial Designer: Um {disfmarker} And then {disfmarker} Yeah . Yeah they would , um you would make the , the product as you normally would , apart from the , the bits that hold it all together would be made out of this shape-memory alloy . And that's the part that would um allow all the other parts to be separated at the end . I mean , the user would return the p product to the company , 'cause it's the product's responsibility to get rid of what they've made . Um , and then the company could then just use , make use of this shape-memory alloys to split up the components ,\nProject Manager: Yeah .\nIndustrial Designer: and then either reuse some bits , and other bits which are obviously gonna wear out with time , or not usable , they might be like be able to put into scrap metal . Something like the case , if it's scratched or something , you would want to reuse it , but you might be able to melt it down and reuse it again somewhere else .\nProject Manager: Mm-hmm . Would we be the company that would break down these , or uh metals ? Or would we contribute to another group ?\nIndustrial Designer: You could {disfmarker} we could probably empl em employ a , a side company or something to do that for us . But it would be our responsibility to get that done and to dispose of the products that we made . For a certain percentage at least .\nProject Manager: Alright .\nIndustrial Designer: Not every , not a hundred percent of everything we produce ,\nProject Manager: Okay . This sounds like a really great idea .\nIndustrial Designer: but {disfmarker}\nProject Manager: One thing we have to consider is our uh one hundred percent um turnover goal that we have for our financial sector .\nIndustrial Designer: Yeah . Yeah .\nProject Manager: Um , so we'll have to investigate how much that will cost us , cost the company ,\nIndustrial Designer: Yeah .\nProject Manager: um 'cause it sounds very labour-intensive . You would have to hire a number of people , and it might be more expensive .\nIndustrial Designer: Well I {disfmarker} the fact of the shape-memory alloys is that they , they don't need to be manually de um deconstructed . Like , you don't have to individually um unscrew all the screws . Because of this , their properties are smart material .\nProject Manager: Mm-hmm .\nIndustrial Designer: All you need is just the heat , so they self-destruct themselves .\nProject Manager: Alright . We'll still have to investigate the financial implications .\nIndustrial Designer: So I suppose it does need like high contact , yeah , you know high uh quality machinery , and very specific machinery , but {disfmarker}\nProject Manager: Alright . I like the environmental approach . Um , we'll have to see if that can meet our financial goals as well .\nIndustrial Designer: Yeah . Okay . Um also there is um components . This'll be how it uh will actually work . But I haven't put this plan together yet .\nProject Manager: I'm sorry , could you {disfmarker}\nIndustrial Designer: There we go\nProject Manager: Those were um {disfmarker}\nIndustrial Designer: . Sorry , should I go back . This would actually show the circuit diagram . Although I haven't come up with the final circuit yet .\nProject Manager: Okay .\nIndustrial Designer: So I just {gap} put all those components in .\nProject Manager: So those are what , um , we'll c construct the remote . Those are all the {disfmarker}\nIndustrial Designer: Yeah . I it just shows what sort of energy source . It could be a battery , like rechargeable probably . Um , an' yeah , well how the infrared will actually be sent through the chip to be received by the chip on the television set itself .\nProject Manager: Alright . Great .\nIndustrial Designer: Okay ? So , now is it F_ eight again to escape ? Or escape ? There we go . Okay .\nProject Manager: Alright . Thank you very much . And , um , the next presenter will be Tara .\nIndustrial Designer: Thank you .\nUser Interface: {vocalsound}\nIndustrial Designer: There you go Tara .\nUser Interface: Thanks . Can you see ?\nMarketing: Oh , {vocalsound}\nUser Interface: Do you think {disfmarker} Is it uh , function eight yeah ?\nProject Manager: Yeah .\nIndustrial Designer: Function F_ eight .\nMarketing: {vocalsound} Function F_ eight .\nProject Manager: Function F_ eight . Sorry .\nIndustrial Designer: The one at the top .\nUser Interface: Oh right . Okay .\nMarketing: That looks right .\nProject Manager: Yeah .\nUser Interface: Okay . I'm the User {vocalsound} um User Interface Designer . Uh , the technical functions design of the apparatus is the effect the apparatus should have . Um , in this case it's the function of the remote control , which is to send messages to the television , television set . By taking inspiration from other similar designs , we'll try and come up with an original trendy remote control , which is sellable international . There're two functional design options . A multifunctional remote control , which can be used for several entertainment devices . And a single function remote control , used specifically for the television . {vocalsound}\nMarketing: I'm sorry , what was that last one . Multifunctional and {disfmarker}\nUser Interface: Sorry . Um , a single function just for the television itself .\nMarketing: Ch Oh , I see .\nUser Interface: Yeah . Um , multifunctional controls can be difficult to use , as the multitude of buttons can be confusing . A single function remote control is simpler to use , but it means you have to have other remote controls for your other entertainment devices .\nMarketing: 'Kay .\nUser Interface: Um , I think that a single function remote control would be preferable , because it's easier to use . It'd be more compatible with a range of television sets , making it more internationally sellable . Um , it will make an original design more obtainable , as we have less functional necessities to include in the design . And it would be more profitable as it would be more simplistic . And less functions would have to be included . So it would be cheaper to make . And probably more sellable just because it's more compatible with a r a wider range of devices . Does anyone have any questions ? {vocalsound}\nMarketing: {vocalsound} So as far as we know , um , a single function television remote control is us usable internationally ?\nUser Interface: Well , it's just that , when we're creating it , we're , we have to make it um compatible with different brands of devices .\nMarketing: {gap} Right .\nUser Interface: And it would be easier to make it compatible with just different brands of television devices rather than other ent ,\nMarketing: D_V_D_s and V_C_R_ ?\nUser Interface: yeah ,\nProject Manager: Right .\nMarketing: Okay .\nUser Interface: other entertainment devices .\nProject Manager: Does everyone agree with this ? Does anyone object and , and find the multifunctional might be a better way to go ?\nIndustrial Designer: Um , {vocalsound} I was just wondering about the , what , what Genevieve said before , about having like some hidden controls like having the outer casing . And that would probably , um , I d , well well what you said before about it being a more profitable simplistic design . I suppose having that would complicate it a lot more .\nUser Interface: Yeah . Yeah .\nIndustrial Designer: {vocalsound} And limit the design {gap} . Do you think ?\nMarketing: Yeah , I think I agree with the single design thing for now , because we're trying to do so much , that if we're trying to make a unique , user-friendly , dadada , and it's also multi also multifunctional , um , we're gonna go over budget for one thing .\nIndustrial Designer: Yeah . Yeah . That's true . Yeah .\nUser Interface: Yeah .\nMarketing: So {disfmarker}\nProject Manager: Mm-hmm .\nUser Interface: Yeah . And with this we'll have more room in the budget probably to make a more original design .\nIndustrial Designer: Yeah .\nMarketing: Mm-hmm .\nUser Interface: We'll have more money to go into the design side of it .\nProject Manager: Yeah .\nIndustrial Designer: Okay . Yeah .\nProject Manager: Alright . Sounds great .\nMarketing: Mm , 'kay .\nProject Manager: Alright , well , um ,\nMarketing: {vocalsound}\nProject Manager: are you ready for your presentation Genevieve ?\nMarketing: Yes I am .\nProject Manager: Fabulous . Except you're not hooked up to the {disfmarker}\nMarketing: Oh ,\nUser Interface: {vocalsound}\nMarketing: I'm not hooked up , but other than that , completely ready . {vocalsound}\nProject Manager: {vocalsound} Great .\nMarketing: Okay . Okay . Oh . I just lost my microphone .\nProject Manager: {gap} No problem ,\nMarketing: Just a moment .\nProject Manager: we can {disfmarker}\nMarketing: Okay . So I'll be discussing the functional requirements of this remote control . Um , and I'll give you a little briefing on what that means exactly . Um , if you all remember from the email we got before our very first uh kick-off meeting , with the coffee machine ? The functional requirements of that was to produce hot coffee quickly . Um , so what I'll be talking about now is the equivalent for a remote control . Um , so basically what needs and desires are to be fulfilled . Um , I've done some marketing research , a lot of interviews with remote control users , um , and some internet research . And I'll show you my findings . Oh , and firstly I wanted to remind you about our company motto and purpose . So we believe in providing international market with fashionable products . Um , hence our motto , we put the fashion in electronics . So I think that should be our priority here . Um , and we should also be looking to trends in clothing and interior design . Not just in electronic fashion . So that it's something that fits in the household .\nProject Manager: I'm sorry , what was that last thing that you just said ?\nMarketing: Um , we should be looking towards trends in both clothing and interior design .\nProject Manager: Mm-hmm .\nMarketing: Any trends that are going on in , in the public , even media ,\nIndustrial Designer: Mm .\nMarketing: you know who's famous , what T_V_ shows are being watched ,\nIndustrial Designer: Yeah .\nMarketing: um , to influence our remote control . Okay , so the findings . Um , seventy five percent of users of remote controls find them ugly . Which is a , quite a significant number .\nIndustrial Designer: {vocalsound}\nMarketing: Um , the other twenty five percent didn't specify if they love them or found them , you know , neutral . Eighty percent of users would spend more money when a remote control would look fancy . Current remote controls do not match well the operating behaviour of the user .\nProject Manager: I'm sorry , that eighty percent of users would spend more money when a remote control would look fancy . You mean that they would spend more money on a fancy-looking remote control ?\nMarketing: Yeah , they're willing , they're willing to spend money on a remote control with personality .\nProject Manager: Okay .\nMarketing: As opposed to your basic , you know , oval black , all same size button remote control .\nIndustrial Designer: Mm . Yeah .\nMarketing: Um , so it is something that people care about . It's not , it's not ignored in the household . Um , seventy five percent of remote control users said that they zap a lot . Zapping meaning they go through channels a lot .\nIndustrial Designer: Mm-hmm .\nMarketing: They're you know thumb-masters . Um , and fifty percent of users say they only use ten percent of the buttons . That A very small amount . Thought that was interesting .\nProject Manager: Alright , so it might be very appealing if , um , we have very concise buttons .\nIndustrial Designer: Mm . {gap} the single function .\nProject Manager: And another thing with um lots of surfing , we'd probably have to work on something that could be um a lot more durable ,\nIndustrial Designer: Yeah .\nProject Manager: because I find with um channel-changers that , um , a lot of the numbers get rubbed down if they're printed on the button .\nMarketing: Yes .\nIndustrial Designer: Yeah that's a good point .\nUser Interface: Yeah . Yeah .\nMarketing: And actually to go with that , I'm gonna give you some statistics on the uh relevancy of the buttons , how much they're used . And uh how important the uh users find them . So the power button , obviously , in an hour is only used once . Hopefully the person's not turning on and off the T_V_ . Um , but the relevance of that button is nine out of ten . So people wanna be able to turn on the T_V_ with the remote control . Um , as opposed to standing up and turning on the television set . Channel selection is used a hundred and sixty eight times on average per hour .\nIndustrial Designer: {vocalsound}\nMarketing: That's a huge amount . This is the most important button . Um , so obviously when commercials come on they're changing it , so as you said we want a durable button that's not gonna run down . Relevance of that button , our users found was uh ten , ten out of ten . Uh , ditto for volume selection , so ten out of ten . And it's used on average four times an hour . Not as much as channel selection , but still significant . Um , audio settings is used on average zero point eight times an hour . Relevance is two . Screen settings , which means brightness , colour etcetera , zero point five times an hour . Um , and relevance of one point five . We're getting to specific statistics here . Teletext , um , now I'm not too clear on what that is . I don't know if you can help me . Flipping pages .\nUser Interface: It's um {disfmarker}\nMarketing: Is that {disfmarker}\nIndustrial Designer: It's like the news . Or like information .\nUser Interface: It has {disfmarker} T_V_ has like information , it has information on holidays , the news , entertainment .\nProject Manager: Yeah .\nIndustrial Designer: The {disfmarker}\nProject Manager: It's um {disfmarker}\nIndustrial Designer: and what's on .\nMarketing: So like a running banner , underneath {disfmarker}\nProject Manager: No it's a button that you press , and then you , uh , like a menu pops up .\nUser Interface: No , li Yeah .\nProject Manager: I haven't used it before\nUser Interface: Yeah .\nProject Manager: but {disfmarker}\nMarketing: Oh .\nIndustrial Designer: It's like {disfmarker}\nUser Interface: And you have page numbers like for the menu , and you press the page numbers with your remote , and it , it'll come up .\nIndustrial Designer: It's like very basic internet . Sort of ,\nMarketing: Okay .\nUser Interface: Very basic internet , yeah .\nIndustrial Designer: um {disfmarker}\nUser Interface: But you have {disfmarker}\nMarketing: Okay . Like tells you the weather , and {disfmarker}\nUser Interface: Yeah . But you have no interaction back with it , you know .\nMarketing: Okay .\nUser Interface: Like the internet you can send emails and {disfmarker} You've no interaction .\nIndustrial Designer: Yeah , it's just information that um , like television timetables , what's on , what's on now , what's on next , on every channel , and {disfmarker}\nMarketing: Right .\nUser Interface: Yeah .\nMarketing: Alright . Well I guess I'm not with it , because I wasn't {disfmarker} But it's , it's being used fourteen times an hour . Um , and has a r a high relevance of six point five . So it looks like something that we're gonna want to do some research on and include on our remote control .\nUser Interface: Yeah .\nIndustrial Designer: Yeah .\nMarketing: Um , channel settings . Zero point zero one times an hour . Relevance of three . Channel settings .\nUser Interface: Uh , probably just tuning in the channels , would it be ?\nMarketing: P Sorry . Changing the channels ?\nUser Interface: Tuning them in at the very start . You know if you get a new T_V_ set , you tune in all the channels ,\nIndustrial Designer: To get the right reception and picture , I suppose .\nUser Interface: do you th do you think ?\nMarketing: Oh , okay .\nUser Interface: Yeah . Yeah .\nMarketing: Yeah . Okay .\nProject Manager: Mm .\nMarketing: Um , so it's not used very often , but people still find it relevant . Okay . Um , biggest frustrations of uh the people that we interviewed . Remote controls are often lost somewhere . So that was already discussed by Poppy . How we could have a , an alarm system so that people can find it . Um , takes too much time to learn how to use a new remote control .\nIndustrial Designer: {gap}\nMarketing: So it should be very user-friendly , you know . People know what to do very quickly . Um , remote controls are bad for R_S_I_ . {vocalsound} {gap}\nIndustrial Designer: Repetitive strain injury .\nUser Interface: Repeti Uh .\nMarketing: Ah .\nIndustrial Designer: I think .\nMarketing: Is that what it is ? People with arthritis and such ?\nProject Manager: That's rather sad . {vocalsound}\nIndustrial Designer: {vocalsound}\nUser Interface: {vocalsound} {vocalsound}\nIndustrial Designer: {vocalsound}\nMarketing: Um , maybe our\nIndustrial Designer: Oh , I'm guessing that's what it is . I'm not {disfmarker} {vocalsound}\nUser Interface: Yeah , yeah . I think it is .\nMarketing: designers can look into that . Um , buttons that don't require , you know , very firm pushing , if they respond .\nIndustrial Designer: Mm . Yeah .\nMarketing: But we'll have to also avoid , you know , buttons responding to the slightest touch as well . That's a problem .\nIndustrial Designer: Yeah . It is .\nMarketing: Okay . Did you guys uh get that one down ?\nIndustrial Designer: Mm-hmm .\nProject Manager: Yep .\nMarketing: Um {vocalsound} okay , here's some ideas for you . A large percentage of the public would pay for voice recognition on the remote controls . So I'll show you some numbers here . Um , so the youngest age group , fifteen to twenty five . Ninety one point two percent said that they would pay extra money to have voice recogni voice recognition included on their remote control . Um , and you can see that number decreases a bit with ol s Interestingly enough , twenty five to thirty five is the lowest amount . Um , that would , are willing to pay extra . So I guess we're gonna have to figure out what age group we're , we're targeting , and if and if voice recognition is something we wanna look into . And if we have the budget for it . Um , if we are targeting young adults , it looks like something that would pay off . Seeing as ninety percent , over ninety percent would pay for it .\nProject Manager: I agree with um {disfmarker} if we're targeting young adults then it would be something we should look into . Um , financially and and functionally .\nMarketing: Mm-hmm .\nProject Manager: Um , and especially if we are um trying to be trendy , go with fashions , things like that .\nIndustrial Designer: Mm .\nProject Manager: Um , ages like from thirty five to sixty five which show lower numbers probably won't be as concerned .\nMarketing: So that , that's a whole other field of research . I don't know if it'd be , if we'd still have a remote , or if you're talking to your television and saying change channel .\nProject Manager: Mm-hmm .\nMarketing: Um and depending on how many members you have in households .\nIndustrial Designer: Yeah .\nMarketing: So it m it may be too complicated for us , but it's something to keep in mind anyway .\nProject Manager: Yeah . And something that might further complicate it is that the T_V_ makes noise itself .\nMarketing: {vocalsound} Right .\nProject Manager: Wonder if it would have {disfmarker}\nUser Interface: Yeah .\nIndustrial Designer: And if there was conversation in the room at the same time ,\nProject Manager: Yeah .\nMarketing: Mm-hmm .\nIndustrial Designer: although in theory it doesn't tend to be when you're watching television ,\nProject Manager: {vocalsound}\nIndustrial Designer: but {vocalsound} {gap} could be very difficult to get the specific uh design .\nProject Manager: {gap} Yeah . If we're looking for a simplistic design , if {disfmarker}\nMarketing: Mm-hmm .\nProject Manager: We need to decide if that is our um intention is , is a simplistic design .\nIndustrial Designer: Yeah . Mm .\nProject Manager: Um , because if , if it is then I think voice , um voice-activated {disfmarker}\nMarketing: It looks like {disfmarker}\nProject Manager: Yeah , and that would sort of negate the whole remote control thing ,\nMarketing: Mm-hmm .\nProject Manager: because if people can activate the television with their voice then they won't be using a , they won't be talking into a remote , I'm sure .\nMarketing: It'd be like the ultimate remote . {gap} Um {vocalsound} okay . And th the last thing here was a , an L_C_D_ screen . So , I mean voice recognition might be a little too extreme for us . Not practical . Um an L_C_D_ screen though might be something that , you know , you can shift through pages kind of li the way this PowerPoint is working .\nIndustrial Designer: Yeah .\nMarketing: So that you don't have so many buttons to deal with .\nProject Manager: Um , I don't know what an L_C_D_ screen is .\nMarketing: Oh sorry , just , just a screen , like a computer screen . S Or like um {disfmarker}\nUser Interface: Mobile phone .\nIndustrial Designer: Mm .\nUser Interface: Yeah .\nMarketing: Yeah . Or {disfmarker} Like an alarm clock . You'd have an L_C_D_ versus just a , a normal clock .\nIndustrial Designer: What , what would appear on the screen ?\nProject Manager: I have no idea still . {vocalsound} I'm sorry . {vocalsound}\nMarketing: Oh just like an electronic screen . As opposed to just buttons . There would be like a little , like on {disfmarker}\nProject Manager: Oh , on the remote . Okay .\nMarketing: Yeah . Like on the top of a cellphone , the the little L_C_D_ screen .\nProject Manager: Yeah .\nMarketing: Um , now that's , I , I dunno exactly what exactly we'd put on there . I guess the channel that you're on , the v the volume setting .\nUser Interface: Yeah . Could it it {disfmarker} It would be good if it had the actual programme that was on , and what was next . But that would probably be {disfmarker}\nIndustrial Designer: Like linked in with the teletext ,\nUser Interface: Yeah . That would be good , yeah .\nMarketing: Mm-hmm .\nIndustrial Designer: or sort of like an teletext at your fingers , without having to access that through the television .\nUser Interface: Yeah . Might be quite expensive to do that though .\nIndustrial Designer: Mm , Yeah . Could be . {vocalsound}\nUser Interface: {vocalsound}\nMarketing: {vocalsound} Well I guess that's something we can all take back to our respective research .\nProject Manager: Right .\nIndustrial Designer: Mm-hmm .\nMarketing: Um , and finally , whoops , my personal preferences and thoughts . Um , I think our priority really should be unique design . Um , we want something that people want in their home . Every remote control looks the same , so uh in my opinion it should be , um , user-friendly and unique . So the other stuff might be a little too , a little too gadgety for some people .\nIndustrial Designer: Yeah .\nMarketing: Um , I th myself , voice recognition kind of scares me off .\nUser Interface: {vocalsound}\nMarketing: So if we're , if we're aiming to make this an international university , universally accepted product {disfmarker}\nIndustrial Designer: Mm .\nProject Manager: {vocalsound}\nMarketing: Um , and for all , the other thing is like age market . I mean if we wanted to concentrate on fifteen to twenty five years olds , we could go for the fancy stuff . But if we wanna make fifty million , and and have everyone want this remote control , we should maybe stick to the basics .\nProject Manager: Mm-hmm .\nUser Interface: And we should keep in mind that fifteen to twenty five year olds might not have twenty five Euros to spend on a remote control . Like their priorities might not be a fancy remote control , when they're just starting out\nMarketing: Mm-hmm .\nUser Interface: and , yeah .\nMarketing: Right . And we have to keep in mind the , the reliability of our research . I mean , you know , a sixteen year old boy would say , yeah I'd pay extra for voice recognition , until they realise that's three months allowance .\nUser Interface: {vocalsound} Yeah .\nProject Manager: {vocalsound}\nUser Interface: {vocalsound} Yeah . {vocalsound}\nMarketing: Um , so I I think , I think the older generations we should be catering to a bit more .\nUser Interface: Early twenties , that's the kind of age group .\nProject Manager: Yeah . And if one of the largest , uh , or most complained about thing is that it takes so long to get to know how to use a remote control ,\nUser Interface: Twenties .\nMarketing: {vocalsound} Yeah .\nIndustrial Designer: Yeah .\nProject Manager: I'm sure that something like an L_C_D_ screen or remote control would be just furthering that problem .\nIndustrial Designer: Yeah . Complicated jus complicating things even fo Mm .\nMarketing: Yep .\nProject Manager: Yeah .\nUser Interface: Yeah .\nProject Manager: Alright .\nIndustrial Designer: Okay .\nMarketing: Okay . That's it for the market research .\nProject Manager: Okay . Before we go into uh more discussion on {gap} we want this design to look like , I've received some information from the management that will affect some of our decisions . Um , for one thing , because {disfmarker} Having controls with D_V_D_ , V_C_R_ , that sort of thing , would really complicate the design of the remote control . Um , we've decided not to include them and make it a specific , just a specific television um function . Which is good as , as we've sort of decided that we would like to go with that anyway . Um , for many reasons . So um we have that decision sort of made for us . Another thing that might um affect other decisions is that um the management feels that teletext is outdated , because more people are using the internet now . And so uh we won't concern ourselves with um navigating the teletext option .\nIndustrial Designer: Can I just interrupt ?\nProject Manager: Yep .\nIndustrial Designer: Would you like to plug in your {disfmarker}\nMarketing: Yeah . Maybe we can do the {disfmarker}\nProject Manager: Okay , sure .\nIndustrial Designer: Have you got a PowerPoint or not ?\nProject Manager: Yeah I do . I'm looking at {disfmarker} looking at it right now .\nIndustrial Designer: Okay . Thanks .\nMarketing: There you go .\nProject Manager: {gap} thank you .\nMarketing: Oh , come back screen .\nProject Manager: {vocalsound}\nMarketing: Hmm . {gap}\nIndustrial Designer: Were they , was the management suggesting use of the internet rather than teletext , or just avoiding both altogether ?\nProject Manager: Um , well , I mean we don't have the resources or or possibility of using the internet with the remote control ,\nIndustrial Designer: {gap} Yeah . Yeah .\nProject Manager: but um they were just pretty much saying that the teletext would not be used .\nIndustrial Designer: Okay . Yeah . Okay .\nProject Manager: Alright , and another thing . This is for the design , the design of the product is that um we wanna create , um more of a sense that people know that this is from our company . So , um , all the remote controls must have our um {disfmarker} We'll incorporate our logo and colour in in some way .\nIndustrial Designer: Right . Yeah .\nProject Manager: So , um , perhaps um our logo on the bottom , or wherever you feel like it would look good .\nIndustrial Designer: Yeah . Okay .\nProject Manager: Um , it doesn't have to be the colour of our um of our company\nIndustrial Designer: Just {disfmarker}\nProject Manager: but , another thing is that , um\nIndustrial Designer: {vocalsound}\nProject Manager: we need to , we probably would have to have that colour and , and logo decided upon . Um , I'm assuming that we already have one , but for the purposes of this meeting I , I wasn't offered a , like a type of logo or colour , so if that could be um somewhere on the design so that we can be recognisable .\nIndustrial Designer: Okay . Work on that .\nMarketing: It's probably R_ R_R_ in yellow . {vocalsound}\nUser Interface: Yeah .\nIndustrial Designer: Yeah .\nProject Manager: The little R_ R_ yellow thing ? Okay .\nIndustrial Designer: Mm-hmm .\nUser Interface: Yeah .\nMarketing: Yeah , I think .\nProject Manager: Real Reaction ? Okay . Um , yes , those are the changes . Um , so , now we need to discuss , um and come to a decision on our remote control functions , of , of how this is going to be . I'm just going to look at my notes for a second . Um , we have to decide on a target group and the functions of the remote control . So , um , we already know that it'll just be for the television .\nIndustrial Designer: Okay .\nProject Manager: It'll {disfmarker} It won't have teletext . But um , you know , we could discuss um those other options that you brought up , Genevieve .\nIndustrial Designer: {gap}\nMarketing: Okay , so I {disfmarker} Are we going to write off the L_C_D_ option ?\nIndustrial Designer: Yeah .\nProject Manager: Is that how most people feel about that ?\nUser Interface: Yeah .\nMarketing: Yeah ?\nIndustrial Designer: Yeah .\nProject Manager: Okay .\nMarketing: Okay . So no L_C_D_ , no teletext , and no voice recognition .\nUser Interface: I think it would be annoying though if {disfmarker} I don't use teletext that much , but if it was on your T_V_ , you'd want to be able to use it , if {disfmarker}\nProject Manager: Yeah , but another thing is that if we're reaching an international crowd , um , I know for one that in North America there is no such thing as teletext , so it'd be really superfluous .\nUser Interface: You'd {disfmarker} Yeah .\nMarketing: Yeah .\nUser Interface: So is it just {disfmarker}\nIndustrial Designer: Yeah .\nMarketing: Never heard of it .\nUser Interface: Okay . Alright .\nProject Manager: Yeah . I don't know about other countries besides the U_K_ .\nUser Interface: Right .\nProject Manager: Do you know if anywhere else has it ?\nIndustrial Designer: I don't know .\nUser Interface: I don't know .\nIndustrial Designer: More research required , I think .\nUser Interface: I don't know . {vocalsound}\nProject Manager: Alright .\nIndustrial Designer: {vocalsound} But if {disfmarker} Was it a management decision that we're having {disfmarker}\nProject Manager: It was a management decision ,\nIndustrial Designer: Okay .\nProject Manager: so it's , it's pretty much out of our hands at this point .\nIndustrial Designer: So {disfmarker}\nUser Interface: Yeah .\nIndustrial Designer: Okay .\nUser Interface: Okay then .\nProject Manager: 'Kay . So , I guess we're looking at something rather simple .\nMarketing: Um , well I guess , just from my findings it looks like we wanna minimise buttons .\nIndustrial Designer: 'Kay .\nMarketing: Um .\nIndustrial Designer: Minimal {disfmarker}\nMarketing: And the {disfmarker} What was the word they used ? F findability is important .\nIndustrial Designer: {vocalsound}\nUser Interface: {vocalsound}\nProject Manager: Yeah . I think we should definitely go ahead with the alarm system idea that you had .\nIndustrial Designer: Yeah okay .\nMarketing: {vocalsound} Mm-hmm .\nProject Manager: 'Cause I'm sure that could be inex inexpensive because we could use the same kind of infrared\nUser Interface: Yeah .\nIndustrial Designer: Yeah . The same signalling .\nProject Manager: the same signal through that and it could just like make a little beeping noise .\nIndustrial Designer: I mean {disfmarker}\nProject Manager: It's not that expensive to do .\nIndustrial Designer: Or vibrate just the same as a mobile phone . Like you just a , a buzz or something .\nProject Manager: Yeah . Yeah . Okay . I like that idea .\nIndustrial Designer: Yeah .\nMarketing: Mm-hmm .\nUser Interface: Would you be able to , um , put the little device anywhere ? {vocalsound} 'Cause uh isn't our remote control for all T_V_s , so\nIndustrial Designer: If {vocalsound} {disfmarker}\nUser Interface: you'd ha\nIndustrial Designer: Do you mean the the link between the {disfmarker}\nUser Interface: Yeah , with the button that you pressed .\nProject Manager: Yeah . The button {disfmarker}\nIndustrial Designer: Well , if the button was actually on {disfmarker}\nProject Manager: Oh .\nUser Interface: Yeah .\nIndustrial Designer: Oh , yeah . {vocalsound}\nProject Manager: {vocalsound} Minor detail there .\nUser Interface: C 'cause then it would only be a applicable to one T_V_ set , so it would need to be something that you could stick somewhere , or something .\nIndustrial Designer: Maybe {disfmarker} Yeah , yeah .\nProject Manager: Yeah , it would have t\nIndustrial Designer: Maybe something adhesive that you could like stick onto the back of any set that would be um yeah not very obtrusive .\nUser Interface: Yeah .\nProject Manager: Mm-hmm .\nIndustrial Designer: Obviously something small that's {disfmarker} Yeah , that's a good point .\nUser Interface: Yeah .\nProject Manager: Yeah . Then it wouldn't , it probably wouldn't be able to use {disfmarker} It would be able to use the same reception on the remote c control I guess , but the actual device would have to have its own infrared signaller .\nIndustrial Designer: Yeah .\nUser Interface: Yeah .\nProject Manager: Okay .\nIndustrial Designer: Yeah , okay .\nUser Interface: Would it need a battery then ?\nProject Manager: Maybe , um {disfmarker}\nIndustrial Designer: Pr probably .\nProject Manager: Probably , I mean .\nIndustrial Designer: Unless it could be {disfmarker} {vocalsound}\nProject Manager: That's your department you'll have to sort that out .\nUser Interface: {vocalsound}\nMarketing: Mm .\nIndustrial Designer: Okay . Um , unless some way , it could have some universal connection to like the socket , the same socket that the T_V_'s supplied from . I mean the power for the T_V_ .\nUser Interface: Yeah .\nProject Manager: Yeah , you'll have to {disfmarker}\nIndustrial Designer: So , mm , more research into that one .\nProject Manager: Yeah , you'll have to investi Do some research on that ,\nUser Interface: {vocalsound}\nIndustrial Designer: Yeah .\nMarketing: Mm .\nProject Manager: alright ? Great . Um , alright , and I'm sure that , um um , the glow-in-the-dark , fluorescent , whatever , system , um is a go ahead . Is everyone interested in that ?\nIndustrial Designer: Y\nMarketing: On the buttons ?\nUser Interface: I I like the light up suggestion . I think that would be better .\nIndustrial Designer: Yeah .\nProject Manager: Yeah .\nUser Interface: 'Cause you know the way fluorescent lights lose their brightness after certain time , so\nIndustrial Designer: Yeah . Yeah .\nProject Manager: Yeah .\nIndustrial Designer: Yeah .\nMarketing: {gap} it doesn't {disfmarker}\nUser Interface: I would go for {disfmarker}\nMarketing: It could it could be a tactile thing as well . Um right , if w if we're minimising buttons , we might be able to make them actually larger . And there's something on it . S you know like up arrow down arrow for , for volume .\nIndustrial Designer: Like a raised {disfmarker}\nMarketing: Um , and I don't know what we could do for , for channels . S\nUser Interface: Well just the numbers could be embossed , couldn't it ? Like raised .\nMarketing: The numbers themselves .\nUser Interface: Yeah . Could be raised .\nMarketing: But then the like up button and down button for the channel , channel changing .\nUser Interface: Just little arrows , that you could feel , maybe ?\nIndustrial Designer: Yeah {disfmarker}\nMarketing: Yeah .\nProject Manager: Hmm .\nMarketing: I just thought that {gap} it , it might be sucking more battery power , if there , if it is a light up . I'm not sure .\nUser Interface: Yeah .\nProject Manager: Yeah .\nIndustrial Designer: That's true .\nProject Manager: But I mean {disfmarker}\nIndustrial Designer: And also y , uh Heather you mentioned before , um like how it should be accessible to everybody .\nProject Manager: Yeah .\nIndustrial Designer: Um , so like big b um buttons , {gap} for people you are visually impaired . The glow-in-the-dark or light up won't make any difference anyway .\nUser Interface: Yeah .\nMarketing: Mm-hmm .\nIndustrial Designer: So like you say tactile might be better , because it'd be more available to everybody .\nUser Interface: That , I think that's good , yeah .\nProject Manager: Yeah . Could we somehow {disfmarker} We could , may , possibly , sorry , incorporate them both so that the buttons could maybe be in the shape of the numbers themselves and be made out of some glow-in-the-dark material .\nIndustrial Designer: Yeah .\nMarketing: Mm-hmm .\nIndustrial Designer: Yeah .\nUser Interface: Yeah . Yeah .\nIndustrial Designer: Mm-hmm .\nProject Manager: 'Cause I d I don't think that glow-in-the-dark material , um , like the actual soft plastic , um , costs that much more than other colours .\nIndustrial Designer: Yeah .\nUser Interface: Yeah .\nMarketing: Mm-hmm .\nIndustrial Designer: No , it's not these days .\nUser Interface: No , I wouldn't say so .\nMarketing: {vocalsound}\nIndustrial Designer: I mean , it's quite easily accessible .\nProject Manager: Yeah .\nMarketing: I guess the other option , referring to the battery thing is , you know how cellphones will t light up for fifteen seconds or something , when you're s and then it goes ,\nIndustrial Designer: Yeah . Yeah .\nUser Interface: That's good {disfmarker} Yeah that a good idea .\nMarketing: so if , if you're like changing the volume during a movie . I know , I'm thinking of mostly when you're watching a movie you turn all the lights off right .\nIndustrial Designer: Yeah . Yeah .\nUser Interface: Yeah .\nMarketing: And you don't want to turn on the lights , {vocalsound} to turn it down , because there's suddenly an explosion , and it's gonna wake up the baby .\nUser Interface: {vocalsound} Yeah .\nMarketing: Um , so if you touch the button , it kind of reactivates it .\nIndustrial Designer: Yeah .\nMarketing: It lights up for {disfmarker}\nIndustrial Designer: Yeah .\nUser Interface: That , yeah , that's a good idea .\nMarketing: On self timer .\nIndustrial Designer: So self-timed lighting .\nProject Manager: Alright we have five minutes left\nMarketing: Yeah .\nIndustrial Designer: Um , I {disfmarker}\nProject Manager: um , for the meeting , but I think we should discuss this light subject a little bit more before we close . Um , what was {disfmarker} I missed the last moment , reading that . What were you talking about with the lighting up buttons ?\nMarketing: Oh , just if it was kinda the same way that a cell You know how a cellphone will light up for about ten , fifteen seconds when you touch a button , after having not touched it for a while .\nProject Manager: Yeah . Yeah .\nMarketing: Um , if instead of a constant light up on the , on the remote control , if it lights up for ten seconds when it's touched again .\nProject Manager: Mm . So it could be any button that would be pressed .\nIndustrial Designer: Yeah .\nMarketing: Yeah , and you , you touch it and it just kind of lights up a bit , and it gives a faint glow .\nIndustrial Designer: So , self-timed {disfmarker}\nMarketing: So if you have all the lights off in your living room , you'll , you'll temporarily see it .\nProject Manager: Yeah .\nMarketing: Because usually you're not fooling around for it for more than what ten seconds .\nIndustrial Designer: Yeah .\nProject Manager: Okay , so {disfmarker}\nUser Interface: Yeah .\nMarketing: So {disfmarker}\nProject Manager: That's probably feasible .\nIndustrial Designer: Yeah .\nProject Manager: So , do you think that we should do the lighting up thing , and the glow-in-the-dark thing , and the shape of the numbers ? Do we have to kind of decide what we're gonna do with this .\nIndustrial Designer: I think the shape of the numbers is a really good idea .\nMarketing: Mm-hmm .\nProject Manager: Yeah , okay .\nIndustrial Designer: And I think that's un unique as well .\nUser Interface: Yeah . For visually impaired , yeah .\nProject Manager: Yeah .\nIndustrial Designer: I mean , I haven't seen that . And as you're saying like numbers can wear off if they're just sort of like painted on , you know printed .\nMarketing: Mm-hmm .\nProject Manager: Yeah , yeah . And it could {gap} , if it's that softer rubber material it'll be , maybe , um , uh , better for people with um els no\nIndustrial Designer: {gap} durable .\nProject Manager: what's it called , R_S_I_ , what was it that we were talking about ?\nIndustrial Designer: Oh yeah . Yeah . Yeah .\nUser Interface: Yeah .\nProject Manager: Yeah .\nMarketing: Oh right , the {disfmarker}\nProject Manager: Yeah instead of like hard buttons .\nIndustrial Designer: Repetitive strain injury .\nProject Manager: Okay . Um , did we want to go for the glow-in-the-dark look ?\nIndustrial Designer: Mm-hmm .\nProject Manager: Or did we want to go for the lighting up instantly ?\nUser Interface: If {disfmarker}\nProject Manager: Like should we do both ? Or we can have one or the other ? Because it might , for , for our design purposes , I mean , the lighting up thing might be better because glow-in-the-dark material has a funny kinda colour .\nMarketing: Mm-hmm .\nProject Manager: And it might not go with different like face plates that we might come up with .\nMarketing: I was gonna say , {gap}\nIndustrial Designer: Yeah .\nMarketing: Exactly . It the {disfmarker} it might be perceived as tacky , glow-in-the-dark .\nProject Manager: Yeah .\nMarketing: It's kind of like Eighties neon-style .\nIndustrial Designer: Yeah , and we could {disfmarker}\nMarketing: Um , whereas we're trying to be trendy and fashionable .\nIndustrial Designer: Yeah there are now like loads , or a huge range of different colours that it could light up in as well ,\nMarketing: So {disfmarker}\nIndustrial Designer: which could like link in with the company colours . Like it could be blue or green or yellow ,\nUser Interface: {vocalsound}\nProject Manager: Right .\nMarketing: Mm-hmm .\nIndustrial Designer: or like we've just limited t with the , just ordinary phosphorescent so {disfmarker}\nProject Manager: Right . Alright . So we've decided on lighting up things .\nUser Interface: I was thinking though , if it was glow-in-the-dark , you could put the um Real Reaction symbol as glow-in-the-dark , and then it would be constantly advertised .\nIndustrial Designer: Yeah . Every time the , that it lit up , you c that could light up as well .\nMarketing: Mm .\nProject Manager: Yeah .\nUser Interface: Yeah .\nIndustrial Designer: Or , or the , whate\nProject Manager: Yeah .\nUser Interface: {gap} Yeah .\nProject Manager: But with the same thing , I mean . If you touch the button and then it could be , it could be lit up as well .\nMarketing: That's true .\nIndustrial Designer: Yeah .\nUser Interface: Yeah . Okay .\nProject Manager: Is {disfmarker} Are you okay with that ? Okay . Cool .\nUser Interface: Yeah . {vocalsound}\nProject Manager: Um {disfmarker} Alright . So I think that um that completes most of our um our more uh practical decisions .\nIndustrial Designer: Is {disfmarker}\nProject Manager: And now it's up to designing . And um making sure that this can be feasible . And do you have anything {disfmarker}\nMarketing: What um {disfmarker}\nProject Manager: Do you have anything to say ? {vocalsound}\nMarketing: Oh sorry . Yeah well , I was just gonna throw out there the thought about um personalising the remote control . Um , it , you , 'cause you mentioned face plates . So I I dunno if there's something that diff , you know like five different face plates . I dunno if this will start making it more complicated , but it could increase the popularity of the , of the remote . Um\nIndustrial Designer: Okay . Like you can have changeable um mobile covers or something .\nUser Interface: Oh yeah . Interchangeable thing ?\nMarketing: Yeah , {gap} {disfmarker}\nProject Manager: Like an iPod or something ?\nUser Interface: That would be good .\nIndustrial Designer: Yeah , or {disfmarker}\nMarketing: Exactly , like an iPod .\nProject Manager: Okay .\nUser Interface: Yeah .\nMarketing: Exactly .\nIndustrial Designer: Okay .\nMarketing: Or , or like mobile ph .\nProject Manager: Like a cellphone ? Yeah .\nMarketing: And I dunno if we'd want to go with like T_V_ show themes or something . Like a Bart Simpson faceplate .\nUser Interface: Yeah , and then that would be uh more profitable like as a sideline to the remote as well .\nMarketing: {vocalsound} But {disfmarker}\nIndustrial Designer: {gap} Yeah .\nProject Manager: Mm-hmm .\nUser Interface: Y Could buy extra {disfmarker}\nMarketing: Mm-hmm .\nProject Manager: Accessories .\nMarketing: Exactly . You could start out with three , and if , if we hit it big then we can add some on .\nIndustrial Designer: Person {disfmarker}\nUser Interface: Yeah .\nIndustrial Designer: Yeah . Well , that's great .\nUser Interface: That's a good idea . Yeah .\nProject Manager: Yeah . I think that we should incorporate that .\nIndustrial Designer: Interchangeable .\nProject Manager: 'Cause that wouldn't be very expensive at all .\nIndustrial Designer: Um , als\nProject Manager: You'd just get one mould ,\nUser Interface: No .\nIndustrial Designer: Yeah .\nMarketing: Mm-hmm .\nProject Manager: throw some plastic in it , you know . {vocalsound}\nIndustrial Designer: Interchan And also possible {disfmarker} I mean , uh , we could gain out of that by advertising certain T_V_ shows , or {disfmarker}\nProject Manager: Yeah . Well , that might be com problematic with um copyright issues .\nUser Interface: Oh yeah .\nMarketing: Right .\nProject Manager: So , if it takes off then we'll , we'll , we'll try that out .\nIndustrial Designer: Yeah . But if we , there is {disfmarker}\nUser Interface: If w\nIndustrial Designer: Yeah . We could {disfmarker} Um , the environmental factor , we didn't bring that up again .\nProject Manager: Right .\nMarketing: Right .\nProject Manager: We'll have to do more research . Like as of yet , that has nothing to do with , um , the way it'll look . Um , does it need to be reached a de\nIndustrial Designer: Yeah .\nProject Manager: Do we need to reach a decision on that right now ?\nIndustrial Designer: Um , I've {disfmarker}\nProject Manager: Because we need to investigate the financial implications .\nIndustrial Designer: Okay .\nMarketing: {vocalsound}\nProject Manager: Okay . Is it {disfmarker}\nIndustrial Designer: Let's {disfmarker}\nProject Manager: Does it need to be uh decided on now ? Or should we {disfmarker}\nIndustrial Designer: I think we could probably leave that 'til later on , then .\nProject Manager: Okay . Good . Alright then . Anyone else have anything more to say before we close ?\nUser Interface: No .\nIndustrial Designer: No .\nProject Manager: Alright , well . Let's have lunch and we'll discuss this later .\nUser Interface: {vocalsound} Okay .\nMarketing: {vocalsound}\nProject Manager: Alright ?\nIndustrial Designer: Okay . Thank you .", "source": "meeting_summ", "evaluation": "rouge"}
{"instructions": ["Summarize discussion on what to include in the meeting corpus and how to structure it", "Summarize discussion on issues with data storage", "What did the participants think about what constitutes a meeting?", "What did PhD I think about segmentation?", "What did the Professor think about storing data?", "What did the participants think about using CD's for backup?", "Summarize the meeting"], "outputs": ["The discussion centered on the extent to which the recordings should be segmented for the corpus and which recordings should be included in the corpus. The team expressed that it would be helpful to filter out breath and non-verbal sounds. It also expressed that for two person conversations and transcripts that do not follow their general meeting setup, it could create a different directory.", "The team felt that the current file system they were using was running out of space, specifically back-up capacity. They needed to figure out a way to back-up the data they were collecting. They decided that the tape system that ICSI has is pretty reliable. But they needed to discuss the matter with the system administrator.", "The participants were skeptical that a two person conversation in the hallway constituted a meeting for their purposes. They thought that it would be okay to include this kind of data in their corpus for future researchers, but they should separate it. The Professor has a strong opinion that these interactions were not actually meetings.", "PhD I thought that the team should re-evaluate recognition without cheating on the segmentation. PhD I explained to the team that they had so far been using a simplified version of the scoring and brought up that Thilo wanted to use recognizer alignments to train his speech detector. He was not sure how much hand labeling would be needed to generate data for the detector.", "The professor expressed that the team should not recycle backed up disk space and explained the rate at which they could acquire disks. He was surprised that burned CD's wear out after a year or two. He thought that putting the data on tape was a good idea.", "PhD I suggested putting the data on a CD-ROM but was informed that the data gets lost in a few years. PhD F expressed that it was generally a bad idea to have a copy on a medium that failed. Professionally pressed discs last longer, but they would be burning them in-house. The idea of re-burning the CD's each year was also not adopted.", "The participants discussed how meetings would be transcribed, what kind of information to include in their corpus as well as how to structure it, issues with storing data, and their model. They were particularly concerned with how IBM could assist with transcribing meetings and how they would manage large amounts of data if they include more information in their corpus, given that they were running low on storage. They decided that they could store the data on tapes for backup, and that they would wait and see how IBM transcribes their meetings. As for the modeling, PhD I reported several results and a few members of the team decided to further discuss progress in a smaller meeting later on."], "input": "Grad H: st\nGrad F: So we 're on .\nGrad H: Yeah . That 's better .\nGrad F: And , {comment} somewhere is my agenda . I think the most important thing is Morgan wanted to talk about , uh , the ARPA {pause} demo .\nProfessor D: Well , so , here 's the thing . Um , why don't we s again start off with {disfmarker} with , uh , Yeah , I 'll get it . I 'll get the door . Um , I think we want to start off with the agenda . And then , given that , uh , Liz and Andreas are gonna be {pause} ten , fifteen minutes late , we can try to figure out what we can do most effectively without them here . So {disfmarker} {vocalsound} So {disfmarker} so , one thing is , yeah , talk about demo ,\nGrad F: OK . So , uh {disfmarker} uh , IBM transcription status ,\nProfessor D: IBM transcription . Uh , what else ?\nGrad F: \nProfessor D:  What 's SmartKom ? SmartKom ?\nGrad F: Uh , we wanna talk about if w if we wanna add the data to the mar Meeting Recorder corpus .\nPhD E: The data . The data which we are collecting here .\nProfessor D: What {disfmarker} what {disfmarker} what are we collecting here ?\nPhD E: Data ?\nGrad F: So why don't we have that on the agenda and we 'll {disfmarker} we 'll get to it and talk about it ?\nPhD E: The SmartKom data ?\nProfessor D: Yeah , right .\nPhD E: Yeah .\nProfessor D: Uh , right . Uh .\nGrad F: Uh , reorganization status .\nProfessor D: Reorganization status .\nPostdoc A: Oh . Files and directories ?\nProfessor D: Files and directories .\nGrad F: Yep . Uh - huh . Absinthe , which is the multiprocessor UNIX {disfmarker} Linux . I think it was {pause} Andreas wanted to talk about segmentation and recognition , and update on SRI recognition experiments .\nProfessor D: Um {disfmarker}\nGrad F: And then if ti if there 's time I wanted to talk about digits , but it looked like we were pretty full , so I can wait till next week .\nProfessor D: Right . OK . Well , let 's see . I think the a certainly the segmentation and recognition we wanna maybe focus on when An - Andreas is here since that was particularly his thing .\nPhD E: And also the SmartKom thing should b\nProfessor D: SmartKom also , Andreas . Absinthe , I think also he has sort of been involved in a lot of those things .\nGrad F: At least ,\nProfessor D: Yeah .\nGrad F: yeah , he 'll t he 'll probably be interested .\nProfessor D: Yeah .\nGrad F: But .\nProfessor D: Um So , I mean , I think they 'll be inter I 'll be interested in all this , but {disfmarker} but , uh , probably , if we had to pick something {pause} that we would talk on for ten minutes or so while they 're coming here . Or I guess it would be , you think , reorganization status , or {disfmarker} ?\nGrad F: Yeah . I mean , I think , Chuck was the one who added out the agenda item . I don't really have anything to say other than that we still haven't done it .\nPhD B: Well , I mean , I uh {disfmarker} {vocalsound} just basically that {disfmarker}\nGrad F: So .\nPhD B: maybe I said {disfmarker} maybe we said this before {disfmarker} just that we met and we talked about it and we sort of have a plan for getting things organized and {disfmarker}\nPostdoc A: And I {disfmarker} and I think a crucial part of that is the idea of {disfmarker} of not wanting to do it until right before the next level zero back - up so that there won't be huge number of {disfmarker} of added ,\nPhD B: Right .\nPostdoc A: uh {disfmarker}\nGrad F: Right .\nPhD B: That {disfmarker} that was basically it . Not {disfmarker} not much @ @ {disfmarker}\nGrad F: Although Dave basically said that if we wanna do it , just tell him and he 'll do a d level zero then .\nPostdoc A: Yeah . Uh - huh . Oh , excellent .\nGrad F: So .\nPostdoc A: Oh , good .\nPhD B: Oh , so maybe we should just go ahead and get everything ready , and {disfmarker}\nGrad F: Yep . So , I think we do need to talk a little bit about {disfmarker} Well , we don't need to do it during this meeting .\nPhD B: Yeah .\nGrad F: We have a little more to discuss . But , uh , we 're {disfmarker} we 're basically ready to do it . And , uh , I have some web pages on ts {comment} more of the background . So , naming conventions and things like that , that I 've been trying to keep actually up to date . So . And I 've been sharing them with U - d UW folks also .\nPostdoc A: I 'm sorry , you 've been what ? Showing them ?\nProfessor D: OK .\nPostdoc A: Sharing them .\nGrad F: Sharing them with the UW folks .\nPostdoc A: OK . OK .\nProfessor D: OK . Well , maybe uh , since that {disfmarker} that was a pretty short one , maybe we should talk about the IBM transcription status . Someone can {vocalsound} fill in Liz and Andreas later . Uh\nGrad F: OK . So , we , uh {disfmarker} we did another version of the beeps , where we separated each beeps with a spoken digit . Chuck came up here and recorded some di himself speaking some digits , and so it just goes \" beep one beep \" and then the phrase , and then \" beep two beep \" and then the phrase . And that seems pretty good . Um , I think they 'll have a b easier time keeping track of where they are in the file .\nPhD E: And we have done that on the {pause} automatic segmentations .\nGrad F: And we did it with the automatic segmentation , and I don't think {disfmarker} We ne we didn't look at it in detail . We just sent it to IBM . We {disfmarker} we sorta spot - checked it .\nPhD B: I listened to {pause} probably , uh , five or ten minutes of it from the beginning .\nPhD E: Yeah .\nGrad F: Oh , really ?\nPhD B: Yeah .\nGrad F: OK .\nPhD B: And {disfmarker}\nGrad F: I sorta spot - checked here and there and it sounded pretty good . So . I think it 'll work .\nProfessor D: OK .\nGrad F: And , uh , we 'll just hafta see what we get back from them . Uh {disfmarker}\nPhD B: And the main thing will be if we can align what they give us with what we sent them . I mean , that 's the crucial part .\nGrad F: Right .\nPhD B: And I think we 'll be able to do that at {disfmarker} with this new beep format .\nGrad F: Yep . Well , I think it 's also they are much less likely to d have errors .\nPhD B: Mm - hmm .\nGrad F: I mean , so the problem wi last time is that there were errors in the transcripts where they put beeps where there weren't any , or {disfmarker} and they put in extraneous beeps .\nPhD B: Right . Yeah .\nGrad F: And with the numbers there , it 's much less likely .\nPhD B: Yeah , one interesting note is {disfmarker} uh , or problem {disfmarker} I dunno if this was just because of how I play it back , I say , uh , SND - play and then the file , every once in a while , @ @ {comment} uh , like a beep sounds like it 's cut into two beeps .\nPhD E: Yeah . Into two pieces .\nPhD B: Yeah , and I {disfmarker} I dunno if that 's an , uh , artifact of playback {disfmarker}\nPhD E: Yeah . Yep .\nPhD B: bu uh , I don't think it 's probably in the original file . Um , but , uh {disfmarker}\nPhD E: I recognize that , too . Yeah .\nGrad F: Ha . That 's interesting . I didn't hear that .\nPhD B: Yeah . But with this new format , um , that hopefully they 're not hearing that , and if they are , it shouldn't throw them .\nPhD E: Yep .\nPhD B: So .\nGrad F: Well , maybe we better listen to it again , make sure , but , I mean , certainly the software shouldn't do that ,\nPhD B: Yeah . That 's what I thought .\nGrad F: so .\nPostdoc A: Mm - hmm .\nPhD B: I it 's probably just , you know , mmm , somehow the audio {pause} device gets hung for a second ,\nPhD E: Yeah . Some latency or something .\nGrad F: Hiccups .\nPhD E: Yeah ?\nPostdoc A: As long as they have one number , and they know that there 's only one beep maximum {vocalsound} that goes with that number .\nPhD B: or {disfmarker}\nPhD E: Yeah .\nPhD B: Yeah . Right .\nGrad F: Yeah . The only {disfmarker} the only part that might be confusing is when Chuck is reading digits .\nPhD B: Right .\nPhD E: Yep .\nPostdoc A: Well , you know , actually , are we having them {disfmarker}\nPhD B: So {vocalsound} th\nGrad F: \" Seven four eight beep seven beep {vocalsound} eight three two \" .\nPostdoc A: Yeah , but are we having them do digits ?\nGrad F: Yes . Because , uh , we don't {disfmarker} we didn't {disfmarker} In order to cut them out we 'd have to listen to it .\nPhD B: We {disfmarker} we didn't cut those out .\nPhD E: Yeah . They are not transcribed yet . So . Yeah .\nPostdoc A: OK .\nPhD E: Yeah .\nGrad F: And we wanted to avoid doing that ,\nPostdoc A: OK .\nGrad F: so we {disfmarker} they are transcribing the digits .\nPostdoc A: OK .\nPhD B: We can {disfmarker} we can ignore it when we get it back ,\nGrad F: Although we could tell them {disfmarker} {comment} {vocalsound} we could tell them , if you hear someone reading a digits string just say \" bracket digit bracket \"\nPhD B: huh .\nGrad F: and don't bother actually computing the di writing down the digits .\nPhD B: Yeah .\nPostdoc A: That 'd be great . That 'd be what I 'm having the transcribers here do , cuz it can be extracted later .\nGrad F: Yep . And then I wanted to talk about {disfmarker} but as I said I {disfmarker} we may not have time {disfmarker} what we should do about digits . We have a whole pile of digits that haven't been transcribed .\nProfessor D: Le - let 's talk about it , because that 's {disfmarker} that 's something that I {disfmarker} I know Andreas is less interested in than Liz is ,\nGrad F: OK .\nProfessor D: so , you know . It 's good {disfmarker}\nGrad F: Do we have anything else to say about transcription ? About IBM stuff ?\nPhD B: Uh , Brian {disfmarker} I {disfmarker} I {vocalsound} sent bresset {disfmarker} {vocalsound} {vocalsound} sent Brian a message about {pause} {vocalsound} the meeting and I haven't heard back yet . So . I g hope he got it and hopefully he 's {disfmarker}\nGrad F: OK .\nPostdoc A: Hmm .\nPhD B: maybe he 's gone , I dunno . He didn't even reply to my message . So . I should probably ping him just to make sure that he got it . \nGrad F: Alright . So , we have a whole bunch of digits , if we wanna move on to digits .\nProfessor D: Actually , maybe I {disfmarker} One {disfmarker} one relate more related thing in transcription . So that 's the IBM stuff . We 've got that sorted out . Um , how 're we doing on the {disfmarker} on the rest of it ?\nPostdoc A: We 're doing well . I {disfmarker} I hire {disfmarker} I 've hired two extra people already , expect to hire two more .\nGrad F: Hmm .\nPostdoc A: And , um , {vocalsound} I 've prepared , um , uh , a set of five which I 'm {disfmarker} which I 'm calling set two , which are now being edited by my head transcriber , {vocalsound} in terms of spelling errors and all that . She 's also checking through and mar and {disfmarker} {vocalsound} and monitoring , um , the transcription of another transcriber . You know , I mean , she 's going through and doing these kinds of checks .\nProfessor D: Uh - huh .\nPostdoc A: And , I 've moved on now to what I 'm calling set three . I sort of thought if I do it in sets {disfmarker} groups of five , then I can have , like , sort of a {disfmarker} a parallel processing through {disfmarker} through the {disfmarker} the current .\nProfessor D: Uh - huh .\nPostdoc A: And {disfmarker} and you indicated to me that we have a g a goal now , {vocalsound} for the {disfmarker} for the , um , {nonvocalsound} {vocalsound} the , uh , DARPA demo , of twenty hours . So , I 'm gonna go up to twenty hours , be sure that everything gets processed , and released , and {disfmarker} {pause} {comment} and that 's {disfmarker} that 's what my goal is . Package of twenty hours right now , {vocalsound} and then once that 's done , move on to the next .\nProfessor D: Yeah , uh , so twenty hours . But I guess the other thing is that , um , that {disfmarker} that 's kinda twenty hours ASAP because the longer before the demo we actually have the twenty hours , the more time it 'll be for people to actually do cool things with it .\nPostdoc A: Mm - hmm . Good . I 'm {disfmarker} I 'm hiring people who , {vocalsound} uh , really are {disfmarker}\nProfessor D: So . OK .\nPostdoc A: They would like to do it full - time , several of these people . And {disfmarker} and I don't think it 's {vocalsound} possible , really , to do this full - time , but , that {disfmarker} what it shows is motivation to do as many hours as possible .\nProfessor D: Mm - hmm .\nGrad F: It 'll keep your accuracy up . Yep .\nProfessor D: Yeah .\nPostdoc A: And they 're really excellent .\nProfessor D: Yeah . Well , that 's good .\nPostdoc A: Yeah . Got a good core group now .\nProfessor D: Yeah , I mean , I guess the {disfmarker} So the difference if {disfmarker} if , um , if the IBM stuff works out , the difference in the job would be that they p primarily would be checking through things that were already done by someone else ?\nPostdoc A: Again . Mm - hmm .\nProfessor D: Is that most of what it {disfmarker} ?\nGrad F: And correcting .\nProfessor D: I mean {disfmarker} Correcting .\nGrad F: Correcting . We 'll {disfmarker} we 'll expect that they 'll have to move some time bins and do some corrections .\nPostdoc A: And I {disfmarker} you know , I 've also d uh , discovered {disfmarker} So with the new transcriber I 'm {disfmarker} um {disfmarker} So {disfmarker} Uh , lemme say that my , uh {disfmarker} So , um {disfmarker} At present , um , the people have been doing these transcriptions a channel at a time . And , that sort of , um , {vocalsound} is useful , and t you know , and then once in a while they 'll have to refer to the other channels to clear something up . OK . Well , {vocalsound} I realize that , um , w i we we 're using the pre - segmented version , and , um , the pre - segmented version is extremely useful , and wouldn't it be , useful also to have the visual representation of those segments ? And so I 've {disfmarker} {pause} uh , {pause} I , uh , uh , I 've {comment} trained the new one {disfmarker} uh , the new the newest one , {vocalsound} to , um , {vocalsound} use the visual from the channel that is gonna be transcribed at any given time . And that 's just amazingly helpful . Because what happens then , is you scan across the signal and once in a while you 'll find a blip that didn't show up in the pre - segmentation .\nGrad F: Oh , right .\nPostdoc A: And that 'll be something like {disfmarker} {vocalsound} I it 's ver {disfmarker} it 's interesting .\nGrad F: I see what you mean . A backchannel , or {disfmarker}\nPostdoc A: Once in a while it 's a backchannel .\nPhD E: Yep .\nPostdoc A: Sometimes it seems to be , um , similar to the ones that are being picked up .\nGrad F: Mm - hmm .\nPostdoc A: And they 're rare events , but you can really go through a meeting very quickly . You just {disfmarker} you just , you know , yo you s you scroll from screen to screen , looking for blips . And , I think that we 're gonna end up with , uh {pause} better coverage of the backchannels ,\nProfessor D: Yeah .\nPostdoc A: but at the same time we 're benefitting tremendously from the pre - segmentation because {vocalsound} there are huge places where there is just absolutely no activity at all . And , uh , the audio quality is so good {disfmarker}\nProfessor D: Mm - hmm .\nPhD B: So they can {disfmarker} they can , um , scroll through that pretty quick ?\nPostdoc A: Yeah . Mm - hmm .\nPhD B: That 's great .\nPostdoc A: Yeah . So I think that that 's gonna , also {pause} eh , {comment} you know , speed the efficiency of this part of the process .\nProfessor D: Hmm . OK . Uh , yeah . So , uh {disfmarker} Yeah . So let 's talk about the digits , since they 're not here yet .\nGrad F: Uh , so , we have a whole bunch of digits that we 've read and we have the forms and so on , um , but only a small number of that ha well , not a small number {disfmarker} only a subset of that has been transcribed . And so we need to decide what we wanna do . And , uh , Liz and Andreas {disfmarker} actually they 're not here , but , they did say at one point that they thought they could do a pretty good job of just doing a forced alignment . And , again , I don't think we 'll be able to do with that alone , because , um , sometimes people correct themselves and things like that . But {disfmarker} so , I was just wondering what people thought about how automated can we make the process of finding where the people read the digits , doing a forced alignment , and doing the timing .\nProfessor D: Well , forced alignment would be one thing . What about just actually doing recognition ?\nGrad F: Well , we {disfmarker} we know what they read , because we have the forms .\nProfessor D: No , they make mistakes .\nGrad F: Right . But , the point is that we wanna get a set of clean digits .\nPhD B: You 're talking about as a pre - processing step .\nProfessor D: Right .\nPhD B: Right , Morgan ?\nProfessor D: Um {disfmarker}\nPhD B: Is that what you 're {disfmarker} ?\nProfessor D: Yeah , I 'm {disfmarker} I 'm not quite sure what I 'm talking about . I mean {disfmarker} I {disfmarker} I mean , uh , we 're talking about digits now . And {disfmarker} and so , um , there 's a bunch of stuff that hasn't been marked yet . Uh . And , um , {vocalsound} there 's the issue that {disfmarker} that they {disfmarker} we know what {disfmarker} what was said , but do we ?\nGrad F: I mean , so one option i\nProfessor D: Because people make mistakes and stuff . I was just asking , just out of curiosity , if {disfmarker} if with , uh {disfmarker} uh , the SRI recognizer getting one percent word error , uh , would we {disfmarker} would we do {pause} better {disfmarker} ? So , if you do a forced alignment but the force but the {disfmarker} but the transcription you have is wrong because they actually made mistakes , uh , or {vocalsound} false starts , it 's {disfmarker} it 's much less c {vocalsound} it 's {pause} much less common than one percent ?\nGrad F: But that 's pretty uncommon . Um , if we could really get one percent on {disfmarker}\nProfessor D: We should be able to .\nGrad F: Well , I guess {disfmarker} yeah , I guess if we segmented it , we could get one percent on digits .\nProfessor D: Right ?\nPhD B: Yeah .\nProfessor D: Yeah . So that 's just my question . I 'm not saying it should be one way or the other , but it 's {disfmarker} If {disfmarker}\nGrad F: But , Well , there {disfmarker} there 're a couple different of doing it . We could use the tools I 've already developed and transcribe it . Hire some people , or use the transcribers to do it . We could let IBM transcribe it . You know , they 're doing it anyway , and unless we tell them different , they 're gonna transcribe it . Um , or we could try some automated methods .\nProfessor D: Well {disfmarker}\nGrad F: And my {disfmarker} my tendency right now is , well , if IBM comes back with this meeting and the transcript is good , just let them do it .\nProfessor D: Yeah , it 's {disfmarker} Y you raised a point , kind of , uh , euphemistically {disfmarker} but , I mean , m maybe it is a serious problem . Ho - what will they do when they go {disfmarker} hear \" beep {pause} seven {pause} beep {pause} seven three five two \" {disfmarker} I mean , {vocalsound} you think they 'll {disfmarker} we 'll get {disfmarker} ?\nGrad F: It 's pretty distinct .\nProfessor D: Yeah ?\nGrad F: The beeps are {pause} pre - recorded .\nPhD B: It 'll {comment} only be a problem for m for mine .\nPhD E: Yeah .\nPostdoc A: Well it {disfmarker} it {disfmarker} well , it 'd be preceded by \" I 'm reading transcript so - and - so \" ?\nPhD B: Yeah .\nGrad F: Yes .\nPostdoc A: So , I think if they 're processing it at {disfmarker}\nGrad F: I mean , it 'll be {disfmarker} it will be in the midst of a digit string .\nProfessor D: Yeah .\nGrad F: So {disfmarker} I mean it {disfmarker} sure , there {disfmarker} there might be a place where it 's \" beep seven {pause} beep eight {pause} beep {pause} eight {pause} beep \" . But , you know , they {disfmarker} they 're {disfmarker} they 're gonna macros for inserting the beep marks . And so , I {disfmarker} I don't think it 'll be a problem . We 'll have to see , but I don't think it 's gonna be a problem .\nProfessor D: OK . Well , I {disfmarker} I {disfmarker} I dunno , I {disfmarker} I think that that 's {disfmarker} if they are in fact going to transcribe these things , uh , certainly any process that we 'd have to correct them , or whatever is {disfmarker} needs to be much less elaborate for digits than for other stuff .\nGrad F: Right .\nProfessor D: So , why not ? Sure . That was it ?\nGrad F: That was it . Just , what do we do with digits ?\nProfessor D: OK .\nGrad F: We have so many of them , {vocalsound} and it 'd be nice to {pause} actually do something with them .\nProfessor D: Well , we {disfmarker} we {disfmarker} we wanna have them . Yeah , I {disfmarker}\nPhD I: You mean there 're more than ten ?\nGrad F: Anything else ? Your mike is a little low there .\nProfessor D: I in Berkeley , yeah . So , {vocalsound} uh {pause} You {disfmarker} you have to go a little early , right ? At twenty {disfmarker}\nPhD I: Well , I can stay till about , uh , three forty .\nProfessor D: Alright . So le let 's make sure we do the ones that {disfmarker} that , uh , saved you .\nPhD I: Yeah . Mm - hmm .\nProfessor D: So there was some {disfmarker} Uh {pause} {vocalsound} In {disfmarker} in {disfmarker} Adam 's agenda list , he had something from you about segmentation this last recognition ?\nPhD I: Well , yeah . So this is just partly to inform everybody , um , and {disfmarker} and of course to get , um , input .\nGrad F: Oops .\nPhD I: Um , so , {nonvocalsound} uh , we had a discussion {disfmarker} Don and Liz and I had discussion last week about how to proceed with , uh , you know , with Don 's work ,\nPhD E: Ch\nPhD I: and {disfmarker} {vocalsound} and {disfmarker} and , uh , one of the obvious things that occur to us was that we 're {disfmarker} since we now have Thilo 's segmenter and it works , you know , amazingly well , {vocalsound} um , we should actually basically re - evaluate the recognition , um , results using {disfmarker} you know , without cheating on the segmentations .\nPhD E: So {disfmarker}\nPhD I: And , that should be fairly {disfmarker}\nPhD E: And how do we find the transcripts for those so that {disfmarker} ? Yeah . The references for {disfmarker} for {pause} those segments ?\nPhD I: Oh , OK . So , there 's actually {disfmarker}\nPhD E: It 's not that {disfmarker}\nPhD I: Why do you ask ?\nGrad F: I could {disfmarker}\nPhD I: No , actually , um , NIST has , um m a fairly sophisticated scoring program {vocalsound} that you can give a , um {disfmarker} {vocalsound} a time ,\nGrad F: Hand ones .\nPhD G: Well {disfmarker}\nPhD E: OK .\nPhD I: uh {disfmarker} You know , you basically just give two {pause} time - marked sequences of words , and it computes the um {disfmarker} the , {comment} uh {disfmarker} {comment} you know , the {disfmarker} the {disfmarker} th\nPhD B: It does all the work for you .\nPhD I: it does all the work for you .\nPhD B: Yeah .\nPhD E: OK .\nPhD I: So , it {disfmarker} we just {disfmarker} and we use that actually in Hub - five to do the scoring . Um . So what we 've been using so far was sort of a {pause} simplified version of the scoring . And we can {disfmarker} we can handle the {disfmarker} the {disfmarker} the type of problem we have here .\nPhD E: So , basically you give some time constraints for {disfmarker} for the references and for {disfmarker} for the hypothesis ,\nPhD I: So , we ha Yeah . Right .\nPhD E: and {disfmarker} Yeah , OK .\nPhD G: Yeah .\nPhD I: Right .\nPhD G: Maybe the {pause} start of your speech and the end of it ,\nPhD I: So do\nPhD E: OK .\nPhD G: or stuff like that .\nPhD I: Right . It does time - constrained word - alignment .\nPhD E: OK .\nPhD I: So . So that should be possible . I mean that shouldn't be a problem . Uh , so that was the one thing , and the other was that , um {disfmarker} What was the other problem ? Oh ! That Thilo wanted to use {pause} the recognizer alignments to train up his , um , speech detector .\nPhD E: Yeah .\nPhD I: Um , so that we could use , uh {disfmarker} you know there wouldn't be so much hand {vocalsound} labelling needed to , uh {disfmarker} to generate training data for {disfmarker} for the speech detector .\nPhD E: Yeah . I 'm just in progress of {disfmarker} of doing that . So .\nPhD I: And I think you 're in the process of doing that .\nPhD E: Yeah .\nPhD I: So , you can {disfmarker} {comment} you can {disfmarker}\nPhD B: It 'll give you a lot more data , too . Won't it ?\nPhD E: Yeah . So , it 's basically {disfmarker} s I think , eight meetings or something which {disfmarker} which I 'm using , and , {vocalsound} it 's {disfmarker} {vocalsound} before it was twenty minutes of one meeting .\nPhD I: Mm - hmm .\nPhD E: So {disfmarker} should {comment} be a little bit better .\nPhD I: Right .\nPhD B: Great .\nPhD I: That won't be perfect {disfmarker} the alignments aren't perfect ,\nPhD E: Yeah . But {disfmarker}\nPhD I: but , um , it 's probably still better to have all this extra data , than {disfmarker}\nPhD G: Yeah .\nPhD E: Yeah . Yep .\nPhD I: Yeah .\nPhD E: We 'll see that .\nPhD I: Yeah .\nProfessor D: OK .\nPhD G: Actually , I had a question about that . If you find that you can {vocalsound} lower the false alarms that you get where there 's no speech , that would be useful {pause} for us to know . So , um {disfmarker}\nPhD E: There were the false alarms .\nPhD G: Yeah . So , {vocalsound} r right now you get f fal you know , false {disfmarker} false , uh , speech regions when it 's just like , um , {vocalsound} breath or something like that ,\nPhD E: OK . Yeah . Yep .\nPhD G: and I 'd be interested to know the {disfmarker} wha if you retrain um ,\nPhD E: Yeah .\nPhD G: do those actually go down or not ? Because {pause} of {disfmarker}\nPhD E: Yeah . I 'll {disfmarker} can make {disfmarker} an can , like , make a c comparison of {disfmarker} of the old system to the {disfmarker} to the new one , and {pause} then {disfmarker}\nPhD G: Yeah , just to see if by doing nothing in the modeling of {disfmarker} just having that training data wh what happens .\nPhD E: Yeah . Yeah . Yep .\nProfessor D: Um another one that we had on Adam 's agenda {pause} that definitely involved you was s something about SmartKom ?\nGrad F: Right . So , Rob Porzel {disfmarker} eh , Porzel ? and the , uh {disfmarker} Porzel {disfmarker} and the , uh , SmartKom group are collecting some dialogues .\nPhD I: Porzel . Porzel .\nGrad F: Basically they have one person sitting in here , looking at a picture , and a wizard sitting in another room somewhere . And , uh , they 're doing a travel task . And , uh , it involves starting {disfmarker} I believe starting with a {disfmarker} It 's {disfmarker} it 's always the wizard , but it starts where the wizard is pretending to be a computer and it goes through a , uh , {vocalsound} speech generation system .\nPhD E: Yeah . Actually , it 's changed to a synthesis for {disfmarker} for the first part now .\nGrad F: Synthesis system .\nPhD E: Yeah .\nGrad F: Um , and then , it goes to a real wizard and they 're evaluating that . And they wanted to use this equipment , and so the w question came up , is {disfmarker} well , here 's some more data . Should this be part of the corpus or not ? And my attitude was yes , because there might be people who are using this corpus for {pause} acoustics , as opposed to just for language . Um , or also for dialogue of various sorts . Um , so it 's not a meeting . Right ? Because it 's two people and they 're not face to face .\nProfessor D: Wait a minute . So , I just wanted to understand it , cuz I {disfmarker} I 'm {disfmarker} uh , hadn't quite followed this process .\nPhD E: Yeah .\nProfessor D: Um . So , it 's wizard in the sen usual sense that the person who is asking the questions doesn't know that it 's , uh , a machi not a machine ?\nPhD I: Right .\nGrad F: At the beginning .\nPhD I: Actually {disfmarker} actually , w w the {disfmarker} the {disfmarker} We do this {disfmarker} I dunno who came up with it , but I think it 's a really clever idea . We simulate a computer breakdown halfway through the session , and so then after that , the person 's told that they 're now talking to a , uh {disfmarker} to a human .\nProfessor D: Yeah .\nPhD E: It 's a human operator .\nProfessor D: Yeah .\nPhD E: Yeah .\nGrad F: But of course they don't know that it 's the same person both times .\nPhD I: So , we {disfmarker} we collect {disfmarker} we collect both human - computer and human - human data , essentially , in the same session .\nProfessor D: You might wanna try collecting it the other way around sometime , saying that th the computer isn't up yet\nPostdoc A: Hmm .\nProfessor D: and then {disfmarker} so then you can separate it out whether it 's the beginning or end kind of effects .\nPhD I: That 's an idea .\nProfessor D: But , yeah .\nGrad F: Yep .\nPhD I: Yeah .\nPostdoc A: That 's a good idea .\nGrad F: \" I have to go now . You can talk to the computer . \"\nPhD B: It 's a lot more believable , too ,\nGrad F: \" No ! \"\nPhD B: if you tell them that they 're {disfmarker} the computer part is running on a Windows machine . And the whole breakdown thing kinda makes sense .\nPhD I: O Just {disfmarker} just reboot it .\nGrad F: Abort {disfmarker} abort , retry , fail ?\nPhD G: So did they actually save the far - field {pause} data ?\nPhD E: Yes .\nGrad F: Well , this was {disfmarker} this was the question .\nPhD G: Cuz at first they weren't {disfmarker} they weren't sa\nPhD I: Yeah .\nGrad F: So {disfmarker} so they were saying they were not going to ,\nPhD E: Yeah .\nPhD G: OK .\nGrad F: and I said , \" well that 's silly , if {disfmarker} if we 're gonna try to do it for a corpus , there might be people who are interested in acoustics . \"\nPhD G: Yeah .\nPhD I: Wow .\nPhD E: No .\nPhD G: Or {disfmarker}\nPhD E: projector {comment} We were not saying we are not {pause} doing it .\nPhD G: Yeah .\nProfessor D: S\nPhD E: We wer we just wanted to do {disfmarker}\nPhD I: No , the {disfmarker} the question is do we save one or two far - field channels or all of them ?\nPhD G: Right .\nPhD E: Yeah . Yeah .\nGrad F: I {disfmarker} I see no reason not to do all of them .\nProfessor D: Um {disfmarker}\nGrad F: That {disfmarker} that if we have someone who is doing acoustic studies , uh , it 's nice to have the same for every recording .\nPhD G: Nnn . Yeah .\nPhD I: Hmm .\nProfessor D: So , what is the purpose of this recording ?\nPhD I: Mm - hmm .\nProfessor D: This is to get acoustic and language model training data for SmartKom. OK .\nPhD I: It 's to be traini to b training data and development data for the SmartKom {pause} system .\nPhD E: The English system ? Yeah .\nPhD I: Yeah . Right . Right .\nPhD B: Where does this {disfmarker} ?\nProfessor D: \nPhD G: Maybe we can have him vary the microphones , too ,\nProfessor D: Well ,\nPhD E: B\nPhD G: or they 're different s speakers .\nGrad F: Right . So {disfmarker} so {disfmarker} so for their usage , they don't need anything .\nProfessor D: so why not {disfmarker} ?\nPhD E: Yeah .\nGrad F: Right ?\nPhD E: But {disfmarker} but I 'm not sure about the legal aspect of {disfmarker} of that . Is {disfmarker} is there some contract with SmartKom or something about the data ?\nPhD I: Yeah .\nPhD E: What they {disfmarker} or , is {disfmarker} is that our data which we are collecting here ,\nProfessor D: We 've never signed anything that said that we couldn't use anything that we did .\nPhD E: or {disfmarker} ? OK . OK .\nPhD I: We weren't supposed to collect any data .\nPhD E: So . OK .\nProfessor D: Yeah .\nPhD E: So . Yeah , th th that was the question .\nPhD I: This was all {disfmarker}\nPhD E: If {disfmarker} if {disfmarker} ? Yeah .\nPhD I: Yeah .\nProfessor D: No that 's not a problem .\nPhD E: Basically .\nProfessor D: I {disfmarker} L look , it seems to me that if we 're doing it anyway and we 're doing it for these {disfmarker} these purposes that we have , {vocalsound} and we have these distant mikes , we definitely should re should save it all as long as we 've got disk space ,\nPhD I: Mm - hmm .\nProfessor D: and disk is pretty cheap .\nPhD I: OK .\nProfessor D: So should we save it ?\nGrad F: And then {disfmarker}\nProfessor D: Now th Yeah . So we save it because it 's {disfmarker} it {disfmarker} it 's potentially useful . And now , what do we do with it is {disfmarker} is a s separate question .\nGrad F: Right .\nProfessor D: I mean , anybody who 's training something up could {vocalsound} choose to put it {disfmarker} eh , to u include this or not .\nPhD I: Right .\nProfessor D: I {disfmarker} I would not say it was part of the meetings corpus . It isn't . But it 's some other data we have , and if somebody doing experiment wants to train up including that then they can . Right ?\nPhD I: Mm - hmm .\nGrad F: So it 's {disfmarker} It {disfmarker} it {disfmarker} I guess it {disfmarker} the {disfmarker} begs the question of what is the meeting corpus . So if , at UW they start recording two - person hallway conversations is that part of the meeting corpus ?\nProfessor D: I think it 's {disfmarker} I {disfmarker} I think {disfmarker} I th think the idea of two or more people conversing with one another is key .\nGrad F: Well , this has two or more people conversing with each other .\nProfessor D: Nnn , well\nPhD E: Yeah .\nPostdoc A: Well this {disfmarker}\nGrad F: They 're just not face to face .\nPhD G: What if we just give it a {disfmarker} a name like we give these meetings a name ?\nProfessor D: No , it doesn't . Right ? It has {disfmarker}\nGrad F: I mean , that was my intention .\nPhD G: And then later on some people will consider it a meeting and some people won't ,\nPostdoc A: Well this {disfmarker}\nProfessor D: Yeah .\nGrad F: That was my intention . So {disfmarker} so {disfmarker} s {vocalsound} so part of the reason that I wanted to bring this up is , {vocalsound} do we wanna handle it as a special case or do we wanna fold it in ,\nPhD G: and {disfmarker} Just give it a {vocalsound} title .\nPostdoc A: Oh .\nProfessor D: I think it is a s\nGrad F: we give everyone who 's involved as their own user ID , give it session I Ds , {vocalsound} let all the tools that handle Meeting Recorder handle it , or do we wanna special case it ? And if we were gonna special case it , who 's gonna do that ?\nPhD E: So .\nPhD I: Well , it {disfmarker} it makes sense to handle it with the same infrastructure , since we don't want to duplicate things unnecessarily .\nPhD E: It {disfmarker} it {disfmarker} it {disfmarker}\nPostdoc A: I think {disfmarker}\nPhD I: But as far as distributing it , we shouldn't label it as part of this meeting corpus .\nProfessor D: Yeah .\nPhD I: We should let it be its own corp\nPostdoc A: Well it 's {disfmarker} it {disfmarker} well , because {disfmarker}\nGrad F: I don't see why not . It 's just a different topic .\nPostdoc A: I ha I have an extra point , which is the naturalness issue . Because we have , like , meetings that have a reason . That 's one of the reasons that we were talking about this . And {disfmarker} and those {disfmarker} and this sounds like it 's more of an experimental setup .\nProfessor D: Yeah .\nPostdoc A: It 's got a different purpose .\nProfessor D: It 's scenario - based , it 's {disfmarker} it 's human - computer interface {disfmarker} {vocalsound} it 's really pretty different .\nPostdoc A: Yeah .\nProfessor D: But I I {disfmarker} I have no problem with somebody folding it in for some experiment they 're gonna do , but I don't think i it {disfmarker} it doesn't match anything that we 've described about meetings .\nGrad F: Mm - hmm .\nProfessor D: Whereas everything that we talked about them doing at {disfmarker} at UW and so forth really does . They 're actually talking {disfmarker}\nGrad F: OK . So w so what does that mean for how we are gonna organize things ?\nPostdoc A: Hmm .\nPhD E: Yeah .\nProfessor D: You can {disfmarker} you can {disfmarker} Again , as {disfmarker} as I think Andreas was saying , {vocalsound} if you wanna use the same tools and the same conventions , there 's no problem with that . It 's just that it 's , you know , different directory , it 's called something different , it 's {disfmarker} you know . It is different . You can't just fold it in as if it 's {disfmarker} I mean , digits are different , too . Right ?\nGrad F: Yeah , but those are folded in ,\nPhD I: It might also be potentially confusing .\nGrad F: and it 's just {disfmarker} you just mark the transcripts differently . So {disfmarker} so one option is you fold it in ,\nPhD I: Right .\nGrad F: and just simply in the file you mark somewhere that this is this type of interaction , rather than another type of interaction .\nPhD I: Yeah , I th\nProfessor D: Well , I don I wouldn't call reading digits \" meetings \" . Right ? I mean , we {disfmarker} we {disfmarker} we were doing {disfmarker}\nGrad F: Well , but {disfmarker} but , {vocalsound} I put it under the same directory tree .\nProfessor D: Well {disfmarker}\nGrad F: You know , it 's in \" user doctor speech data MR \" .\nPhD G: Can we just have a directory called , like , \" other stuff \" ?\nGrad F: Other .\nPhD G: And {disfmarker} Well {disfmarker} or , I dunno .\nProfessor D: I mean , I don't care what directory tree you have it under .\nPhD G: And {disfmarker} {vocalsound} and just , um , store it there .\nProfessor D: Right ? I mean that 's just a {disfmarker}\nGrad F: OK . My preference is to have a single procedure so that I don't have to think too much about things .\nPhD I: Yes .\nPhD G: I mean {disfmarker}\nProfessor D: Yeah .\nGrad F: And , just have a marking .\nProfessor D: O - You {disfmarker} you can use whatever procedure you want that 's p convenient for you .\nGrad F: If we do it any other way that means that we need a separate procedure , and someone has to do that .\nProfessor D: All I 'm saying is that there 's no way that we 're gonna tell people that reading digits is meetings . And similarly we 're not gonna tell them that someone talking to a computer to get travel information is meetings .\nGrad F: Right .\nProfessor D: Those aren't meetings . But if it makes it easier for you to pu fold them in the same procedures and have them under the same directory tree , knock yourself out .\nPhD B: There 's a couple other questions that I have too ,\nProfessor D: You know ?\nPhD B: and {disfmarker} and {pause} one of them is , what about , uh , consent issues ? And the other one is , what about transcription ? Are {disfmarker} ?\nPhD E: Transcription is done in Munich .\nPhD B: OK . So we don't have to worry about transcribing it ?\nProfessor D: Alright .\nPhD E: Yeah .\nGrad F: So , w we will hafta worry about format .\nPhD I: That 's a {disfmarker} that 's another argument to keep it separate , because it 's gonna follow the SmartKom transcription conventions and not the ICSI meeting transcription conventions .\nPhD E: Yeah .\nGrad F: Oh , OK .\nProfessor D: Ah . Good point .\nGrad F: OK . Well , I didn't realize that . That 's {disfmarker} that 's a {disfmarker}\nProfessor D: Good point . But I 'm sure no one would have a problem with our folding it in for some acoustic modeling or {disfmarker} or some things . Um . Do we h do we have , uh , um , American - born folk , uh , reading German {disfmarker} German , uh , pla uh , place names and so forth ? Is that {disfmarker} ?\nPhD E: Yeah .\nPhD I: Exactly .\nProfessor D: Yeah , great .\nPhD E: Yeah .\nGrad F: Yep .\nPhD I: Yeah .\nGrad F: They {disfmarker} they even have a reading list .\nPhD B: I bet that sounds good , huh ?\nProfessor D: Yeah .\nGrad F: It 's pretty funny .\nPhD I: Yeah .\nPhD E: You can do that if you want .\nPhD B: OK .\nProfessor D: Yeah .\nPhD B: I dunno if you want that .\nProfessor D: Right .\nPhD I: Yeah .\nPostdoc A: Hmm .\nProfessor D: Heidelberg\nGrad F: So {disfmarker}\nPhD I: Exactly\nGrad F: Disk might eventually be an issue so we might {disfmarker} we {disfmarker} we might need to , uh , {vocalsound} get some more disk pretty soon .\nPhD I: Do you wanna be a subject ?\nProfessor D: Yeah , I be pretty good .\nPhD I: We {disfmarker} Yeah .\nGrad F: We 're about {disfmarker} we 're about half {disfmarker} halfway through our disk right now .\nPhD B: Yeah .\nPhD I: That was one of our concerns .\nPhD B: Are we only half ? I thought we were more than that .\nGrad F: We 're probably a little more than that because we 're using up some space that we shouldn't be on . So , once everything gets converted over to the disks we 're supposed to be using we 'll be probably , uh , seventy - five percent .\nPhD B: Well , when I was looking for space for Thilo , I found one disk that had , uh , I think it was nine gigs and another one had seventeen .\nGrad F: Yep .\nPhD B: And everything else was sorta committed . Uh {disfmarker}\nGrad F: Were those backed - up or non - backed - up ?\nPhD B: Those were non - backed - up .\nPhD E: Non - back - up .\nGrad F: Right . So that 's different .\nPhD B: S oh , you 're talking about backed - up .\nGrad F: I 'm much more concerned about the backed - up . The non - backed - up ,\nPhD B: I haven't looked to see how much of that we have .\nGrad F: yeah , i is cheap . I mean , if we need to we can buy a disk , hang it off a s uh , workstation . If it 's not backed - up the sysadmins don't care too much .\nProfessor D: Yeah . So , I mean , pretty much anytime we need a disk , we can get it at the rate that we 're {disfmarker}\nPhD I: You can {disfmarker} I shouldn't be saying this , but , you can just {disfmarker} you know , since the back - ups are every night , you can recycle the backed - up diskspace .\nGrad F: Yeah . But that 's {disfmarker} that 's {disfmarker} {pause} that 's risky .\nProfessor D: Yeah . You really shouldn't be saying {disfmarker}\nGrad F: Mmm . Mmm .\nPhD I: I didn't say that .\nGrad F: Yeah , that 's right .\nPhD I: I didn't say that .\nGrad F: Beep that out .\nProfessor D: Da - we had allowed Dave to listen to these {disfmarker} {vocalsound} these , {vocalsound} uh , recordings .\nPhD I: Right .\nProfessor D: Um {disfmarker} {vocalsound} Yeah , I me and there 's been this conversation going on about getting another file server , and {disfmarker} and {vocalsound} we can do that .\nPhD I: Mm - hmm .\nProfessor D: We 'll take the opportunity and get another big raft of {disfmarker} {vocalsound} of disk , I guess .\nGrad F: Yeah . It 's really the back - up issue rather than the file server issue .\nPhD I: Well , I think {disfmarker} {comment} I think there 's an argument for having {disfmarker} you know , you could use our old file server for {disfmarker} for disks that have data that {pause} is very rarely accessed , and then have a fast new file server for data that is , um , heavily accessed .\nGrad F: Yeah . My understanding is , the issue isn't really the file server .\nPhD I: Yeah .\nGrad F: We could always put more disks on .\nPhD I: Yeah . It 's the back it 's the back - up capaci\nGrad F: It 's the back - up system .\nPhD I: Yeah .\nGrad F: So {disfmarker} which is near saturation , apparently . So .\nPhD B: I think {disfmarker} I think the file server could become an issue as we get a whole bunch more new compute machines .\nProfessor D: Soon .\nPhD B: And we 've got , you know , fifty machines trying to access data off of Abbott at once .\nGrad F: Well , we 're alright for now because the network 's so slow .\nPhD I: I mean , I think {disfmarker} I think we 've raised this before and someone said this is not a reliable way to do it , but the {disfmarker} What about putting the stuff on , like , C - CD - ROM or DVD or something ?\nGrad F: Yeah . That was me . I was the one who said it was not reliable . The - they {disfmarker} they wear out .\nPhD I: OK . Oh , OK .\nGrad F: Yeah . The {disfmarker} the {disfmarker} th\nPhD I: But they wear out just from sitting on the shelf ?\nGrad F: Yep . Absolutely .\nPhD I: Or from being {pause} read and read ?\nGrad F: No . Read and write don't hurt them too much unless you scratch them .\nPhD I: Oh , OK .\nGrad F: But the r the write once , and the read - writes , don't last . So you don't wa you don't wanna put ir un reproduceable data {pause} on them .\nPhD I: Uh - huh .\nPhD B: Wear out after what amount of time ?\nGrad F: Year or two .\nPostdoc A: Would it be {disfmarker} ?\nProfessor D: Year or two ?\nGrad F: Yep .\nProfessor D: Wow .\nPostdoc A: Hmm .\nPhD I: But if that {disfmarker} then you would think you 'd {pause} hear much more clamoring about data loss\nPhD E: Yeah .\nPhD I: and {disfmarker}\nProfessor D: I mean , yeah , all the L\nGrad F: I {disfmarker} I don't know many people who do it on CD . I mean , they 're {disfmarker} the most {disfmarker} fo\nProfessor D: LDC - all the LDC distributions are on CD - ROM .\nPhD G: Yeah .\nGrad F: They 're on CD , but they 're not {disfmarker} tha that 's not the only source .\nPhD G: Like {disfmarker}\nGrad F: They have them on disk . And they burn new ones every once in a while . But if you go {disfmarker} {vocalsound} if you go k\nPhD I: But , you know , we have {disfmarker}\nPhD G: But we have like thirty {pause} you know , from {pause} ten years ago ?\nProfessor D: We have all sorts of CD - ROMs from a long time ago .\nPhD G: No .\nPhD E: Yeah .\nPhD G: Yeah !\nGrad F: Well , th th OK .\nPhD G: Ten years ago .\nPhD I: Right .\nPhD G: Ninety - one , and they 're still all fine .\nProfessor D: Yeah .\nGrad H: Were they burned or were they pressed ?\nPhD G: Uh , both . I 've burned them and they 're still OK .\nGrad H: Yeah .\nGrad F: The {disfmarker} the pressed ones last for\nPhD G: I mean , usually they 're {disfmarker}\nGrad F: well , not forever , they 've been finding even those degrade .\nProfessor D: Oh , I see .\nGrad F: But , uh , the burned ones {disfmarker} I mean , when I say two or three years what I 'm saying is that I have had disks which are gone in a year .\nPhD G: That 's what I {disfmarker}\nGrad F: On the average , it 'll probably be three or four years . But , uh {disfmarker} I {disfmarker} I {disfmarker} you don't want to per p have your only copy on a media that fails .\nPhD I: Mmm .\nGrad F: And they do . Um , if you have them professionally pressed , y you know , they 're good for decades .\nPhD I: So how about {disfmarker} ? So {disfmarker} so how about putting them on that plus , like on a {disfmarker} on {disfmarker} on DAT or some other medium that isn't risky ?\nGrad F: I think th um , we can already put them on tape . And the tape is hi is very reliable .\nPhD I: OK . Mm - hmm .\nGrad F: So the {disfmarker} the only issue is then {pause} if we need access to them . So that 's fine f if we don't need access to them .\nPhD I: Right . Well , if {disfmarker} if {disfmarker} if you {disfmarker} if they last {disfmarker} Say , they actually last , like , five years , huh , in {disfmarker} in the typical case , and {disfmarker} and occasionally you might need to recreate one , and then you get your tape out , but otherwise you don't . Can't you just {disfmarker} you just put them on {disfmarker} ?\nGrad H: So you just archive it on the tape , and then put it on CD as well ?\nPhD I: Yeah . Right .\nGrad F: Oh . So you 're just saying put them on C Ds for normal access .\nGrad H: Yeah .\nPhD I: Right .\nPhD B: What you {disfmarker}\nGrad F: Yeah . I mean , you can do that but that 's pretty annoying , because the C Ds are so slow .\nPhD G: See {disfmarker} Yeah .\nGrad H: Yeah .\nPhD I: Mmm .\nPhD B: What 'd be nice is a system that re - burned the C Ds every {vocalsound} year .\nPhD G: H everytime it was a \" gonna \" {disfmarker} \" gonna die \" .\nProfessor D: Well {disfmarker}\nGrad F: Well , I mean , the C Ds are {disfmarker} are an op\nPhD E: Yeah .\nPhD I: It 's like {disfmarker} like dynamic ra DRAM .\nPhD E: Just before .\nPhD B: Yeah .\nPhD G: Just before they be before it goes bad , it burns them in .\nGrad F: The {disfmarker} the CD is an alternative to tape .\nGrad H: Yeah .\nGrad F: ICSI already has a perfectly good tape system and it 's more reliable .\nProfessor D: You know {disfmarker} I would think {disfmarker}\nGrad F: So for archiving , we 'll just use tape .\nPhD I: One {disfmarker} one thing I don't understand is , if you have the data {disfmarker} if {disfmarker} if you if the meeting data is put on disk exactly once , then it 's backed - up once and the back - up system should never have to bother with it , uh , more than once .\nGrad F: Well , regardless {disfmarker} Well , first of all there was , um , a problem with the archive in that I was every once in a while doing a chmod on all the directories an or recursive chmod and chown , because {vocalsound} they weren't getting set correctly every once in a while ,\nPhD I: Mm - hmm .\nGrad F: and I was just , {vocalsound} doing a minus R star , {vocalsound} not realizing that that caused {pause} it to be re - backed - up .\nPhD I: Mm - hmm .\nPhD G: Ah .\nGrad F: But normally you 're correct . But even without that , the back - up system is becoming saturated .\nPhD I: But {disfmarker} but this back - up system is smart enough to figure out that something hasn't changed and doesn't need to be {pause} backed - up again .\nProfessor D: The b I think th the {disfmarker} at least the once tha that you put it on , it would {disfmarker} {vocalsound} it would {comment} {vocalsound} kill that .\nGrad F: Sure , but we still have enough changed that the nightly back - ups are starting to take too long .\nPhD I: OK . So {disfmarker} so then , if {disfmarker} So {disfmarker} so then , let 's {disfmarker}\nProfessor D: So .\nGrad F: It has nothing to do with the meeting . It 's just the general ICSI back - up system is becoming saturated .\nPhD I: Right . OK . Right . So , what if we buy , uh {disfmarker} uh , what {disfmarker} what do they call these , um {pause} high density {disfmarker} ?\nGrad F: Well , why don't you have this {disfmarker} have a {disfmarker} this conversation with Dave Johnson tha rather than with me ?\nPhD I: No , no . Because this is {pause} maybe something that we can do without involving Dave , and {disfmarker} and , putting more burden on him . How about we buy , uh {disfmarker} uh {disfmarker} uh , one of these high density tape drives ? And we put the data actually on non - backed - up disks . And we do our own back - up once and for all {disfmarker} all , and then {disfmarker} and we don't have to bother this @ @ up ?\nGrad F: Actually , you know , we could do that just with the tape {disfmarker} with the current tape .\nPhD I: I dunno what the these tapes {disfmarker} uh , at some point these {disfmarker} I dunno . What kind of tape drive is it ?\nGrad F: I dunno but it 's an automatic robot so it 's very convenient .\nPhD I: Is it {disfmarker} is {disfmarker} ?\nProfessor D: Wh The o the one that we have ?\nGrad F: You just run a program to restore them .\nPhD I: Right .\nProfessor D: The {disfmarker} I mean {disfmarker}\nGrad F: Yeah .\nPhD I: But it might interfere with their back - up schedule ,\nPhD G: But {disfmarker}\nProfessor D: No , we have s we {disfmarker} Don't we have our own ?\nPhD I: eh .\nProfessor D: Something wi th that doesn't {disfmarker} that isn't used by the back - up gang ? Don't we have something downstairs ?\nPostdoc A: Well they {disfmarker}\nPhD B: What kinda tape drive ?\nProfessor D: Just in {disfmarker} ? Yeah .\nGrad F: Well {disfmarker} but {disfmarker} no , but Andreas 's point is a good one . And we don't have to do anything ourselves to do that . They 're already right now on tape .\nPhD I: Right .\nGrad F: Right . So your {disfmarker} your point is , and I think it 's a good one , that we could just get more disk and put it there .\nPhD I: Mmm . On an XH {disfmarker} uh , X {disfmarker} X whatever partition .\nGrad F: Yeah . That 's not a bad idea .\nPhD I: Yeah .\nProfessor D: Yeah , that 's basically what I was gonna say , is that a disk is {disfmarker} is so cheap it 's es essentially , you know , close to free . And the only thing that costs is the back - up {pause} issue , {vocalsound} eh , to first order .\nGrad F: So once it 's on tape {disfmarker}\nPhD I: Right . Right .\nProfessor D: And we can take care of that by putting it on non - back {pause} up drives and just backing it up once onto this tape .\nPhD I: Mm - hmm .\nGrad F: I think that 's a good idea .\nPhD I: Right .\nProfessor D: Oh . Yeah .\nPhD I: OK .\nProfessor D: Good . It 's good .\nPhD G: So , who 's gonna do these back - ups ? The people that collect it ?\nGrad F: Uh Well , I 'll talk to Dave , and {disfmarker} and see what th how {disfmarker} {nonvocalsound} what the best way of doing that is .\nPhD B: It 's probably gonna n\nGrad F: There 's a little utility that will manually burn a tape for you , and that 's probably the right way to do it .\nPhD B: Yeah , and we should probably make that part of the procedure for recording the meetings .\nPhD G: Well , s\nGrad F: Yep .\nPhD G: Yeah . That 's what I 'm wondering , if {disfmarker}\nGrad F: Well {pause} we 're g we 're gonna automate that .\nPhD G: OK .\nGrad F: My intention is to {pause} do a script that 'll do everything .\nPhD G: I mean , you don't have to physically put a tape in the drive ?\nGrad F: No . It 's all tape robot ,\nPhD G: Or s ? s ? {comment} Oh , OK .\nGrad F: so you just sit down at your computer and you type a command .\nPhD G: So it 's just {disfmarker} Oh , OK .\nPhD I: Yeah , but then you 're effectively using the resources of the back - up system . Or is that a different tape robot ?\nGrad F: Yeah .\nPhD G: But not at the same time .\nGrad F: But y but you would be anyway .\nPhD B: No , no , no .\nGrad F: Right ?\nPhD B: He 's saying get a whole different drive .\nGrad F: Because {disfmarker}\nPhD I: No , no . See {disfmarker}\nGrad F: But there 's no reason to do that .\nPhD I: Yeah , just give a dedi\nGrad F: It {disfmarker} we already have it there and it {disfmarker} it 's {disfmarker}\nPhD I: Well , I 'm saying is @ @ i if you go to Dave , and {disfmarker} and {disfmarker} and ask him \" can I use your tape robot ? \" , he will say , \" well {pause} that 's gonna screw up our back - up operation . \"\nGrad F: No , we won't . He 'll say \" if {disfmarker} if that means {pause} that it 's not gonna be backed - up standardly , great . \"\nProfessor D: He - I {disfmarker} Dave has {disfmarker} has promoted this in the past . So I don't think he 's actually against it .\nGrad F: Yeah . It 's {disfmarker} it 's definitely no problem .\nPhD I: Oh , OK . Alright .\nProfessor D: Yeah .\nPhD I: Alright .\nProfessor D: OK .\nPhD I: Good .\nPhD G: What about if the times overlap with the normal back - up time ?\nGrad F: Um , it 's {disfmarker} it 's just {disfmarker} it 's just a utility which queues up . It just queues it up and {disfmarker} and when it 's available , it will copy it .\nPhD G: OK .\nProfessor D: Yeah .\nGrad F: And then you can tell it to then remove it from the disk or you can , you know , do it a a few days later or whatever you wanna do , after you confirm that it 's really backed - up .\nPhD G: OK .\nGrad F: NW {disfmarker} ?\nPostdoc A: You saying NW archive ?\nGrad F: NW archive .\nPostdoc A: Yep {comment} {vocalsound} And if you did that during the day it would never make it to the nightly back - ups .\nGrad F: That 's what it is .\nProfessor D: OK .\nGrad F: Right .\nPostdoc A: And then there wouldn't be this extra load .\nPhD I: Well , it {disfmarker} if he {disfmarker} you have to put the data on a {disfmarker} on a non - backed - up disk to begin with .\nPostdoc A: Well , but you can have it NW archive to {disfmarker} you can have , {vocalsound} uh , a non - backed - up disk NW archived ,\nGrad F: Right .\nPhD I: So that {disfmarker} so that {disfmarker} otherwise you don't {disfmarker} you {disfmarker}\nPostdoc A: and it 'll never show up on the nightly back - ups .\nGrad F: Right . And then it never {disfmarker}\nPhD I: Right . Right .\nGrad F: Right . Which I 'm sure would make ever the sysadmins very happy .\nPhD I: Right .\nPostdoc A: Yeah .\nGrad F: So , I think that 's a good idea .\nPhD I: OK .\nGrad F: That 's what we should do .\nPhD I: OK .\nGrad F: So , that means we 'll probably wanna convert all {disfmarker} all those files {disfmarker} filesystems to non - backed - up media .\nPhD B: That sounds good .\nProfessor D: Yeah .\nGrad F: Yep .\nProfessor D: Um , another , thing on the agenda said SRI recognition experiments ? What 's that ?\nPhD I: SRI recognition ? Oh .\nGrad F: That wasn't me .\nProfessor D: Uh .\nPhD I: Um . well ,\nProfessor D: Who 's that ?\nPhD I: we have lots of them . Uh , I dunno . Chuck , do you have any {disfmarker} any updates ?\nPhD B: N I 'm successfully , uh , increasing the error rate . Uh {disfmarker}\nGrad F: That 's good .\nGrad H: Mmm .\nPhD I: Oh .\nPhD G: Lift the Herve approach .\nPhD B: Yeah . So , I mean I 'm just playing with , um , the number of Gaussians that we use in the {disfmarker} the recognizer , and {disfmarker}\nPhD I: Well , you have to sa you have to {pause} tell people that you 're {disfmarker} you 're doing {disfmarker} you 're trying the tandem features .\nPhD B: Yes , I 'm using tandem features .\nGrad F: Oh you are ?\nPhD B: And {disfmarker}\nGrad F: Cool .\nPhD I: A and I 'm still tinkering with the PLP features .\nGrad F: \nProfessor D: Yeah , I got confused by the results . It sai because {disfmarker} uh , the {pause} meeting before , {vocalsound} you said \" OK , we got it down to where they 're {disfmarker} they 're within a tenth of a percent \" .\nPhD B: That was on males .\nPhD I: Right . That was {disfmarker} that was before I tried it on the females .\nProfessor D: Oh .\nPhD I: See , women are nothi are , trouble .\nProfessor D: It 's the women are the problem . OK .\nPhD I: Right ? As we all know . So .\nPhD G: Well , let 's just say that men are simple .\nPhD I: So {disfmarker} {comment} so , when {disfmarker} So I {disfmarker} I had {disfmarker} I ha\nGrad F: That was a quick response .\nPhD I: So , we had reached the point where {disfmarker}\nPhD G: I 'm well rehearsed .\nProfessor D: Yeah .\nPhD I: we had reached the point where , {comment} um , on the male portion of the {pause} development set , the , um {disfmarker} or one of the development sets , I should say {disfmarker} {vocalsound} the , um {disfmarker} the male error rate with , uh , ICSI PLP features was pretty much identical with , uh , SRI features . which are {pause} MFCC . So , um , then I thought , \" Oh , great . I 'll j I 'll {disfmarker} just let 's make sure everything works on the females . \" And the error rate {disfmarker} you know , there was a three percent difference .\nProfessor D: Oh . Uh - huh .\nPhD I: So ,\nPhD G: Is there less training data ?\nPhD I: uh {disfmarker}\nPhD G: I mean , we don\nPhD I: No , actually there 's more training data .\nPhD G: This is on just digits ?\nProfessor D: No .\nPhD I: No , no .\nGrad F: No .\nPhD B: Hub - five .\nGrad F: It 's , uh , Swi\nPhD G: Oh , sorry . OK . This is on {disfmarker}\nPhD I: This is Hub - five .\nPhD G: Oh , OK .\nGrad F: Hub - five . Yeah .\nPhD I: Yeah . Um , and the test data is CallHome and Switchboard . So , uh {disfmarker} so then {pause} um {disfmarker} Oh , and plus the {disfmarker} the vocal tract {pause} length normalization didn't {disfmarker} actually made things worse . So something 's really seriously wrong . So {disfmarker} Um {disfmarker}\nProfessor D: Aha ! OK .\nPhD I: So {disfmarker} So {disfmarker}\nProfessor D: So {disfmarker} but you see , now , between {disfmarker} between the males and the females , there 's certainly a much bigger difference in the scaling range , than there is , say , just within the males . And what you were using before was scaling factors that were just from the {disfmarker} the m the {pause} SRI front - end . And that worked {disfmarker} that worked fine .\nPhD I: That 's true . Yeah .\nProfessor D: Uh , but now you 're looking over a larger range and it may not be so fine .\nPhD I: Well , um {disfmarker} So {disfmarker} I just {disfmarker} d so the one thing that I then tried was to put in the low - pass filter , which we have in the {disfmarker} So , most {disfmarker} most Hub - five systems actually band - limit the {disfmarker} uh , at about , uh , thirty - seven hundred , um , hertz .\nProfessor D: Uh - huh .\nPhD I: Although , you know , normally , I mean , the channel goes to four {disfmarker} four thousand . Right ? So , um {disfmarker} And that actually helped , uh {disfmarker} uh , a little bit .\nProfessor D: Uh - huh .\nPhD I: Um {pause} and it didn't hurt on the males either . So , um {disfmarker} And I 'm now , uh , trying the {disfmarker} Oh , and suddenly , also the v the vocal tract length normalization only in the test se on the test data . So , you can do vocal tract length normalization on the test data only or on both the training and the test .\nProfessor D: Yeah .\nPhD I: And you expect it to help a little bit if you do it only on the test , and s more if you do it on both training and test .\nProfessor D: Yeah .\nPhD I: And so the {disfmarker} It now helps , if you do it only on the test , and I 'm currently retraining another set of models where it 's both in the training and the test , and then we 'll {disfmarker} we 'll have , hopefully , even better results . So {disfmarker} But there 's {disfmarker} It looks like there will still be some difference , maybe between one and two percent , um , for the females .\nProfessor D: Huh .\nPhD I: And so , um , you know , I 'm open to suggestions .\nGrad F: Mm - hmm .\nPhD I: And it is true that the , uh {disfmarker} that the {disfmarker} {vocalsound} you know , we are using the {disfmarker} But {disfmarker} it can't be just the VTL ,\nProfessor D: Uh - huh .\nPhD I: because if you don't do VTL in both systems , uh , you know , the {disfmarker} the females are considerably worse in the {disfmarker} with the PLP features .\nProfessor D: No {disfmarker} no . I {disfmarker} I remember that .\nGrad F: It 's much worse . Yeah .\nPhD I: So there must be some {disfmarker} something else going on .\nPhD G: Well , what 's the standard {disfmarker} ? Yeah , so I thought the performance was actually a little better on females than males .\nGrad F: That 's what I thought , too .\nPhD I: Um , {pause} that {pause} ye {comment} overall , yes , but on this particular development test set , they 're actually a little worse . But that 's beside the point . We 're looking at the discrepancy between the SRI system and the SRI system when trained with ICSI features .\nPhD G: Right . I 'm just wondering if that {disfmarker} if {disfmarker} if you have any indication of your standard features ,\nGrad F: What 's {disfmarker} Are the freq ?\nPhD G: you know , if that 's also different {pause} or in the same direction or not .\nProfessor D: You 're {disfmarker} This is {disfmarker} lemme ask a q more basic que\nPhD G: Cuz {disfmarker}\nProfessor D: I mean , is this , uh {disfmarker} uh , iterative , Baum - Welch training ?\nPhD I: Mm - hmm .\nProfessor D: Or is it Viterbi training ? Or {disfmarker} ?\nPhD I: It 's Baum - Welch training .\nProfessor D: Baum - Welch training . And how do you determine when to {disfmarker} to stop iterating ?\nPhD I: Um {disfmarker} Well , actually , we {disfmarker} we just basically do a s a fixed number of iterations .\nGrad F: Hmm .\nPhD I: Uh , in this case four . Um , which {disfmarker} Eh , we used to do only three , and then we found out we can squeeze {disfmarker} And it was basically , we 're s we 're keeping it on the safe side . But you 're d Right . It might be that one more iteration {vocalsound} would {disfmarker} would help , but it 's sort of\nProfessor D: Or maybe {disfmarker} or maybe you 're doing one too many .\nPhD I: you know .\nProfessor D: I mean it 's {disfmarker} it 's {disfmarker}\nPhD I: No , but with Baum - Welch , there shouldn't be an over - fitting issue , really .\nProfessor D: Uh . {comment} Well , there can be . Sure .\nGrad F: Well , you can try each one on a cross - validation set ,\nPhD I: Um .\nProfessor D: It d if you {disfmarker} if you remember some years ago Bill Byrne did a thing where he was {disfmarker} he was looking at that ,\nGrad F: can't you ?\nProfessor D: and he showed that you could get it .\nPhD I: Yeah .\nProfessor D: So . But {disfmarker} {comment} but {disfmarker} {vocalsound} but , um {disfmarker}\nPhD I: Well , yeah . We can {disfmarker} Well , that 's {disfmarker} that 's the easy one to check ,\nProfessor D: Yeah .\nPhD I: because we save all the intermediate models\nGrad F: Do you {disfmarker} ?\nPhD I: and we can {disfmarker}\nProfessor D: And in each case , ho\nGrad F: What {disfmarker} ?\nProfessor D: um , I 'm sorry {disfmarker} in each case how do you determine , you know , the {disfmarker} the usual {pause} fudge factors ? The , uh {disfmarker} {vocalsound} the , uh , language , uh , scaling , acoustic scaling , uh , uh {disfmarker}\nPhD I: Um {pause} I uh {disfmarker} {comment} I 'm actually re - optimizing them . Although that hasn't shown to make {pause} a big difference .\nProfessor D: OK . And the pru the question he was asking at one point about pruning , uh {disfmarker} Remember that one ?\nPhD I: Pruning {disfmarker} ?\nProfessor D: Well , he was {disfmarker} he 's {disfmarker} it looked like the probabil at one point he was looking at the probabilities he was getting out {disfmarker} at the likelihoods he was getting out of PLP versus mel cepstrum , and they looked pretty different ,\nPhD I: Pruning in the {disfmarker} ?\nPhD B: Yeah , the likelihoods were {pause} lower for the PLP .\nProfessor D: as I recall .\nPhD G: Oh .\nProfessor D: And so , uh , there 's the question {disfmarker}\nPhD I: I you mean {disfmarker} did you see this in the SRI system ?\nPhD B: Mm - hmm . Was just looking through the log files ,\nPhD I: Um . Well , the likelihoods are {disfmarker}\nPhD B: and {disfmarker}\nPhD I: You can't directly compare them , because , for every set of models you compute a new normalization . And so these log probabilities , they aren't directly comparable\nPhD B: Oh .\nPhD I: because you have a different normalization constants for each model you train .\nPhD B: Hmm .\nProfessor D: But , still it 's a question {disfmarker}\nPhD I: So {disfmarker}\nProfessor D: if you have some threshold somewhere in terms of beam search or something ,\nPhD B: Well , yeah . That 's what I was wondering .\nProfessor D: or {disfmarker} ?\nPhD I: W yeah . I mean {disfmarker} Uh {disfmarker}\nPhD B: I mean , if you have one threshold that works well because the range of your likelihoods is in this area {disfmarker}\nPhD I: We prune very conservatively . I mean , as we saw with the meeting data , um {pause} we could probably tighten the pruning without really {disfmarker} So we we basically we have a very open beam .\nProfessor D: But , you 're only talking about a percent or two .\nPhD B: Yeah .\nProfessor D: Right ? Here we 're - we 're saying that we there {disfmarker} gee , there 's this b eh , there 's this difference here . And {pause} it {disfmarker} See cuz , i i {comment} there could be lots of things . Right ? But {disfmarker} but {disfmarker} but {disfmarker} but , um , let 's suppose just for a second that , uh , we 've sort of taken out a lot of the {disfmarker} the major differences , uh , between the two .\nPhD I: Right . Course . Mm - hmm . Right .\nProfessor D: I mean , we 're already sort of using the mel scale and we 're using the same style filter integration , and {vocalsound} and , well , we 're making sure that low and high {disfmarker}\nPhD I: Actually , there is {disfmarker} the difference in that . So , for the PLP features we use the triangular filter shapes . And for the {disfmarker} in the SRI front - end we use the trapezoidal one .\nGrad F: And what 's the top frequency of each ?\nPhD I: Well , now it 's the same . It 's thirty {disfmarker} thirty to seven hundred and sixty hertz .\nGrad F: Yeah . Exp - one 's triangular , one 's trapezoidal . So {disfmarker}\nPhD I: No , no . But {disfmarker}\nProfessor D: Before we {disfmarker} i i th with straight PLP , it 's trapezoidal also .\nPhD I: Well {disfmarker} But {disfmarker}\nProfessor D: But then we had a slight difference in the {disfmarker} in the scale . Uh , so .\nPhD I: Since currently the Feacalc program doesn't allow me to change {pause} the filter shape independently of the scale .\nGrad F: Uh - huh .\nPhD I: And , I did the experiment on the SRI front - end where I tried the {disfmarker} y where the standard used to be to use trapezoidal filters . You can actually continuously vary it between the two . And so I wen I swi I tried the trap eh , triangular ones . And it did slightly worse , but it 's really a small difference .\nGrad F: Hmm .\nProfessor D: Coup - Couple tenths of a percent or something .\nPhD I: So {disfmarker}\nGrad F: OK .\nProfessor D: Right .\nGrad F: So it 's not just losing some {vocalsound} frequency range .\nPhD I: Yeah , exactly . So , it 's not {disfmarker} I don't think the filter shape by itself will make a huge {comment} difference .\nProfessor D: Yeah . Right . So the oth {vocalsound} the other thing that {disfmarker}\nGrad F: Yeah .\nProfessor D: So , f i We 've always viewed it , anyway , as the major difference between the two , is actually in the smoothing , that the {disfmarker} that the , um , {vocalsound} PLP , and {disfmarker} and the reason PLP has been advantageous in , uh , slightly noisy situations is because , {vocalsound} PLP does the smoothing at the end by an auto - regressive model ,\nPhD I: Mm - hmm . Mm - hmm .\nProfessor D: and mel cepstrum does it by just computing the lower cepstral coefficients .\nPhD I: Mm - hmm .\nProfessor D: Um . So , um {disfmarker} Mm - hmm .\nPhD I: OK . So {pause} one thing I haven't done yet is to actually do all of this with a much larger {disfmarker} with our full training set . So right now , we 're using a {disfmarker} I don't know , forty ? I i it 's {disfmarker} it 's {disfmarker} eh {comment} it 's a f training set that 's about , um , you know , by a factor of four smaller than what we use when we train the full system . So , some of these smoothing issues are over - fitting for that matter .\nProfessor D: Mm - hmm .\nPhD I: And the Baum - Welch should be much less of a factor , if you go full {disfmarker} whole hog .\nProfessor D: Could be . Yeah .\nPhD I: And so , w so , just um {disfmarker} so the strategy is to first sort of treat things {pause} with fast turn - around on a smaller training set and then , {vocalsound} when you 've sort of , narrowed it down , you try it on a larger training set .\nProfessor D: Yeah .\nPhD I: And so , we haven't done that yet .\nProfessor D: Now the other que related question , though , is {disfmarker} is , {vocalsound} uh , what 's the boot models for these things ?\nPhD I: Th - th the boot models are trained from scratch . So we compute , um {disfmarker} So , we start with a , um , alil alignment that we computed with the b sort of the best system we have . And {disfmarker} and then we train from scratch . So we com we do a , you know , w um {disfmarker} {vocalsound} We collect the {disfmarker} uh , the observations from those alignments under each of the feature sets that {disfmarker} that we {pause} train . And then , from there we do , um {disfmarker} There 's a lot of , actually {disfmarker} {vocalsound} The way it works , you first train a phonetically - tied mixture model . Um . You do a total of {disfmarker} First you do a context - independent PTM model . Then you switch to a context {disfmarker} You do two iterations of that . Then you do two iterations of {disfmarker} of {disfmarker} of context - dependent phonetically - tied mixtures . And then from that you {disfmarker} you do the {disfmarker} you {disfmarker} you go to a state - clustered model ,\nProfessor D: Yeah .\nPhD I: and you do four iterations of that . So there 's a lot of iterations overall between your original boot models and the final models . I don't think that {disfmarker} Hmm . We have never seen big differences . Once I thought \" oh , I can {disfmarker} Now I have these much better models . I 'll re - generate my initial alignments . Then I 'll get much better models at the end . \" Made no difference whatsoever . It 's {disfmarker} I think it 's {disfmarker} eh , i\nProfessor D: Right . Well , mis for making things better .\nPhD I: the boot models are recur\nProfessor D: Yeah . But , this for making things worse . This it migh Th - the thought is {disfmarker} is {disfmarker} is possible {disfmarker} another possible {pause} partial cause is if the boot models {vocalsound} used a comple used a different feature set , that {disfmarker}\nPhD I: Mm - hmm . Mm - hmm . But there are no boot models , in fact . You {disfmarker} you 're not booting from initial models . You 're booting from initial alignments .\nProfessor D: Which you got from a different feature set .\nPhD I: That 's correct .\nProfessor D: So , those features look at the data differently , actually .\nPhD I: Yeah , but {disfmarker}\nProfessor D: I mean , you know , they {disfmarker} they will find boundaries a little differently , though {disfmarker} You know , all th all that sort of thing is actually slightly different . I 'd expect it to be a minor effect ,\nPhD I: But {disfmarker} but {disfmarker} but , what I 'm {disfmarker} what I 'm saying is {disfmarker}\nProfessor D: but {disfmarker}\nPhD I: So , we e w f w For a long time we had used boot alignments that had been trained with a {disfmarker} {vocalsound} with the same front - end but with acoustic models that were , like , fifteen percent worse than what we use now .\nProfessor D: Mm - hmm .\nPhD I: And with a dict different dictionary {disfmarker} with a considerably different dictionary , which was much less detailed and much less well - suited .\nProfessor D: Mm - hmm . Yeah .\nPhD I: And so , {vocalsound} then we switched to new boot alignments , which {disfmarker} which now had the benefit of all these improvements that we 've made over two years in the system .\nProfessor D: Right .\nPhD I: And , the result in the end was no different .\nProfessor D: Right .\nPhD I: So , what I 'm saying is , the exact nature of these boot alignments is probably not {pause} a big factor in the quality of the final models .\nProfessor D: Yeah , maybe not . But {pause} it {disfmarker} it {disfmarker} I st still see it as {disfmarker} I mean , {vocalsound} there 's {disfmarker} there 's a history to this , too ,\nPhD I: Yeah .\nProfessor D: but I {disfmarker} uh , I don't wanna go into ,\nPhD I: Mm - hmm .\nProfessor D: but {disfmarker} but I {disfmarker} I {disfmarker} I th I think it could be the things {pause} that it {disfmarker} the data is being viewed in a certain way , uh , that a beginning is here rather than there and so forth ,\nPhD I: Yeah . Right .\nProfessor D: because the actual signal - processing you 're doing is slightly different .\nPhD I: Right .\nProfessor D: But , {vocalsound} it 's {disfmarker} it 's {disfmarker} that 's probably not it .\nPhD I: Yeah . Anyway , I {disfmarker} I {disfmarker} I should really reserve , uh , any conclusions until we 've done it on the large training set , um , and until we 've seen the results with the {disfmarker} with the VTL in training .\nProfessor D: Yeah . At some point you also might wanna take the same thing and try it on , uh , some Broadcast News data or something else that actually has {disfmarker} has some noisy {disfmarker} {vocalsound} noisy components , so we can see if any conclusions we come to holds {vocalsound} across {pause} different data .\nPhD I: So . Yeah . Right .\nProfessor D: Uh {disfmarker}\nPhD I: And , uh , with this , I have to leave .\nProfessor D: OK .\nGrad H: Hmm !\nProfessor D: So , is there something quick about Absinthe {pause} that you {disfmarker} ?\nPhD I: With this said .\nGrad F: Uh . Just what we were talking about before , which is that I ported a Blass library to Absinthe , and then got {disfmarker} got it working with fast - forward , and got {vocalsound} {vocalsound} a speedup roughly proportional to the number of processors times the clock cycle .\nPhD I: Oh .\nGrad F: So , that 's pretty good .\nPhD I: Oh ! Cool .\nGrad F: Um , I 'm in the process of doing it for Quicknet , but there 's something going wrong and it 's about half the speed that I was estimating it should be , and I 'm not sure why .\nPhD I: Mm - hmm .\nGrad F: But I 'll keep working on it . But the {disfmarker} what it means is that it 's likely that for net training and forward passes , we 'll {disfmarker} Absinthe will be a good machine . Especially if we get a few more processors and upgrade the processors .\nPhD I: A few more processors ? How many are you shooting for ?\nGrad F: There 're five now . It can hold eight .\nPhD I: Oh , OK .\nProfessor D: Yeah , we 'll just go buy them , I guess .\nGrad F: And it 's also five - fifty megahertz and you can get a gigahertz .\nPhD I: Yeah .\nGrad F: So .\nPhD I: Can you mix {pause} t uh , processors of different speed ?\nGrad F: I don't think so . I think we 'd have to do all {disfmarker}\nPhD I: OK .\nProfessor D: Probably just throw away the old ones , and {disfmarker}\nGrad F: Yep .\nProfessor D: Thank you {pause} for the box ,\nPhD I: Oh , OK .\nProfessor D: and {disfmarker} {vocalsound} I 'll just go buy their process .\nGrad H: Hmm !\nPhD I: Maybe we can stick them in another system . I dunno .\nGrad F: We 'd have to get a {disfmarker} almost certainly have to get a , uh , Netfinity server .\nPhD I: I see .\nGrad F: They 're pretty {disfmarker} pretty specialized .\nProfessor D: Yeah . OK .\nPhD I: OK .\nProfessor D: Is {disfmarker} is Liz coming back , do you know , or {disfmarker} ? I dunno . Yeah . Oh , you don't . OK . Alright . Alright . See you . Um . Alright . So {disfmarker} Uh , they 're having tea out there . So I guess the other thing that we were gonna talk about is {disfmarker} is , uh , demo . And , um , so , these are the demos for the {pause} uh , July , uh , meeting {pause} and , um {disfmarker} DARPA mee\nGrad F: July what ? Early July ? Late July ?\nProfessor D: Oh , I think it 's July fifteenth .\nPostdoc A: Sixteen to eighteen , I think .\nProfessor D: Is that it ?\nPostdoc A: Roughly .\nProfessor D: Yeah , sixteenth , eighteenth . Yeah . So , we talked about getting something together for that , but maybe , uh {disfmarker} maybe we 'll just put that off for now , given that {disfmarker} But I think maybe we should have a {disfmarker} a sub - meeting , I think , uh , probably , uh , Adam and {disfmarker} and , uh , Chuck and me should talk about {disfmarker} should get together and talk about that sometime soon .\nGrad F: Over a cappuccino tomorrow ?\nProfessor D: Yeah {comment} something like that . Um , uh , you know , maybe {disfmarker} maybe we 'll involve Dan Ellis at some {disfmarker} some level as well .\nGrad F: Mm - hmm .\nProfessor D: Um . OK . The {disfmarker} the tea is {disfmarker} is going , so , uh , I suggest we do , uh {disfmarker} uh , a unison .\nGrad F: A unison digits ?\nPostdoc A: OK .\nProfessor D: Yeah . Gets our {disfmarker}\nGrad F: Which is gonna be a little hard for a couple people because we have different digits forms .\nPhD E: Oops .\nGrad F: We have a {disfmarker} I found a couple of old ones .\nProfessor D: Oh .\nGrad H: Hmm .\nProfessor D: Well , that 'll be interesting . So , uh {disfmarker}\nGrad F: Have you done digits before ?\nProfessor D: No .\nGrad C: I haven't done it .\nGrad F: OK . So , uh , the idea is just to read each line {pause} with a short pause between lines ,\nGrad C: Alright .\nGrad F: not between {disfmarker} And , uh , since we 're in a hurry , we were just gonna read everyone all at once . So , if you sorta plug your ears and read {disfmarker}\nGrad C: OK .\nGrad F: So first read the transcript number , and then start reading the {pause} digits .\nGrad C: Sure .\nGrad F: OK ? One , two , three .\nProfessor D: OK we 're done .\nGrad F: And {disfmarker}", "source": "meeting_summ", "evaluation": "rouge"}
{"instructions": ["Why did Marketing disagree with kinetic energy as a solution proposed by Industrial Designer?", "Why did the group discard voice recognition function?", "Summarize the group discussion about case design.", "What decision did the group make on changeable cases when discussing case design?", "Why did the group give up the idea of positioning symmetrical buttons on both the left and right side?", "Summarize the whole meeting."], "outputs": ["For one thing, Marketing argued that target customers as the elder generation tended not to shake their remote controls before using. For another, he believed that the docking station was in a position to load up the batteries, therefore, the basic normal battery would be sufficient for the charging need, which was confirmed by User Interface who pointed out that remote control with a minor display would in no way be power-consuming.", "Marketing first brought up price concern, implying that voice recognition could significantly drive up cost and price. Also, Marketing argued that unlike the LCD screen, the elderly would not fancy speech recognition because it would not make the remote control more user-friendly. Project Manager applauded Marketing's opinion and agreed that the LCD screen should be given priority over voice recognition.", "Firstly, the group reached a consensus that material should be plastic with wooden colour as opposed to wood. Then, User Interface brought forward a changeable case as a solution and was unanimously accepted. After that, the group discussed the shape of the control and chose single-curved for the time being. Finally, they drew out a specific case design and roughly determined the position of each button while taking the convenience of left-handed users into account.", "As Marketing explained, a single remote control would be designed to fit into an original wooden cover as well as a standard plastic one, in order to meet the differentiated needs of the customers. As a result, besides remote control, two types of cases would also be sold as extra products.", "Firstly, despite the convenience of left-handed users, symmetrical button design would create extra buttons and hence inevitably confuse users. Also, Project Manager pointed out that left-handed users have no difficulty handling the remote control by either side of hands. User Interface added that a thumb was sufficient for this motion, so no difference should exist between left and right.", "The whole meeting was focused on the conceptual design of the new remote control product. After Project Manager briefly reaffirmed the agreements reached in previous meetings, Marketing, User Interface, and Industrial Designer each gave a presentation about trend-watching, interface design, and components design respectively. Then, Project Manager started a group discussion about important points just covered, including energy source, voice recognition, LCD screen, as well as case design, on which more emphasis was paid in the last half of the meeting. Finally, the group roughly drew out a specific case design."], "input": "Project Manager: Okay . Uh good afternoon . This is our third meeting already .\nMarketing: Good afternoon .\nProject Manager: I hope you enjoyed your lunch . {vocalsound} I did anyway . {vocalsound} Um let's see . Presentation three . Okay this is um the second phase uh we're going to discuss today . It's the conceptual design meeting . And a few points of interest in this meeting um are the conceptual specification of components . Uh conceptual specification of design . And also trend-watching . Um these are hopefully the points you addressed in uh your pre uh presentations you're going to show me in a few minutes . Um but first I'll show you the agenda . Uh first the opening . Then we have three presentations . Uh after that we have to come to a decision on remote control concepts . How we're going to make it . And then we're closing . We have about forty minutes . Uh so I suggest let's get started . Uh did someone encounter any problems during the preparation ? No ?\nUser Interface: No .\nProject Manager: Everything fine ?\nMarketing: {gap}\nProject Manager: That's nice . Then a little uh thing about the last meeting . Uh these are the points um we agreed on . The requirements and the target market . Uh requirements are uh teletext , docking station , audio signal , small screen , with some extras that uh button information . And we are going to use default materials . Um does somebody have any comments on these requirements ? Maybe ? No ? These are just the the things we thought of , so maybe if you figured something else or thought of something else , just let me know . And maybe we can uh work it out . And we're going to target uh sixty to to eighty year old customers . So now everybody knows what we're do we're doing , um I suggest let's get started with the presentations . So shall we keep the same uh line-up as uh last time ?\nMarketing: Sure .\nProject Manager: Okay .\nMarketing: I'll start off then .\nProject Manager: Good luck . {vocalsound}\nMarketing: Doh . 'Kay I'm uh gonna inform you about the trend-watching I've done over the past few days . Um we've done some market research . We distributed some more enquetes , questionnaires . And um besides that um I deployed some trend-watchers to Milan and Paris to well get all of the newest trends . And I've consulted some additional trend-watch trend-watchers , after the original trend-watchers return , about what the the best design would be . Um okay these are some overall findings . Um most important thing is the fancy design . Um the research indicated that that was by far the most important factor . Um innovativeness was about half as important as the fancy design . By innovativeness this means um functions which are not featured in other remote controls . Um about half of , half as important as the innovativeness was the was easy to use . Um for our um group , we're focusing on the people of sixty to eighty y years old , this is um , these factors are slightly more equal . 'Kay these are some more group specific findings . Uh the older people prefer dark colours . Uh they like recognisable shapes , and familiar material . And our surveys have indicated that especially wood is pretty much the material for older people . Um this is , this image will give you a little bit of an impression about um the look-and-feel that um the remote should have . Um this leads us to some personal preferences . Uh the remote control and the docking station should uh blend in in the in the room . Um so this would mean no uh eye-catching designs . Just keep it simple and {disfmarker} Well the docking station and small screen would be our main points of interest , because this would be the {disfmarker} These would uh be the innovativeness in the remote control . So this would be very important that we {vocalsound} at least include these features . Um well the trend-watchers I consulted advised that it b should be , the remote control and the docking station should be telephone-shaped . So you could imagine that uh the remote control will be standing up straight in the docking station . This is not really {disfmarker} This is pretty much a new shape to uh older people . So they would prefer uh a design where the remote control just lies flat in the docking station . So it would be kinda more telephone-shaped . Um besides that we would advise um to bring two editions , one with a wood-like colour and maybe feel , and one with a grey-black colour . The wood-like for the more uh exclusive people . People with more money . Uh the grey-black colour for well people with less means . That would be all .\nProject Manager: Okay . Thank you . Any questions about the the trends ?\nMarketing: Any questions ?\nProject Manager: Mayb\nUser Interface: Mm no .\nProject Manager: No ? Okay , we go on to the next one .\nUser Interface: {gap}\nProject Manager: {vocalsound}\nUser Interface: Um {vocalsound} 'kay um yeah . {gap} uh some uh research uh a about um designing of an interface . Um the uh last meeting uh we had a about um uh using a f few buttons . So uh um uh that's w what I what I want to uh uh to do in uh our design . So um finding an attractive uh way to control uh the remote control . Um the uh {disfmarker} I found some uh something about uh speech uh recognition . So maybe uh we can uh use uh that . Um {disfmarker} Uh and uh using a little uh display . So um findings . Um yeah just um we have just to focus on the primary um functions . So uh only uh buttons uh for uh sound , um for uh on-off , um uh shifting u up uh sa uh ca channel or uh down shifting down . Um uh let's see . Um yeah and {disfmarker} Uh {gap} we uh need some uh new a attractive functions uh uh which attract uh uh people for using it . So uh it's uh like a speak uh speech uh recognition and um a special button for selecting uh subtitles . Just uh what we uh mentioned uh last uh meeting . Um and yeah overall um user-friendly . So uh using uh large large buttons . Um {disfmarker} It's uh possible to uh uh to make um quite cheap uh system for uh speech uh recognition . Um you can think about um uh when you lost your um remote control , you can uh call it and um it gives an um sig signal . So uh uh yeah . And and uh for uh shifting up a sen uh c ch channel or uh for um uh putting out uh sound or something , you can uh just give a sign uh say um sound off or {disfmarker} A and uh yeah . Television uh put the sound off uh put the sound off uh . Um {disfmarker} Let's see . Uh yeah . I was thinking about the special uh button for uh subtitles , um just one button to keep it uh simple . Uh one push on the button uh you get uh uh small uh subtitles . Um double push push um , if double click , um so uh you get uh big uh subtitles , for uh people uh um uh which c f uh who can't uh read small uh subtitles . So uh {disfmarker} Um {disfmarker} Yeah and w we have to keep uh in general buttons uh so um we've got um the buttons we have to use . The on-off , sound on-off , sound higher or lower , um the numbers , uh zero to uh uh nine . Um the general buttons m more general b one button for shifting up and shifting down uh channel . Um also we want to uh use a little d display uh for um for displaying the uh the functions of the buttons . And um we can uh build in a function f which uh shows the channel or some uh which the t television is on . So um made a little uh picture of uh it . Um {disfmarker} See . Um yeah . Just um we can put uh the on-off button uh over in this uh corner , um almost uh e all uh remote controls uh are using a on-off button on that place . Um so uh people uh will uh recognise uh um the button .\nIndustrial Designer: {vocalsound}\nUser Interface: So um {disfmarker} D display uh of it , it's uh just a small display . Uh um you can put it uh on top . Um it's uh most uh uh place where people uh , most of {gap} looks at . So uh um and a special uh button for shifting up uh and uh shifting down uh channel , um it's uh on place where um the thumb of of the {disfmarker} So you you can uh easily uh shift up or shift down . Um it's uh quite uh handy place . So um and uh all the f functions for subtitle uh one button , uh for sound uh {disfmarker} Uh and uh for our design , um uh we have to discuss about it uh I think uh so uh the form of it so {disfmarker}\nProject Manager: Okay .\nUser Interface: And that's it .\nProject Manager: Uh thank you . {vocalsound}\nIndustrial Designer: Okay . About the components design . Um for the energy source we can use a basic battery or , a as an optional thing , a kinetic energy , like in a watch , which you just shake and it produces energy . But if we choose for that option , the docking station would c become obsolete . So I don't think it's really an option . Uh for the casing , uh the uh manufacturing department can deliver uh a flat casing , single or double curved casing . It's really up the the design that we're gonna use . It's uh doesn't uh imply any technical restrictions . Uh as a case supplement , we could um , I thought of that l later , uh a rubber uh belt , like a anti-slip . Uh for the b buttons , we can use plastic or rubber . And the chip-set , um it says simple here , but it should be advanced , because we're using an L_C_D_ uh screen . And as uh the trend-watcher presentation showed , um people like wood , but it raises the price and it doesn't really fit the image , unless we would start two product lines . Form should follow function overall . Um well the kinetic energy source is rather fancy . But depends on what we want . I think we should disc discuss that . Um for the case , uh the supplement and the buttons , it really depends on the designer . And the chip-set uh really should be advanced because otherwise uh it would really be a simple uh remote control . And that's it .\nProject Manager: Okay . Thank you . So that brings us to the discussion about our concepts . Mm .\nMarketing: {vocalsound}\nProject Manager: 'Kay . So these are the points we have to discuss . Um first I think we can talk about the energy source , since that's um has a pretty big influence on production price , uh and image .\nUser Interface: {gap}\nProject Manager: Uh so uh f I think first of all we have to see uh it is possible to introduce kinetic energy in our budget , I think .\nIndustrial Designer: Yes w there there are four options . We could use the basic normal battery .\nProject Manager: Yeah .\nIndustrial Designer: Uh a hand dynamo .\nProject Manager: {vocalsound} Okay {gap} . {vocalsound}\nIndustrial Designer: But I don't think that's {vocalsound} really an option .\nUser Interface: {vocalsound}\nIndustrial Designer: You don't wanna swing before you can watch television .\nMarketing: {vocalsound}\nProject Manager: {vocalsound} Yeah .\nIndustrial Designer: Uh solar cells . But not every room is very light\nUser Interface: Mm .\nIndustrial Designer: so it's not a very good option .\nProject Manager: No .\nIndustrial Designer: Or the kinetic energy .\nProject Manager: Yeah . Okay .\nMarketing: And how exactly does the kinetic energy work ?\nIndustrial Designer: Well y you basically shake your remote , and then it powers up .\nMarketing: You just {disfmarker} You use it and it works .\nUser Interface: {vocalsound}\nIndustrial Designer: Yeah .\nProject Manager: Yeah .\nUser Interface: Nah .\nMarketing: Okay . Well personally I don't think that older people like to shake their remote control before they use it .\nUser Interface: {vocalsound}\nIndustrial Designer: {vocalsound} Yeah . That's true .\nMarketing: And besides that you mentioned it would make the docking station obsolete .\nIndustrial Designer: Oh .\nMarketing: And I think our docking station could be one of the marketing issues with which we can um get great popularity for our product .\nProject Manager: Yeah .\nUser Interface: But\nMarketing: Um wel\nUser Interface: what's the function ? Yeah f for loading up uh the batteries {gap} .\nMarketing: Yeah you could load up the batteries ,\nUser Interface: B b\nMarketing: you could um insert the find the lost remote control function in there .\nUser Interface: Okay but uh it won't use uh much e energy uh I I believe . Uh it's uh just a small display so I believe uh it will run on one battery for um six months or f or or more . So I believe one battery uh is just enough .\nProject Manager: Uh {disfmarker}\nUser Interface: Uh so {disfmarker}\nProject Manager: Uh well I think uh elderly people just like to have everything in place .\nMarketing: That's true . {vocalsound}\nProject Manager: And I don't think they they like uh remotes just laying everywhere in their rooms .\nUser Interface: Okay .\nProject Manager: So maybe a docking station will help them give the remote a place .\nUser Interface: Yeah . That's true . Yeah .\nProject Manager: And also what you said . Um you can introduce voice recognition by uh finding back your remote .\nUser Interface: Mm-hmm .\nProject Manager: But I think it's um more efficient and cheaper to put it in the docking station .\nUser Interface: Yeah .\nProject Manager: So you have a but button on your docking station which you can push , and then it starts beeping .\nUser Interface: Okay .\nProject Manager: And then we can we can still use the voice recognition , but maybe then for only the the channels .\nUser Interface: Yeah . Uh .\nProject Manager: That's safe .\nMarketing: I'm wondering um what will the voice recognition mean for the production price ?\nProject Manager: Yeah . That's a good point .\nIndustrial Designer: Mm I don't have any information on pricing . So I'll have to ask the manufacturing department .\nUser Interface: Mm .\nMarketing: 'Cause in our earlier um market research , if you'd allow me to go to the flat board , SMARTboard .\nProject Manager: Yeah , sure . Go ahead .\nMarketing: Um so it was open here . Um we also um asked if w they would , if people would pay more for speech recognition in a remote control . Well you can see here , our target group would not do that .\nProject Manager: No .\nMarketing: So if that would increase the price for which we're selling our remote control\nUser Interface: Mm .\nMarketing: I would greatly advise not to do it .\nProject Manager: Yeah .\nUser Interface: {gap}\nMarketing: I think that would be better to uh insert in our other product , that is meant for the\nProject Manager: Yeah .\nMarketing: younger people .\nUser Interface: 'Kay .\nIndustrial Designer: But that would also go for the L_C_D_ screen then I guess . It's a bit higher percentage , but {disfmarker}\nMarketing: Um well this is Yeah but this is here the question was , would you prefer it . So that doesn't really mean they wouldn't pay extra for it . And on top of that the L_C_D_ screen would um help in making the remote control easier to use .\nUser Interface: Yeah .\nProject Manager: Yeah .\nIndustrial Designer: Okay .\nMarketing: And I think a voice recognition function would not make the remote control much easier to use .\nProject Manager: Easier to use ? No , I think that's a good point .\nUser Interface: But uh is uh our uh research um about um bi large uh L_C_D_ sh uh display , or uh just a small one uh we want to uh use ?\nMarketing: Um well this was for like an L_C_D_ screen like you would have on a on the the most advanced mobile phones .\nUser Interface: Okay .\nMarketing: So pretty large .\nProject Manager: Yeah .\nUser Interface: Yeah .\nProject Manager: I personally think the L_C_D_ screen we wanna use , with the extra information , I think nobody has anything against it . Because it's just uh some extra information ,\nUser Interface: No .\nProject Manager: and it's easy to ignore as well . So if you don't wanna use it you just don't use it .\nUser Interface: Yeah .\nProject Manager: And um yeah I think the um {disfmarker} Maybe we have to uh discard the voice recognition . Because it will increase cost uh signifi uh significantly . And I don't think the {disfmarker} I don't think it will be a lot easier to use , as well .\nUser Interface: Yeah .\nProject Manager: So that brings us back to the energy . If we don't have the voice recognition , it will it won't use a lot of energy to use . Um {disfmarker}\nUser Interface: Mm-hmm .\nProject Manager: So in that case we could use kinetic uh energy , but I think just a simple battery which you can reload on a docking station is just as good . And much cheaper as well .\nUser Interface: Yeah .\nProject Manager: So {disfmarker}\nIndustrial Designer: And that's the best choice .\nProject Manager: Okay let me just choose for the battery . That brings us to the chip .\nIndustrial Designer: Well there isn't any choice there because we're using the the the the display .\nProject Manager: Just the advanced .\nIndustrial Designer: So it's gotta be advanced .\nProject Manager: Okay\nMarketing: 'Kay .\nProject Manager: {gap} , advanced chip . And then we get to the point of the case . Um which brings us a little bit back to marketing as well . Uh if we wanna choose for wood or the black and grey . Or both ? Um as we saw there is not {disfmarker} Yeah wood is a lot more expensive to produce .\nMarketing: Mm-hmm .\nProject Manager: Um but I think it will attract elderly people who wanna have something exclusive , which they can show off to their grandkids .\nMarketing: Mm-hmm .\nProject Manager: Look I've got a new remote control , and uh {disfmarker}\nIndustrial Designer: {vocalsound}\nUser Interface: Uh I dunno .\nMarketing: Well {disfmarker} {vocalsound} And I think most important factor there is the wooden colour . So it wouldn't actually have to be wood ,\nProject Manager: Yeah . That's right .\nMarketing: if it's just\nUser Interface: Mm .\nMarketing: wood-coloured .\nProject Manager: But with colour was a lot more expensive ? Or ?\nIndustrial Designer: Mm I dunno .\nProject Manager: You don't know ?\nIndustrial Designer: I'll have to uh research .\nProject Manager: I think so because {disfmarker} Yeah .\nMarketing: Probably .\nProject Manager: It's a lot more difficult to to handle and to to get in the right shape .\nUser Interface: Mm . Uh is it possible uh to make um changeable uh case . So um uh you 'cause uh {disfmarker} Yeah with uh mobile phones uh uh so uh like the Nokia mobile phones , uh when you can change the case of it .\nProject Manager: Yeah .\nUser Interface: So\nProject Manager: Change the cases . Yeah .\nUser Interface: maybe it's possible uh possibility . So um um you have just to make one um standard um remote control , and um yeah you can sell uh few uh {disfmarker}\nProject Manager: You can sell the cases .\nUser Interface: Yeah .\nProject Manager: Yeah . I think that's a very good option . Because um then you can advertise as well with the {disfmarker} Give your grandfather a new case for his remote control , or whatever . {vocalsound}\nUser Interface: Yeah .\nIndustrial Designer: {vocalsound}\nMarketing: {vocalsound}\nProject Manager: Because that's a {disfmarker} it's something extra , it's something other remotes don't have ,\nUser Interface: Yeah .\nProject Manager: which we can get a great advantage point .\nMarketing: Yeah that is true .\nProject Manager: So and then you can make them with colour . Black and grey , other colours as well .\nUser Interface: Yeah .\nMarketing: Yeah . We would have to look carefully into the design though .\nProject Manager: Costs .\nMarketing: 'Cause we would have to make one w uh control which would fit in with a wooden cover and a plastic cover . The more original one , or the more standard one .\nProject Manager: Yeah . Yeah . So\nMarketing: So that would {disfmarker}\nProject Manager: you suggest we should design two different telephones on which you can apply , yeah {vocalsound} remote controls , on which you can apply different case covers , for example .\nMarketing: Well I wouldn't design a telephone\nIndustrial Designer: {vocalsound}\nMarketing: but {disfmarker} {vocalsound}\nUser Interface: {vocalsound}\nMarketing: Well no I think w we should just , we should then just design one um\nProject Manager: Remote .\nMarketing: one remote , but it would have to be fancy with either the wood cover or the plastic one .\nProject Manager: Yeah . Okay .\nMarketing: So , but that shouldn't be too much of a problem .\nProject Manager: So everybody's okay with the changing covers ? I think that's a good uh good option .\nUser Interface: Yeah .\nIndustrial Designer: Yes .\nProject Manager: Changing case covers .\nMarketing: Um I heard our Industrial Designer talk about uh flat , single and double curved .\nProject Manager: Yeah .\nIndustrial Designer: Yes .\nMarketing: Could you explain that a little more ?\nIndustrial Designer: Well the the general like most older remotes are flat , just straight .\nMarketing: Mm-hmm .\nIndustrial Designer: And uh our d manufacturing department can also deliver single curved or double curved ca curved cases .\nMarketing: And what would single curved and double curved mean ?\nIndustrial Designer: Um it would just only affect the form , for as far as I know . So it's j really just up to the design department what we're gonna use . It doesn't really matter for the price or the functionality .\nMarketing: Okay . So we can pretty much just do whatever we want .\nIndustrial Designer: Pick one you like , yes .\nProject Manager: Mm . Okay .\nMarketing: 'Kay . That's good .\nProject Manager: Uh but the form has to be um {disfmarker} It has to {disfmarker} It's has to be possible to stand up ? Or just only to lie down ?\nMarketing: No just to lie down .\nUser Interface: {gap} okay .\nProject Manager: And the the cover of the the docking station is also\nMarketing: We'll go for that .\nProject Manager: on top of the television then ? Or not ?\nMarketing: Well or besides it .\nProject Manager: And you can just yeah then click it in . That's okay . Um so the interface . What type of interface do we want to use ? Um maybe you can make a little drawing of it on the\nMarketing: {vocalsound} Mm-hmm .\nProject Manager: on the the board .\nUser Interface: Mm .\nProject Manager: Does somebody have ideas for a form or\nUser Interface: Uh we can just use the regular form of it , but it's um not quite uh fancy . So um {disfmarker} Yeah .\nMarketing: Um you uh said you wanted to put the um changing channels button on the right side ,\nUser Interface: Yeah .\nMarketing: so you could , so your thumb would be easily {disfmarker}\nUser Interface: Yeah .\nMarketing: Well uh I think that was a very good point 'cause I pointed out earlier that a lot of remotes cause R_S_I_ .\nUser Interface: {gap}\nMarketing: So that would be great for that . Um I thought maybe we could just make one of those buttons on both the left and the right side .\nUser Interface: For uh {disfmarker} Uh for {disfmarker}\nMarketing: For left-handed users also .\nUser Interface: Yeah yeah .\nProject Manager: Yep .\nUser Interface: Mm . Yeah we Is it possible to um program it s so uh you got on the left side uh or on the right side uh buttons for for shifting u up and shifting up ? And on the uh other uh {vocalsound} uh o other side uh buttons for uh shifting , uh for for the sound ? Or {disfmarker} Or isn't it ?\nMarketing: For the volume . Um well\nProject Manager: Mm .\nMarketing: that could {gap} Yeah we could do that but I'm not sure if that would be very good for the easy , ease of use .\nProject Manager: Usabili Yeah ease of use will be a lot more difficult ,\nUser Interface: Yeah okay .\nProject Manager: and then it's {disfmarker}\nUser Interface: Uh .\nProject Manager: {vocalsound}\nMarketing: But if we would make um a changing channels and changing volume button on both sides , that would certainly yield great options for the design of the remote .\nUser Interface: Mm .\nMarketing: 'Cause it could be made all symmetrical and stuff .\nUser Interface: Yeah\nProject Manager: But you have extra buttons .\nUser Interface: but {disfmarker} {vocalsound}\nProject Manager: So people can get confused .\nUser Interface: Yeah . Yeah .\nMarketing: That is true .\nUser Interface: Yeah .\nProject Manager: Especially if they have the same writings on it .\nUser Interface: See um yeah . Or we have to make a left uh {disfmarker} For lefties\nProject Manager: Can't we make uh {disfmarker} Can't we make a remote which you can flip over and use on the same\nUser Interface: and {disfmarker} {vocalsound} Um {disfmarker}\nProject Manager: functions as the normal one ?\nUser Interface: {vocalsound} You mean um {disfmarker}\nProject Manager: Then you have to {disfmarker}\nUser Interface: Yeah if {disfmarker}\nProject Manager: Let's see if I ca A blank one . And then you get {disfmarker} Here's a little L_C_D_ screen . Uh now I have to think . It's a plus and a min . No it's not very handy I think . Because the plus and the min will be opposite\nUser Interface: Mm no .\nProject Manager: and all kinds of {disfmarker}\nUser Interface: Yeah .\nMarketing: Yeah . {vocalsound}\nProject Manager: No that's not gonna work . I guess . Maybe we should {disfmarker}\nUser Interface: Um {disfmarker}\nProject Manager: Yeah . But is it a problem that left-handed persons use a different hand ? I think the functions are that basic that nobody should have any problems with uh choosing a channel\nMarketing: Yeah . That is true .\nProject Manager: or {disfmarker}\nUser Interface: Yeah . It's just uh u using uh your thumb .\nProject Manager: Y yeah . Yeah .\nUser Interface: So um it's {disfmarker}\nProject Manager: I think we could just uh leave it a normal shape .\nUser Interface: Yeah .\nIndustrial Designer: Yeah .\nProject Manager: Uh but maybe we have to make it a l a bit more fancy . In one or ano another way .\nUser Interface: Yeah . Um {disfmarker}\nIndustrial Designer: I think we should start by by choosing a case . Because that's the basis you're building on .\nUser Interface: Yeah yeah .\nProject Manager: Yeah .\nMarketing: Yeah .\nProject Manager: Um yeah\nIndustrial Designer: So I could draw them out .\nProject Manager: just {disfmarker}\nIndustrial Designer: Let's look at the flat case . Oh . It's from the side so it's rather normal .\nUser Interface: Mm-hmm .\nMarketing: Mm-hmm .\nProject Manager: Yeah .\nIndustrial Designer: The the single curved so I'm not really sure what they're gonna look like , but I think it's something like this . So this type should be better for you or better {disfmarker} Should prevent repetitive strain injury a bit .\nProject Manager: Easier ?\nIndustrial Designer: And the double curved s looks something like this I guess .\nUser Interface: Mm .\nIndustrial Designer: So th those are the three options we have .\nProject Manager: 'Kay .\nMarketing: Mm .\nProject Manager: I suggest um the single curved , because maybe the curve is pretty good to put the the screen in .\nUser Interface: {gap}\nProject Manager: Uh so that elderly people can uh use the remote control and at the same time look easily at the screen , because it's a bit , it has a bit of a angle .\nUser Interface: So um {disfmarker} Do you say this um {disfmarker} S uh {disfmarker} Uh you got like uh sort of a {disfmarker} I believe {disfmarker} {gap} There ?\nMarketing: Mm-hmm .\nUser Interface: So um you want to put a display over here ? Or not ?\nProject Manager: Yeah . I think so . Yeah .\nUser Interface: Yeah . Um {disfmarker} Yeah . Uh\nProject Manager: But now it's {disfmarker}\nUser Interface: we can make it um {disfmarker}\nProject Manager: Do you have it upside down or {disfmarker}\nUser Interface: Mm ?\nProject Manager: Do you have it\nUser Interface: That's the top .\nProject Manager: this that's top ? Okay .\nUser Interface: So uh this top . This down . Um maybe it's possible to uh make this side like um {disfmarker} Let's see . Um {disfmarker} Colour uh okay . Uh to make this side um like mm the right colour .\nProject Manager: {vocalsound}\nUser Interface: Um bit like so uh um in the form of your hand . So um {disfmarker} Uh it's an {disfmarker}\nProject Manager: Yeah .\nUser Interface: So so the remote control have to um lay in your hand . So uh it's possib um yeah for s so and\nProject Manager: So get your mouse . Yeah .\nUser Interface: And to put uh the the buttons for um changing uh the channel uh over here uh {disfmarker}\nProject Manager: Yeah . That's a good one . But I think it's better to put the screen uh on top .\nUser Interface: Yeah .\nIndustrial Designer: Yeah .\nUser Interface: {vocalsound} Uh rem\nProject Manager: So just flip it a hundred and eighty degrees around then you get {disfmarker} {gap} here .\nUser Interface: Yeah but this place um {disfmarker}\nProject Manager: If you can have this one , you turn it like this . And then flip it upside down .\nUser Interface: Uh it's {disfmarker} Yeah I dunno um {disfmarker}\nProject Manager: Because uh maybe your hand is in the way , if you have the display here .\nUser Interface: Yeah .\nMarketing: Mm-hmm .\nUser Interface: {gap}\nIndustrial Designer: It's more logical to have it on top as well\nProject Manager: I think i\nIndustrial Designer: because , like on your mobile phone , it's always above .\nUser Interface: Yeah so {disfmarker}\nProject Manager: On top .\nMarketing: Yeah .\nUser Interface: So {disfmarker}\nProject Manager: Yeah . {vocalsound}\nUser Interface: {vocalsound}\nIndustrial Designer: Oh maybe you should just s start on a blank page .\nProject Manager: {gap} . So\nMarketing: Yeah .\nProject Manager: then we get {disfmarker} Here's {disfmarker} That's the curve .\nUser Interface: Five minutes . {vocalsound}\nProject Manager: Here the display , and then buttons . Yeah and then we can have a little bit off here and here maybe . Just that's for left hand and right hand users .\nUser Interface: Yeah .\nMarketing: Mm-hmm .\nProject Manager: And then h the rest of the buttons over here .\nUser Interface: Yeah . But um the on-off button , um still on the top uh {disfmarker}\nProject Manager: Yeah still here\nUser Interface: Yeah .\nProject Manager: jus\nUser Interface: Yeah .\nProject Manager: That's {disfmarker}\nMarketing: And I'd prefer the corners to be round .\nProject Manager: Yeah .\nUser Interface: Yeah . 'Kay .\nProject Manager: Should be more bit more friendly ,\nMarketing: Think that would be better .\nProject Manager: yeah .\nMarketing: Friendly on the eye .\nProject Manager: 'Kay . Supplements . That's okay . Where's my mouse ? Then {disfmarker} We've got a general idea of the concepts and the materials we're going to use . So now for the next meeting uh we'll have to look at the look-and-feel design . It's important that the corporate design image uh is going to be in the remote . So check out the corporate website maybe . The user interface design , it's the same story . And product evaluation . So the Industrial Designer and User Interface Designer are going to work together on this one . But you're going to get your instructions I think sended by the coach . So just um I will put these um minutes on the in the folder .\nIndustrial Designer: Okay .\nProject Manager: And then we're going to uh try to finish our project , and uh make a good design for all the grandfathers and grandmothers , I think .\nUser Interface: {vocalsound}\nIndustrial Designer: {vocalsound}\nMarketing: {vocalsound}\nProject Manager: {vocalsound} Which are {disfmarker} Uh let's see . I'm not sure if you're going to start right away to work together or {disfmarker} I think you're going to fill in the questionnaires first .\nUser Interface: Yeah .\nProject Manager: And then you'll get a message .\nMarketing: Yeah .\nUser Interface: Yeah .\nProject Manager: So that's uh basically it . Maybe this one ? Then we can save this one in the folders group . Uh yes , it's here .\nMarketing: Yeah .\nProject Manager: {vocalsound} SMARTboard , there it it . So if you wanna have a look at it , it's over there in the projects folder .\nUser Interface: Yeah .\nProject Manager: And then I guess we'll start in thirty minutes again . Thank you .\nMarketing: Very good .\nUser Interface: Okay .", "source": "meeting_summ", "evaluation": "rouge"}
{"instructions": ["What did the group discuss about merits of speech recognition inclusion?", "What did Marketing think about the merits of speech recognition inclusion?", "What are the benefits of the speech recognition feature?", "Summarize the group's discussion of market research on remote control users' desired features.", "What features of the remote control did Marketing think were important?", "Did Marketing and User Interface agree on desired features?", "Summarize the whole meeting."], "outputs": ["The group decided that speech recognition appeals to mostly younger people. The team decided speech recognition is mostly just a gimmick and is not used unless it works very well.", "Marketing agreed that speech recognition gets old and is a gimmick. Marketing also thought that since younger people are not the consumers spending money on remotes their preference for speech recognition might not matter greatly.", "According to Marketing's research, ninety one percent of the youngest age groups said they would spend more money to buy a remote with speech recognition.", "Marketing presented the results of interviews conducted with remote control users. Eighty percent of users indicated that they would be willing to pay more for a remote that looked fancier. Fifty percent of users indicated that they generally only use about ten percent of the buttons on their remote controls. User Interface then presented the difficulties of a universal remote and also mentioned that few buttons are needed frequently by users.", "Marketing thought that making the remote look cool and modern was important. Marketing also thought that many buttons could be removed or combined. Marketing also thought a tracking device and speech recognition could be good ideas.", "Marketing and User Interface agreed on the importance of fewer buttons for a user-centered remote. Marketing and User Interface also agreed on the importance of the appearance of a remote control.", "The group met to decide which features were desired by users and to decide how to design the shape and appearance of the remote control. Marketing and User Interface presented on what features were desired by remote control users, and Industrial Designer presented on the required internal components of a remote control. They decided not to pursue speech recognition and settled on designing a rounded one-handed remote control with minimal buttons."], "input": "Marketing: {vocalsound}\nProject Manager: Okay .\nMarketing: {gap} .\nProject Manager: Right . Okay . Alright . Is everyone here ? {vocalsound}\nMarketing: {vocalsound} Yep . {vocalsound}\nUser Interface: Yep .\nProject Manager: Okay . This is our conceptual design meeting . And {disfmarker} {vocalsound} I'll just take a few minutes and uh go through the previous minutes . Um then each of you will have your presentation , um and then we will need to make a decision on the concept for the remote control . And then we'll have uh forty minutes for finishing up . Um {disfmarker} {vocalsound} I'll go through the mee through the minutes first . Um , we just refreshed our our uh goal of making the finest remote control available .\nIndustrial Designer: {vocalsound}\nProject Manager: {vocalsound} Um we decided that , or we know that we need to use company colours , company logo . Um {vocalsound} and our Marketing Expert uh gave us some i uh information from interviews with a hundred different remote users . Um with some statistics that backed basically what we were thinking before . People thought their remotes were ugly , um um that remotes zap a lot . Um they only use uh a finite amount of buttons .\nIndustrial Designer: {vocalsound}\nProject Manager: Um and that they often lose the {disfmarker} it's easy to lose a remote . Um which were all things we were thinking we would {disfmarker} wanna make it simple . Um {disfmarker} {vocalsound} And uh some sort of locator . Either a button or tracking device . Um {disfmarker} And that it should look different than what's out there . Um {disfmarker} Kind of mixed mixed response on the speech recognition . The younger people said they wanted it , older people did not . Um uh I think we decided that um the expense was not necessarily worth it , and that it was probably a gimmick , that um would increasingly wear on the consumers' nerves . Um {vocalsound} {disfmarker} Then the User Interface Designer um explored some of the technical functions of the remote . Um the simple versus the um the complex . The simple one being better for a user , the complex better for an engineer . Um {disfmarker} Um and some personal preferences that were found in that would be that it should be a user-oriented remote , something simple . Um and that we didn't wanna go with a universal remote , because uh increasing cost and increasing complexity . Um we would just have a T_V_ remote . Um and that we should also focus on the appearance of the remote . Have it s be something that looks different . And finally our um Industrial Designer uh gave us a rundown of how the remote will work . Um from energy source , um uh what we would use . Batteries because we don't wanna have a a cable . Um {disfmarker} {vocalsound} How that would power the remote and the lamp . If we were to to have one . Uh um the user interface then would connect to a chip , {vocalsound} which would work with the infrared controls uh to send the signal to the T_V_ . Um {disfmarker} I believe then we came up with a couple of ideas for what we think the design of the remote will be . Um {disfmarker} {vocalsound} Um something that will fit into uh easily into someone's hand . {vocalsound} And with a , just a few buttons . Just the basics . And with a scrolling um function also . Okay and I will leave that , leave it at that . So {disfmarker} Marketing ?\nMarketing: Okay .\nProject Manager: We're watching trends .\nMarketing: Yep . Can I have your cable please ?\nProject Manager: I suppose that you can have this .\nIndustrial Designer: {vocalsound}\nMarketing: Thanks . Okay so I was looking at trend-watching . Um unfortunately I wasn't given too much information . I was given a brief executive summary , and then an update on some recent fashion trends that we might like to look at . And then I'll just tell you some personal preferences that I got from that . Um okay the most important finding was that the fancy look-and-feel seems to be twice as important to the users as the current functional look-and-feel design , which I think we've kind of already discussed before . Um the second most important finding was that the remote should be technologically innovative . And again these are all things we've kind of already come up with on our own , but this just backs it up . And thirdly the remote would be easy to use . As far as fashion update , we've learned that fruits and vegetables will be the most important theme for cloths , shoes and furniture .\nIndustrial Designer: {vocalsound}\nMarketing: So that might be a bit of a challenge to incorporate this into our remote , but we can try . Um and also , as opposed to last year , this year the material is expected to be spongy in feel . {vocalsound} Okay so from that um , as we've already said , we need to focus on a fancy look-and-feel . Um I think we've already discovered that it's kind of hard to go away from the traditional rectangular design . But I think that , even if it's very subtle , we need to kind of trick our consumers , so they at least get the idea that they're getting something that's new and modern and sleek and {disfmarker} Whether it's through the shape or the colours or all of that . Um for technologically innovative , we've talked about the tracking device . We brought up the idea of having two pieces , which we could discuss further . And Manuel had suggested um the energy source and the user interface , discussing some of those , um that we could change a little bit . We need to keep it simple , have limited buttons , which I think the two piece idea might be really beneficial for . {vocalsound} Um {vocalsound} we need to incorporate this fashion trend of fruits and vegetables . I don't know , I mean I guess the two options are if we had our remote in the shape of a fruit or vegetable .\nProject Manager: {vocalsound} A banana shape ?\nUser Interface: Oh it was sort of banana shaped . {gap}\nMarketing: {vocalsound} Yeah . Yeah . Right . Or with exterior designs . But my question is , I mean the stereotypically speaking , you kind of picture males with their remote controls , and I'm not sure how they'd feel about having fruity logos on the outside .\nProject Manager: {vocalsound}\nMarketing: So maybe we could have something that's somewhat removable , or I don't know , different options for female , male target groups . And then the spongy feel . I guess we could look at mobile phones and other technology that's out there . C and look at different types of material that {vocalsound} might please our users who want spongy-feeling remote controls . So that's that .\nProject Manager: So possibly like a uh ,\nIndustrial Designer: Alright .\nMarketing: {vocalsound}\nProject Manager: sorry , just to butt in for a second . Possibly uh like a cover like they have for mobile phones ?\nMarketing: That's what I was thinking yeah .\nUser Interface: Those like , yeah , sort of spongy ones .\nProject Manager: You have one with a flag , and one with a banana and one that's a spongy\nUser Interface: {vocalsound}\nMarketing: {vocalsound} {vocalsound} Yeah . So when you buy your remote you can buy\nProject Manager: feel to it . {vocalsound} You can {disfmarker}\nMarketing: various coverings .\nProject Manager: Mm various covers .\nUser Interface: What's it called ? Cust you {disfmarker} {vocalsound} personalised , yeah .\nMarketing: Personalise your remote . {vocalsound}\nProject Manager: We could leave that to the cover department . {vocalsound}\nUser Interface: Yeah . {vocalsound}\nMarketing: {vocalsound} Mm-hmm .\nIndustrial Designer: {vocalsound}\nProject Manager: {vocalsound} {vocalsound} We all know they've got nothing to do all day .\nIndustrial Designer: {vocalsound}\nMarketing: {vocalsound}\nIndustrial Designer: {vocalsound}\nUser Interface: Okay . Why can't I see the {disfmarker} crazy . Um yeah I {disfmarker} talking about the interface concept and how the customer relates to , will use the , consumer will use the actual device . Um so I've looked at some of the stuff I was sent , um , try and get some inspiration . But keep in mind that our own ideas that we had . Um I was sent some information from the company saying that they , the technology department have devised a new speech recognition technology , where you can program questions into such devices . They gave an example of a coffee machine where you program a question , you program the answer , and the machine responds accordingly . Um okay . There's different ways of a user can use products l like a remote . Um there's a graphical use , where you you look at pictures and well on a screen . A command line where you obviously type things in , and you get a response . Um and then it ju that's just to point out the sort of inconsistent u sort of use of interface in remotes . You can't really see that picture well , but there's various different remotes , once again with lots of different buttons on , making it more complicated .\nIndustrial Designer: {vocalsound}\nUser Interface: So , then I had a look at new products that are on the market . Not necessarily remote controls but ones that you'll recognise . Um this is the voice , there is a voice recognition remote control , which can control mus multiple devices . I have a {disfmarker} there is a picture {gap} . You surf your favourite channels uh with your voice . Store up to eighty speech samples , controls four devices , T_V_ , cable , satellite , V_C_R_ , D_V_D_ and audio . And you can record your own v verbal labels , that are connected to remote control functions . So the technology is there . Um the one on the left is very similar to what we drew up on the board in the previous meeting , where there {disfmarker} has scroll down functions on the side . You can sort of just make those out . And then on the right is obviously an iPod , which is you know possibly one of the simplest things to use out there , and really is , and all that is is just a a nice big scroll menu that y you sort of go through . That is a {vocalsound} possibility . And nothing's simpler really . Um then there's things like this , which is a a a kid's remote , where the the parents have the facility to control and program what children can watch before . So the remote control it o only allows them to access the channels that their parents want them to watch . And um it means that th children have a novelty of having their own remote control . So I don't know {gap} if there's a possibility of having one remote contr you know like we just had two components , maybe it can have more components you know , different remotes . Um the point made at the end there here is that you have to be sort of be {disfmarker} need to be clear on your um devices , as to what , you know , things you use . Sometimes an arrow pointing down , which may suggest volume down , could become confused just as a V_ for volume . Just little things like that , which would need to be made clear in the design . Um I think , d carrying on from what I've already said , a user friendly remote with minimum buttons . Maybe we've so suggested this two-part thing , where if it was to have a speech recognition thing , you could maybe control that on the {disfmarker} do it {disfmarker} or program all that on the control bit . And then just have the simple sort of hand-held thing that we sort of devised earlier , as the actual remote . Um I don't {disfmarker} it could be a graphical display , the actual remote contr the actual control port maybe could have like an iPod where you just sort of control through the menus . Stuff like {gap} gets more and more compli complicated . And then the the hand-held bit should be ergonomically designed . And that is it . Why am I {disfmarker} Oh yeah . Just {gap} . {gap} Where are we ? Uh . Just to sort of show you . M {gap} they've even got things like that .\nProject Manager: {vocalsound}\nUser Interface: Huge things . Which is just {gap} for your gr ninety year old grandma yeah ?\nProject Manager: {vocalsound}\nMarketing: {vocalsound}\nIndustrial Designer: That's industrial design for cranes , stuff like that .\nUser Interface: Yeah . Yeah .\nProject Manager: {vocalsound} Notice the giant dog bone shape ?\nMarketing: {vocalsound} Dunno .\nIndustrial Designer: Makes sense , makes sense .\nUser Interface: And that {disfmarker} yeah .\nIndustrial Designer: {vocalsound}\nProject Manager: Also good for animals .\nUser Interface: Yeah . See . {gap} things {gap} . {gap} . Why's my screen crazy ?\nIndustrial Designer: Uh {disfmarker} Well let's see . I'm going to bore you with a couple of descriptions of the interior .\nProject Manager: {vocalsound}\nMarketing: {vocalsound}\nIndustrial Designer: Just to to make it more obvious what we have to fit in there , and that we do have to fit the stuff in there . I've more information on possible materials um as well . What we can and cannot do . Um but let's just wait for this to load up and I'll show you what we're talking about here . Okay . The details of the components' design , as you can see there , what we have is the board , main board of the remote control . {vocalsound} The underside , that's pretty cheap piece of of technology really {gap} top left side you can see the chip , which is the , what we were talking about , this was is the device to recognise the signals the input , and it passes it on to a row of um further transistors and stuff like that on the right side that actually amplify the signal , which later on is being , is being transferred to a infrared lamp which then um of course shines infrared light onto the television which then will recognise what signal um it's getting and will do what you tell it . Um {disfmarker} So much for the the workings of the of the uh remote control itself . {vocalsound} Its job is to wait for you to press a key , then to translate that key press into infrared light signals , um that are received by the television . When you press a key um you complete a specific connection . The chip senses the connection and knows what button you pressed . It produces a morse code line signal specific to that button . Right . Pretty clear . Transistor amplifies the signal and then sends the m sends the signal to the L_E_D_ which translates the signal into infrared light . The sensor in the T_V_ can see the infrared light , and seeing the signal reacts appropriately . This is the circuit board from the other side . Um the lower part of it , I don't know if you can see that properly , with the green greenish board is is what we what we saw in the first the first slide just flipped over . Um you can see the circuit board itself . That's the cheapest uh way to make electronic connections basically on the market . Um what you do is you have , don't have cables , but you have the connections actually in these in these lines on the on the board . These are the actual keys that are being pressed . They close the electric circuit . That then sends the signal to the chip on the other side . That would be behind here . Um which uh sends it over to the transistors and all that stuff that\nMarketing: {vocalsound}\nIndustrial Designer: amplify the signal and all that is being sent to the infrared lamp up there . Now as you can see this is the the rubber button version of it . {vocalsound} Um the way it works is that you have the keys here . The rubber button has a little metal uh plate on the other side , which closes the circuit here . And thus gives on the signal . Now this is the simple version . {vocalsound} Um we are talking um this this the simple and cheapest version at the same time . We are talking something more complicated of course , it's going to be more expensive as well . And not only that . Um we are also restricted in the use of our outer shell , or in the material that we could use for our outer shell . Um {vocalsound} I've gotten some information that we could use for the case material plastic , rubber , as well . Um rubber that is used in these anti-stress balls . So it's pretty squishy . That would that would serve that purpose .\nMarketing: {vocalsound} Spongy ?\nIndustrial Designer: Um {vocalsound} we could also use wood , or titanium .\nProject Manager: {vocalsound} What's the approximate per hundred thousand for the titanium ? {vocalsound}\nUser Interface: {vocalsound}\nMarketing: {vocalsound}\nUser Interface: {vocalsound}\nIndustrial Designer: Oh fya\nMarketing: {vocalsound}\nIndustrial Designer: I don't have an information on that . However our company {vocalsound} obviously can provide us with uh with the titanium , so I assume , I'm , I was given an okay to use it .\nProject Manager: {vocalsound}\nIndustrial Designer: {vocalsound} It certainly is an expensive material ,\nProject Manager: {vocalsound}\nIndustrial Designer: I'm aware of that , but I was given an okay .\nMarketing: {vocalsound}\nIndustrial Designer: But there are certain restrictions to certain materials . Now let's first go through the list with the materials . So we what we can use is plastic , rubber , wood and titanium . Can also mix these . Um as for the energy source , um we were talking about that shortly in the other meeting . Um what we could use is , or what I was offered , or what we could use , is a basic bateer battery . Right ? Uh a dynamo . Interestingly enough .\nMarketing: {vocalsound}\nIndustrial Designer: Um we could use solar cells . Or a device that was not n not further specified that provides kinetic energy . Such as like watches you know . Where you just move them m move the the actual device and this pr uh provides it with with uh some energy . So um obviously I personally have to say that dynamo is out of the question really .\nProject Manager: {vocalsound}\nUser Interface: Mm .\nMarketing: {vocalsound}\nIndustrial Designer: You don't wanna wind up your remote control before you can use it right ? Um solar cell is interesting . {vocalsound} May fail though , every here and there .\nUser Interface: Would you have to leave it by the window ?\nIndustrial Designer: Mm . Yeah\nUser Interface: {gap} yeah . {vocalsound}\nIndustrial Designer: . Or you know you lose it , it lies behind the couch for a week\nUser Interface: Yeah .\nIndustrial Designer: and {disfmarker} yeah mm .\nProject Manager: Works well in Arizona but in Edinburgh not so {disfmarker}\nIndustrial Designer: Always the {disfmarker} you {disfmarker} But {disfmarker}\nMarketing: Y probably not yeah .\nIndustrial Designer: exactly .\nUser Interface: Yeah .\nIndustrial Designer: Um the kinetic energy thing um might work , um but the same problem . You leave it lying around and you first have to shake it before it it starts to work .\nMarketing: {vocalsound}\nIndustrial Designer: So I'd say what we're stuck with really is um the basic battery . Which also makes a base station basically obsolete . We don't need that then . Um {disfmarker} However our interface options are push-buttons . In which uh in the production of which or in manufacture of which um our company is expert . Um {disfmarker} However we've discussed that scroll wheels are a better option . And they are possible . We have an okay for scroll wheels . Okay . Um however {vocalsound} when it comes to the scroll wheel of the iPod I've one big objection and that is that we have to fit an L_C_D_ into the remote control as well . This however may exclude certain um materials . If you have a squishy uh kind of remote control , then an L_C_D_ screen may be affected by the movement . Hence we might not be able to put it in there . So um {disfmarker} There's also restrictions {vocalsound} to , when it comes to the chip . If we have a more sophistic uh sophisticated scroll wheel rather than this very basic uh set-up that we that I've just presented , um the chip has to be more s more sophisticated and thus more expensive as well . I don't have any details to , when it comes to the cost but um it will be a significant difference . I'd rather say drop the titanium and therefore let's have a more sophisticated chip , but that's not up to me to decide really . {vocalsound} So that's for the for the scroll wheel . Um it limits our choice and squishy is hip , so I'd say rather not go for for that . Let's see now . Um um solar cells cannot be used on a curved or latex um surface or um remote control . But obviously that's not our problem um since we have decided or against solar cells , I assume right ? Or is anybody still {disfmarker}\nMarketing: Mm .\nUser Interface: Yeah .\nProject Manager: {vocalsound} No I think I think batteries are probably the way to go .\nIndustrial Designer: alright .\nMarketing: No . Hmm .\nIndustrial Designer: {vocalsound} Alright .\nUser Interface: Yeah .\nIndustrial Designer: Uh which makes it very conventional but therefore traditional I assume . Um {disfmarker} Um {disfmarker} With the titanium um we cannot make it a curved design . We would just be able to make it flat and and um yeah a straight design pretty much . Which I assume would exclude uh some of the more sophisticated versions . {vocalsound} {vocalsound}\nUser Interface: Would the sort of {vocalsound} spongy and the the plasticky thing {disfmarker} y you can get those mobile phones that initially have a {disfmarker} it is plastic but then they have sort of a a s a cover on it which is just sort of soft and stuff .\nMarketing: Mm . Like a covering . Yeah .\nUser Interface: So I don't know if that would still be possible to have you know {gap} in plastic . But then where do people hold it ?\nProject Manager: Yeah .\nUser Interface: Just all be sort of spongy .\nMarketing: The we can have the fruits and vegetables on the spongy parts , so they can remove it .\nUser Interface: {vocalsound} {vocalsound} So you {vocalsound} as the the possibility of having a a graphical display on it , like a screen ? Like the iPod ?\nIndustrial Designer: You can have an L_C_D_ screen . Um but therefore no rubber will be used .\nUser Interface: Right .\nIndustrial Designer: Alright ? So plastic yes , titanium yes , but this will of course influence the form . With plastic , as I understand it , you can use any form . Um latex is tricky . Or rubber and um and titanium also seems to be tricky when it comes to the form . So the way to go is if you want a scroll wheel you either make it flat and angular , uh add an L_C_D_ screen , and um then you can basically choose either plastic or titanium . Or wood even .\nUser Interface: Yeah . {vocalsound}\nIndustrial Designer: Um if you wanna make it a particular shape , use plastic . Add an L_C_D_ screen , add a scroll wheel , that'll be fine .\nUser Interface: Yeah .\nIndustrial Designer: Or make it just push-buttons . Basically plastic gives you the b biggest variety of of options . Maybe not the nicest feel . Or not much originality really .\nProject Manager: So the ru wait the rubbery {disfmarker} we can shape it however we want ? Or the rubbery we cannot ?\nIndustrial Designer: {vocalsound} With rubber we could uh sh pretty much shape it the way we wanted it ,\nProject Manager: 'Kay .\nIndustrial Designer: but we cannot add scroll wheels , and we cannot add an L_C_D_ screen .\nProject Manager: Mm .\nMarketing: Mm .\nProject Manager: Mm . {vocalsound}\nIndustrial Designer: {vocalsound} That's the tricky thing .\nUser Interface: Could we not you know have a shape with a scroll and the screen , and then j just sort of that initial shape we had , just which is uh sort of banana-esque . So that's {gap} thing if we did it yellow .\nProject Manager: Yeah .\nUser Interface: And um you know you just p stick on just sort of rubber things that that sort of grip the thumb bit . They wouldn't have any {disfmarker} they're just on the exterior . They wouldn't be necessary to the actual shape of the thing .\nProject Manager: Is that an option , a plastic shell with a rubbery coating on at certain spots ?\nIndustrial Designer: S Certainly can be done yes . Um yeah . if that doesn't affect the functional side of it all .\nUser Interface: Yeah .\nIndustrial Designer: Like say just the underside or so then it can be done . I assume . Yeah . So {disfmarker} {vocalsound} The fruit design um {disfmarker} How about um affecting the surface of the actual um remote control ? Say we don't make it p a particular fruit shape obviously ,\nMarketing: Mm .\nIndustrial Designer: but uh give it like the surface of an orange , banana , whatever . You name it .\nUser Interface: Mm .\nProject Manager: What about a smell ?\nIndustrial Designer: Just design-wise .\nUser Interface: {vocalsound}\nMarketing: {vocalsound}\nProject Manager: T {vocalsound} to the remote ? {vocalsound}\nIndustrial Designer: Mm . Nice one .\nUser Interface: You could just sell it in different colours as well I suppose . In different ye yellows .\nMarketing: Bright citrus colours yeah . {vocalsound}\nIndustrial Designer: Mm .\nUser Interface: I don't suppose we have to stick to co\nIndustrial Designer: Well we we're supposed to stick to the company colours though ,\nUser Interface: Stick to the colours yeah .\nMarketing: Oh yeah .\nIndustrial Designer: that's yellow and grey .\nMarketing: Yellow and grey .\nProject Manager: Yellow and grey .\nIndustrial Designer: So what have we , lemon , banana , is {disfmarker}\nUser Interface: Mm grapefruit . {vocalsound}\nProject Manager: Grapefruit .\nIndustrial Designer: Grapefruit\nMarketing: {vocalsound}\nIndustrial Designer: is what we'd go for , when it comes to the outer appearance perhaps . But {disfmarker} mm .\nProject Manager: I would say , if I were to make a decision , I would probably put the fruit aspect at the lower lower end of the spectrum of of importance .\nUser Interface: Yeah .\nMarketing: {vocalsound}\nUser Interface: {gap} .\nProject Manager: Um {disfmarker}\nMarketing: I think having a shape could be a little ridiculous ,\nProject Manager: {vocalsound}\nMarketing: {vocalsound} like {disfmarker}\nUser Interface: Yeah .\nIndustrial Designer: Well we have it banana-shaped already , kind of .\nMarketing: {vocalsound} Well we kinda do yeah .\nUser Interface: Yeah .\nIndustrial Designer: So {disfmarker}\nProject Manager: Well perhaps the implied shape will be enough to lure that fruit-minded remote buyer .\nUser Interface: Yeah . {gap} {vocalsound} and if it if it was done yellow , which is a company colour .\nMarketing: {vocalsound} And if it's yellow ? {vocalsound}\nIndustrial Designer: Right .\nProject Manager: It's it's yellow . It's curved .\nIndustrial Designer: I it's yellow .\nMarketing: Grey buttons yeah .\nProject Manager: It's sort of {vocalsound}\nIndustrial Designer: Well so why not add a couple of grey stripes and make it look like a banana ? {vocalsound}\nProject Manager: couple of couple of grey stripes .\nMarketing: {vocalsound}\nUser Interface: Yeah . {vocalsound}\nProject Manager: {gap} We could put the grey stripes on the bottom so that that person could turn it over .\nUser Interface: On the the gr the rubbery grips could be grey .\nProject Manager: It would look like a banana just sitting on their table .\nMarketing: Mm .\nUser Interface: Yeah .\nIndustrial Designer: There you go .\nProject Manager: Rather than {disfmarker} {vocalsound} rather th {vocalsound}\nIndustrial Designer: {vocalsound}\nMarketing: {vocalsound}\nUser Interface: It could {disfmarker} and then you could actually h put the banana-shaped thing on the fruit bowl , on the coffee table ,\nMarketing: Oh .\nUser Interface: and then people would always know where it was .\nProject Manager: Maybe the holder , if we were to have a holder , it could be shaped like a fruit .\nMarketing: Nice . Could look like a fruit bowl .\nIndustrial Designer: It could be an ape . {vocalsound}\nProject Manager: {vocalsound} Could be ,\nMarketing: {vocalsound}\nUser Interface: {vocalsound} Yeah .\nProject Manager: it could be an ape or a fruit bowl . we could have a variety of options here .\nUser Interface: Yeah .\nIndustrial Designer: {vocalsound}\nMarketing: {vocalsound}\nProject Manager: {vocalsound}\nMarketing: 'Kay .\nIndustrial Designer: Yeah .\nProject Manager: Do you have more to your presentation ?\nIndustrial Designer: {vocalsound} That's pretty much it . I informed you about the materials , what the interior has to look like , and what the limitations to certain materials are on\nProject Manager: Oh .\nIndustrial Designer: {disfmarker} there you go .\nProject Manager: Okay . I'm gonna plug in here real quick . If I could .\nIndustrial Designer: Sure . Hang on . There you go .\nProject Manager: Like I said we have to make a decision on a couple of these items here . Um {disfmarker} ow . Ow .\nMarketing: So is the two piece idea out ? Or have we not decided ?\nUser Interface: Well we sort of {disfmarker} {gap} rid of that because {gap} gonna use a battery . And the base station might not be necessary .\nMarketing: Oh right okay .\nIndustrial Designer: Well we can still design a two-piece uh remote um without having a base , having one of them be a base station ,\nUser Interface: Yeah .\nMarketing: {vocalsound}\nIndustrial Designer: but just have it be an optional either big remote with lots of functions , or you take out the smaller piece .\nUser Interface: Yeah .\nMarketing: Mm .\nIndustrial Designer: We can still do that . However {vocalsound} of course this would be like designing two remotes pretty much .\nProject Manager: Mm-hmm .\nIndustrial Designer: So um which then , as I understand it , would probably limit the , limit again the the the use of certain materials , because they would be too expensive . Say like have a scroll wheel and uh on both of them , or have an L_C_D_ screen and so on so on . You'd probably have to stick rather with a just traditional rubber button\nMarketing: Mm .\nIndustrial Designer: design which we saw there .\nMarketing: Mm . {vocalsound}\nIndustrial Designer: But could be done , of course .\nProject Manager: Okay . Uh so these are the decisions that we do need to make by the end of this meeting . Um for our components concept we need to come up with the energy source , um the chip-on-print , and the case . Probably case um material . And probably a shape also . Um and then for the user interface concept we need to decide what the tape , what , what the type is . And what kind of supplements we'll have . Um {disfmarker} {vocalsound} Energy source I think we've , I think we've decided batteries , although not exciting , are probably our best bet .\nIndustrial Designer: Right .\nProject Manager: And we have five minutes .\nIndustrial Designer: Okay when it comes to the chip-on-print , as I said , the the more advanced features you want , um the fancier the chip has to be and the more expensive . Uh if you want just a normal button version , the chip-on-print is gonna be\nMarketing: Mm .\nIndustrial Designer: a cheap one .\nProject Manager: 'Kay .\nIndustrial Designer: Right ?\nProject Manager: So {disfmarker} Um I guess we should pick the case then . If we go with the plasticky case , or the the plastic case , um then the chip-on-print is still kind of , we could have either or . We could have a complex one or a a non-complex . But did we decide that the rubbery feel was important enough to us ?\nIndustrial Designer: Yeah .\nMarketing: Well what about what you said , like putting the\nUser Interface: Just {disfmarker}\nProject Manager: {gap} .\nUser Interface: just maybe {disfmarker}\nMarketing: finger grips just on top of the plastic ?\nUser Interface: yeah . Just a little bit of {gap} .\nProject Manager: Okay . So we would , we would have the L_C_D_ screen ?\nIndustrial Designer: {gap} as long as the pla uh the rubber is nowhere near the controls , yes .\nProject Manager: 'Kay . So I guess the case would be plastic , with {disfmarker} Perhaps that's not even enough rubber to qualify as being part of it . It's more of a su it's more of a supplement maybe .\nIndustrial Designer: {gap} .\nUser Interface: Yeah .\nIndustrial Designer: M more of a l lamination perhaps . {vocalsound}\nMarketing: Yeah .\nUser Interface: Yeah .\nMarketing: So then for the scroll , are we going for the iPod type ?\nUser Interface: Yeah I think so . I think {disfmarker}\nMarketing: Yeah ? Okay .\nProject Manager: {vocalsound} Which will require a more expensive chip-on-print right ?\nIndustrial Designer: Yes . It does .\nProject Manager: 'Kay . So {disfmarker} I guess that , is that , is that about it ? So we have a good idea of what we're gonna need to to do on this ?\nIndustrial Designer: Right .\nProject Manager: Um okay so we will have another meeting in thirty minutes . Um {vocalsound} {disfmarker} Here's what's gonna be going on . Um {disfmarker} Um Ryan you'll be working on the user interface design . Um {disfmarker} Manuel you'll be working on the look-and-feel design .\nIndustrial Designer: Right .\nProject Manager: Corrine we'll want a product evaluation . And the two of you get to play with the uh modelling components and uh\nUser Interface: {vocalsound}\nMarketing: {vocalsound}\nProject Manager: maybe and and get us a prototype . Which should go along well with your look-and-feel design and your interface .\nUser Interface: {vocalsound}\nProject Manager: So that {vocalsound} basically {gap} just be working on the prototype , {vocalsound} uh we'll accomplish your other two actions .\nIndustrial Designer: {vocalsound}\nProject Manager: Alright . {vocalsound} Okay . Let's do it . {vocalsound}\nIndustrial Designer: {vocalsound}", "source": "meeting_summ", "evaluation": "rouge"}
{"instructions": ["Summarize the discussion about the reduction of buttons and application of speech recognition.", "What did Marketing and Project Manager come up with when it came to reducing buttons?", "Why didn't the team believe that the remote control could fully depend on speech recognition and have no buttons?", "What did the group discuss about energy sources?", "What did Project Manager think about energy source?", "What did Industrial Designer propose when discussing energy sources?", "Summarize the whole meeting."], "outputs": ["Marketing summarized the market research results and revealed that fifty percent users only use ten percent of the buttons. So the team proposed to reduce buttons to a minimum. Marketing believed that speech recognition could also contribute to this regard. User Interface showed a user-centred remote control and an engineering-centred one and preferred the user-centred one as it had fewer buttons and was easier to hold.", "Marketing proposed to apply speech recognition and suggested that some of the buttons could be hidden from everyday use. Project Manager agreed and proposed to get the remote control with no buttons but later rejected the idea and supposed that dual functions could be used.", "Age group data for remote control use was not available; many people may not want to learn to use the new remote control; some buttons are still needed, such as channel control, volume settings and on/off.", "Project Manager expected to have a remote control permanently available. Industrial Designer proposed to have a rechargeable battery or a battery dock, while Project Manager preferred a disposable one. Then Industrial Designer came up with a combination of both solar and conventional batteries.", "Project Manager preferred to have disposable remote control of which battery life was predetermined and proposed to move parts more by not even having a battery compartment. The usage of permanent batteries was also proposed.", "Industrial Designer initially proposed to have rechargeable energy sources and then suggested a combination of both solar and conventional batteries. It means that if there's enough light, then it's using the light, but when it is dark, then the battery is used.", "This is the second meeting of the design group. Project Manager went through the notes of the last meeting and informed the team of the management's requirements. They expected the remote control to cover television only and asked the team to incorporate the company logo and colours. As the team is looking at extreme simplicity, the buttons should be reduced to the absolute minimum. Voice recognition can also be added to reach this point. In addition, the remote control can be powered by a rechargeable or permanent battery."], "input": "Industrial Designer: {vocalsound}\nProject Manager: Okay , welcome to the second meeting of this uh design group . Um {vocalsound} I'll briefly go through the uh notes of the of the last meeting uh just done in in note form and I haven't attributed anything to individuals , because we're working strictly as a team here and uh n nobody's working equally ,\nUser Interface: Sorry .\nProject Manager: so uh . Um we we s we saw that the the problems with existing remote controls were the uh b a boring shape and boring colour . Um and and we s we saw that the um what we needed to do was to to make sure the device um controls several items , that switching was easy , that you shouldn't need to point the thing at uh anything in particular , um that it need to be contoured to make it interesting , that the keys might be concave , simply because that hasn't been done before that we know of . Um should have interchangeable fascias so people can personalise it , um illuminated so that people can see it in dark rooms . Um and that people might want it as as {disfmarker} in addition to their existing remote controls . Um {vocalsound} and that it sh it should just always work , whenever you uh um mm uh use it . And that it shouldn't be too small , mm that it it gets lost . Um . {gap} Now uh uh I'll shortly ask for for three three presentations . Uh before I do that , however , I will go through some new project requirements that um {disfmarker} the the management have placed on us and uh will be challenging in terms of what we discussed at the first meeting . Um the uh the ma the management has had it's own thoughts on this and uh the they don't necessarily agree with with what we uh we thought . Um and and then we'll {disfmarker} as a result of that we will then talk through the the functions that we see the the device um actually b carrying out , and we have uh forty minutes to do this in and I uh {disfmarker} Anyway . Okay . Now , the n the new requirements are um the the management team see that um teletext is no longer of any importance given the uh the rise of the internet . Um and and they want it only to cover televisions . Um now , what is not q quite clear from their directive is whether they mean th they don't want it to cover teletext or whether they don't want it to cover , you know , videos , D_V_D_s , um satellite boxes , which uh {disfmarker} I mean we saw as being fundamental to the uh to the exercise . The um the actual wording of the directive is that it should cover television only . Um and on that basis um I I think we we need to bear that in mind , um but possibly uh keep at the backs of our minds that the reality that people even when they uh no longer {disfmarker} they don't look at teletext anymore , they certainly do look at other things . Um {vocalsound} the device has to incorporate the company logo and colours . Um the the logo uh being at b the bottom of the screen there , the the the two R_s in grey against uh a yellow background . Um now this doesn't {vocalsound} necessarily mean that we have to give up some of our ideas about making it attractive to the t to the market . But uh do do introduce some some constraints as to how we might do that . Um it also has to be simple , which to some extent goes along w with the first one , and that {disfmarker} we've already said that it must be simple 'cause that's what people want anyway . Um but they also want it to be simple to get it to the market quickly , which um mm {vocalsound} uh is is is their choice , but uh um we we need to talk that through . Um okay , so uh after the meeting it'll be summarised and uh\nIndustrial Designer: {vocalsound}\nUser Interface: {vocalsound}\nProject Manager: um notes sent out and uh etcetera . Okay , so {vocalsound} we'll first of all mm have individual reports from everybody . Um again I {vocalsound} {disfmarker} there is no order of precedence here um so I I I'll leave it up to you to {disfmarker} who who who thinks they would like to go go first ?\nMarketing: Uh I don't mind . {gap}\nProject Manager: P fine .\nMarketing: Uh can I steal the cable ?\nProject Manager: Oh sorry , you can indeed .\nMarketing: Cheers .\nProject Manager: {vocalsound} {vocalsound} {vocalsound}\nMarketing: {vocalsound} I got a {disfmarker} how do I start there ?\nProject Manager: Oh , if you click on the um uh the one that that looks like a projection screen , no the one to the right of that . That one .\nMarketing: That one . Cool . Well these are functionality requirements from the {disfmarker} our our guys down in the the research lab . Took hundred people and covered all the aspects of what um is needed by people and what they want to see . Um {vocalsound} everything kinda from functionality and how individual functions are {disfmarker} how mu how how often they're used and how much their necessary and stuff . And general opinions about current current remotes . See that , as we kinda noticed , seventy five percent of people find their remote controls ugly . So some kind of a new style should be incorporated that's less ugly {vocalsound} . Uh along with um looking less ugly , if it looks better , eighty percent of people said they'd spend more money on it . Which is a a plus for us , if we can make it look better , it'd be uh more cost effective and we can put the price up . Current remote controls do not match the operating behaviour of the user . I can empl I kinda take that to mean as um {vocalsound} they they don't uh {disfmarker} they , yeah , they only use {disfmarker} they only work for the television or yeah like as in in my flat I've got six remote controls for a stereo system , a digital box , a D_V_D_ player , a video player and T_V_ . If it was uh {disfmarker} I mean th my behaviour is to use multiple things at the same time and multiple remotes aren't really matched well to my behaviour . {vocalsound} Uh again , seventy five percent is {disfmarker} seventy five percent of users say they zap a lot . I took to mean that they just {disfmarker} they use it a lot , they use it regularly rather than standing up and manually change channels or volume {gap} . {vocalsound} And uh yeah , uh I think the big issue is fifty percent users only use ten percent of the buttons , 'cause uh wh if we got a remote that like {disfmarker} well we'll have some buttons taken off by the lack of teletext , but uh oh and we're going to see uh on the {disfmarker} uh that some of the functions like audio settings aren't h hardly ever used and used very {disfmarker} aren't considered relevant by the user . So I think maybe fewer buttons , which also make the design look sleeker , I dunno . Uh um yeah and uh frustrations of like people losing remote control .\nProject Manager: Mm .\nMarketing: I dunno maybe some kind of system of you press a button on the T_V_ or maybe that's b it would have to incorporate {gap} , but like some kind of system where you can f use something else to find the remote control . Maybe like it'll beep or something . And um , yep , the uh time taken to learn new remote controls is {disfmarker} Uh don't want to make it too complicated , easy to use for uh new {disfmarker} like first time users and stuff . And uh repetitive strain injury , I suppose we should make it more comfortable and make ma possibly even use {disfmarker} have to make it , yeah , fewer buttons , like I was saying about the whole mice {disfmarker} the mouse idea of it feels more comfortable .\nProject Manager: Mm .\nMarketing: Maybe don't even have to hold it as such .\nProject Manager: Gosh , must be some telly addicts out there if they get R_S_I_ from their television remote , is all I can say .\nIndustrial Designer: {vocalsound}\nMarketing: {vocalsound}\nUser Interface: {vocalsound}\nMarketing: But uh yeah . It also asked um if we would {disfmarker} if people would pay more for speech recognition\nProject Manager: {vocalsound} {gap}\nMarketing: and younger people say they would . And uh there was another section on our {disfmarker} on the report for uh L_C_D_ displays , but the data wasn't there , so . I don't actually know what the results for that were ,\nProject Manager: Mm . Right . Mm .\nMarketing: so . {vocalsound} May be incrementally emitting , but yeah .\nProject Manager: Yeah , I must say that um the uh {disfmarker} I c can't remember what {vocalsound} um f you know phone service I was using the other day , but that had sorta speech recognition which worked uh remarkably well , so that is indeed a uh um a thought\nMarketing: And uh {vocalsound} it would cut out the R_S_I_ as well if you {disfmarker} {vocalsound}\nProject Manager: and it it cuts out uh {disfmarker} I was was gonna say , you can't get a lot of R_S_I_ ,\nIndustrial Designer: {vocalsound}\nProject Manager: j just get jaw ache . Okay , sorry . {vocalsound}\nMarketing: Yeah , um {disfmarker} oh yeah , so possibly the speech recognition is possibly something could add into the design . Oh , I've got some other things I couldn't fit onto this presentation . Um . You see this okay ? Almost {disfmarker} no ? It's {disfmarker} sorry it's a bit {gap} . I'll read out to you . Uh functionality , uh like people's opinions on functionality , the relevance to the remote and how often they're used . So um like the power . Using the using the d swi the power switch to switch on T_V_ is a high relevance of nine , but it's not frequently used . You see what I mean ?\nProject Manager: Yeah . {vocalsound}\nMarketing: Whereas channel selection , which is very high relevance\nProject Manager: Mm-hmm .\nMarketing: is used the most . So m we can maybe even start to cut down on {disfmarker} or I was possibly even thinking of a design that maybe some of the buttons are hidden from everyday use . Maybe like uh a folding ledge or something . So that we can maybe go into the channel settings and the audio settings ,\nIndustrial Designer: Mm .\nMarketing: which are low relevance\nProject Manager: {vocalsound} Mm-hmm . I mean {disfmarker}\nMarketing: and rarely used . And keep the v volume selection and channel selection very easily {disfmarker}\nUser Interface: It could be {disfmarker} oh uh I was just gonna say uh maybe like the flip phones that they use ?\nIndustrial Designer: Mm .\nUser Interface: Have you seen the new mo mobile phones\nProject Manager: {vocalsound} Yeah .\nUser Interface: that flip out and they have the like texting , and then the numbers on one side ,\nMarketing: Oh yeah .\nUser Interface: so\nProject Manager: Mm .\nUser Interface: you could have the most {vocalsound} used buttons on top and flip it out or something .\nProject Manager: Hmm , hmm .\nIndustrial Designer: Mm .\nMarketing: Yeah , like the one that like slides back\nProject Manager: Uh . Should we actually bite the bullet here ?\nMarketing: and the buttons are concealed underneath .\nUser Interface: Yeah .\nIndustrial Designer: Mm .\nProject Manager: If people really don't use those buttons to any extent at all um {vocalsound} remove them altogether .\nMarketing: Just remove them completely ?\nProject Manager: We we could actually have we could actually have a remote control with um {disfmarker}\nUser Interface: That might be the {disfmarker}\nProject Manager: I wonder whether we could get the remote control with no buttons at all if we went for voice recognition , given that um the {disfmarker} {vocalsound} Um now the the age structure we were looking at {disfmarker} um I mean w we had usage by age structure , what we didn't have was what proportion of people using remotes were in those particular age groups . Now do we know whether they {disfmarker}\nMarketing: Uh yeah .\nProject Manager: Forty {disfmarker} no sorry {disfmarker} for forty five to fifty five age group , uh to put myself right in the middle of it , um u use remote controls to a great extent .\nMarketing: {vocalsound}\nIndustrial Designer: {vocalsound}\nProject Manager: Yes we {disfmarker}\nMarketing: Um no this is for {disfmarker} pay more for speech recognition .\nProject Manager: That would 've speech recogn right . So , we're looking at {disfmarker} um well again , we don't know the relative proportion {disfmarker} the relative numbers in the age groups .\nMarketing: Yeah , that's true .\nProject Manager: If we wanted something different , truly different , then the buttonless remote control w would be it .\nIndustrial Designer: P Well the only problem I can think of with that is if you've got a lot of people that don't wanna be bothered learning how to use new rem remote controls . If you just kind of take away everything that they're used to knowing , that's gonna be quite a change .\nProject Manager: But if you just lift it up and say , channel one or B_B_C_ {disfmarker}\nIndustrial Designer: It might {disfmarker}\nMarketing: Or even {disfmarker} I mean you could even just have it left on .\nUser Interface: Maybe i\nMarketing: You could just put it down once on top your T_V_ and never have to {disfmarker}\nUser Interface: Yeah , have a big kind of like the satellite box or the cable box\nProject Manager: {vocalsound}\nUser Interface: and have it just go on the T_V_ and then it doesn't matter where in the room you are ,\nIndustrial Designer: Mm .\nUser Interface: you won't lose it .\nMarketing: Yeah .\nProject Manager: It c well it {disfmarker} I can I can see technical problems with that in terms of the , you know , the sound from the television ,\nIndustrial Designer: Mm .\nUser Interface: No .\nProject Manager: because if somebody actually on the television says uh uh , you know , I_T_V_ and you're watching B_B_C_ then then it might um change itself ,\nMarketing: {vocalsound} B_B_C_ one . {vocalsound}\nIndustrial Designer: Yeah . {vocalsound}\nUser Interface: {vocalsound} Oh . {vocalsound}\nIndustrial Designer: Yeah .\nMarketing: {vocalsound}\nProject Manager: so it probably needs to be um {disfmarker} possibly actually need a button on it\nUser Interface: Yeah , that's true .\nProject Manager: just to activate it .\nMarketing: Oh yeah .\nProject Manager: Or or something just to identify that you've lifted it up and it's use . And and then just say , oh I don't know , a thought and and then {disfmarker}\nUser Interface: Yeah .\nProject Manager: uh I mean that that would certainly be uh truly different . {vocalsound} Um 'cause uh you know audio settings , nought point eight percent . I mean if they weren't there , {vocalsound} would people miss them ?\nMarketing: Mm-mm .\nIndustrial Designer: But look at the importance of them . The volume settings .\nProject Manager: {vocalsound}\nMarketing: Relevance of two out of ten ,\nProject Manager: Vol volume ,\nMarketing: yeah .\nIndustrial Designer: Yeah .\nProject Manager: yes um\nIndustrial Designer: They're not used often\nProject Manager: th {vocalsound}\nIndustrial Designer: but they are quite important when they're used .\nProject Manager: w we need to s identify things that {vocalsound} people actually need\nIndustrial Designer: Yeah .\nProject Manager: and and it's a function of frequency and relevance . And um I would say ignoring ig ignoring power for the moment , um the channel and volume\nIndustrial Designer: Mm .\nProject Manager: and th w w given given that we've been told to ignore teletext . Uh channel and volume are the only ones that\nMarketing: Yeah .\nProject Manager: {vocalsound} uh would appear to be essential .\nMarketing: Stand out .\nProject Manager: Um . So {disfmarker} if we can design something that that looks interesting , know , or looks different , um incorporates the the logo and and the colours and um we can still have our interchangeable fascias even if it's {gap} the yellow and grey , um and uh I dunno , buttons or or buttons as an option .\nMarketing: Uh I just had a thought actually , sorry to interrupt .\nProject Manager: Do , please .\nMarketing: Uh you were saying about um it could {disfmarker} technical problems of like uh someone on the television saying a channel number and it changed {disfmarker}\nProject Manager: Mm-hmm .\nMarketing: we could maybe have like an activation word .\nProject Manager: You cer certainly could .\nMarketing: 'Cause I've seen I've seen this used on computers before , where you just {disfmarker} you address the remote ,\nProject Manager: {vocalsound} Depe uh i depends whether um {disfmarker}\nIndustrial Designer: Mm .\nMarketing: you address the computer , and then give it a command .\nProject Manager: if we want to make this so simple that anybody can walk into the room and lift it up and say\nMarketing: Oh I see . Oh yeah , I see .\nProject Manager: B_B_C_ one . Um okay , I mean you could print {disfmarker} actually print it on the uh\nMarketing: {vocalsound} Mm-hmm , yeah .\nProject Manager: device itself . Um .\nMarketing: I mean I'm just thinking of the point of view of peop you could still like lose this remote .\nProject Manager: S th this I th {vocalsound} that's always gonna be a problem I think .\nIndustrial Designer: {vocalsound}\nMarketing: Mm .\nProject Manager: Um and I I I s so I suppose one um {disfmarker} could make it so desirable that if people lose it they immediately go out and buy another one .\nIndustrial Designer: {vocalsound}\nUser Interface: {vocalsound}\nMarketing: {vocalsound}\nProject Manager: Anyway , sorry , carry on . Do you want to just carry on with {disfmarker}\nMarketing: Oh no\nProject Manager: or {disfmarker}\nMarketing: I I interrupted you ,\nProject Manager: no no , no uh b I was in the middle of in the middle of your report there . {vocalsound}\nMarketing: sorry {vocalsound} . Oh okay . Um well , I was just kinda wrapping up there . Yeah ,\nProject Manager: Mm okay . {vocalsound}\nMarketing: I was thinking um , yeah , maybe such things are relevant . We could make things much more f I think the the eighty percent of people would spend more on uh a remote uh that looks better , combined with uh decrease the {disfmarker} or take out the limited functio functions that we don't really use much . {gap} alright take out teletext , but as for channel settings and stuff it might it might um turn people somewhe peop some people that want the whole functionality away . But , since {disfmarker} if we're marketing a more kind of fashionable approach then it'd {disfmarker} it would be fashion and fashion over practicality .\nProject Manager: Mm-hmm . S s we could {disfmarker} we could make it dual function {gap} voice recognition and {gap} still have buttons on it um\nMarketing: {vocalsound} Oh , we could , yeah . We c yeah ,\nProject Manager: 'cause we're {disfmarker}\nMarketing: we could even have it as like a {disfmarker} yeah the buttons control this and the voice functions control the f things that you would do all the time , so .\nProject Manager: {vocalsound} Certainly could . Yeah , yeah .\nIndustrial Designer: Mm .\nMarketing: So uh yeah , if we could uh {disfmarker} power on and channel selection and and volume selection , wouldn't have to really {disfmarker}\nProject Manager: {gap} The {disfmarker} I mean the the advantage of doing away the buttons altogether is it makes the thing cheaper .\nMarketing: Yeah and probably it would look better as well .\nProject Manager: No , it cou certainly opens up the possibility for making it uh , you know , visually very distinctive .\nMarketing: Yeah . yeah .\nProject Manager: Um 'cause you know , it does not have to be a oblong box .\nIndustrial Designer: Mm .\nMarketing: Lined with numbered buttons and {disfmarker}\nProject Manager: Mm , yeah . Okay , who {disfmarker} sorry , have you have you finished there Andy ?\nMarketing: Uh yeah , yeah , that's everything .\nProject Manager: Yep , yep . Um {vocalsound} given that we've already had a extensive discussion uh {disfmarker} {vocalsound} .\nIndustrial Designer: {vocalsound}\nUser Interface: {vocalsound}\nMarketing: {vocalsound}\nUser Interface: Okay well , I can do mine .\nIndustrial Designer: Hmm .\nMarketing: Do you want the cable ?\nUser Interface: Yeah , let's see if I can make this work . Um .\nIndustrial Designer: Oh , you have to hit like function and F_ something .\nUser Interface: Oh .\nMarketing: F_ eight .\nIndustrial Designer: F_ eight .\nUser Interface: Is it doing {disfmarker}\nIndustrial Designer: {vocalsound} Dunno .\nMarketing: Uh , give it about twenty seconds , or so .\nUser Interface: Okay .\nProject Manager: Ah , there we go . {vocalsound}\nIndustrial Designer: Oh yeah , it's going .\nUser Interface: Oh okay . {vocalsound} Okay , so this is just about the technical functions .\nProject Manager: Alright .\nUser Interface: So the method , I looked online for examples of other similar products and then just kind of was trying to brainstorm some possible design ideas and um identify what the necessary things are , what people are {disfmarker} what you really wanna have a remote control do . Um and then there are two different kinds that I found . There's a user centred one and an engineering centred one which I will have pictures of and then we kinda have to decide which one this should be .\nProject Manager: Mm-hmm .\nUser Interface: {vocalsound} So these are the two different ones . This one um {disfmarker} this is the user centred , it has uh quite a few mm uh um fewer buttons\nMarketing: {vocalsound}\nUser Interface: and then this is the engineering centred , which has a lot more buttons ,\nProject Manager: Mm-hmm .\nUser Interface: and probably this is one that people complain about , about having too many buttons that you don't use . So basically , what a remote control is is you {disfmarker} it's to send messages to the television set , you know , turn on , off , switch the channels and the volume and things such as that . And so for this product it's gonna be television only , and then it has to have the uh logos for the company and the colours . And so , for my personal preferences , I think this one is easier to use and has quite a {disfmarker} you know , fewer buttons . Um we want something that sends messages easily to the television and I was kind of wondering about this example that they have . It looks kind of narrow at the top , and I was thinking maybe if it were wider at the top ,\nProject Manager: Mm , yeah .\nUser Interface: then that would be easier . Um {vocalsound} and so we have to decide what's gonna make our product different . E the unique style , maybe have it light up so it's visible in the dark , um the changeable face-plates , and the lighting up and visible I was {disfmarker} when we were talking about havi losing it , maybe to have a button on the television that you press and it {disfmarker} maybe if it makes a noise or lights up or something like that , so it's easier to find if someone has hidden under the couch or something like that . So that's my presentation . Yeah .\nProject Manager: Okay , can I um {disfmarker} I'm actually gonna use the um {disfmarker} it's gonna cause great technical problems over here . I'm actually gonna use the {disfmarker}\nUser Interface: F they probably clip to you .\nIndustrial Designer: Oh yeah , they might be movable .\nMarketing: Yeah .\nIndustrial Designer: Oh yeah , they're all {disfmarker} they're not connected to anything on the table , you just leave 'em on and walk around with 'em . {vocalsound}\nProject Manager: Yes , rather than the uh the the traditional {disfmarker} in fact , um I won't even go that far . Um something like this shape , you know , sort of something that you can {disfmarker} that's sort of a more vertical shape , um that you you sort of hold in your hand , um , well I'm trying to think uh uh uh l uh l such as {disfmarker} I mean um something you hold up like that , possibly with a couple of buttons like that , but with the the entire top with the , you know , the uh the infrared or whatever source .\nIndustrial Designer: Mm .\nProject Manager: Uh so that you know , it's flying off in all directions ,\nIndustrial Designer: Mm .\nProject Manager: so that uh um uh {vocalsound} again the {disfmarker} n need to look at the the the technicalities of um actually achieving that in terms of whether the , you know , the power requirements of the uh {disfmarker} such a source , um you know , compromise the {disfmarker} our our need for uh you know , it it being um mm permanently uh you know , available .\nIndustrial Designer: {vocalsound}\nProject Manager: Uh whether whether different technology {disfmarker} um I mean th all all these remotes are presumably infrared , and like they have been for a long time . Uh we we possibly need to be looking at at at something different , um you know , short range , not like the old uh radio remote controls where you'd change next door's telly when you change yours . Um\nIndustrial Designer: {vocalsound}\nUser Interface: {vocalsound}\nProject Manager: but uh uh I think basically i if we're going for {disfmarker} i if minimum number of buttons is our priority , then we should , as I say , r know , really bite the bullets and and reduce the buttons to absolute minimum , you know , possibly with backup channel and volume buttons and on off . Um and nothing else . {vocalsound} Um so that it can al it could uh almost end up like that , but again , except that um {disfmarker} you know the risk of losing it . Um anyway okay um so Kate , wh what are your uh your thoughts on this ?\nIndustrial Designer: Yes , mm . {gap}\nUser Interface: Oh .\nIndustrial Designer: Which one does this plug into ?\nUser Interface: Hmm I think it's all there .\nIndustrial Designer: That one .\nUser Interface: H\nIndustrial Designer: I can't {disfmarker} did you {gap} {disfmarker} could you see it on you screen when it {disfmarker}\nUser Interface: Oh yeah .\nIndustrial Designer: {vocalsound} That's not cool . {vocalsound}\nUser Interface: That's kind of strange .\nIndustrial Designer: Oh well . Anyways . Um alright , yeah , so um I'll just do my presentation on the working design uh . {vocalsound} Oh there we go . Okay um just at the m yeah the whole sort of method of how the remote control works . Uh the basic function of the remote control is to send messages to another sh system , the the T_V_ or the D_V_D_ player or whatever .\nMarketing: {vocalsound} {vocalsound}\nIndustrial Designer: Um and it does this uh by {disfmarker} well , you need {disfmarker} to start off you need an energy source {vocalsound} and this energy source will feed into an integrated circuit chip and the circuit chip is the part that actually composes the different messages uh within the remote um which will then be sent to the uh the television , the D_V_D_ to tell that what to do . Um and you need a user interface , which controls the chip and thus the messages and uh the user interface is {disfmarker} that's basically just you kn the s sorta design of the actual remote which you hold in your hands and what buttons will be on it . Um {disfmarker} Oh shoot . Okay . Uh just general findings . Uh what we need uh technically speaking for the remote control is some sort of energy source , {vocalsound} uh some sort of user interface , which I think we've mostly been talking about the user interface and the design of that . Um a circuit chip within that to uh control and send the messages and um a sender and receiver . And um {disfmarker} oops . Uh-huh . This is just sort of a little schematic diagram of what we're looking for . Uh this just kinda represents the energy source\nMarketing: Hmm .\nIndustrial Designer: which feeds into the circuit chip uh which maybe then we could have that feed into a switch which would send signals f to um {vocalsound} a subcomponent and on to a light bulb between {disfmarker} so it'll light up once we start {disfmarker} once you start pressing buttons . Um also send signals to the um infrared bulb , which will be the part that actually {disfmarker} {vocalsound} what ? Sends signals to the the television . And then you've got your happy little T_V_ watcher there .\nUser Interface: {vocalsound}\nIndustrial Designer: And so my personal preferences {disfmarker} I I just think we need sorta big uh energy source that won't die out , uh perhaps some sort of rechargeable battery or a battery dock you could place it in , so it'd constantly be charged , so you wouldn't have to uh be worrying about it running out of batteries and not changing channels for you . Uh a wide range uh sender-receiver , so that you can hit the buttons from basically anywhere in the room , and the channel'll still be changed . Uh also definitely a user-friendly interface {vocalsound} um and I think we've all sort of mentioned adding a a locating device on it , so when it does get stuck under the couch cushions , as they inevitably do , you can find them easily . And that's pretty much it .\nProject Manager: Okay . Uh it seems seems to me there are a number of fundamental decisions to make before we um {disfmarker}\nIndustrial Designer: Mm . {gap}\nProject Manager: I think your point about the the big energy source is uh a very valid one .\nIndustrial Designer: Mm .\nProject Manager: Um I don't suppose we've got any statistics on the the life expectancy of uh remote controls , particularly sort of independent ones . Um given you know , the number of things you buy these days , which you know , have a a a lithium whatever battery in , that's uh , you know never needs replacing .\nIndustrial Designer: {vocalsound}\nProject Manager: Um perhaps we should have the the disposable remote control , uh um you know , one {disfmarker} some sort of typical usage . You know , the the the battery will last know , five , ten years . By which time {disfmarker} I mean when all's said and done , the digital television {vocalsound} will be taking over in that time scale . Um\nIndustrial Designer: Mm .\nMarketing: Mm-hmm .\nProject Manager: uh uh p perhaps we should , know , reduce the uh , you know , the sort of moving parts even more by not even having a battery compartment and uh {disfmarker}\nIndustrial Designer: Just having one that's guaranteed to last five to ten years ?\nProject Manager: Yeah , and if if anybody manages to run it down , we'll we'll give 'em a new one .\nIndustrial Designer: Oh , cool . {vocalsound} Yeah , fair enough .\nUser Interface: {vocalsound}\nProject Manager: Um it's , you know , it's {disfmarker} what it saves in cost and you know there there's a {disfmarker} well , it's actually a marketing gimmick . I mean it's hardly a gimmick , it's uh it's totally practical . Uh so I th think you know the idea of a rechargeable one is um uh unless you're really high tech and it sort of just recharges itself if it's n by , you know , magnetic waves or whatever , if if it {disfmarker}\nMarketing: It could have like uh {disfmarker} know like a cordless phone in your house it s got like a base that sits there all the time .\nProject Manager: Yeah . {vocalsound}\nIndustrial Designer: Mm , mm .\nProject Manager: Are are people really gonna use it though ? Um .\nUser Interface: Yeah , people are pro\nMarketing: {vocalsound} I suppose , yeah .\nIndustrial Designer: Mm yeah {vocalsound}\nUser Interface: I would think that people might forget {disfmarker}\nProject Manager: I I th I think {disfmarker}\nUser Interface: I mean people forget to put their cordless phones back on there ,\nMarketing: {gap}\nIndustrial Designer: Mm-mm .\nUser Interface: so .\nProject Manager: Yeah , it's\nMarketing: {vocalsound} Yeah . {vocalsound}\nProject Manager: um {disfmarker} I mean I know that somei times my my wife goes out in the morning and says oh I should have put the phone on to charge\nIndustrial Designer: Mm .\nProject Manager: and then then she's had those for so long that if she hasn't worked that out by now . Um .\nIndustrial Designer: 'Cause I only remember to charge my cell phone uh when battery dies . {vocalsound} And that's pretty much {disfmarker}\nUser Interface: {vocalsound} Yeah .\nMarketing: {vocalsound}\nProject Manager: When it {disfmarker} yeah , wh when it's died is a problem .\nIndustrial Designer: yeah . Yeah , when it turns itself off , that's when I plug it in ,\nProject Manager: Yeah , yeah , yeah , {gap} so uh um\nIndustrial Designer: yeah . {vocalsound}\nUser Interface: {vocalsound}\nProject Manager: what so wh what what do we think about the um the the permanent mm battery ?\nIndustrial Designer: Yeah , think that's a good idea .\nUser Interface: No .\nMarketing: Uh . That sounds pretty good , yeah .\nProject Manager: Is the uh {disfmarker} you know , we we we are really going for the ultimate in ex uh external simplicity here .\nUser Interface: Um .\nIndustrial Designer: Mm .\nProject Manager: Um you know , cut cost within the manufacturing and uh you know , if we have a high tech interior , then then that that sh may well be cost effective .\nUser Interface: Do they make batteries that last that long ?\nProject Manager: I mean th th certainly . Um I can't think of anything off the s top of my head ,\nIndustrial Designer: {vocalsound} They usually have the little light uh {vocalsound} source ,\nProject Manager: but there are certainly things that you buy . I mean calculators for example .\nIndustrial Designer: I dunno what the heck they're called ,\nUser Interface: Yeah , they have that little solar {disfmarker}\nIndustrial Designer: the {disfmarker} but\nProject Manager: {vocalsound} Som well some do ,\nIndustrial Designer: yeah , the little cells that {disfmarker}\nProject Manager: I mean th th but there are battery ones\nIndustrial Designer: Yeah .\nProject Manager: that um are you know , sort of permanently sealed .\nMarketing: Mm-hmm .\nIndustrial Designer: Mm .\nProject Manager: In in fact I'd {disfmarker}\nUser Interface: Yeah .\nIndustrial Designer: Most of them , don't they have sort of a combination of the two , like when there is light , they'll work off the light ,\nProject Manager: Yeah ,\nIndustrial Designer: and if there isn't , they'll kick into this battery ,\nProject Manager: uh uh {disfmarker}\nIndustrial Designer: so we can maybe do something like that whereas there is a battery , but if there's enough light , then it's using the light , so that it's not actually draining the battery all the time , but you will have the battery there for when you need it .\nUser Interface: Mm .\nProject Manager: Yeah , I I mean th th this needs going t into the technology a bit .\nIndustrial Designer: Mm .\nProject Manager: I mean the the actual time that a remote control is actually operating\nIndustrial Designer: Mm .\nProject Manager: I would think is i is is probably , you know , no more than minutes in its entire life . Um . {gap}\nIndustrial Designer: Oh , it depend if it's {disfmarker} uh depends who who's using it , who's just sitting there clicking clicking clicking clicking ,\nUser Interface: Yeah , some people are {disfmarker}\nProject Manager: If , but I say if if people are getting R_S_I_ from it then uh then uh then then perhaps we're looking at the wrong market\nIndustrial Designer: yeah . Yeah , {vocalsound} then they're clicking a lot , yeah . {vocalsound}\nUser Interface: Yeah . Yeah .\nMarketing: {vocalsound} W\nProject Manager: n\nMarketing: like like this um this uh market research thing says number of times per hour that it's used , channel selection a hundred and sixty eight\nUser Interface: {vocalsound} Per hour ?\nProject Manager: Right .\nMarketing: times per hour .\nIndustrial Designer: Yeah . {vocalsound} Yeah .\nMarketing: {vocalsound} Yeah .\nUser Interface: Wow . {vocalsound} That's a lot . {vocalsound}\nProject Manager: Oh , I must admit I hadn't um {disfmarker} I'd I'd missed that . That does sound excessive .\nUser Interface: {gap}\nMarketing: But then again , if you think it {disfmarker} of the amount of , you know amount of use it's like {disfmarker}\nProject Manager: Yeah .\nMarketing: That's {disfmarker} it's less than a second , um .\nIndustrial Designer: Yeah . Yeah .\nUser Interface: Yeah .\nProject Manager: Well that's right , and and I I don't I don't even know whether the I don't even know whether the s the signal lasts as long as you actually keep the button pressed ,\nIndustrial Designer: Mm .\nProject Manager: or whether it's just a\nMarketing: {vocalsound} Yeah .\nProject Manager: sorta tenth of a second , no matter how long you press it for , I don't know I don't actually know . Um .\nUser Interface: Though I think with digital T_V_ , like I know on my cable box , you're not supposed to do that because the channel can't keep up with it if you just press it like that ,\nProject Manager: Yeah .\nIndustrial Designer: Mm .\nUser Interface: so you're supposed to use the menu and go through the different\nProject Manager: Mm-hmm .\nMarketing: Mm-hmm .\nUser Interface: channels that way instead of {disfmarker}\nProject Manager: Mm . {gap}\nIndustrial Designer: {vocalsound}\nProject Manager: Right , so I've got a message to say five minutes , I dunno how long ago that appeared . Um 'cause we're we're getting\nUser Interface: Uh-oh .\nProject Manager: um {disfmarker} right , so I'd {disfmarker} I need to sum up very quickly here um . {vocalsound} We're looking at extreme simplicity . We're looking at a radically different shape . Possibly no buttons at all um , but if you can incorporate um channel change and volume buttons um in into the design , then then that's fine . Um in the {disfmarker} I mean the the role of the of the um the user interface des designer becomes b you know more important here , because , you know , shape is no longer an a uh um a serious constraint . But we clearly only need th the main buttons , although , uh if {disfmarker} clearly only need the main functions . Um I don't see why we shouldn't go for voice recognition um and the the only buttons that I think we need are channel control , volume control and on off . Um it needs to incorporate the corporate logo , uh the the grey and yellow colour scheme and {vocalsound} there's no reason why we can't introduce um interchangeable uh covers . {vocalsound} Um uh d so does that accurately summarise what we've discussed ?\nUser Interface: Yeah .\nMarketing: Yeah .\nIndustrial Designer: Yep . Hmm .\nProject Manager: {vocalsound} Right .\nUser Interface: Um {disfmarker} {vocalsound}\nProject Manager: So uh {disfmarker} {vocalsound} Yeah . We are doing just the television .\nUser Interface: Oh I just have one question . So are we doing just the television or are we doing {disfmarker} so not D_V_D_ players ,\nProject Manager: No .\nUser Interface: we okay , okay .\nProject Manager: I think that's quite clear from the the information that we've been given ,\nIndustrial Designer: Mm .\nProject Manager: no ?\nUser Interface: Okay .\nMarketing: Yeah , like in the email of television only . In fact they're {gap} in the constraints email that I got .\nProject Manager: Right .\nMarketing: Didn't you mention the teletext , just television only ?\nProject Manager: Oh yeah well th that's one I s that's one I sent you ,\nIndustrial Designer: Mm .\nUser Interface: Yeah .\nProject Manager: which which was my interpretation of uh of the uh {disfmarker} what came down from from head office . Um {disfmarker} {vocalsound}\nMarketing: Oh okay . {vocalsound} Oh yeah .\nIndustrial Designer: Yeah . {vocalsound}\nUser Interface: Oh {vocalsound} okay .\nIndustrial Designer: Okay .\nProject Manager: {vocalsound} That's {vocalsound} that that that that's their uh their view .\nIndustrial Designer: {vocalsound}\nProject Manager: Okay , so uh we can all give some thought to that uh for for the next meeting , thank you very much indeed .\nUser Interface: Okay .\nIndustrial Designer: Cool .\nUser Interface: {vocalsound}", "source": "meeting_summ", "evaluation": "rouge"}
{"instructions": ["What did the Project Manager think of the profit when discussing the financial issue and why?", "What did the group discuss about the functions of the remote control?", "What did the Project Manager think of the appearance and the buttons of the remote control when discussing about the multi functions?", "Why did Industrial Designer put forward that the appearance design should be paid due attention when discussing the user interface?", "What did the Industrial Designer recommend to do when discussing the naming of remote control and why?", "Summarize the group's plan of their marketing strategy.", "Summarize the whole meeting."], "outputs": ["According to the Project Manager, the finance department proposed to price the product at 25 euros and make a profit of fifty million euros in total. However, the cost might be at only twelve fifty, meaning that the profit would be at one hundred percent.", "The User Interface proposed to build a stand-alone one, which can be different from any other devices. The Project Manager then added that it might be better with more useful functions like changing the faces. Marketing came up with the idea of making it be functional for other devices as well, just including everything in this remote control.", "In terms of the great idea of making a multifunctional remote control, a new problem occurred that no one would be in favour of the product if it is too large or it is too complex to remember which button is for a certain function. One possibly feasible solution was to make it a remote control with a touch screen.", "Industrial Designer was unsatisfied with the existing remote controls, for that they are seemingly cheap and of low quality. Thus the Industrial Designer intended to make it nice and slick, maybe something with multi plates.", "After coming up with the idea of multi plates, the Industrial Designer asked to give the remote control a name and patent it. Within a brief discussion, they named it as Leopard Print out of the hope that it would also be helpful in cold winter days.", "For fear that the exorbitant price of 25 euros of the remote control would shock the potential consumers, Project Manager proposed to trade off some functions for a lower price. Additionally, Project Manager mentioned an American computer electronics store to show that shipping products overseas can also make profits and then added this to the whole plan.", "The meeting was about a preliminary idea of new remote control, covering the price, the functions, the appearance and the name. After a brief self-introduction, Project Manager assigned the task. One of the most important issues of the meeting was about the price. Project Manager supposed the product should be sold at 25 euros with a one hundred percent profit. As it would be a multifunctional remote control, the members were confident that it would stand alone. Moving on to the issue of the appearance, the group analyzed the problems of the existing remotes and briefly talked about the user interface as well as came up with a name of the product."], "input": "Industrial Designer: {vocalsound}\nMarketing: Are you sure I got it all {disfmarker} head's kinda small .\nUser Interface: How're we placed in terms of the {disfmarker}\nMarketing: Okay . {gap}\nUser Interface: alright .\nMarketing: We're okay ?\nIndustrial Designer: {vocalsound} Guess I should probably try to sit up straight .\nUser Interface: {vocalsound}\nProject Manager: Like that ? Okay , cool .\nMarketing: We're good ?\nIndustrial Designer: Oh , I think mine's fallen off .\nUser Interface: It fell {disfmarker} That's why .\nMarketing: I guess it's gonna be hard to drink coffee .\nIndustrial Designer: {vocalsound}\nMarketing: Mm .\nUser Interface: {vocalsound}\nMarketing: Uh okay .\nUser Interface: Ah .\nProject Manager: Okay ? {vocalsound} Right , so I'm just gonna start this PowerPoint real quick . Yeah , PowerPoint .\nIndustrial Designer: Wow .\nUser Interface: {vocalsound}\nMarketing: Very official .\nProject Manager: Yeah , well , you know , {vocalsound} {vocalsound} {vocalsound} {vocalsound} .\nIndustrial Designer: {vocalsound}\nUser Interface: {vocalsound}\nProject Manager: Yeah I kinda like this I'm kinda getting into it . Right . Um . So just to kick off the meeting basically um so we're working now for a real reaction , this is uh so it {vocalsound} right . Just got an agenda to set out what we're gonna try to accomplish in this particular first meeting . Um {vocalsound} We're gonna just do a quick opening and we can hopefully all get acquainted with one another um then we're gonna start {disfmarker} talk a little bit about tool training . Essentially that means getting used to the only thing that we haven't tried out yet , the whiteboard . {vocalsound} Um {vocalsound} we've got a general plan for the project how we're gonna go about accomplishing this and then just a bit of discussion close up . Um I {gap} guess you know game or something um {vocalsound} in real life um so yeah basically I want to {disfmarker} I'm just gonna {disfmarker} you got {disfmarker} of course you can discuss that , I'm thinking about um {vocalsound} uh proposing that since we've got this weird blend of ourselves and our roles that we just don't ask , don't tell . {vocalsound} Um so um if you say something about marketing , right , sorted , um {vocalsound} y is\nMarketing: {vocalsound} You're just gonna believe me ,\nIndustrial Designer: {vocalsound}\nMarketing: we'll go from there .\nProject Manager: Exactly . Um I mean\nMarketing: Fair enough .\nProject Manager: obvi if if you guys {disfmarker} if if at the same time if you {disfmarker} like logically if something doesn't {disfmarker} like if I'm like we're gonna sell a remote control that's the size of this paper book you know um you say like well that doesn't seem like such a good idea because of X_ obviously go with it . I mean we'll discuss it but I'm not gonna ask do you know that or uh yeah it seems like\nMarketing: Prove it\nProject Manager: {vocalsound} yeah yeah exactly\nMarketing: yeah , okay .\nProject Manager: so , 'cause we're {disfmarker} what we're sort of role playing is y g yeah you're gonna tap into your own knowledge as well {vocalsound} um . And that's the same for your when we do introductions I mean um and you talk about your background you know have fun , you know maybe you went to um {vocalsound} uh you know maybe i you're like in Maine you went to U_C_S_B_ but you wanna say you went to Harvard or something like that , why not , you know\nIndustrial Designer: {vocalsound}\nMarketing: {vocalsound}\nProject Manager: you can {disfmarker} this is you know I guess we can have a little bit of fun with it . So are you guys okay with that does that seem logical ?\nIndustrial Designer: Oh yeah , that's fine .\nUser Interface: Sure .\nMarketing: Works for me .\nProject Manager: Sweet . Cool . So I guess that that {vocalsound} we're totally {disfmarker} we're making a remote control which is thrilling\nIndustrial Designer: Right .\nProject Manager: um uh but the idea is that we can make something based on the whole corporate model I dunno if you guys had time to check the {disfmarker} in real life I dunno if you guys uh {vocalsound} checked the um {vocalsound} uh the corporate website . Um we've got to make something as fashionable as possible , that's kind of the corporate strategy is we're gonna try to take ordinary stuff that nobody really thinks about and try to make it nice you know like John Lewis nice or you know if you go to Debenham's or something . So um basically we are reinventing the wheel but we wanna try to do it in a user friendly um slick sleek kind of way . {vocalsound} Um way we're gonna go about doing that is basically at first we're gonna start on the basics . And that's where I'm gonna need you guys the User Interface Designers and the um {vocalsound} um the other designer that I can't remember ,\nMarketing: {vocalsound}\nProject Manager: the the I_D_ and the U_I_D_ right um {vocalsound} the Industrial Designer\nIndustrial Designer: {vocalsound}\nUser Interface: {vocalsound}\nMarketing: {vocalsound}\nProject Manager: hey right on alright ,\nUser Interface: Mm .\nProject Manager: getting into it um\nMarketing: There you go .\nProject Manager: to guide me and guide us on this project 'cause you're gonna be {disfmarker} you're g you guys are the bottom you know you're like no you can't do that you can't have you know X_ and Y_ um at the same time . And then um we'll work up from what is necessary to more like what would be good , you know like um {vocalsound} I I think you guys probably got the same emails I did but the idea of um , yes a coffee pot needs to be able to hold coffee but it's also better if it's not like really cheap glass so that it if you touch it you hurt your hand , or something like that . Um and so we'll work up from there and um then we'll meet on and talk about it and then finally we'll incorporate as kind of the last stage you know where you guys build or tell me {vocalsound} tell us what's possible and then you tell us what we can um hope for and what way to go take the the the take the basics and make it nicer and then ov obviously uh the U_I_D_ and the I_D_ you know you you can keep on the you know sort of at the cutting edge of how to get about maximising what is possible um to try t of sync it all up . So that's the detailed design . So it's a three stage kind of thing . Um right so for now just for th the white board um basically uh just to get used to it , I haven't tried it yet either um I'm just gonna start and um mm carry like five remotes around um and just write down {disfmarker} I'm just gonna write down one of the names of my um desert discs you know if you {disfmarker} if you were trapped on a desert island and you could only bring five C_D_s along with you name one of them that you could , not all five , if you wanna write all five go for it but name one of them that you could um . Oh , we skipped introductions . Nice . I'm a excellent Project Manager . Um .\nMarketing: {vocalsound}\nProject Manager: I'm Marty ,\nIndustrial Designer: {vocalsound}\nUser Interface: {vocalsound}\nProject Manager: um I went to uni at uh U_C_ Santa Barbara and I'm here working on a P_H_D_ in psychology . Um yeah . So {disfmarker}\nMarketing: I'm Sarah , I went to Michigan , and I'm here doing cultural studies and I'm the Marketing Manager or something . Marketing ,\nProject Manager: Expert {vocalsound}\nMarketing: yeah Expert . Expert .\nProject Manager: Don't play yourself down . Expert {vocalsound}\nUser Interface: {vocalsound}\nMarketing: Fine . That's me .\nUser Interface: I'm Ron . I uh once upon a time studied in Victoria and I am the User Interface Designer .\nIndustrial Designer: I'm Nathan , I'm from California , and I'm here doing a Masters degree in social anthropology .\nProject Manager: Where did you go to uni Nathan ?\nIndustrial Designer: {vocalsound} U_C_L_A_ .\nProject Manager: Oh brilliant . Cool . My little brother goes there .\nIndustrial Designer: Yeah . Okay .\nProject Manager: Right so desert island discs .\nMarketing: So .\nProject Manager: Yeah .\nMarketing: So do we have to wait for you to write it down or are you gonna tell us ?\nProject Manager: Well I'll t i\nMarketing: I'm waiting to know .\nProject Manager: no no yeah I'm just gonna write a couple of 'em down . See I'm a big music fan I don't know if you guys are , I'm assuming everybody likes music to some lesser or greater extent\nMarketing: Uh {disfmarker}\nProject Manager: but there's some other options , if you're a T_V_ slut\nMarketing: Fair enough .\nProject Manager: like I am like Smallville terrible television show\nIndustrial Designer: {vocalsound}\nUser Interface: {vocalsound}\nProject Manager: but I happen to love it ,\nMarketing: Oh , Smallville .\nUser Interface: {vocalsound} {vocalsound}\nProject Manager: it's rubbish but I love it .\nMarketing: I went to high school with Tom Willing actually .\nProject Manager: T the the main c the main character ?\nMarketing: The guy . Yeah .\nProject Manager: Wow . Is he a wanker ?\nUser Interface: {vocalsound}\nMarketing: Yeah . {vocalsound} Very much so . Hell of a soccer player but a total bastard nonetheless .\nProject Manager: He looks really tall , like he's gotta be like six six .\nMarketing: Yeah . He is a big guy . Yeah .\nProject Manager: Yeah . Um okay so {vocalsound} I really like Jeff Buckley . You guys heard of Jeff Buckley ?\nIndustrial Designer: Mm-hmm .\nMarketing: Mm-hmm .\nProject Manager: Um that's cool 'cause like not very many people have . Um {vocalsound} and um oh well I might as well throw a British person in there um you can't go wrong with Radiohead .\nUser Interface: {vocalsound}\nProject Manager: It's a r\nMarketing: Good call .\nProject Manager: {vocalsound} Okay so it really works just like a pen only makes noises I think . It's kinda weird . Anyway\nMarketing: Interesting .\nProject Manager: yeah . Yeah , you're like press and it's {vocalsound} .\nMarketing: {vocalsound}\nProject Manager: Kinda cool .\nIndustrial Designer: {vocalsound}\nProject Manager: You'll see . Alright so um\nUser Interface: {vocalsound}\nProject Manager: whoever wants to get up next , you can write down some telly that you watch or whatever you want .\nMarketing: I guess I'll go next then .\nProject Manager: Right on .\nUser Interface: Go for it .\nMarketing: Okay . Don't wanna lose all my mikes , plugged in here . Okay . This is basically just pen practice huh ?\nProject Manager: W\nMarketing: Okay . Oh you're much taller than me so I'm gonna write down here . Um . Right now I'm listening to a lot of somebody nobody's ever heard of , Chris Bathgate ,\nProject Manager: Mm .\nMarketing: local Michigan folk singer ,\nProject Manager: Nice .\nIndustrial Designer: Wow .\nMarketing: really lame\nUser Interface: {vocalsound}\nMarketing: and uh uh what else did I bring with me ? Probably classical , to totally geek it out ,\nProject Manager: Okay yeah yeah .\nMarketing: yeah I think . And my family guy D_V_D_s\nProject Manager: Well yeah .\nMarketing: but we don't need to write that one down .\nProject Manager: Oh , family guy . Isn't h has h\nIndustrial Designer: {vocalsound}\nProject Manager: do you watch the new season ?\nMarketing: No . Are you getting it online ,\nProject Manager: {vocalsound} I think I'm gonna start downloading it\nMarketing: or is it on sky ?\nProject Manager: yeah .\nMarketing: Yeah , that'd be nice .\nUser Interface: Alright . Think I'm just gonna put down one uh one C_D_ . Anybody ?\nProject Manager: Mm-mm .\nIndustrial Designer: No .\nUser Interface: No ? {gap} no ?\nMarketing: 'Fraid not .\nUser Interface: Afro beat orchestra , very cool .\nProject Manager: Afro beat orchestra ? Very cool . Mm .\nUser Interface: Yeah .\nIndustrial Designer: Sounds nice .\nUser Interface: Fift S\nMarketing: Mm .\nUser Interface: they like fifteen members from Brooklyn . Um and I'm hoping to go to the concert in Belgium , in Brussels in April first .\nProject Manager: Wow .\nMarketing: Exciting .\nUser Interface: Yeah . It's supposed to be in Brussels anyways .\nMarketing: That'd be {gap} .\nUser Interface: Um thing I love about Edinburgh {disfmarker}\nMarketing: Oh . I didn't even read those . Oops . I shouldn't admit that . {vocalsound}\nProject Manager: That's what a PowerPoint presentation is for . It's they're designed specifically to ignore . I {disfmarker} it's {disfmarker} th brilliant .\nIndustrial Designer: Oh , wow . {vocalsound}\nMarketing: Yeah .\nUser Interface: {vocalsound}\nMarketing: It's the five by five , I can't read that much .\nProject Manager: Ah yes yes yes okay I see that .\nMarketing: {vocalsound} {vocalsound} Yeah\nProject Manager: Vomit . Yes . {vocalsound}\nMarketing: oh it's so horrible .\nProject Manager: Street pizza .\nUser Interface: {vocalsound} Love um {disfmarker}\nProject Manager: It's so brilliant . {vocalsound} I've seen more urine in this city than ever before ,\nMarketing: Oh my God .\nUser Interface: {vocalsound} I just came from Glasgow\nProject Manager: I mean {disfmarker}\nMarketing: Seriously ?\nUser Interface: and I'm um happy to say that there's the {disfmarker} there's the same quantity approximately .\nIndustrial Designer: There's more vomit there .\nUser Interface: Um .\nProject Manager: It's so minging .\nUser Interface: I w\nMarketing: It really is {vocalsound}\nProject Manager: Uh .\nUser Interface: Does uh yeah .\nIndustrial Designer: Alright . Yep .\nUser Interface: Ready ? Minging ? Nice .\nMarketing: Yeah .\nProject Manager: I'm going local . Going local .\nMarketing: Slide it in there . Yeah .\nProject Manager: I have to be here for three years so I might as well get the terminology right .\nMarketing: Yeah fair enough . I've already got more than I can keep track of . And I'm gonna go home next week and everyone's gonna be like oh my God you're turning into one of those people ,\nProject Manager: Oh , have you been home yet ?\nUser Interface: {vocalsound}\nProject Manager: They'll be like , say something British ,\nMarketing: no .\nProject Manager: and you're like oh shut up family . {vocalsound}\nMarketing: I know . I know .\nUser Interface: Uh-huh .\nIndustrial Designer: Um {disfmarker}\nMarketing: Oh it should be interesting .\nIndustrial Designer: Let's see .\nMarketing: Wait until I tell them I'm not coming back .\nProject Manager: {vocalsound} Right\nUser Interface: {vocalsound}\nMarketing: They're gonna love that one .\nProject Manager: you s you're gonna stay here ?\nMarketing: Probably .\nProject Manager: Wow .\nMarketing: Or at least get a work visa for a while and then decide .\nUser Interface: {vocalsound} Nice .\nProject Manager: Bad religion ?\nMarketing: 'Cause {disfmarker}\nIndustrial Designer: Yeah , that's the music I grew up listening to .\nMarketing: nice .\nProject Manager: Yeah yeah , yeah .\nMarketing: Of course .\nUser Interface: {vocalsound}\nIndustrial Designer: And so there {disfmarker}\nMarketing: Oh , now I can think of so many other ones .\nProject Manager: Well yeah that's why {disfmarker}\nMarketing: That's how it works .\nProject Manager: yeah .\nIndustrial Designer: Something I miss about my hometown .\nProject Manager: I miss coffee .\nIndustrial Designer: Burritos\nMarketing: Mm . {vocalsound}\nProject Manager: {vocalsound} Burritos .\nUser Interface: Nice .\nIndustrial Designer: that cost less than eight Pounds . {vocalsound}\nMarketing: Oh {disfmarker}\nProject Manager: Oh yeah two two bucks .\nMarketing: {vocalsound} Any thing that are like free .\nProject Manager: Where are you from in California by the way ?\nUser Interface: {vocalsound}\nIndustrial Designer: I grew up in San Diego ,\nProject Manager: Did you really ? What part ?\nIndustrial Designer: but yeah um La Jolla , P_B_ {gap} .\nProject Manager: Yeah I'm from San Diego as well . Yeah oh man .\nMarketing: Nice . {vocalsound}\nIndustrial Designer: But really uh I last lived in San Francisco , I haven't lived in Cali well I haven't lived in southern California since I was eighteen .\nProject Manager: Going to s like North Carol I'm sorry you you just can't get a better burrito than what's available in the s in San Diego .\nIndustrial Designer: It's different . 'Cause in San Diego th the tortillas are cooked on the grill and in northern California they steam them .\nMarketing: It must make all the difference . {vocalsound}\nIndustrial Designer: Yeah , it really does .\nProject Manager: Well it's it's {vocalsound} i there's other things too there's {disfmarker} you just can't place it\nMarketing: Ah .\nProject Manager: like I {disfmarker} when I went to school in the U_ {disfmarker} in Santa Barbara which is central California the Mexican food is okay , it's just not good like and yeah it's like two bucks ,\nIndustrial Designer: Mm .\nProject Manager: like literally two bucks for this massive {disfmarker} I miss\nMarketing: Right .\nProject Manager: yeah good call on that .\nIndustrial Designer: Yeah . Where you from in San Diego ?\nMarketing: Mm .\nProject Manager: Um just literally just metropolitan San Diego , I live like five minutes from the zoo . So\nIndustrial Designer: Okay .\nProject Manager: North Park actually if you want to get real specific .\nIndustrial Designer: Yeah , my grandparents lived on um thirty second .\nProject Manager: Yep .\nIndustrial Designer: Close t uh do you know where Clare de Lune coffee shop is ,\nProject Manager: Yes . On university ,\nIndustrial Designer: and\nProject Manager: yeah .\nIndustrial Designer: Cafe Forte {disfmarker}\nProject Manager: Yeah it's actually like literally half a mile from my house .\nIndustrial Designer: Cool .\nProject Manager: Yeah , pretty cool . Small world as we were discussing before .\nIndustrial Designer: Yeah .\nProject Manager: Especially when we're all from the same general region . Right so okay , success on the whiteboard . You can harness the awesome power\nMarketing: There you go .\nProject Manager: a little bit introductions we talked about some of our C_D_s\nIndustrial Designer: Wow .\nUser Interface: {vocalsound}\nProject Manager: and things we like about the city you know , I think we'll {disfmarker}\nUser Interface: {vocalsound}\nProject Manager: Um right so {vocalsound}\nMarketing: {vocalsound}\nProject Manager: moving on to not fun stuff {vocalsound} uh project finance .\nUser Interface: {vocalsound}\nProject Manager: Um basically what we're trying to do is sell this remote for twenty five Euros . Um . {vocalsound} This is what the finance department has told me , the C_F_O_ but I don't know , I'm not sold on this , it's pretty dear , I mean twenty f that's like you know forty bucks for a remote . It would have to pretty much like do my laundry for me . Um so\nMarketing: Mm .\nProject Manager: what we can maybe work on that a later but we're gonna make a lot on it , the profit aims to make fifty million Euros on it . Eur internationally . So {vocalsound} um one of the things I I was gonna mention to you um you guys the designers is that um it m we probably need a rever it needs to be a universal remote control probably . Um so\nIndustrial Designer: Okay .\nProject Manager: something that could do N_T_S_C_ as well as PAL as well as various other formats like if it's gonna control D_V_D_s\nMarketing: Makes sense .\nProject Manager: but um you know\nMarketing: Uh .\nProject Manager: I'll leave that to you guys but that's something that i i it is gonna be an international sold thing . {vocalsound} Um but we wanna try to make it for twelve fifty . So we wanna try to make a hundred percent profit on it if we can . {vocalsound} Um s right so um just to close up , I'm not sure how much time I've used mm next time right Project Manager , sorted . Um . {vocalsound} Is uh we'll meet in another half an hour or so um {vocalsound} and I'd like the um Industrial Designer to get ge think about what needs to be done , like what the basic function of it . Um {vocalsound} U_I_D_ well yeah you right g your assignments are up there and you'll also get s assignments from {disfmarker} in your email as well more spec specifics on what do do . Um mm basic and um so I need you to tell us what um {vocalsound} we {disfmarker} what the user's gonna want .\nMarketing: What they're looking for .\nProject Manager: So actually in a way you guys c maybe in our next meeting chat a bit about what the user's gonna want and what the user can have , you know like uh so {disfmarker}\nMarketing: And negotiate that . Uh .\nProject Manager: yeah well it is {vocalsound} and we'll discuss the trade-offs in between um so yeah specific instructions will be sent in your email . But I think that that is more or less a good place to start for now um and as more things come up we'll have meetings and you'll get emails and so forth . Um any questions , before we get started ?\nUser Interface: I assume that we're building a stand alone uh remote control , we can't kind of build it into other uh products .\nProject Manager: {vocalsound} You mean to like {disfmarker}\nUser Interface: For instance like a mobile phone or something like that .\nIndustrial Designer: Mm . Sounds interesting .\nProject Manager: Hmm . {vocalsound} Yeah .\nMarketing: I don't think there's any rules about it yet . So {disfmarker}\nIndustrial Designer: Maybe our personal coach will have something to say about that .\nProject Manager: {vocalsound}\nMarketing: Yeah .\nUser Interface: Or or you know can we produ can we sell a remote control phone for twenty five pounds or less ?\nProject Manager: Well , have a think about it .\nMarketing: Mm .\nProject Manager: I mean\nUser Interface: Yep . Okay .\nProject Manager: I'm I'm certainly op it seems like yeah it it seems like it's certainly do-able\nMarketing: W yeah .\nProject Manager: isn't it . I mean um or if we can't have a full mobile phone maybe a remote that has some other kind of {vocalsound} useful function .\nIndustrial Designer: Yeah .\nUser Interface: Mm-hmm .\nProject Manager: The clapper . No I mean {vocalsound}\nUser Interface: {vocalsound}\nMarketing: {vocalsound}\nProject Manager: no , good idea , good idea . We'll see what {disfmarker} see what {disfmarker}\nIndustrial Designer: Maybe a remote with changeable faces , like the faces that you can buy for phones .\nUser Interface: {vocalsound} Nice . Hot . {vocalsound}\nMarketing: I like the little cover thingies .\nProject Manager: Uh-huh y I like that {vocalsound}\nIndustrial Designer: Yeah .\nProject Manager: Yeah . That's true , I guess we we probably have some time , maybe we should brainstorm a bit like what we wanna do , go back to um {disfmarker} I don't really have any . Let me bring up something about our basic goals here , what we want to accomplish . Uh project announcement . Ts ts ts {vocalsound} {vocalsound} {vocalsound} Yeah . Not so much .\nIndustrial Designer: {vocalsound}\nMarketing: Hmm .\nProject Manager: All right we'll find them , we're on our own .\nUser Interface: Now are we also discussing kind of our initial ideas at all here ?\nProject Manager: Yeah yeah let's do it , let's do .\nUser Interface: S does anybody have any initial ideas ?\nProject Manager: I'm gonna go ahead and take notes on this too 'cause {disfmarker}\nMarketing: Good idea . Start your minutes . Um {disfmarker}\nProject Manager: Yeah I mean oh yeah right . {vocalsound} So initial ideas . {vocalsound}\nMarketing: Well it's pretty much given it's gonna be universal\nProject Manager: Yeah .\nMarketing: right , we decided that already and it may be functioning for other things , as soon as you said that I was thinking like all the other things you could get a remote to do , like your microwave or your front door\nIndustrial Designer: Yeah .\nMarketing: or like to have everything on one thing ,\nProject Manager: {vocalsound}\nMarketing: but then , I've never been a fan of those huge remotes that have like a million buttons ,\nProject Manager: Mm-hmm .\nIndustrial Designer: S smaller's better .\nMarketing: you can't tell what they do .\nIndustrial Designer: Simple .\nUser Interface: But {disfmarker} I'm thinking {disfmarker} I'm thinking kind of P_D_A_ uh design\nMarketing: Yeah . Specific .\nUser Interface: so touch screen design rather than button\nMarketing: Okay .\nIndustrial Designer: Oh right . That'd be different .\nUser Interface: so that you can kind of flip around all sorts of different things .\nMarketing: Interesting .\nProject Manager: {vocalsound} Yeah that's slick\nIndustrial Designer: {vocalsound}\nProject Manager: isn't it . I mean like {vocalsound} stylist {vocalsound} yeah like a just a\nUser Interface: {vocalsound}\nMarketing: True .\nProject Manager: yeah . Right so we got five minutes more to chat about this , perfect . Um so we've got this kind of an idea of a trade-off between um {vocalsound} uh size and functionality .\nMarketing: Mm . Mm .\nProject Manager: Um and we also {disfmarker}\nMarketing: Right . We want it to be munt multifunctional but at the same time if you get it to do too much you're not gonna be able to tell them apart ,\nIndustrial Designer: Yeah .\nUser Interface: Too confusing .\nIndustrial Designer: It's gonna be too complicated , too crowded with buttons and things .\nProject Manager: I'm also gonna note for future reference this idea\nMarketing: Hmm .\nProject Manager: of um {vocalsound} so you {disfmarker} like {disfmarker} maybe like an L_ {disfmarker} like a touch screen type of remote ?\nUser Interface: Mm-hmm . Possibly .\nMarketing: Mm .\nProject Manager: I don't think one exists .\nMarketing: An interesting option .\nProject Manager: Be a good idea .\nIndustrial Designer: Needs {disfmarker} it needs one outstanding feature to set it apart from all the other remotes .\nMarketing: Yeah . Definitely .\nProject Manager: Yeah all the other universal remotes . Um {vocalsound} I don't know if there's such a thing out there , I guess we could do some uh do some research on or one of us could do some research on it about whether or not there are um multi-format like um you know PAL , N_T_S_C_ , region one {disfmarker}\nMarketing: Right .\nUser Interface: I'm pretty sure there is .\nProject Manager: Okay .\nUser Interface: I mean I I have a friend who has a P_D_A_\nProject Manager: Okay .\nUser Interface: that he just points at his telev any television he wants\nMarketing: That {disfmarker}\nUser Interface: and it'll figure out the {vocalsound} the specifications of it\nMarketing: Yeah .\nUser Interface: and will control it\nProject Manager: {vocalsound} Interesting . Okay .\nUser Interface: um so\nMarketing: Awesome .\nUser Interface: I th I assume that that can be done with uh kind of around the world .\nProject Manager: Okay . Okay .\nMarketing: Yeah .\nProject Manager: {vocalsound} Um all right . So . I li I'm liking that idea , this idea of a touch screen remote with multi-format features . Um .\nMarketing: Mm-hmm .\nIndustrial Designer: Right .\nProject Manager: Um . {vocalsound} Let's see .\nIndustrial Designer: I think , making it out of a nice material would be very important , because so many of those remotes that you see , these universal remotes look so cheap and low quality .\nMarketing: Yeah .\nProject Manager: Mm .\nMarketing: Yeah . Keeping it nice and slick , would be important . And {disfmarker} I don't know , like , there's such a problem with losing them ,\nProject Manager: {vocalsound}\nMarketing: that adding this whole like P_D_A_ pen business is only one more thing to lose ,\nIndustrial Designer: Mm .\nMarketing: so we're gonna have to be careful with what like {disfmarker}\nUser Interface: Oh .\nMarketing: Just something like keep in mind when we start actually dealing with this stuff but that would be really cool .\nProject Manager: {vocalsound} Uh let's see . Um .\nUser Interface: I like the idea of the uh multi plate .\nIndustrial Designer: {vocalsound}\nProject Manager: Yeah yeah okay .\nMarketing: Yeah .\nIndustrial Designer: {vocalsound}\nUser Interface: {vocalsound} In in\nMarketing: Fi b like what are they called , those face plate things ?\nProject Manager: Think they're just called face plates ?\nMarketing: Isn't there a name for them ?\nProject Manager: I don't know .\nIndustrial Designer: {gap} something ,\nMarketing: Are they ? I dunno .\nIndustrial Designer: uh we'll have to come up with a name ,\nUser Interface: I like .\nIndustrial Designer: patent it .\nUser Interface: We should c we should come up with a fuzzy one as well .\nMarketing: Yeah . Something really cool .\nProject Manager: {vocalsound}\nIndustrial Designer: {vocalsound}\nMarketing: {vocalsound} Leopard print or something . {vocalsound}\nUser Interface: {vocalsound} For those cold winter days . {vocalsound}\nIndustrial Designer: Leopard print . {vocalsound}\nProject Manager: Um .\nMarketing: Hmm .\nIndustrial Designer: I think , it wouldn't be such a bad idea to have a like a locator device , maybe a simple button that you have on your television to help you find your remote .\nMarketing: True .\nProject Manager: Mm . But if we're bundling it {disfmarker} {vocalsound} unless we're selling their telly with the remote .\nMarketing: Right .\nProject Manager: Um {vocalsound}\nIndustrial Designer: Mm .\nUser Interface: Well if we bundle it as a phone then you can always call it .\nIndustrial Designer: True .\nUser Interface: If you're not doing that then we can have something that just kind of rings from either {disfmarker}\nMarketing: True .\nUser Interface: well there used to be those whistling devices but that's a little bit annoying .\nMarketing: Right .\nProject Manager: Cou could we not do something where like just a little lit like literally just a very small kind of thing that comes with the remote that you could place something else that you press and it makes the remote page . Kinda like how on a lot of um {vocalsound} uh cordless regular phones , you have a page button and it goes {vocalsound} ,\nUser Interface: Th\nMarketing: Right .\nUser Interface: Yeah .\nIndustrial Designer: Yeah .\nMarketing: Right .\nProject Manager: could we do something like that ?\nIndustrial Designer: {vocalsound} I think so .\nUser Interface: That's cool .\nMarketing: Probably .\nUser Interface: I think we could design into that . {vocalsound}\nIndustrial Designer: Yeah .\nMarketing: {vocalsound} Good .\nProject Manager: Um yeah {vocalsound} I think this material quality as well like I guess what we can think about what kind of um uh you know Apple 's been really successful with this surgical white kind of business or this sleek kind of\nMarketing: Mm . Yeah .\nProject Manager: you know {disfmarker}\nIndustrial Designer: Mm .\nMarketing: And that titanium the new silver sleek ones that's last couple of years , very much so .\nProject Manager: Yeah .\nUser Interface: Curves .\nProject Manager: Yeah .\nMarketing: Mm .\nProject Manager: We do have the minimum am amount I mean we were talking finances I dunno , selling a a forty Pound remote would h or a forty Dollar remote , twenty five Euro remote would be pretty {disfmarker} you know it's pretty expensive\nMarketing: Right .\nProject Manager: so maybe we might wanna trade off some of the features for a lower price . Without without getting into that whole like you know go down to bargain store remote you know bargain store universal remote\nMarketing: {vocalsound} Right .\nProject Manager: that's black and you know m massive ,\nIndustrial Designer: Yeah .\nProject Manager: some kind of I dunno a balance there in somewhere .\nMarketing: Mm . Definitely .\nProject Manager: But um have a think about what we can do , have a think about what we want to do , how we're gonna sell it\nMarketing: Yeah .\nProject Manager: and um {disfmarker}\nMarketing: Or if you our users in mind , like these {disfmarker} grandmas are not gonna be into this whole new let's design , no it's {disfmarker} they're used to the buttons so we'll have to be careful of exactly who we're marketing this to ,\nIndustrial Designer: Yeah .\nProject Manager: Mm .\nMarketing: and who we're gonna be able to get it out of . {vocalsound}\nIndustrial Designer: 'S true .\nMarketing: But {disfmarker}\nUser Interface: We're talking twenty five Pounds or twenty five Euros ?\nProject Manager: Twenty five Euros .\nMarketing: Euros .\nUser Interface: {vocalsound} Slight difference I guess .\nIndustrial Designer: {vocalsound}\nProject Manager: Yeah . {vocalsound} They're all weaker than {disfmarker} they're all stronger than the Dollar . Although , computer parts , all {disfmarker}\nMarketing: Mm .\nProject Manager: if you're gonna upgrade your computer , buy it in the States . Like um do you guys know Fry's ? Huge computer uh electronics store ?\nUser Interface: No .\nMarketing: Mm-mm .\nProject Manager: They serve um {disfmarker} right they sa tha s they will sell things overseas so you can buy stuff in America\nMarketing: Mm .\nProject Manager: and have it shipped over for like twenty thirty Pounds about . Right so um let's go ahead and wrap that up here for now , I'm gonna put these initial ideas that we've got in the um {vocalsound} project documents , so if you guys wa need a reminder about what we've talked about um the different you know kind of trade-offs that we've got and the other ideas , you can consult them at your leisure .\nIndustrial Designer: Okay .\nMarketing: Okay .\nProject Manager: And uh right so thanks for that . Let's just uh head back to work on what we were talking about bef uh goi h h getting into .\nMarketing: With half an hour ?\nProject Manager: Um . Yes .\nMarketing: 'Kay . Perfect .\nProject Manager: Thanks guys .\nMarketing: Cool .\nIndustrial Designer: Alright .\nUser Interface: Thank you .", "source": "meeting_summ", "evaluation": "rouge"}
{"instructions": ["Summarize the discussion about the state of the final model", "What did PhD E say about the best result?", "What did the professor say about the final model?", "Summarize the discussion on frame dropping and noise estimation", "What did PhD E think about improving the model?", "What did the professor think about improving the model?", "Summarize the meeting"], "outputs": ["The team had started putting together the various techniques they had developed into a single software. Their score was 53.6 and it was working on spectral subtraction and noise addition after cleaning up mel bins. The professor did not think much had changed.", "PhD E explained that the best result was when FFT bins were applied with a Wiener filter and no noise was added. The results with noise addition were very close, but not as good.", "The professor was happy to hear that the team had already started putting together a final software. The professor also noted that Finnish and Spanish had the smallest overall number compared to Aurora.", "The team thought that the differences in performance between well-matched and high mismatch may have to do with the frame dropping problem. Tinkering around and changing a few small things was suggested as a way of improving performance. The team though it would also be nice to have the net on the server side where it would use less bandwidth. The team also discussed if averaging over the entire spectrum was a good idea.", "PhD E thought that changing a few things could result in an improvement, but they had to be careful with the neural net. PhD also played around with noise estimation to improve the model but did not play around with it much.", "The professor wanted to know how much the model improved due to frame dropping. He thought four or five changes would result in good improvements. The professor highlighted that improvements should not come at a higher bandwidth.", "The group discussed the current state of their work, which was coming close to a conclusion. They were putting together their final model, including the various techniques they had explored. Their performance on the Aurora tasks was second and very close to those in first place. The professor thought that further tweaking and incorporation of a neural network would improve their scores. The team discussed which method to use for noise suppression, which had not been decided yet. They also delved into a more detailed discussion of the VAD and latency. Their method for noise estimation would add a notable delay to the model. Finally, the team delved further into how to finish up the model."], "input": "PhD A: Alright . We 're on .\nProfessor B: Test , um . Test , test , test . Guess that 's me . Yeah . OK .\nGrad D: Ooh , Thursday .\nProfessor B: So . There 's two sheets of paper in front of us .\nPhD A: What are these ?\nPhD E: Yeah . So .\nProfessor B: This is the arm wrestling ?\nPhD C: Uh . Yeah , we formed a coalition actually .\nPhD E: Yeah . Almost .\nPhD C: We already made it into one .\nProfessor B: Oh , good .\nPhD C: Yeah .\nProfessor B: Excellent .\nPhD E: Yeah .\nProfessor B: That 's the best thing .\nPhD E: Mm - hmm .\nProfessor B: So , tell me about it .\nPhD E: So it 's {disfmarker} well , it 's {pause} spectral subtraction or Wiener filtering , um , depending on if we put {disfmarker} if we square the transfer function or not .\nProfessor B: Right .\nPhD E: And then with over - estimation of the noise , depending on the , uh {disfmarker} the SNR , with smoothing along time , um , smoothing along frequency .\nProfessor B: Mm - hmm .\nPhD E: It 's very simple , smoothing things .\nProfessor B: Mm - hmm .\nPhD E: And , um , {vocalsound} the best result is {vocalsound} when we apply this procedure on FFT bins , uh , with a Wiener filter .\nProfessor B: Mm - hmm .\nPhD E: And there is no noise addition after {disfmarker} after that .\nProfessor B: OK .\nPhD E: So it 's good because {vocalsound} {vocalsound} it 's difficult when we have to add noise to {disfmarker} to {disfmarker} to find the right level .\nProfessor B: OK .\nPhD A: Are you looking at one in {disfmarker} in particular of these two ?\nPhD E: Yeah . So the sh it 's the sheet that gives fifty - f three point sixty - six .\nProfessor B: Mm - hmm .\nPhD E: Um , {vocalsound} the second sheet is abo uh , about the same . It 's the same , um , idea but it 's working on mel bands , {vocalsound} and it 's a spectral subtraction instead of Wiener filter , and there is also a noise addition after , uh , cleaning up the mel bins . Mmm . Well , the results are similar .\nProfessor B: Yeah . I mean , {vocalsound} it 's {disfmarker} {comment} it 's actually , uh , very similar .\nPhD E: Mm - hmm .\nProfessor B: I mean , {vocalsound} if you look at databases , uh , the , uh , one that has the smallest {disfmarker} smaller overall number is actually better on the Finnish and Spanish , uh , but it is , uh , worse on the , uh , Aurora {disfmarker}\nPhD E: It 's worse on {disfmarker}\nProfessor B: I mean on the , uh , TI - TI - digits ,\nPhD E: on the multi - condition in TI - digits . Yeah .\nProfessor B: uh , uh . Um .\nPhD E: Mmm .\nProfessor B: So , it probably doesn't matter that much either way . But , um , when you say u uh , unified do you mean , uh , it 's one piece of software now , or {disfmarker} ?\nPhD E: So now we are , yeah , setting up the software .\nProfessor B: Mm - hmm .\nPhD E: Um , it should be ready , uh , very soon . Um , and we\nPhD A: So what 's {disfmarker} what 's happened ? I think I 've missed something .\nProfessor B: OK . So a week ago {disfmarker} maybe you weren't around when {disfmarker} when {disfmarker} when Hynek and Guenther and I {disfmarker} ?\nPhD C: Hynek was here .\nPhD A: Yeah . I didn't .\nProfessor B: Oh , OK . So {disfmarker} Yeah , let 's summarize . Um {disfmarker} And then if I summarize somebody can tell me if I 'm wrong , which will also be possibly helpful . What did I just press here ? I hope this is still working .\nPhD E: p - p - p\nProfessor B: We , uh {disfmarker} we looked at , {nonvocalsound} uh {disfmarker} anyway we {disfmarker} {vocalsound} after coming back from QualComm we had , you know , very strong feedback and , uh , I think it was {vocalsound} Hynek and Guenter 's and my opinion also that , um , you know , we sort of spread out to look at a number of different ways of doing noise suppression . But given the limited time , uh , it was sort of time to {pause} choose one .\nPhD A: Mm - hmm . Mmm .\nProfessor B: Uh , and so , uh , th the vector Taylor series hadn't really worked out that much . Uh , the subspace stuff , uh , had not been worked with so much . Um , so it sort of came down to spectral subtraction versus Wiener filtering .\nPhD A: Hmm .\nProfessor B: Uh , we had a long discussion about how they were the same and how they were d uh , completely different .\nPhD A: Mm - hmm .\nProfessor B: And , uh , I mean , fundamentally they 're the same sort of thing but the math is a little different so that there 's a {disfmarker} a {disfmarker} {vocalsound} there 's an exponent difference in the index {disfmarker} you know , what 's the ideal filtering , and depending on how you construct the problem .\nPhD A: Uh - huh .\nProfessor B: And , uh , I guess it 's sort {disfmarker} you know , after {disfmarker} after that meeting it sort of made more sense to me because {vocalsound} um , if you 're dealing with power spectra then how are you gonna choose your error ? And typically you 'll do {disfmarker} choose something like a variance . And so that means it 'll be something like the square of the power spectra . Whereas when you 're {disfmarker} when you 're doing the {disfmarker} the , uh , um , {vocalsound} looking at it the other way , you 're gonna be dealing with signals\nPhD C: Mm - hmm .\nProfessor B: and you 're gonna end up looking at power {disfmarker} uh , noise power that you 're trying to reduce . And so , eh {disfmarker} so there should be a difference {vocalsound} of {disfmarker} you know , conceptually of {disfmarker} of , uh , a factor of two in the exponent .\nPhD A: Mm - hmm .\nProfessor B: But there 're so many different little factors that you adjust in terms of {disfmarker} of , uh , {vocalsound} uh , over - subtraction and {disfmarker} and {disfmarker} and {disfmarker} and {disfmarker} and so forth , um , that {vocalsound} arguably , you 're c and {disfmarker} and {disfmarker} and the choice of do you {disfmarker} do you operate on the mel bands or do you operate on the FFT beforehand . There 're so many other choices to make that are {disfmarker} are almost {disfmarker} well , if not independent , certainly in addition to {pause} the choice of whether you , uh , do spectral subtraction or Wiener filtering , that , um , {vocalsound} @ @ again we sort of felt the gang should just sort of figure out which it is they wanna do and then let 's pick it , go forward with it . So that 's {disfmarker} that was {disfmarker} that was last week . And {disfmarker} {vocalsound} and , uh , we said , uh , take a week , go arm wrestle , you know ,\nGrad D: Oh .\nProfessor B: figure it out . I mean , and th the joke there was that each of them had specialized in one of them .\nPhD A: Oh , OK .\nProfessor B: And {disfmarker} and so they {disfmarker} so instead they went to Yosemite and bonded , and {disfmarker} and they came out with a single {disfmarker} single piece of software . So it 's {vocalsound} another {disfmarker} another victory for international collaboration . So .\nPhD A: So {disfmarker} so you guys have combined {disfmarker} or you 're going to be combining the software ?\nProfessor B: Uh .\nPhD C: Well , the piece of software has , like , plenty of options ,\nPhD E: Oh boy .\nPhD C: like you can parse command - line arguments . So depending on that , it {disfmarker} it becomes either spectral subtraction or Wiener filtering .\nPhD A: Oh , OK .\nPhD C: So , ye\nPhD A: They 're close enough .\nProfessor B: Well , that 's fine , but the thing is {disfmarker} the important thing is that there is a piece of software that you {disfmarker} that we all will be using now .\nPhD C: Yeah . Yeah .\nProfessor B: Yes .\nPhD C: There 's just one piece of software .\nPhD E: Yeah .\nProfessor B: Yeah .\nPhD E: I need to allow it to do everything and even more {disfmarker} more than this .\nPhD C: Right .\nPhD E: Well , if we want to , like , optimize different parameters of {disfmarker}\nPhD C: Parameters . Yeah .\nProfessor B: Sure .\nPhD E: Yeah , we can do it later . But , still {disfmarker} so , there will be a piece of software with , {vocalsound} {vocalsound} uh , will give this system , the fifty - three point sixty - six , by default and {disfmarker}\nProfessor B: Mm - hmm .\nPhD A: How {disfmarker} how is {disfmarker} how good is that ?\nPhD E: Mm - hmm .\nPhD A: I {disfmarker} I {disfmarker} I don't have a sense of {disfmarker}\nPhD E: It 's just one percent off of the {pause} best proposal .\nPhD C: Best system .\nPhD E: It 's between {disfmarker} i we are second actually if we take this system .\nPhD A: OK .\nProfessor B: Yeah .\nPhD C: Yeah .\nPhD E: Right ?\nPhD A: Compared to the last evaluation numbers ? Yeah .\nProfessor B: But , uh {disfmarker} w which we sort of were before\nPhD C: Yeah .\nPhD E: Mm - hmm . Yeah .\nProfessor B: but we were considerably far behind . And the thing is , this doesn't have neural net in yet for instance . You know ?\nPhD E: Mm - hmm .\nPhD A: Hmm .\nProfessor B: So it {disfmarker} so , um , it 's {disfmarker} it it 's not using our full bal bag of tricks , if you will .\nPhD A: Mm - hmm .\nProfessor B: And , uh , and it {disfmarker} it is , uh , very close in performance to the best thing that was there before . Uh , but , you know , looking at it another way , maybe more importantly , uh , {vocalsound} we didn't have any explicit noise , uh , handling {disfmarker} stationary {disfmarker} dealing with {disfmarker} e e we didn't explicitly have anything to deal with stationary noise .\nPhD A: Mm - hmm .\nProfessor B: And now we do .\nPhD A: So will the {pause} neural net operate on the output from either the Wiener filtering or the spectral subtraction ? Or will it operate on the original ?\nProfessor B: Well , so {disfmarker} so {disfmarker} so argu arguably , I mean , what we should do {disfmarker} I mean , I gather you have {disfmarker} it sounds like you have a few more days of {disfmarker} of nailing things down with the software and so on . But {disfmarker} and then {disfmarker} but , um , {vocalsound} arguably what we should do is , even though the software can do many things , we should for now pick a set of things , th these things I would guess , and not change that .\nPhD E: Mm - hmm .\nProfessor B: And then focus on {pause} everything that 's left . And I think , you know , that our goal should be by next week , when Hynek comes back , {vocalsound} uh , to {disfmarker} uh , really just to have a firm path , uh , for the {disfmarker} you know , for the time he 's gone , of {disfmarker} of , uh , what things will be attacked . But I would {disfmarker} I would {disfmarker} I would thought think that what we would wanna do is not futz with this stuff for a while because what 'll happen is we 'll change many other things in the system ,\nPhD A: Mm - hmm .\nProfessor B: and then we 'll probably wanna come back to this and possibly make some other choices . But , um .\nPhD A: But just conceptually , where does the neural net go ? Do {disfmarker} do you wanna h run it on the output of the spectrally subtracted {disfmarker} ?\nPhD E: Mmm .\nProfessor B: Well , depending on its size {disfmarker} Well , one question is , is it on the , um , server side or is it on the terminal side ? Uh , if it 's on the server side , it {disfmarker} you probably don't have to worry too much about size .\nPhD A: Mm - hmm .\nProfessor B: So that 's kind of an argument for that . We do still , however , have to consider its latency . So the issue is {disfmarker} is , um , {vocalsound} for instance , could we have a neural net that only looked at the past ?\nPhD A: Right .\nProfessor B: Um , what we 've done in uh {disfmarker} in the past is to use the neural net , uh , to transform , {vocalsound} um , all of the features that we use . So this is done early on . This is essentially , {vocalsound} um , um {disfmarker} I guess it 's {disfmarker} it 's more or less like a spee a speech enhancement technique here {disfmarker}\nPhD A: Mm - hmm .\nProfessor B: right ? {disfmarker} where we 're just kind of creating {vocalsound} new {disfmarker} if not new speech at least new {disfmarker} new FFT 's that {disfmarker} that have {disfmarker} you know , which could be turned into speech {disfmarker} uh , that {disfmarker} that have some of the noise removed .\nPhD E: Mm - hmm .\nPhD A: Mm - hmm .\nProfessor B: Um , after that we still do a mess of other things to {disfmarker} to produce a bunch of features .\nPhD A: Right .\nProfessor B: And then those features are not now currently transformed {vocalsound} by the neural net . And then the {disfmarker} the way that we had it in our proposal - two before , we had the neural net transformed features and we had {vocalsound} the untransformed features , which I guess you {disfmarker} you actually did linearly transform with the KLT ,\nPhD E: Yeah . Yeah . Right .\nProfessor B: but {disfmarker} but {disfmarker} but {disfmarker} uh , to orthogonalize them {disfmarker} but {disfmarker} {vocalsound} but they were not , uh , processed through a neural net . And Stephane 's idea with that , as I recall , was that {vocalsound} you 'd have one part of the feature vector that was very discriminant and another part that wasn't ,\nPhD A: Mm - hmm .\nProfessor B: uh , which would smooth things a bit for those occasions when , uh , the testing set was quite different than what you 'd trained your discriminant features for . So , um , all of that is {disfmarker} is , uh {disfmarker} still seems like a good idea . The thing is now we know some other constraints . We can't have unlimited amounts of latency . Uh , y you know , that 's still being debated by the {disfmarker} by people in Europe but , {vocalsound} uh , no matter how they end up there , it 's not going to be unlimited amounts ,\nPhD A: Yeah .\nProfessor B: so we have to be a little conscious of that . Um . So there 's the neural net issue . There 's the VAD issue . And , uh , there 's the second stream {pause} thing . And I think those that we {disfmarker} last time we agreed that those are the three things that have to get , uh , focused on .\nPhD A: What was the issue with the VAD ?\nProfessor B: Well , better {comment} ones are good .\nPhD A: And so the w the default , uh , boundaries that they provide are {disfmarker} they 're OK , but they 're not all that great ?\nProfessor B: I guess they still allow two hundred milliseconds on either side or some ? Is that what the deal is ?\nPhD E: Mm - hmm . Uh , so th um , they keep two hundred milliseconds at the beginning and end of speech . And they keep all the {disfmarker}\nPhD A: Outside the beginnings and end .\nPhD E: Yeah .\nPhD A: Uh - huh .\nPhD E: And all the speech pauses , which is {disfmarker} Sometimes on the SpeechDat - Car you have pauses that are more than one or two seconds .\nPhD A: Wow .\nPhD E: More than one second for sure . Um .\nPhD A: Hmm .\nPhD E: Yeah . And , yeah , it seems to us that this way of just dropping the beginning and end is not {disfmarker} We cou we can do better , I think ,\nPhD A: Mm - hmm .\nPhD E: because , um , {vocalsound} with this way of dropping the frames they improve {pause} over the baseline by fourteen percent and {vocalsound} Sunil already showed that with our current VAD we can improve by more than twenty percent .\nPhD A: On top of the VAD that they provide ?\nPhD C: No .\nPhD E: Just using either their VAD or our current VAD .\nPhD C: Our way .\nPhD A: Oh , OK .\nPhD E: So , our current VAD is {disfmarker} is more than twenty percent , while their is fourteen .\nPhD A: Theirs is fourteen ? I see .\nPhD E: Yeah .\nPhD A: Huh .\nPhD E: So . Yeah . And {pause} another thing that we did also is that we have all this training data for {disfmarker} let 's say , for SpeechDat - Car . We have channel zero which is clean , channel one which is far - field microphone . And if we just take only the , um , VAD probabilities computed on the clean signal and apply them on the far - field , uh , test utterances , {vocalsound} then results are much better .\nPhD A: Mm - hmm .\nPhD E: In some cases it divides the error rate by two .\nPhD A: Wow .\nPhD E: So it means that there are stim {comment} still {disfmarker}\nPhD A: How {disfmarker} how much latency does the , uh {disfmarker} does our VAD add ?\nPhD E: If {disfmarker} if we can have a good VAD , well , it would be great .\nPhD A: Is it significant ,\nPhD E: Uh , right now it 's , um , a neural net with nine frames .\nPhD A: or {disfmarker} ?\nPhD E: So it 's forty milliseconds plus , um , the rank ordering , which , uh , should be\nPhD C: Like another ten frames .\nPhD E: ten {disfmarker} Yeah .\nGrad D: Rank . Oh .\nPhD E: So , right now it 's one hundred and forty {pause} milliseconds .\nProfessor B: With the rank ordering {disfmarker} ? I 'm sorry .\nPhD C: The {disfmarker} the {disfmarker} the smoothing {disfmarker} the m the {disfmarker} the filtering of the probabilities .\nPhD E: The {disfmarker} The , um {disfmarker}\nPhD C: on the R .\nPhD E: Yeah . It 's not a median filtering . It 's just {disfmarker} We don't take the median value . We take something {disfmarker} Um , so we have eleven , um , frames .\nProfessor B: Oh , this is for the VAD .\nPhD C: Yeah .\nPhD E: And {disfmarker} for the VAD , yeah {disfmarker}\nProfessor B: Oh , OK .\nPhD C: Yeah .\nPhD E: and we take th the third .\nPhD C: Yeah .\nGrad D: Dar\nPhD E: Um .\nProfessor B: Yeah . Um . So {disfmarker} {comment} Yeah , I was just noticing on this that it makes reference to delay .\nPhD E: Mmm .\nProfessor B: So what 's the {disfmarker} ? If you ignore {disfmarker} Um , the VAD is sort of in {disfmarker} in parallel , isn't i isn't it , with {disfmarker} with the {disfmarker} ? I mean , it isn't additive with the {disfmarker} the , uh , LDA and the Wiener filtering , and so forth .\nPhD C: The LDA ?\nProfessor B: Right ?\nPhD C: Yeah . So {disfmarker} so what happened right now , we removed the delay of the LDA .\nPhD E: Mm - hmm .\nProfessor B: Yeah .\nPhD C: So we {disfmarker} I mean , if {disfmarker} so if we {disfmarker} if {disfmarker} so which is like if we reduce the delay of VA So , the f the final delay 's now ba is f determined by the delay of the VAD , because the LDA doesn't have any delay . So if we re if we reduce the delay of the VAD , I mean , it 's like effectively reducing the delay .\nPhD A: How {disfmarker} how much , uh , delay was there on the LDA ?\nPhD C: So the LDA and the VAD both had a hundred millisecond delay . So and they were in parallel , so which means you pick either one of them {disfmarker}\nPhD A: Mmm .\nPhD C: the {disfmarker} the biggest , whatever .\nPhD A: I see .\nProfessor B: Mm - hmm .\nPhD C: So , right now the LDA delays are more .\nProfessor B: And there {disfmarker}\nPhD A: Oh , OK .\nProfessor B: And there didn't seem to be any , uh , penalty for that ? There didn't seem to be any penalty for making it causal ?\nPhD C: Pardon ? Oh , no . It actually made it , like , point one percent better or something , actually .\nProfessor B: OK . Well , may as well , then .\nPhD C: Or something like that\nProfessor B: And he says Wiener filter is {disfmarker} is forty milliseconds delay .\nPhD C: and {disfmarker}\nProfessor B: So is it {disfmarker} ?\nPhD C: Yeah . So that 's the one which Stephane was discussing , like {disfmarker}\nPhD E: Mmm .\nProfessor B: The smoothing ?\nPhD C: Yeah . The {disfmarker} you smooth it and then delay the decision by {disfmarker} So .\nProfessor B: Right . OK . So that 's {disfmarker} that 's really not {disfmarker} not bad . So we may in fact {disfmarker} we 'll see what they decide . We may in fact have , {vocalsound} um , the {disfmarker} the , uh , latency time available for {disfmarker} to have a neural net . I mean , sounds like we probably will . So .\nPhD C: Mm - hmm .\nProfessor B: That 'd be good . Cuz I {disfmarker} cuz it certainly always helped us before . So .\nPhD A: What amount of latency are you thinking about when you say that ?\nProfessor B: Uh . Well , they 're {disfmarker} you know , they 're disputing it .\nPhD A: Mmm .\nProfessor B: You know , they 're saying , uh {disfmarker} one group is saying a hundred and thirty milliseconds and another group is saying two hundred and fifty milliseconds . Two hundred and fifty is what it was before actually . So ,\nPhD A: Oh .\nProfessor B: uh , some people are lobbying {disfmarker} lobbying {comment} to make it shorter .\nPhD A: Hmm .\nProfessor B: Um . And , um .\nPhD A: Were you thinking of the two - fifty or the one - thirty when you said we should {pause} have enough for the neural net ?\nProfessor B: Well , it just {disfmarker} it {disfmarker} when we find that out it might change exactly how we do it , is all .\nPhD A: Oh , OK .\nProfessor B: I mean , how much effort do we put into making it causal ? I mean , {vocalsound} I think the neural net will probably do better if it looks at a little bit of the future .\nPhD A: Mm - hmm .\nProfessor B: But , um , it will probably work to some extent to look only at the past . And we ha you know , limited machine and human time , and {vocalsound} effort . And , you know , how {disfmarker} how much time should we put into {disfmarker} into that ? So it 'd be helpful if we find out from the {disfmarker} the standards folks whether , you know , they 're gonna restrict that or not .\nPhD A: Mm - hmm .\nProfessor B: Um . But I think , you know , at this point our major concern is making the performance better and {disfmarker} and , um , {vocalsound} if , uh , something has to take a little longer in latency in order to do it that 's {pause} you know , a secondary issue .\nPhD A: Mm - hmm .\nProfessor B: But if we get told otherwise then , you know , we may have to c clamp down a bit more .\nGrad D: Mmm .\nPhD C: So , the one {disfmarker} one {disfmarker} one difference is that {disfmarker} was there is like we tried computing the delta and then doing the frame - dropping .\nGrad D: S\nPhD E: Mm - hmm .\nPhD C: The earlier system was do the frame - dropping and then compute the delta on the {disfmarker}\nProfessor B: Uh - huh .\nPhD C: So this {disfmarker}\nPhD A: Which could be a kind of a funny delta . Right ?\nPhD C: Yeah .\nProfessor B: Oh , oh . So that 's fixed in this . Yeah , we talked about that .\nPhD C: Yeah . So we have no delta . And then {disfmarker}\nPhD E: Yeah . Uh - huh .\nProfessor B: Good .\nPhD C: So the frame - dropping is the last thing that we do . So , yeah , what we do is we compute the silence probability , convert it to that binary flag ,\nProfessor B: Uh - huh .\nPhD C: and then in the end you c up upsample it to {vocalsound} match the final features number of {disfmarker}\nPhD E: Mm - hmm .\nPhD A: Did that help then ?\nPhD C: It seems to be helping on the well - matched condition . So that 's why this improvement I got from the last result . So . And it actually r reduced a little bit on the high mismatch , so in the final weightage it 's b b better because the well - matched is still weighted more than {disfmarker}\nProfessor B: So , @ @ I mean , you were doing a lot of changes . Did you happen to notice how much , {vocalsound} uh , the change was due to just this frame - dropping problem ? What about this ?\nPhD C: Uh , y you had something on it . Right ?\nPhD E: Just the frame - dropping problem . Yeah . But it 's {disfmarker} it 's difficult . Sometime we {disfmarker} we change two {disfmarker} two things together and {disfmarker} But it 's around {pause} maybe {disfmarker} it 's less than one percent .\nProfessor B: Uh - huh .\nPhD C: Yeah .\nPhD E: It {disfmarker}\nProfessor B: Well . {vocalsound} But like we 're saying , if there 's four or five things like that then {vocalsound} pretty sho soon you 're talking real improvement .\nPhD E: Yeah . Yeah . And it {disfmarker} Yeah . And then we have to be careful with that also {disfmarker} with the neural net\nProfessor B: Yeah .\nPhD E: because in {comment} the proposal the neural net was also , uh , working on {disfmarker} after frame - dropping .\nProfessor B: Mm - hmm .\nPhD E: Um .\nProfessor B: Oh , that 's a real good point .\nPhD E: So . Well , we 'll have to be {disfmarker} to do the same kind of correction .\nProfessor B: It might be hard if it 's at the server side . Right ?\nPhD E: Mmm . Well , we can do the frame - dropping on the server side or we can just be careful at the terminal side to send a couple of more frames before and after , and {disfmarker} So . I think it 's OK .\nProfessor B: OK .\nPhD A: You have , um {disfmarker} So when you {disfmarker} Uh , maybe I don't quite understand how this works , but , um , couldn't you just send all of the frames , but mark the ones that are supposed to be dropped ? Cuz you have a bunch more bandwidth . Right ?\nProfessor B: Well , you could . Yeah . I mean , it {disfmarker} it always seemed to us that it would be kind of nice to {disfmarker} in addition to , uh , reducing insertions , actually use up less bandwidth .\nPhD A: Yeah . Yeah .\nProfessor B: But nobody seems to have {vocalsound} cared about that in this {pause} evaluation .\nPhD A: And that way the net could use {disfmarker}\nProfessor B: So .\nPhD A: If the net 's on the server side then it could use all of the {pause} frames .\nPhD C: Yes , it could be . It 's , like , you mean you just transferred everything and then finally drop the frames after the neural net .\nPhD A: Mm - hmm .\nPhD C: Right ? Yeah . That 's {disfmarker} that 's one thing which {disfmarker}\nPhD E: Mm - hmm .\nPhD A: But you could even mark them , before they get to the server .\nPhD C: Yeah . Right now we are {disfmarker} Uh , ri Right now what {disfmarker} wha what we did is , like , we just mark {disfmarker} we just have this additional bit which goes around the features , {vocalsound} saying it 's currently a {disfmarker} it 's a speech or a nonspeech .\nPhD A: Oh , OK .\nPhD C: So there is no frame - dropping till the final features , like , including the deltas are computed .\nPhD A: I see .\nPhD C: And after the deltas are computed , you just pick up the ones that are marked silence and then drop them .\nPhD A: Mm - hmm . I see . I see .\nProfessor B: So it would be more or less the same thing with the neural net , I guess , actually .\nPhD E: Mm - hmm .\nPhD C: So . Yeah , that 's what {disfmarker} that 's what {disfmarker} that 's what , uh , this is doing right now .\nPhD A: I see . OK .\nProfessor B: Yeah .\nPhD E: Mm - hmm .\nProfessor B: Um . OK . So , uh , what 's , uh {disfmarker} ? That 's {disfmarker} that 's a good set of work that {disfmarker} that , uh {disfmarker}\nPhD C: Just one more thing . Like , should we do something f more for the noise estimation , because we still {disfmarker} ?\nProfessor B: Yeah . I was wondering about that . That was {disfmarker} I {disfmarker} I had written that down there .\nPhD C: Yeah .\nPhD E: Mm - hmm .\nProfessor B: Um {disfmarker}\nPhD E: So , we , uh {disfmarker} actually I did the first experiment . This is {pause} with just fifteen frames . Um . We take the first fifteen frame of each utterance to it ,\nProfessor B: Yeah .\nPhD E: and average their power spectra . Um . I tried just plugging the , um , {vocalsound} uh , Guenter noise estimation on this system , and it {disfmarker} uh , it got worse . Um , but of course I didn't play {pause} with it .\nProfessor B: Uh - huh .\nPhD E: But {disfmarker} Mm - hmm . Uh , I didn't {pause} do much more {pause} for noise estimation . I just tried this ,\nProfessor B: Hmm . Yeah . Well , it 's not surprising it 'd be worse the first time .\nPhD E: and {disfmarker}\nProfessor B: But , um ,\nPhD E: Mm - hmm .\nProfessor B: it does seem like , you know , i i i i some compromise between always depending on the first fifteen frames and a a always depending on a {disfmarker} a pause is {disfmarker} is {disfmarker} is a good idea . Uh , maybe you have to weight the estimate from the first - teen {disfmarker} fifteen frames more heavily than {disfmarker} than was done in your first attempt . But {disfmarker}\nPhD E: Mm - hmm .\nProfessor B: but {disfmarker}\nPhD E: Yeah , I guess .\nProfessor B: Yeah . Um . No , I mean {disfmarker} Um , do you have any way of assessing how well or how poorly the noise estimation is currently doing ?\nPhD E: Mmm . No , we don't .\nProfessor B: Yeah .\nPhD E: We don't have nothing {pause} that {disfmarker}\nPhD C: Is there {disfmarker} was there any experiment with {disfmarker} ? Well , I {disfmarker} I did {disfmarker} The only experiment where I tried was I used the channel zero VAD for the noise estimation and frame - dropping . So I don't have a {disfmarker} {vocalsound} I don't have a split , like which one helped more .\nPhD E: Yeah .\nPhD C: So . It {disfmarker} it was the best result I could get .\nPhD E: Mm - hmm .\nPhD C: So , that 's the {disfmarker}\nProfessor B: So that 's something you could do with , um , this final system . Right ? Just do this {disfmarker} everything that is in this final system except , {vocalsound} uh , use the channel zero .\nPhD C: Mm - hmm . For the noise estimation .\nProfessor B: Yeah .\nPhD C: Yeah . We can try something .\nProfessor B: And then see how much better it gets .\nPhD C: Mm - hmm . Sure .\nProfessor B: If it 's , you know , essentially not better , then {pause} it 's probably not worth\nPhD E: Yeah .\nProfessor B: any more .\nPhD C: Yeah . But the Guenter 's argument is slightly different . It 's , like , ev even {disfmarker} even if I use a channel zero VAD , I 'm just averaging the {disfmarker} {vocalsound} the s power spectrum . But the Guenter 's argument is , like , if it is a non - stationary {pause} segment , then he doesn't update the noise spectrum . So he 's , like {disfmarker} he tries to capture only the stationary part in it . So the averaging is , like , {vocalsound} different from {pause} updating the noise spectrum only during stationary segments . So , th the Guenter was arguing that , I mean , even if you have a very good VAD , averaging it , like , over the whole thing is not a good idea .\nProfessor B: I see .\nPhD C: Because you 're averaging the stationary and the non - stationary , and finally you end up getting something which is not really the s because , you {disfmarker} anyway , you can't remove the stationary part fr I mean , non - stationary part from {vocalsound} the signal .\nProfessor B: Not using these methods anyway . Yeah .\nPhD C: So {disfmarker} Yeah . So you just {pause} update only doing {disfmarker} or update only the stationary components . Yeah . So , that 's {disfmarker} so that 's still a slight difference from what Guenter is trying \nProfessor B: Well , yeah . And {disfmarker} and also there 's just the fact that , um , eh , uh , although we 're trying to do very well on this evaluation , um , we actually would like to have something that worked well in general . And , um , relying on having fifteen frames at the front or something is {disfmarker} is pretty {disfmarker}\nPhD C: Yeah , yeah .\nProfessor B: I mean , you might , you might not .\nPhD C: Mmm .\nPhD E: Mm - hmm .\nProfessor B: So , um . Um , it 'd certainly be more robust to different kinds of input if you had at least some updates . Um .\nPhD E: Mm - hmm .\nProfessor B: But , um . Well , I don't know . What {disfmarker} what do you , uh {disfmarker} what do you guys see as {disfmarker} as being what you would be doing in the next week , given wha what 's {pause} happened ?\nPhD C: Cure the VAD ?\nPhD E: Yeah .\nPhD A: What was that ?\nPhD C: VAD .\nPhD A: Oh .\nPhD C: And {disfmarker} \nProfessor B: OK .\nPhD E: So , should we keep the same {disfmarker} ? I think we might try to keep the same idea of having a neural network , but {vocalsound} training it on more data and adding better features , I think , but {disfmarker} because the current network is just PLP features . Well , it 's trained on noisy {pause} PLP {disfmarker}\nPhD C: Just the cepstra . Yeah .\nPhD E: PLP features computed on noisy speech . But {vocalsound} {vocalsound} there is no nothing particularly robust in these features .\nPhD A: So , I I uh {disfmarker}\nPhD C: No .\nPhD E: There 's no RASTA , no {disfmarker}\nPhD A: So , uh , I {disfmarker} I don't remember what you said {vocalsound} the answer to my , uh , question earlier . Will you {disfmarker} will you train the net on {disfmarker} after you 've done the spectral subtraction or the Wiener filtering ?\nProfessor B: This is a different net .\nPhD A: Oh .\nPhD C: So we have a VAD which is like neur that 's a neural net .\nPhD E: Oh , yeah . Hmm .\nPhD A: Oh , you 're talking about the VAD net . OK .\nPhD C: Yeah .\nPhD E: Mm - hmm .\nPhD A: I see .\nPhD C: So that {disfmarker} that VAD was trained on the noisy features .\nPhD A: Mm - hmm .\nPhD C: So , right now we have , like , uh {disfmarker} we have the cleaned - up features , so we can have a better VAD by training the net on {pause} the cleaned - up speech .\nPhD A: Mm - hmm . I see . I see .\nPhD C: Yeah , but we need a VAD for uh noise estimation also . So it 's , like , where do we want to put the VAD ? Uh , it 's like {disfmarker}\nPhD A: Can you use the same net to do both , or {disfmarker} ?\nPhD C: For {disfmarker}\nPhD A: Can you use the same net that you {disfmarker} that I was talking about to do the VAD ?\nPhD C: Mm - hmm . Uh , it actually comes at v at the very end .\nPhD A: Mm - hmm .\nPhD C: So the net {disfmarker} the final net {disfmarker} I mean , which is the feature net {disfmarker} so that actually comes after a chain of , like , LDA plus everything . So it 's , like , it takes a long time to get a decision out of it . And {disfmarker} {vocalsound} and you can actually do it for final frame - dropping , but not for the VA - f noise estimation .\nPhD A: Mm - hmm .\nProfessor B: You see , the idea is that the , um , initial decision to {disfmarker} that {disfmarker} that you 're in silence or speech happens pretty quickly .\nPhD A: Oh , OK .\nPhD C: Hmm .\nPhD A: Cuz that 's used by some of these other {disfmarker} ?\nProfessor B: And that {disfmarker} Yeah . And that 's sort of fed forward , and {disfmarker} and you say \" well , flush everything , it 's not speech anymore \" .\nPhD A: Oh , OK . I see .\nPhD C: Yeah .\nPhD A: I thought that was only used for doing frame - dropping later on .\nProfessor B: Um , it is used , uh {disfmarker} Yeah , it 's only used f Well , it 's used for frame - dropping . Um , it 's used for end of utterance\nPhD E: Mmm .\nProfessor B: because , you know , there 's {disfmarker} {vocalsound} if you have {pause} more than five hundred milliseconds of {disfmarker} of {disfmarker} of nonspeech then you figure it 's end of utterance or something like that .\nPhD A: Mm - hmm .\nProfessor B: So , um .\nPhD E: And it seems important for , like , the on - line normalization . Um . We don't want to update the mean and variance during silen long silence portions . Um . So it {disfmarker} it has to be done before\nPhD A: Oh . I see .\nPhD E: this mean and variance normalization . Um .\nProfessor B: Um . Yeah . So probably the VAD and {disfmarker} and maybe testing out the noise {pause} estimation a little bit . I mean , keeping the same method but {disfmarker} but , uh , {vocalsound} seeing if you cou but , um noise estimation could be improved . Those are sort of related issues .\nPhD E: Mm - hmm .\nProfessor B: It probably makes sense to move from there . And then , uh , {vocalsound} later on in the month I think we wanna start including the {pause} neural net at the end . Um . OK . Anything else ?\nPhD E: The Half Dome was great .\nProfessor B: Good . Yeah . You didn't {disfmarker} didn't fall . That 's good .\nPhD C: Well , yeah .\nProfessor B: Our e our effort would have been devastated if you guys had {comment} {vocalsound} run into problems .\nPhD A: So , Hynek is coming back next week , you said ?\nProfessor B: Yeah , that 's the plan .\nPhD A: Hmm .\nProfessor B: I guess the week after he 'll be , uh , going back to Europe , and so we wanna {disfmarker}\nPhD A: Is he in Europe right now or is he up at {disfmarker} ?\nProfessor B: No , no . He 's {disfmarker} he 's {disfmarker} he 's dropped into the US . Yeah . Yeah .\nPhD A: Oh . Hmm .\nProfessor B: So . Uh . {vocalsound} So , uh . Uh , the idea was that , uh , we 'd {disfmarker} we 'd sort out where we were going next with this {disfmarker} with this work before he , uh , left on this next trip . Good . {vocalsound} {vocalsound} Uh , Barry , you just got through your {vocalsound} quals , so I don't know if you {vocalsound} have much to say . But , uh .\nGrad D: Mmm . No , just , uh , looking into some {disfmarker} some of the things that , um , {vocalsound} uh , John Ohala and Hynek , um , gave as feedback , um , as {disfmarker} as a starting point for the project . Um . In {disfmarker} in my proposal , I {disfmarker} I was thinking about starting from a set of , uh , phonological features , {vocalsound} or a subset of them . Um , but that might not be necessarily a good idea according to , um , John .\nPhD A: Mm - hmm .\nGrad D: He said , uh , um , these {disfmarker} these phonological features are {disfmarker} are sort of figments of imagination also .\nPhD A: Mm - hmm .\nGrad D: Um . S\nProfessor B: In conversational speech in particular . I think you can {disfmarker} you can put them in pretty reliably in synthetic speech .\nGrad D: Ye\nProfessor B: But {vocalsound} we don't have too much trouble recognizing synthetic speech since we create it in the first place . So , it 's {disfmarker}\nGrad D: Right . Yeah . So , um , a better way would be something more {disfmarker} more data - driven ,\nPhD A: Mm - hmm .\nGrad D: just looking at the data and seeing what 's similar and what 's not similar .\nPhD A: Mm - hmm .\nGrad D: So , I 'm {disfmarker} I 'm , um , taking a look at some of , um , {vocalsound} Sangita 's work on {disfmarker} on TRAPS . She did something where , um {disfmarker} {vocalsound} w where the TRAPS learn She clustered the {disfmarker} the temporal patterns of , um , certain {disfmarker} certain phonemes in {disfmarker} in m averaged over many , many contexts . And , uh , some things tended to cluster .\nPhD A: Mm - hmm .\nGrad D: Right ? You know , like stop {disfmarker} stop consonants clustered really well .\nPhD A: Hmm .\nGrad D: Um , silence was by its own self .\nPhD A: Mm - hmm .\nGrad D: And , uh , um , {vocalsound} v vocalic was clustered .\nPhD A: Mm - hmm .\nGrad D: And , {vocalsound} um , so , {vocalsound} those are {pause} interesting things to {disfmarker}\nPhD A: So you 're {disfmarker} now you 're sort of looking to try to gather a set of these types of features ?\nGrad D: Right .\nPhD A: Mm - hmm .\nGrad D: Yeah . Just to see where {disfmarker} where I could start off from ,\nPhD A: Mm - hmm .\nGrad D: uh , you know ? A {disfmarker} a {disfmarker} a set of small features and continue to iterate and find , uh , a better set .\nPhD A: Mm - hmm .\nGrad D: Yeah .\nProfessor B: OK . Well , short meeting . That 's OK .\nPhD A: Yeah .\nProfessor B: OK . So next week hopefully we 'll {disfmarker} can get Hynek here to {disfmarker} to join us and , uh , uh .\nPhD A: Should we do digits ?\nProfessor B: Digits , digits . OK , now .\nPhD A: Go ahead , Morgan . You can start .\nProfessor B: Alright . Let me get my glasses on so I can {pause} see them . OK .\nPhD A: OK . And we 're off .\nProfessor B: Mm", "source": "meeting_summ", "evaluation": "rouge"}
{"instructions": ["Summarize the extent that the experts consider that the money is being targeted appropriately.", "What do the group think of the question whether the eligibility for free school meals is the best measure?", "How do the group think of the extent and condition that schools actually make good use of that funding of PDG?", "How would the group assess the impact of PDG on attendance and subsequent engagement with education from children having free school meals?", "Summarize the discussion about why children on free school meals were less resilient in the exam system last year.", "What is the role of schools with PDG for looked-after children as compared to the regional consortia in this field?", "What does the group think of the EAS consortium's approach to using the looked-after and adopted PDG as part of a broader approach targeted at vulnerable learners?", "What does the group discuss about the dataset on tracking adopted children?", "What does the group think of the exclusion rates amongst looked-after children (over six times more likely to be given a fixed-term exclusion)?", "What lessons the Government is taking from that three-year investment of Schools Challenge Cymru into the school improvement agenda?", "What is the progressing condition of the Schools Challenge Cymru?", "Summarize the discussion on the roles regional consortia and Cabinet Secretary should play.", "What does the group think of the extent they'd like to see the PDG used to track the progress of eligible pupils?", "Summarize the whole meeting."], "outputs": ["According to Kirsty Williams,  when it comes to individual interventions, those individual interventions of PDG should only be targeted at those children who are eligible for free school meals; but in some cases, schools may use their PDG funding to provide a universal intervention. One of the things that they've used PDG for is the focus on the concept of growth mindset in school, a universal thing that they've trained all the teachers in.  There are some other ways to drive the potential of talented and able children, like the example of \"a window on the world bus\" paid for by schools.", "According to Kirsty Williams, it's probably the best that they've got at present, and will continue to have discussions with local government about whether there are different ways.  Officials are working all the time in conjunction with the department in England, to understand their thinking in this area so that we are in a position to make some decisions about what a notional eligibility for free school meals will look like going forward, but before I make any decisions, I want to assure everybody that there will be a full public consultation on that.", "As identified by Estyn, most schools are using this money to good effect. When PDG first started,in some schools it was spent on investing in tracking children, because they had never thought about tracking these children, they didn't have systems in place to look at the performance of these children and to have a system in place. Now they have moved from spending money on the infrastructure around support for FSM children into actual inputs in terms of teaching and learning. And they have appointed regional PDG advisers to better deploy the fund.", "Over the period of the last inspection report, they have seen improvements in attendance, but still need to look at again how PDG can support this particular agenda. There are some excellent examples of how schools use the money to address this, some schools send the staff out and create walking buses, so that they walk the children into the school. Despite these good measures, there is still a gap between the attendance of free-school-meal pupils and non-free-school-meal pupils. It gets more challenging the older the children get.", "According to Kirsty Williams, there is no specific answer. There's no single reason why there seems to be less resilience in this cohort of children. They think that they can't draw broad-brush conclusions. The challenge is to go into individual schools and understand what was happening in that particular school that ensured that their children did really well. They continue to have discussions with Qualifications Wales to get a better understanding of this, and in May, they'll be doing a deep dive into this particular subject.", "The most awareness around PDG is around free school meals, and there is less awareness around the availability of PDG to support looked-after children. In the nature of the cohort, there are more children subject to free school meals than are subject to being looked after. The thinking behind that at the time was around a greater strategic deployment of that resource and to try and drive a greater impact than how it was being used previously, so the looked-after PDG is held at a regional level.", "They believe that if they can get it right for our most vulnerable learners, they'll be getting it right for all of our learners. An emerging theme is the impact, the growing awareness and the growing numbers of children who have attachment disorder, and how schools are best able to respond to that in their children.  So, vulnerable learners, regardless of their background, will benefit from having teachers who are better trained, understanding and have intervention strategies in place to be able to address that need. And this is an action applied across four regions.", "According to Kirsty Williams, they are actively looking at whether they should try and find a way of collecting this data. They can't force parents to divulge information that is a matter for them. But there is an active discussion going on at the moment about whether they could create a dataset where people divulge this information and we can then track the children through. They can't see the educational attainment of looked-after children just being a job of education. It has to be a job of social services and the health service as well.", "According to Kirsty Williams, people should look at exclusions and also have to read across about how the whole system works, not just the PDG element of the system. 66% of looked-after learners have some additional learning need, so they can't just look at it in terms of this particular source of funding. It can't be just the job of the PDG.", "They are looking at systems and processes, the placement of comprehensive systems of tracking and processes within the school. They are looking at the teacher quality \u2014 how can they ensure that we have got consistent strategies in place to drive up pedagogy and teacher quality in the classroom. And also, collaborative activity. One of the key themes of the national mission is a self-improving system, so collaborative working is necessary where schools are looking outside of each other, learning from best practice from other schools.", "Some of the Schools Challenge Cymru schools are making sustained improvement now that the programme has come to an end. Like the example of Tredegar, where we have seen continual improvement and moving up through the categorisation system. The challenge is for those schools that Schools Challenge Cymru didn't work for, and they haven't seen the progress of how to use the school improvement system now to continue to work with those schools . So now the focus is a whole-system approach, rather than choosing 39 schools to get that level of support. Schools Challenge Cymru would probably need about five years to really have the impact that it was intended to have.", "According to Kirsty Williams, she expects their challenge and support advisers to be having conversations that they need to have when they are with that school, to know about how they are using their PDG, and how they're demonstrating an impact for those resources. It's a fundamental role for the challenge and support advisers in the regional consortia in their school improvement work.", "Kirsty Williams thinks that it's absolutely crucial that we track performance. Where they weren't tracking pupils at all, initial investment in PDG was used to establish these systems within schools. One of the outcomes from the schools challenge review, and one of the lessons learnt was the importance of individual tracking of pupils throughout their school career. But they can't dictate a single system.", "The conference is about an inquiry into targeted funding to improve educational outcomes in the Wales education system. First, they primarily discussed the Pupil Development Grant, its targeting, eligibility, use and impact. Then, the group discussed care of looked-after children and adopted children. They discussed the condition and impact of another student support program the Schools Challenge Cymru program and the advisory role of regional consortia, Cabinet Secretary."], "input": "Lynne Neagle AM: Good morning, everyone, and welcome to this morning's Children, Young People and Education Committee. We've received no apologies for absence. Can I ask Members who are present if they wish to declare any interests? Okay, thank you. Item 2 this morning is our final evidence session for our inquiry into targeted funding to improve educational outcomes. I'm very pleased to welcome Kirsty Williams AM, Cabinet Secretary for Education; Steve Davies, director of the education directorate; and Ruth Conway, deputy director, support for learners division. Welcome to all of you, and thank you for your attendance and also for the paper that you've provided in advance. If you're happy, we'll go straight into questions, and the first questions are from Llyr Gruffydd.\nLlyr Gruffydd AM: Bore da. I just want to start by asking some questions around the targeting of the pupil development grant because, clearly, we've had a lot of evidence around this apparent blurring of eligibility to an extent. I'm just wondering how comfortable you are that the money is being targeted appropriately because, clearly, it's being targeted more widely than just those eligible for free school meals, from some of the evidence we've had, but also that it seems to be predominantly focused on low-attaining frees\u2014pupils who are eligible for free school meals.\nKirsty Williams AM: Thank you, Llyr. I think it's important to be absolutely clear that when it comes to individual interventions, those individual interventions should only be targeted at those children who are eligible for free school meals. But in some cases, schools may use their PDG funding to provide a universal intervention, but we would want to\u2014in challenge advisers' discussions in schools\u2014we'd want to have evidence that that universal intervention would have a disproportionate effect on the outcomes for children on free school meals. So, for instance, if I give you an example in your own region, Llyr: at Brynteg County Primary School in Wrexham, if you look at that primary school in Wrexham, their results for free-school-meal children at the end of their primary school period in school are equivalent to their non-free-school-meal counterparts. So, there is no differentiation in those results. One of the things that they've used their PDG for is to really focus on the concept of growth mindset in school. So, that's a universal thing that they've trained all the teachers in, but what we know is that that has a disproportionate effect on those children who are on free school meals. So, if you're familiar with the concept of a growth mindset, it's about really challenging learners to think that, 'I can do things. If sometimes I fail, I pick myself up, I'm more resilient.' Now, that has been, as I said, trained to all the teachers in the school\u2014it's an ethos for the whole school\u2014but we have seen that the impact on the free-school-meal children has been even greater, and now they're at the same level. So, that's the important distinction. Individual intervention per child has to be targeted at those children who are eligible\u00a0for free school meals, but sometimes a school will employ a whole-school approach to train their staff, for instance, and that, then, has to demonstrate it has a disproportionate effect on free school meals. So, growth mindset; it may be attachment disorder training for staff, for instance, where we know it's of benefit to everybody, but will have particular benefits for that cohort of students. With regard to more able and talented, you know, Llyr, that this is an area of concern for me, generally, within the Welsh education system; that we've not been particularly good at identifying, supporting and driving attainment for those children. I'm absolutely clear that PDG needs to be used for those children who are eligible to drive potential, whatever the potential of that child is, including more able and talented. And again, I'll give you an example that has been seen as good practice in Pembrokeshire: a window on the world bus, again paid for by schools. I don't know if you're aware of it.\nLlyr Gruffydd AM: We've heard about that.\nKirsty Williams AM: Oh, you've heard about it; well, it's a really good example the window on the world. And, again, that's very much targeted at raising aspirations and giving children who are more able and talented, who are eligible for PDG, those experiences,\u00a0and to really push them. So, yes, I'm absolutely clear that PDG shouldn't just be seen to be getting individuals to the average. For those children who are more able and talented, it should be used to support them\u2014\nLlyr Gruffydd AM: And we all share those aspirations, I'm sure, and you pointed to examples of good practice, but of course, it's not universal, is it, so what I'm asking is: do you think that the guidance is sufficient as it is? Do you think that there's a great enough awareness of how the PDG should be used at the coalface? And also, are you confident that consortia and others have the measures in place to be able to demonstrate that\u00a0it is being used properly?\nKirsty Williams AM: I think, if we look at what Estyn has said about PDG, it does actually recognise that the PDG is being used to push more able and talented children, but as always with the system, Llyr, it's whether we can be sure that that is strategic and that it's happening across all of our schools. So, you're\u2014\nLlyr Gruffydd AM: But not just in relation to more able and talented, I'm referring to the eligibility and the targeting.\nKirsty Williams AM: Oh, the eligibility. You'll be aware that, on the advice of Sir Alasdair, we have employed and appointed new PDG regional advisers, and I think their role is going to be absolutely crucial in spreading that good practice across the region, whether that's use of PDG for more able and talented, or ensuring that PDG is used in the appropriate way. So, that's there to provide strategic overall advice. And obviously, we have been very clear with regional challenge advisers, in the relationship and the conversations they're having with individual schools, that they're really challenging their schools about the use of PDG, not just in terms of targeting, but the programmes, what the money is being spent on, whether there is an evidence base for that and whether we are clear on impact. So, I think the new regional advisers are going to be crucial in enabling us to ensure more consistent practice across the regions.\nLlyr Gruffydd AM: So, are you content that eligibility for free school meals is the best measure, really, of identifying which pupils to target?\nKirsty Williams AM: Llyr, in the absence of anything better. I'll be the first person to say that maybe it's not as absolutely focused, but in the absence of anything different to identify a proxy for need, I think it's probably the best that\u00a0we've got at present. And we will continue to have discussions with local government about whether there\u00a0are different ways. We have to be mindful. Some of the policy levers in this area are out of my hands, so if we look at the roll-out of universal credit, for instance, we've got officials working very hard at the moment to try and understand what universal credit is going to mean and where we are going to be able to identify relative need, going forward. We haven't had any additional resource as a result of this, but we're very mindful that, potentially, this has an impact, going forward. And, officials are working all of the time, I must say, in conjunction with the department in England, to understand their thinking in this area so that we are in a position to make some decisions about what a notional eligibility for free school meals will look like going forward, but before I make any decisions, I want to assure everybody that\u00a0there will be a full public consultation on that.\nLlyr Gruffydd AM: Okay. Finally for now, on this issue of once a year, in January, if you're eligible for free school meals, then you're in that\u00a0group for that year. We've had some quite strong evidence about how difficult that makes longer term planning for a number of schools and we've also been pointed in the direction of what's happened in England with the Ever 6, and I'm just wondering\u00a0whether you're giving any thought to maybe changing that a little bit.\nKirsty Williams AM: Well, we're certainly giving thought to flexibility. In conversations with Alasdair, who is our independent adviser on this agenda, and individual schools, we're actively giving thought to greater flexibility and maybe longer term projections, so that schools know, for a number of years ahead, what their allocation will be. There are advantages to that system, because you could give that flexibility, you could give that long-term approach, but then, how do you make that responsive if a school suddenly has more children? We do know that, actually, the number of free-school-meal pupils is dropping. But there can be changes, you know, regional working in areas of north Wales in tourism, or maybe in other areas at Christmas time, parents are able to get a period of work.\u00a0So, how can we create a more flexible system? We're actively looking at that at the moment. I wouldn't use it as an Ever 6\u00a0concept, but as an 'Ever 2' concept. We have looked at Ever 6,\u00a0and I'm going to be absolutely blunt with you: to introduce an Ever 6\u00a0concept for Wales would mean in the region of identifying an additional \u00a340 million. I'm going to be absolutely straight and blunt with you: we're not in a position at the moment to be able to identify an additional \u00a340 million to introduce an Ever 6. But issues around flexibility, certainly, are actively under consideration. In fact, we'll be having a discussion later on today about decisions, going forward, for the next two years.\nLlyr Gruffydd AM: Thank you.\nLynne Neagle AM: Darren on this.\nDarren Millar AM: It's just a very brief point in response to the \u00a340 million price ticket that you just put on that. That's, of course, assuming that you maintain the current level of PDG,\u00a0yes? So, if you reduced the level of PDG slightly, but made it available to more individuals, if you like, via allocating it in a different way, then that \u00a340 million price ticket wouldn't be there, would it?\nKirsty Williams AM: I was asked a question about had I ever\u00a0considered an Ever 6. We have looked at that, we've priced that up. I have to make decisions in the envelope of resources that are available to me. We could, indeed, change the way in which we allocate PDG money, but we have to do it within the envelope that is available to me, over \u00a390 million. That's a significant level of investment, but, of course, as always, Darren, we could cut the amount per pupil, but that might have quite challenging swings in allocations. What we have done\u2014because what I am clear on is that there was evidence to suggest that in the secondary sector, a great deal of PDG was being focused on years 10 and 11, especially year 11, in catch-up provision, and you'll be aware, because we've said this in evidence to the committee in the papers, we've set a challenge to secondary schools to say, 'Actually, the majority of your PDG allocation has to be used in key stage 3.'\u00a0Now, we have to balance the needs, the moral hazard of turning round to children in years 10 and 11 and saying, 'We're\u00a0not going to provide catch-up opportunities for you,'\u00a0because, clearly, those children need that support. But the evidence and the advice that we're receiving is: actually, strong focus on early years, primary and key stage 3, if we get that right, should negate the need for spending money on catch-up at years 10 and 11. That's why we, in our advice to local authorities and schools, say that we want to see evidence that they're spending this money earlier on in a child's career, rather than just a scramble at year 11 to say, 'Right, we've got to get you through your exams.'\nDarren Millar AM: Okay, but have you actively considered, then, reducing the level you have?\nKirsty Williams AM: We've\u2014\nRuth Conway: Sorry\u2014I was just going to say that one of the things is looking at the scope of the definition,\u00a0and I think it's about being more flexible with the definition, rather than reducing the amount per head.\nDarren Millar AM: Okay. Thank you.\nLynne Neagle AM: Thank you. If we can go on, then, to talk about some of the practical uses of the PDG, you write in your written paper that 'the majority of schools are making\u00a0well thought out and appropriate decisions' on how to use it. But Estyn reported that only two thirds\u00a0of primary and secondary schools make effective use of the PDG. Given that we've had it now for six years, would you not have expected there to be a higher level of schools actually making good use of that funding?\nKirsty Williams AM: Well, to flip it on its head, the vast majority of schools, as identified by Estyn, are using this money to good effect. So, that's the way I like to see it\u2014that the vast majority of schools are doing well. What Estyn\u00a0has also indicated is the intrinsic link here to leadership within individual schools, and as you'll be aware, leadership, improving capacity in leadership and developing leadership talent in the Welsh education system is a key priority for me in our national mission. Of course, that's being developed in a different work stream. I think what's fair to say is that the use of PDG is evolving over time. I think we are seeing, increasingly, more and more schools understanding how best to deploy that money for best effect for students. So, if we're honest, when PDG first started, I think, in some schools\u00a0it was spent on investing in tracking of children, because they'd never thought about tracking these children, they didn't have systems in place to look at the performance of these children, and to have a system in place. So we've moved now from spending money on the infrastructure around support for FSM children into actual inputs in terms of teaching and learning. We're also seeing from Estyn that, actually, in terms of money following the evidence of what we know works, Estyn says that PDG is probably the best example of schools following tried and tested and evidence-based interventions to deploy the money. But clearly we want all of this money to be deployed as well as it can be, and again we come back to the decision I've made to appoint regional PDG advisers so that we can get that better consistency of approach. We are, in the discussions that I have with the regional consortia about how they challenge individual schools on usage, looking for very clear evidence of schools using the Sutton Trust toolkit, and we could have a discussion about whether that's the right thing, because that's on my mind too. But we want to see schools demonstrating their evidence base, and if they're not, if a school isn't doing that, okay, so demonstrate to us why you've made those decisions and, crucially, what are you doing as the school to judge whether that decision is actually making a difference for your individual pupils. So, if you're moving away from tried and tested interventions, what we know works, if you're doing something different with your money, okay, you need to justify that and you need to explain how you're going to demonstrate impact. But I think what we're seeing is increasing good practice in this area as the PDG develops and as our understanding of our school-to-school working in our self-improving school system also develops. I think we're seeing better usage of the money year on year.\nLynne Neagle AM: Thank you. Llyr on this.\nLlyr Gruffydd AM: You mentioned some schools will be moving from the tried-and-tested interventions, really, and I'm just wondering to what extent that evolution of use of PDG is being driven by cuts to core funding.\nKirsty Williams AM: No, I don't think it's being driven by cuts to core funding. I think there has been\u2014. One of the biggest impacts of PDG has not been\u2014well, I suppose it is\u00a0the money in itself, because the money has concentrated the minds, hasn't it? So, one of the most important things that PDG has done is highlight the importance of this agenda within schools, and really raise this up in the thinking of leadership and senior management teams in our schools, and has driven a focus on scrutiny and accountability in the systems that are working with our schools. I think the changing use of PDG reflects the journeys that schools have been on, some of them from a very low base where this was not a priority for them, to better understanding, and as research and as intelligence grows over time in this area, both in Wales and outside of Wales, schools are increasingly learning to use that evidence to tailor approaches in their schools.\nLlyr Gruffydd AM: So you wouldn't accept at all that some of this money's being used to paper over some funding cracks from elsewhere. Because the unions and some others have told us that, whether we like it or not, there is some of that going on.\nKirsty Williams AM: As I said, Llyr, we're very clear about the usage that this money can be spent on in terms of individuals or universal application within schools, and that forms an important part of the checks and balances that we have in our system. Can we continue to improve, and ensure that more and more of our schools are employing best practice? Yes, we can, and as I've said, we've taken steps to put in place the infrastructure to support that.\nLynne Neagle AM: Thank you. Mark's questions are next.\nMark Reckless AM: Cabinet Secretary, how would you assess the impact of PDG on attendance and hopefully subsequent engagement with education from children who have free school meals?\nKirsty Williams AM: I think what's important to note is that, as Estyn have themselves said, over the period of the last inspection report, we have seen improvements in attendance,\u00a0but I do think we need to, again, look at how PDG can support this particular agenda. And as always in the Welsh education system, there are some excellent examples of how schools use the money to address this. Ysgol y Preseli in Pembrokeshire is a very good example of how they've deployed their money. Forgive me; I can't off the top of my head remember the name of the primary school I visited, again in north Wales, where the school has proactively used this money, and they actually send teaching assistants out of school in the morning before the start of the school day, and they actually have a walking bus. They call at homes for children, and they walk the children to the breakfast club. So, they're proactively going out into the community and making sure that those children are in the classrooms, because the teacher said, 'We recognised we had a problem with attendance. We tried a variety of means of improving that, but in the end we have taken this quite bold step\u2014we actually send the staff out and they create that walking bus, and they walk the children into school'. They say that they know that, for some of those children, because of the difficult circumstances they and their families are living in, they probably wouldn't be in school if it wasn't for that proactive approach. So, we're looking again at what more we can do to support this particular agenda in terms of improving attendance, because although, again, there are examples of good practice, there is still a gap between the attendance of free-school-meal pupils and non-free-school-meal pupils. And, of course, we can have the best curriculum in the world with really high-quality teaching, but unless the children are in the classes then we're not going to make the difference for them. Whilst that differential exists, then it's going to be hard to close the attainment gap for those children.\nMark Reckless AM: I was actually quite shocked just reading in advance of this meeting that the proportion attending 95 per cent or more, who have pretty full attendance, was only 35 per cent for free-school-meal children at level 4, compared to 60 per cent for non-free-school-meal pupils. It still is an extraordinary difference. My colleague here showed me, I think, last week, a graph showing the link between attendance and attainment, in particular. When people were absent, a lot of the\u2014. As I'm sure you're aware, there's a huge connection. What more can PDG do to deal with it? In the example you give I can see how a school with an awful lot of free-school-meal children could do that, but a lot of the free-school-meal children are actually in schools that don't have that high a proportion of free school meals, where it would be much more challenging to bring in that type of initiative.\nKirsty Williams AM: Yes, indeed, and I think it gets more challenging the older the children get. I think it's more difficult to find interventions that are successful higher up, so key stage 4. So, you can do a walking bus with little ones, can't you, but I don't suppose your average 15 or 16-year-old is going to take very kindly to that. So, you do need a different approach to that. But again, we see in Ysgol y Preseli the employment of staff to directly work with families of older children to reinforce the messages around, as you quite rightly say, the linkage between attendance and attainment, and really work with individual families to understand the barriers to attendance: what's going on in the family that is preventing that child from going to school, and what more can the school do to address those situations. But you're absolutely right; there is more that we need to do to address this particular agenda of attainment. I don't know if there's anything extra you wanted to add, Steve.\nSteve Davies: There is also another very good example\u2014and I take what you say about where there are small numbers\u2014but in our secondary schools where there are significant numbers, they're investing PDG in resources like a school nurse and a school counsellor, not just to work with the children but link to other agencies on whom the children and the families are dependent to support them in terms of working with schools. So, it's something, particularly in our most challenging areas, where it cannot just be delivered within the school. So, good use of that resource is being made to employ people to support them in those wider areas.\nMark Reckless AM: Thank you. To what extent is PDG also used to seek to reduce the higher rates of exclusion for children entitled to free school meals?\nKirsty Williams AM: So, if we looked at permanent exclusions, there isn't a differential, but if we look at temporary exclusions, there we see there is a disproportionate number of children on free school meals that are subject to those exclusions. Again, I think\u00a0what schools employing best practice understand is that you need a multi-agency approach to supporting that particular child. Some of those exclusions can be as a result of the need to address other issues going on in a child's life. So, this is where we come back to the committee's work, for instance, on mental health and support for children, support for behaviour in school. So, again, it's a multi-agency approach that I think we need, and, in our good schools, our really, really good schools, there's a recognition of that need to have a whole team around a child to support that child in education. With EOTAS,\u00a0we made some changes last year regarding PDG for EOTAS. So, for those children who do find themselves in education other than at school, we are providing additional support that previously was not available.\nMark Reckless AM: Thank you.\nLynne Neagle AM: Okay. We're going to move on now to talk about the impact of PDG on attainment. Hefin David has got some questions.\nHefin David AM: It appears that the attainment gap at 2017 has actually widened, in spite of PDG levels. Is that correct?\nKirsty Williams AM: Yes. So, if you look at it\u2014with the usual caveats about whether you can make direct comparisons on level 2 plus between the exams the year before and the exams that we had last summer\u2014on the face of it, the gap has increased. I think what's important to recognise, Hefin, is a direction of travel. I'm sure we all want to, because I want to, have a discussion about why children on free school meals were less resilient in the exam system last year. But, if we look at the period that we have been employing PDG, over that period, we have seen a narrowing of the gap. I think what's quite stark,\u00a0if we think about it\u2014. So, if we look at where we started from: in 2009, one in five children on free school meals got level 2 plus\u2014one in five\u2014by 2016, we had got that down to one in three. Obviously, there's still a way to go, but, Sir Alasdair, who knows about these things, says that that is a significant improvement.\u00a0Last year, we got some challenges. We need to understand why that happened, but I do think it's\u2014\nHefin David AM: Why, do you think?\nKirsty Williams AM: Why, do I think?\u00a0What I do think is there is no one answer. There is no one answer to this. I think we could look at and we can have discussions around the move from BTEC to science GCSEs. I think we have supplied figures to the committee about the significant change in the number of children on free school meals who weren't doing a single science GCSE and are now doing science GCSEs. We can look at the unintended consequences of literature. Again, we've supplied figures. Where children have done language and literature, whether that be through the medium of English or through the medium of Welsh, there is more resilience. So, it's that exposure to literacy\u00a0in all its forms that I think\u00a0could potentially make a difference. So, I think there's no one answer to why free-school-meal children were not so resilient last year. We continue to have discussions with Qualifications Wales to get a better understanding of this. At my next ministerial policy board, in May, we'll be doing a deep dive into this particular subject.\nHefin David AM: So, to what extent would exam\u00a0boards be responsible for lack of grade stability?\nKirsty Williams AM: It could be one of the contributory factors. What I think is important is that there is no one, single reason why there seems to be less resilience in this cohort of children.\nHefin David AM: Will you be speaking to the exam boards about this and raising concerns?\nKirsty Williams AM: I have written to Qualifications Wales, we've had discussions about it, but I've asked them to formally submit evidence ahead of my policy board for May, where, as I said, we will be doing a formal, deep-dive discussion across the department about these issues. But, again,\u00a0Hefin,\u00a0what we've got to be clear on is\u2014while we look at overall factors, you know, our overall national statistic\u2014we did see some schools last year whose FSM performance was better than it had been the year before. So, what was it in those schools that enabled those children to do really well, whereas, in other schools, the performance was different? Even in individual cities, you can see a huge variety of performance. So, take Cardiff and Swansea, our two biggest cities. You've got schools in those cities with comparative levels of free school meals. So, you could have really high-performing schools with a very small number of the cohort on free school meals. The difference between those performances in a single city\u2014so, that's the same local education authority and the same regional consortium\u2014you can see a massive change. There's one school I can talk to: their free-school-meal performance is 88 per cent. A similar school in the same city with the same proportion of children on free school meals, their performance is down in the 20 per cents. So, I think what's important is that we can't draw broad-brush conclusions. For me, the challenge is to go into individual schools and understand what was happening in that particular school that ensured that their children did really well. We've got one school in Swansea, their FSM performance at GCSE level 2 outperforms non-FSM pupils.\nHefin David AM: But we still need to rely on the trends from a distance. If we take your argument that 2017 was an unusual year and the trends up to 2016 were positive, in a few years' time, when we will be looking back in two years' time, how are we going to measure this progress, say, in 2019? What are we likely to see and what methods are you going to use to measure progress that way?\nKirsty Williams AM: Well, you'll be aware that we are moving away from level 2 plus as a performance measure anyway because of the\u2014\nHefin David AM: So, what performance measures will you use?\nKirsty Williams AM: So, for the lack of sophistication around the level 2 plus, and for the unintended behaviours that that particular performance measure has driven within our schools. I'll be making a statement shortly to the Assembly around a new performance measure for schools. We were, at our most recent secondary heads conference, working with schools to develop that. What's important to me is that we have a more sophisticated model that looks at school performance for all children. What level 2 plus does is narrow, very much, the focus of schools on an individual part of the cohort, usually the C/D borderline, which is why then we have problems with the number of students getting a B grade or above. We have marked success in our schools by saying to schools that a C is good enough. Well, if a child gets a C but came to you in year 7 and they were destined to get an E, yes, indeed, a C is a success, because you've moved that child on; but, if that child came to you destined to get an A* and gets a C, then we haven't done a good job by that particular child. So, we need a performance measure that is much more sophisticated, looks at each individual child, tracks that progress, and measures the value added by that school in performance.\nHefin David AM: Last question: therefore, should we have confidence in the data up to 2016? Is there a lack of confidence in that data?\nKirsty Williams AM: No, it's not a lack of confidence in the data. The data is the data. What I'm saying is, using that as a performance measure and an accountability measure within our school system may have been right for the time. I think it is now right to have a different way of measuring success in schools. I think that particular set of performance measures has driven certain behaviours\u2014not because Ministers wanted that to happen, but as an unintended consequence. I think we can work together with our school system, learning the lessons of international best practice, to develop much more sophisticated accountability and performance measures for individual schools, and, I should say, for the Government. So, you will be aware of my intention to issue the first national report card on Government performance later on this year. So, this is not about trying to avoid scrutiny. It's about trying to develop a more sophisticated way, which is in line with our national mission, where every child's education is valued, and where the impact of the school can be tracked more effectively.\nLynne Neagle AM: Okay, thank you. Can I just ask, Cabinet Secretary, are you still holding on to your target of 37 per cent of free-school-meal pupils achieving the level 2 threshold?\nKirsty Williams AM: Well, we're moving away from the level 2 threshold. So, that's the first thing to say. So, we will want to develop a new suite, in line with our new accountability\u00a0measures, as we go forward.\u00a0So, we will be absolutely continuing to track and evaluate the performance of free-school-meal pupils. When we announce our new accountability measures, I will be in a position to address how we'll measure\u00a0the Government's\u00a0performance, and national performance, going forward. But, given the fact that we're moving\u00a0away from level 2 plus, then we will need a different set of performance\u00a0indicators.\nLynne Neagle AM: Okay, thank you. The next questions are on looked-after children and adopted children, and I've got questions from Michelle then Mark.\nMichelle Brown AM: Thank you. Good morning\u2014\nMark Reckless AM: I was to come in first, I think. I was about to ask about ICF consulting.\nLynne Neagle AM: Go on then.\nMark Reckless AM: I think my questions are first, but, Michelle, please do correct me if you were planning to come in before. The PDG for looked-after children\u00a0doesn't quite seem to have the degree of visibility\u00a0as the PDG for the free-school-meals. I think we had the MORI/WISERD survey\u2014only 15 per cent of primary schools and 23 per cent of secondary\u00a0schools were aware that PDG was targeted at looked-after children. I just wonder\u2014can you clarify on the record here what is the role of schools with PDG for looked-after children as compared to the regional consortia\u00a0in this field?\nKirsty Williams AM: Okay. I think it is absolutely fair to say that most awareness around PDG is around free school meals. There is less awareness around the availability of PDG to support looked-after children. I think that's probably in the nature of the cohort, so, there are more children subject to free school meals than are subject to being looked after. So, I think that's part of the explanation. A decision was taken in 2015 to regionalise PDG for looked-after children. My understanding was that the thinking behind that at the time was around a greater strategic deployment\u00a0of that resource and to try and drive a greater impact than how it\u00a0was being used previously. So, looked-after PDG is held at a regional level. We have looked-after children PDG co-ordinators\u2014they're in their second year this year\u2014to look at a regional deployment of that resource. And that resource can be done in a variety of ways, through individual allocation to a school to support an individual child, through to capacity building\u00a0for the whole system. So, for instance, if I give you an example, in Carmarthenshire, there's been a big emphasis on attachment\u00a0disorder and training teachers with regard to the impact of attachment disorder. Carmarthenshire happens\u00a0to be one of those local authorities\u00a0that does quite well in terms of attainment for looked-after children. But, clearly, I have\u2014not concerns. 'Concerns' isn't the right word. But I have asked officials to give greater scrutiny to how that resource has been used in the last year. Steve, on my behalf, wrote out to the system, setting out our expectations, but also advising them of the fact we will be asking very detailed questions of accountability for that money. So, what has that money\u00a0been used on and how can you account for the effect? But, Steve, maybe you can give some greater detail.\nSteve Davies: I think the challenge that\u2014. One of the rationales\u00a0for shifting\u2014not that all the money stays in the region, but having a regional strategic\u00a0support\u2014was that, historically, the money was going directly\u00a0with that child to the school. Given the quite often rapid turnover of children in schools\u2014the very nature of looked-after children is they do sometimes move through foster parents\u2014historically, what happened, the money lands in the school, because, at that time in the year, when it's measured, the school gets the money and can spend it on some additional support for staff, but quite often that child moves on to another school and the money\u00a0doesn't transfer. Some schools will go through quite a number of years without having\u00a0a looked-after child and will not think strategically, 'How do I need to support them?' So, that was the rationale of the shift. In terms\u00a0of the implementation of the regional allocation, as of this financial year finishing, we are going into local authorities and regions to evaluate where they've located the resource, what the impact of that resource has been, so that is reinforced\u00a0and shared more widely.\nKirsty Williams AM: And then, to reassure, it's not just internally that we're looking at this. We have a contract with an external agency to do an evaluation\u2014\nMark Reckless AM: That's ICF consulting.\nKirsty Williams AM: Yes. Yes, so that was done in the autumn of last year, because, as I said, we had concerns about whether this was really having the effect that was intended. So, my expectation is that we will be in a position to receive that report later on this spring, and of course it would be my intention that that report would be made public for people to have a look at what\u2014\nMark Reckless AM: That was commissioned last autumn\u2014\nKirsty Williams AM: Yes, in November 2017.\nMark Reckless AM: November 2017.\nKirsty Williams AM: So, I'm hoping to have that published before the summer recess. I'm very reluctant to say months; I've learnt not to say months, because they move.\nLynne Neagle AM: I'm going to go to Michelle now, Mark, because\u2014\nMark Reckless AM: Sure. I will come back in if I have anything further to ask here after Michelle.\nLynne Neagle AM: \u2014both of you asked for these questions, and that's what the pre-meeting is for.\nMark Reckless AM: Michelle, I defer to you.\nLynne Neagle AM: Michelle.\nMichelle Brown AM: Okay, thank you. Would you be open, Cabinet Secretary, to the idea of adjusting the eligibility of the PDG so that pupils who have been looked after or adopted at any point within a previous given period of time would attract the PDG, rather than only if they're looked-after on a one-off date?\nKirsty Williams AM: As I said earlier, in questions from, I think it was, Llyr, who was talking about concepts of concepts of Ever 6, we are constantly looking at how we can get that balance between focus and flexibility for this resource. Llyr opened with the question of, 'How can you absolutely ensure that these children are getting the money?', but then there's also a tension about how can you create some flexibility around the school's usage of the grant. So, we will look at that. I think there is the issue of where a school would know of a child that was looked after. Issues around adoption are slightly more sensitive, because we couldn't force a family to tell a school that their child was an adopted child. So, a family may be very open and very keen to explain that to a school, but we can't necessarily track as closely children who have been adopted, especially if that adoption happens before the child goes to school. We can't be in a position of forcing families to disclose this information if they don't want to, but we certainly can, as I say, look to strengthen our monitoring arrangements around PDG support for looked-after children and the impact that that's having. I just think we need to be a bit mindful of people's privacy in some instances. If they don't want to divulge that, it wouldn't be my job to tell a family, 'You have to let us know if your child is adopted.'\nLynne Neagle AM: Michelle.\nMichelle Brown AM: Fair enough; thank you for that answer. The EAS consortium's approach to using the looked-after and adopted PDG is to use it as part of a broader approach targeted at vulnerable learners in general. What are your views on that approach?\nKirsty Williams AM: I'm a great believer in if we can get it right for our most vulnerable learners, we'll be getting it right for all of our learners. I gave the example earlier, for instance, of attachment disorder, and, Chair, you will know that I have had conversations. One of the emerging themes for me, as I go around visiting schools, is the impact and the growing awareness and the growing numbers of children who have attachment disorder, and how schools are best able to respond to that in their children. So, for instance, as I said about Carmarthenshire, there's been a huge effort to address that in the school sector in Carmarthenshire. Now, that has a disproportionate benefit for those children, because you're more likely to see attachment disorder in children who are care experienced, because of the nature of the lives that those children have lived, but that doesn't necessarily mean that attachment disorder is exclusively found in those children that are looked after. It can be found in other families as well. So, that vulnerable learner, regardless of their background, will benefit from having teachers who are better trained, understanding and have intervention strategies in place to be able to address that need.\nSteve Davies: I think it's also important to add that this is not one region's approach; this is across four regions, so the others\u2014. For example, ERW have run a significant programme looking at the impact of adverse childhood experiences on pupils, which has\u00a0enabled teachers to detect some of the impact of some of those and then considers some of the work they need to do within the school but also with other agencies. So, it is something that's\u00a0applied consistently across the four regions.\nKirsty Williams AM: I was in Pil\u00a0Primary School recently where they use their PDG, both FSM PDG, and no doubt an element of PDG for\u00a0looked-after, for nurture groups. So, for those children who really, really find it very difficult to be in the main classroom, they can have that nurture group experience to address issues around emotional behaviour, feelings, and it gets them in a position where they are able then to join the main classroom because issues around behaviour have been addressed and they're in a\u00a0better position to learn. So, again, this is an example of how vulnerable learners in the wider sense can benefit.\nLynne Neagle AM: Okay. Mark, did you have anything you wanted to ask?\nMark Reckless AM: Yes. Can I follow up on tracking adopted children? I entirely understand that you can't force parents to disclose that their child is adopted. However, my understanding was that, in England, there was a dataset with social services that was shared with schools in a way that I'm not clear is happening in Wales and how, if at all, that links to the pupil level annual school census data.\u00a0Perhaps sort of linked to that, isn't there an argument for making the parents of adopted children in the schools, potentially, with adopted children more aware that adopted children who\u00a0were previously looked after have this potential grant, and would they not be more willing to disclose this, at least confidentially to the school and Government, if they knew there was this upside of doing so?\nKirsty Williams AM: We're actively looking at whether we should try and find a way of collecting this data, with the caveats that I just gave earlier. We can't force parents to divulge information that is a matter for them, nor would I want to. But there is an active discussion going on at the moment about whether we could create a dataset where people divulge this information and we can then track the children through. You're absolutely right. One of the ways in which we can often encourage take-up, for instance, of free school meals, especially in those communities where there is a sense of reluctance to apply for support\u2014even though people are entitled to it, there's a reluctance to do it; sometimes we see this in rural areas\u2014. Actually, appealing to the parents by saying, 'Actually,\u00a0this will mean more money for your child's school budget'\u00a0is a much more compelling reason why people will apply for it then saying, 'Actually, it's going to help you',\u00a0because they don't want to be seen being dependent, they don't want to be seen being helped.\u00a0But, if you say to them, 'Actually,\u00a0do you know that this means more money for your child's school?', they go, 'Oh, all right then, I'll fill in the forms now.'\u00a0So, you're right, I think there is something that we could do to make parents understand, in the round, that this has an impact. But we are actively looking at and discussing whether we could create a dataset around adopted children and how we can do that in line with data protection and data sharing. One of the things I am concerned about in the performance of looked-after children generally is how we can, across Government, work more closely together. We can't see the educational attainment of looked-after children just being a job of education. It's got to be a job of social services and the health service as well. There's got to be a joined-up approach to doing that. Now, officials were at the ministerial advisory group that's chaired by David Melding on prospects for looked-after children. They were there at the group last week. David tells me that the paper was very positively received by the group. I will be sitting down with David Melding to talk through what more we can do on the education side. I think there's really an appetite between me and the Minister for children to get a closer working relationship on this. We can't expect schools to do it on their own and alone.\u00a0And there are things that we can do out there in local authorities to help improve outcomes. It's not just about the PDG; it is about, when social services are thinking about a placement,\u00a0where does the discussion about where children are going to go to school\u2014when does that take place? Do we talk about the placement, move a child and then think, 'Oh\u00a0my goodness me, what are we going to do about the schooling?'\u00a0If you can imagine, the school could have been working really, really hard with a pupil to get them in a good place, to get them being able to access the curriculum, and then social services decide that the placement is being changed. So, we potentially lose all of that. So, a greater involvement in education\u00a0and better linked-up working in local authorities will help us with this. It can't be just the job of the PDG. If we think we can crack this with just PDG, then we're being delusional. It has to be a cross-government approach at a national level, and at a local government level as well, to get this right. Sometimes, data protection\u2014how can we break down some of these barriers between, you know, the school doesn't need to, schools shouldn't see, the entire social services report? Well, maybe the school does need to see some of that background information if they're going to have an impact for that child.\u00a0So, there's more work to do, but it cannot be just the job of education on its own if we're going to make a difference, nor can it just be the job of the PDG to make a difference for those children.\nLynne Neagle AM: Thank you. Julie's got some more questions on the impact on adopted and looked-after children.\nJulie Morgan AM: Yes, before I go on to those, I just wanted to support, really, what Mark was saying about adopted children and how important it is, I think, that the adoptive parents feel able to speak to the school and to give information. Because certainly any evidence we've had from adoptive parents, and generally knowing about what adoptive parents do feel, is that they often feel that there's a degree of a lack of sensitivity in the school about the issues of adoption. I would certainly support some move towards ensuring that the atmosphere was open in a way that would encourage them to realise that it would be a help for the children if there was an awareness in the school. So, I just wanted to really reinforce that.\nKirsty Williams AM: Yes, and that would chime with what I hear from many adoptive parents. I'm just trying to be sensitive by saying we can't force people to divulge this information if they don't want to.\nJulie Morgan AM: No,\u00a0but they need to be given the opportunity.\nKirsty Williams AM: Yes,\u00a0you're right. We need to make sure that those parents feel that they can discuss this with school leaders and classroom teachers and explore how best those individual children can be supported, and how best we can support parents. Because, again\u2014and I've said this a lot\u2014after the quality of teaching, the second biggest impact on a child's educational outcome will be parental engagement. So, being able to create an environment where adoptive parents feel very confident and able to talk about their children's education is absolutely crucial if we're going to get that parental engagement that we need for all of our children.\nJulie Morgan AM: Yes. Thank you. Going on to looked-after children, you say that the latest data on looked-after children's attainment is extremely disappointing. Can you expand on that and what effect the PDG has had in this result, or not had?\nKirsty Williams AM: Well,\u00a0there's no getting away from it: the way in which we currently measure outcomes for looked-after children, the results are not good enough. It's a source of huge concern to me that we need to do better for those children. That's why officials are engaging with the group that David Melding is chairing, to make sure that education is integral to that group and it's not lost sight of. There's a discussion to be had about the cohort, whether it's right and correct to compare looked-after children to the main cohort, or whether these statistics are useful in any way. Sometimes as well\u2014this is not to make an excuse because, as I've said in my paper, it's extremely disappointing, but sometimes it can be really difficult. Because the cohort sometimes can be very, very small, it can swing the statistics to look perhaps more dramatic.\nJulie Morgan AM: I think, generally, when you look at how looked-after children do\u2014\nKirsty Williams AM: It's not good.\nJulie Morgan AM: \u2014in\u00a0a much wider evaluation, they're not doing well, are they?\nKirsty Williams AM: They're not doing well. So, that's why we've got the review, the independent review, into the impact of the PDG in this area. This is why Steve is doing the work that he is doing with the regional consortia because, clearly, at the moment, we are not doing what we need to do for that particular cohort of children. I would not make any bones about that at all.\nSteve Davies: I think we will not move away from the fact that these children need good GCSEs to gain employment, so we'll continue to measure that. I think we need to look at more nuanced evaluations of the data at a lower level. So, for example, there were significant improvements in terms of PDG pupils who got three and four good GCSEs but didn't get past the threshold. That's not to cover anything that is not working in terms of improvement, but we will look at the full range and\u00a0still hold on to the fact\u00a0that we have to look at a measure that relates to the likelihood of these children going on to further education and training.\nJulie Morgan AM: And then just one more question about the exclusion rates amongst looked-after children. They are, I understand, over six times more likely to be given a fixed-term exclusion. So, is there any way of trying to address this? Is the PDG used for anything to do with exclusions?\nKirsty Williams AM: We can look at exclusions. We also have to read across about how the whole system works, not just the PDG element of the system. So, we know, for example, that 66 per cent of looked-after learners have some additional learning need, so we can't just look at it in terms of this particular source of funding; we have to look at it at a wider level of support. So, given that the majority of those children will have an ALN, how can we make sure that\u00a0our new ALN legislation and our new ALN regime meets the needs of these children? So, I think what we're looking at, again, is to say that it can't be just the job of the PDG. That's there as an additional level of support, but actually, we've got to get our ALN right. Unless we get our ALN right, lots and lots of these children are not going to get the support that they need day in, day out via that system. We do know that sometimes, if we're not addressing ALN, then we're not addressing behaviour issues that then potentially lead to an expulsion or potentially lead to non-attendance. So, we've got to look at it in the round and recognise the connections between the sometimes quite complex needs that these children have within the school setting, that are not just as a result of the fact that they're looked after; they have other needs as well.\nSteve Davies: And investment in well-being\u2014\nKirsty Williams AM: Absolutely. Steve is reminding me that that's why well-being is part of the national mission\u2014to address issues around supporting children with their well-being, which is a way of keeping them in school.\nLynne Neagle AM: Thank you. We're going to move on to Schools Challenge Cymru now. Llyr.\nLlyr Gruffydd AM: Thank you, Chair. I was just wondering what your assessment\u00a0is as to why some schools made progress and others didn't.\nKirsty Williams AM: I think we have to recognise that the 39 schools that were part of the programme were in very, very different places. So, I think one of the reasons why some schools did well was because their needs were not so complex, not so deep-seated and a certain level of intervention was enough to get them moving forward. Some schools had very, very different needs. I think, talking to those involved\u00a0in the programme, as always, we had some support advisers, challenge advisers working with those schools as part of the programme who were really, really excellent and really good, and were the right fit for the school and really drove the school onwards. We had other people employed in the programme who, perhaps, were less effective at driving change within those individual schools. So, what we have is a mixed bag of performance, again reflecting the very different challenges that those schools were facing, which led them to be chosen for the programme in the first place.\nLlyr Gruffydd AM: Yes, okay\u2014\nSteve Davies: Sorry. One of the other key additional factors was the extent to which there had been recent appointment of a new headteacher to that school just before the programme had started, because\u2014\nKirsty Williams AM: Leadership is all.\nLlyr Gruffydd AM: And that was seen as a positive.\nSteve Davies: A positive, yes. I think one of the challenges is that sometimes the time it takes to make changes in leadership can be protracted and can be a barrier, sometimes, to the speed with which you can move. But, for a significant minority of the schools, there had been recent new appointments of headteachers, which was seen to be contributing, when you looked at the evaluation, to the speed with which they were able to engage.\nLlyr Gruffydd AM: The reason I was asking was I wanted to understand what lessons the Government is taking from that three-year investment, really, and how, maybe, you're applying some of those lessons to your wider school improvement programme. I know Professor Mel Ainscow identified six interconnected lessons, although I also note that the Cabinet Secretary didn't actually meet him for about six or seven months after coming into post. So, I'm just wondering, can you give us confidence that, actually, you are serious about taking lessons from Schools Challenge Cymru and applying them to the wider school improvement agenda?\nKirsty Williams AM: Well, absolutely, Llyr. I don't think anything should be read into when I met the individual concerned, because officials were meeting the individual concerned. Individual challenge advisers were meeting with the regions, there was crossover work with the FSM agenda as well, and we are absolutely determined that best practice and those interventions that drove school improvement are embedded in the new support that we have via the regional consortia.\u00a0It's no coincidence that some of the best people that were employed by Schools Challenge Cymru are now in the employment of our regional consortia. So, those people that were really good and really made a difference don't work for the Schools Challenge Cymru\u00a0scheme any more, they work for our regional school improvement services. So, we're absolutely determined. The things that we have learned, as always, are around leadership. It is absolutely key and crucial to have strong, capable school leadership as a driver for change within the system. We're looking at systems and processes, so, actually, has a school got in place comprehensive systems of tracking and processes within the school?\u00a0We're looking at the teacher quality\u2014how can we ensure that we have got consistent strategies in place to drive up pedagogy and teacher quality in the classroom? Collaborative activity\u2014again, absolutely key. A school cannot see itself in isolation, and one of the key themes of the national mission is a self-improving system, so, collaborative working where schools are looking outside of each other, learning from best practice from other schools. So, there are lots of things that we've drawn from the evaluation that you will see as key themes running through the national mission, and, as I said, it's no coincidence that our really good people that were working in Schools Challenge Cymru\u00a0are now working for the regional consortia, being able to use that expertise not just for a very small proportion of our schools\u2014but that expertise is available to all our schools.\nLlyr Gruffydd AM: Although Estyn\u00a0has told us, of course, that you can't expect the consortia to\u00a0really carry on with that level of intervention and the same kind of intensity as was provided previously, so I'm just wondering\u2014\nKirsty Williams AM: In what way?\nLlyr Gruffydd AM: Well, we were told by Estyn\u00a0in evidence that they didn't necessarily think that we could expect the consortia to provide the same type of tailored support, and certainly the level of intensity with the improvement boards and everything\u2014\nKirsty Williams AM: Well, the improvement boards are carrying on, so the improvement boards still exist, and I would\u2014not that I want to argue with Estyn\u2014\nLlyr Gruffydd AM: Well, feel free; this is your opportunity to do so if you\u2014\nKirsty Williams AM: What I would say is that those improvement boards are staying on, and our schools categorisation system is used to identify the level of support. Now, if you're a red school, that gives you the entitlement to 25 days of support. That is more than you would have got under the Schools Challenge Cymru programme,\u00a0which would've been 20 days. So, actually, moving to this system allows us to really focus in on those schools that need that intensive level of support. And what's important for me, Llyr,\u00a0in this, okay, is that those schools are not necessarily just the schools that were in the programme. Our system now of challenge, advice and support allows us to target resources across all of our schools and across all of our sectors, because you'll be aware that Schools Challenge was only available to secondary schools, not available to primary schools. What our system now allows us to do, via the schools categorisation, is to identify schools, wherever they are in Wales and whatever sector they're in, to have that intensive level of support that they need to make improvements.\nLlyr Gruffydd AM: So, you're confident that that level of momentum is continuing through the consortia that was previously enjoyed by those particular schools, and you're also confident that there is minimal risk that they'll slip back to where they were, potentially, or at least part of the way back.\nKirsty Williams AM: Well, actually, there are some really good examples of some of the Schools Challenge Cymru\u00a0schools making that sustained improvement now that the programme has come to an end. You only have to look at Tredegar, where we have seen continual improvement and moving up through the categorisation system. That school is now a green school, so they've been able to sustain their progress at the end of the programme. If we look at Armando in Eastern High School, again\u2014gosh, my goodness me, we had lots of debates in a previous Chamber about the future of Eastern. There was one person that said that Eastern had to be closed and that the only way forward for that particular school was for it to be shut down, but what we have seen is investment via Schools Challenge Cymru,\u00a0but ongoing, continual support from the regional consortium, and that school has come out of special measures. I pay absolute tribute to the staff of that school and that community that have done such a good job. So, I'm absolutely convinced that where we've got good\u00a0leadership and good support,\u00a0some of those schools are making continued, sustained progress even after the end of the programme. The challenge for me is for those schools that Schools Challenge Cymru didn't work for, and we haven't seen that progress\u2014how we can use our school improvement system now to continue to work with those schools to give them the level of support that they need to make a difference. So that's what my focus is on now: a whole-system approach, rather than choosing 39 schools to get that level of support, when we recognise that there are schools everywhere, potentially, that need intervention, support and challenge, and in the primary sector as well.\nLlyr Gruffydd AM: Okay. So, you wouldn't agree with a number of\u2014well, the near-unanimous evidence that we've had from academics, some of whom are Government advisers from consortia et cetera, that this kind of programme such as Schools Challenge Cymru would probably need about five years to really have the impact that it was intended to have.\nKirsty Williams AM: What I would say is that, from my understanding, from the outset, it was a time-limited programme. The schools were aware of that. There were no surprises that it was supposed to be a time-limited programme. Evidence from across the UK showed that school challenge programmes have differed in time. So, for instance, Manchester's challenge was a three-year programme. So, there's no consensus about how many years you need to run a programme for. The previous Minister was quite clear about the time-limited nature of the programme. That's not to say it was the wrong decision, because what's important, and an ongoing legacy of the programme, was the investment in regional school improvement capacity, because at the time our school improvement services and the regions were young, in their infancy. The ability of individual local authorities to make a difference, with so many local authorities in an Estyn categorisation, was limited, so one of the ongoing legacies of the programme is that significant investment of over \u00a310 million in the capacity of the regions to be able to continue this support and the school improvement work.\nLlyr Gruffydd AM: So, how disappointed were you that the money for Schools Challenge Cymru went back into reserves and didn't stay in your envelope, as you described it earlier? I presume you made a pitch for it. Did you make a case for that money to stay within your department?\nKirsty Williams AM: Llyr, we are constantly having discussions with the Minister for Finance around support for the education budget. The Minister for Finance was quite clear that it was a time-limited programme. We were able to secure investment from the Finance Minister to be able to secure the programme and run it and phase it out to make sure there was transition support, so as we moved from the schools challenge programme into the regional consortia, there were resources to do that.\nLlyr Gruffydd AM: Did you feel there was a case to be made to add to the consortia's resources and be able to continue that level of support that schools had previously had?\nKirsty Williams AM: Well, we did make resources available to the regional consortia to do that. As I say, from the outset, the previous Minister was very clear it was a time-limited programme. Certainly the schools that I talk to\u2014. And I want to be absolutely clear: I have visited many, many Schools Challenge Cymru schools. I have used that opportunity to talk to them about\u2014Heolddu being one of them, Hefin, which we went to visit, and Willows, for instance. I'm going to one this afternoon\u2014I'm going to St Illtyd's this afternoon, and I always take\u2014. I've been to Caergybi in Anglesey. I always take the opportunity to speak to those teachers about their experience of the programme and to understand and assure myself that they are getting ongoing support that they see as an appropriate level for them. I think I've done 19 of the schools.\nLynne Neagle AM: Hefin on this.\nHefin David AM: With regard to it being a time-limited programme, the previous Minister was clear that it was a time-limited programme, but it wasn't quite as time-limited as you've decided to be. Is that fair to say?\nKirsty Williams AM: No, it was supposed to be a three-year programme at the most. So, there's no differential between when I decided it was time-limited and the expectations\u2014\nHefin David AM: So the time limit was the same that the previous Minister put on it.\nKirsty Williams AM: Yes. No change.\nLlyr Gruffydd AM: But Mel Ainscow did tell us that there was a fade out in that third year\u2014not that people were giving up, don't get me wrong, but clearly there wasn't that commitment coming from Government because the decision had been made, and people felt that it was just fizzling out a little bit, and that impacted on the momentum.\nKirsty Williams AM: I wouldn't characterise it as that. I think there certainly was a transition phase when we knew that the programme was moving and schools were moving into a different level of support,\u00a0but I certainly wouldn't describe it as a fading out\u2014not at all. As I said, we were aware that the programme was transitioning and we were determined to get that right for those individual schools, and to learn the lessons and, crucially, to be able to apply those lessons right across the board.\nSteve Davies: I can see where the perception would come if a programme director like Mel was managing the programme right to the end of the three years exactly the same, and it falls off\u2014not a cliff, but it falls off, then the readiness for schools and the readiness in the system to hand over\u2014so part of the shift of focus was that working as a Government with the programme in those schools to working with the programme, those schools and the region. So, I think, inevitably, one party might see it as a decrease in terms of emphasis on their work, but it was necessary for the transition.\nLlyr Gruffydd AM: But does that cast a bit of a shadow over the transition, then\u2014that one key player within that process felt as such, or are you confident that that was managed well and effectively?\nKirsty Williams AM: I think it was managed well, and we were very clear to recognise success where success has been achieved, but not to gloss over where the programme had not made an impact, because that wouldn't be good for anybody. There was a formal event to close the programme, which gave everybody an opportunity to get together, to be formally thanked, and for, as I said, congratulations to be given to those people who had really made a difference\u00a0and, crucially, key staff transferred over into the regional consortia. So, for those individuals, they were able to continue their work, but just be able to apply that work on a regional basis rather than just in an individual school. So, I don't see that there was any fading out, but there was a transition into a new system, and many of those key personnel transitioned into the system with us.\nLynne Neagle AM: Have you got any figures for the numbers of staff who went from the programme into the consortia?\nKirsty Williams AM: Not off the top of my head, but I can let you know.\nLynne Neagle AM: Okay. I've got Darren first, then Mark.\nKirsty Williams AM: And can I just say, I met with some of them? I met with a selection of those people who had been involved in the programme to get their feedback on what they felt had gone right, and what they didn't feel had gone right in the programme. So, I took the time not just to meet the figurehead\u00a0of the programme, but actually to meet the people who were doing the work in the individual schools. Sorry.\nDarren Millar AM: Yes, I just wanted to ask you, you mentioned the figurehead there, I assume by 'the figurehead' you mean Professor Ainscow. And you've mentioned as well that you said you wanted to learn lessons from Schools Challenge Cymru, but he told us that nobody had been in touch with him since March of last year in order to have any sort of follow-up engagement, or to have a dialogue about his perspective on what worked, what didn't work, why there were failures in some areas and why there were successes in others. Why haven't you sought that level of engagement with the person who was responsible for running the programme?\nKirsty Williams AM: I've had that conversation with Mr Ainscow. We had the evaluation of the programme. We've spoken to the people who were actually involved in running the programme on a daily basis in individual schools. We've spoken to the regional consortia. We've spoken to local education authorities. We've spoken to a wide variety of people to get their insight into the lessons learned, what was valuable and what was not valuable. So, a wide variety of people have been involved in those conversations.\nDarren Millar AM: But you've hardly engaged with Mr Ainscow\u2014with Professor Ainscow himself.\nSteve Davies: I would actually say that I have had meetings\u2014\nDarren Millar AM: Since March of last year.\nSteve Davies: Yes, since March of last year. I haven't got the exact dates for you. I've had discussions with Mel Ainscow, and my line manager at the time, Owen Evans, also had meetings and discussions.\nDarren Millar AM: So, when he told us, 'Since last March, I literally have had no contact at all with anybody from Welsh Government', he was telling porky pies, was he?\nSteve Davies: That's not my recollection. I'll go back and check for you.\nLynne Neagle AM: If you could check and let us know, that would be good. Mark.\nKirsty Williams AM: Yes, well, I just talked about the celebration event to formally mark the end of the programme. My understanding was that it was July of last year, so people were engaged in that. And this idea that somebody has been ignored or frozen out is not how I see or how I regard that situation.\nLynne Neagle AM: Mark.\nMark Reckless AM: I have to say, with Professor Ainscow my impression was he took great, great pride in the work that he'd done with Schools Challenge Cymru, and I think he really enjoyed the engagement, the work and the positive relations with the Welsh Government. But I think there was just a degree of disappointment, perhaps, that at least he didn't feel that he'd been interrogated as much as he might have been about the lessons learned from the programme, and how perhaps to entrench those as well as possible with the regional consortia.\u00a0I just wonder,\u00a0Cabinet Secretary, if you could invite the professor in, perhaps to have a further debrief with you and take account of some of his thoughts and suggestions for what might help in this area.\nKirsty Williams AM: Well, Mark, as I said, I just don't think it should be right to characterise this as a failure to engage with a single individual.\nMark Reckless AM: I'm not characterising it that way, Cabinet Secretary.\nKirsty Williams AM: As I said, I met with him, Steve has met with him,\u00a0Owen Evans\u00a0has met with him, my special policy adviser has met with him and had discussions. So, there has been an ongoing dialogue. But, Mark, I hope that I have demonstrated since I took on this job that I am willing to work with a wide variety of people and to tap into their expertise if it can help me to deliver on the national mission. And if the advice to me is that we haven't sufficiently learnt the lessons, then I'll gladly have another conversation. What I'm saying to you\u2014and I'm absolutely confident\u2014is that we\u00a0have learnt the lessons, we are taking that work and the good practice forward, and we have done that with conversations with a wide variety of people who had a view on this, from individual schools that were involved in the programme, individual people who were working in those schools, local education authorities, some of which have been very scathing about the programme, I should say, regional consortia\u2014. So, the lessons, I am confident, have been learnt.\nMark Reckless AM: I'm glad to hear that, Cabinet Secretary, but I still say that, listening to Professor Ainscow's evidence, there was a perception, at least from him\u00a0individually, that the programme should not be seen to be a failure, but a\u00a0desire that the lessons should be learnt and a feeling or exception, at least on his part, that there was more that he still had to contribute to the process. And just to take one particular example, I think he referred to the Schools Challenge Cymru advisers\u00a0being very successful in bringing in people who might not otherwise have contributed to this, and the regional consortia have had greater challenges in recruiting people, perhaps in some areas, of the same high standard of some particular individuals, but also from a wide range of different areas that the Schools Challenge Cymru do, and that there could be more to learn in that area as to how to support real excellence and a greater diversity of recruitment for those people. Is that something you could perhaps draw on his thoughts further about?\u00a0Because I think he does feel that he has more to say to Welsh Government to help in this area.\nKirsty Williams AM: Firstly, can I say that I have never described the programme as a failure? I would understand, as someone who has put so much personal investment into the brand of schools challenges, that he would not want anybody to characterise that particular approach to school improvement as a failure. And I want to be absolutely clear that I have never described the programme as a failure, and I want to reassure Mr Ainscow of that. As I've said, gosh, my goodness me, if you saw my e-mail inbox and you saw the letters that come in, people are never shy\u00a0in coming forward to give me advice on what I need to do, what I need to do next, what I'm doing right, what I'm doing wrong, and, you know, our doors are always open to listen to people who have interesting things to say about how we can deliver our educational mission. So, people aren't slow in coming forward, I can assure you, with advice.\nLynne Neagle AM: Julie.\nJulie Morgan AM: Just very quickly. I'm sure the Minister is aware that Cardiff put extra funds of its own in to continue Schools Challenge Cymru advisers. So, obviously, they appreciated the value of the scheme, but it does query whether it should have gone on longer.\nKirsty Williams AM: Julie, I think, to be fair, there are some people who think the scheme was absolutely fantastic. I've had feedback from people who didn't think the scheme was helpful at all\u2014in fact, they felt it was a hindrance. I'm very much of the view that the scheme worked really well for some schools in some areas and had less impact\u00a0in some areas. There is a mixed picture. What's important to me is that we understand what it was that led those schools to make those big changes, how we can\u2014like Mark talked about,\u00a0the expertise\u2014how we can keep that expertise in the system, and how we can apply\u00a0the lessons to all schools.\nLynne Neagle AM: The next questions, and the final questions, are from John. So, we're going to need succinct questions and succinct answers.\nJohn Griffiths AM: Some questions on regional consortia, Cabinet Secretary, and, first of all, the role that you believe they should play and how schools use PDG.\nKirsty Williams AM: Well, it's an absolute\u2014. It's one of the things that I have been very clear to the regional consortia that I expect their challenge and support advisers to be asking schools about. So, one of the conversations that they need to have when they are in schools is exploring, with that school, how they are using their PDG, and how they're demonstrating an impact for those resources. So, it's a fundamental role for the challenge and support advisers in the regional consortia in their school improvement work. It's crucial.\nJohn Griffiths AM: That sort of brings to mind some of the research that's been done on the role of the challenge advisers, Cabinet Secretary, which suggested that they're not actually challenging schools in that way, and that there's very little evidence of schools changing their decisions on the use of PDG as a result of any challenge from those challenge advisers. So, how would you respond to those findings?\nKirsty Williams AM: Well, as I said, in my scrutiny of the role and success of our regional consortia, I specifically asked them about free-school-meal performance and the use of PDG within their particular region. I think there is increasing evidence to suggest that good use is being made of that resource, and I think that is being fed back into us. Estyn tell us that it's one of the areas of school expenditure that is closely linked to research and an evidence base. But, clearly, there is more to do, and that's why we have appointed the new regional advisers for PDG going forward, because we think there can be improvements in how this agenda can be supported at a regional level.\nJohn Griffiths AM: Okay. So, you would recognise the findings from that research.\nKirsty Williams AM: Yes. There's always more that we can do, and we are strengthening that role by the appointment of the new regional PDG advisers, so that individual\u00a0school challenge advisers know what they should be looking for, know what they should be doing, and there is a regional approach to good practice.\nJohn Griffiths AM: Okay. Could you tell the committee, Cabinet Secretary, how effective you believe the relationship was between the Schools Challenge Cymru programme and the regional consortia's school improvement functions, and to what extent it varied by region?\nKirsty Williams AM: I think it's fair to say that, on occasion, I have received feedback that there was a conflict between what was going on at an individual school under the school improvement programme and whether, then, they welcomed support from the regional consortia as part of that. So, in some cases, if we're being absolutely honest, there could sometimes be tensions between the two, but in most cases, the relationship was very, very positive and there was continuous feedback between the work going on in the schools under the programme and the regional consortia challenge advisers. But I'm going to be blunt and honest with people\u2014in some cases, it has been reported to me\u2014it's only anecdotal evidence; I haven't got hard and fast evidence\u2014that there sometimes was a conflict: 'We're a school challenge school so we don't need to participate or listen to any advice that's coming from the regional consortia.' Or, a local education authority said to me, 'We felt that we couldn't get involved in that school anymore because it was part of a different programme.' Those were isolated incidents, and, as I said, it's only anecdotal feedback. In most cases, the relationship was a very positive one.\nSteve Davies: Just very quickly, I think that, across the board, it was more complex in the beginning, getting\u2014[Inaudible.]. But when the programme itself recognised that they needed to work with the regions, and the regions needed to work with them\u2014and I think Mel Ainscow in his evidence referred to this\u2014it strengthened after some early challenges. I think Mel Ainscow was working in a number of regions\u2014I can't remember which ones\u2014so he's established relationships\u2014[Interruption.] Sorry?\nKirsty Williams AM: Central south.\nSteve Davies: Central south. He has already been working in that, so I think it possibly had a stronger springboard in terms of the early working.\nKirsty Williams AM: Because he already had relationships that he had already developed in that particular region. As always, with many of these things, it's about individuals and relationships.\nJohn Griffiths AM: Okay. Finally from me, Cabinet Secretary: in 2015-16, Estyn reported on regional consortia not sufficiently focusing on particular groups of pupils and tracking their outcomes\u2014for example, vulnerable pupils. I just wonder what you are able to tell us in terms of to what extent there has been necessary progress since 2015-16.\nKirsty Williams AM: Okay. Well, I think it's important to recognise that all four consortia underwent\u00a0monitoring visits in the autumn of last year, of 2017, which weren't reflected in the Estyn annual report for 2015-16. Estyn, through these 2017 inspections, have said that three out of the four regional consortia are making strong progress in their particular work, and we are continuing, as Welsh Government, to work with the other regional consortia to address the findings of the Estyn report.\nJohn Griffiths AM: And that would include these particular issues.\nKirsty Williams AM: Yes, absolutely. The committee probably hasn't had an opportunity to see, but, only this morning, Estyn has released a report on more able and talented, and has positive things to say in the field of more able and talented, which was being asked about earlier by Members\u2014you know, evidence of improved working and support in that particular arena. But, again, we need to ensure a consistency across all the regions, and that the findings of Estyn's most recent reports into regional performance are followed through.\nLynne Neagle AM: Okay, thank you. As we've got a couple of minutes left, if I can just jump back to the issue of practical uses of the PDG\u2014because it's the only thing we haven't really covered and it would be good to get on the record\u2014can I ask to what extent you'd like to see the PDG used to track the progress of eligible pupils? And the committee's heard that there are several different tracking systems and tools used by schools. To what extent is that an issue to do with what the Welsh Government is promoting? Or is it down to consortia or individual schools? And do you think there needs to be a more centralised push on how the tracking is undertaken?\nKirsty Williams AM: Firstly, can I say it's absolutely crucial that we track performance, absolutely crucial? That's the bedrock. We don't dictate to individual schools the nature of the system that they should employ in their school. There are a number of different programmes that allow schools to do this, but we are absolutely clear, and best practice and evidence shows us, that individual pupil tracking is key and crucial. And, as I said in the beginning, where we weren't tracking pupils at all, initial investment in PDG was used to establish these systems within schools. Again, one of the outcomes from the schools challenge review, and one of the lessons learnt, was, again, the importance of individual tracking of pupils throughout their school career. But we don't dictate a single system.\nLynne Neagle AM: Okay, thank you.\nKirsty Williams AM: But the principle is a really important one.\nLynne Neagle AM: Okay, and you don't think there's more scope to look at what the best system is that can be recommended to schools.\nKirsty Williams AM: That's not something we're actively looking at. I am actively looking at developing a Welsh toolkit around good practice, evidence base and research. At the moment we use the Sutton Trust toolkit, which is fine and excellent, but we are having active discussions about whether we're in a position, now, to look at developing a suite of a Welsh toolkit to support this agenda, and that's under active consideration.\nLynne Neagle AM: Okay. Well, we've reached the end of our session. Can I thank the Cabinet Secretary and the officials for attending and for answering such a wide range of questions? As usual, you'll be sent a transcript to check for accuracy following the meeting, but thank you again for coming.\nKirsty Williams AM: Thank you very much.\nLynne Neagle AM: Thank you. Okay. Item 3, then, is papers to note. Paper to note 1 is a letter from the Minister for Children and Social Care on Families First funding. Paper to note 2 is a letter from the Cabinet Secretary for Education, updating us on the supply teacher issue. Paper to note 3\u2014another letter from the Cabinet Secretary for Education, providing further information following our meeting on 15 February. Paper to note 4 is a letter from the WJEC on availability of textbooks. Paper to note 5\u2014a letter from Qualifications Wales, also on availability of textbooks. And paper to note 6 is a letter from the Cabinet Secretary for Education to the Children's Commissioner for Wales, following up on the dialogue that they've been having about our inquiry. Are Members happy to note those? Thank you. Item 4, then, is for me to propose, in accordance with Standing Order 17.42, that the committee resolves to meet in private for the remainder of the meeting. Are Members content? Thank you.", "source": "meeting_summ", "evaluation": "rouge"}
{"instructions": ["Summarize the discussion on looking at feature streams", "What did PhD C think about silence detection?", "What did the professor think about the silence detection problem?", "Summarize the discussion on fixing the system", "What did the team think about a single KLT?", "What were the professor's concluding comments?", "Summarize the meeting"], "outputs": ["The team used OGI features that then passed through a contextualized KLT, an MLP, and a low-pass filter. The highly mismatched Italian part was still not working well. The team tried using silence detection to improve performance, but the results were not too promising.", "PhD C explained that there was no room left for silence detection because of the server side delay. They were working out a compromise between the handset delay and the server delay, but the delay was too large at the moment.", "The professor thought that the results in the experiment without silence detection were okay as well. He thought some sort of weighted measure between other features should result in good performance.", "It was time for the team to rely on the models they had created so far to fix the system. They were deciding when to fix it. The professor explained that they should do so by Tuesday, and when they get new data later in the week, they need not train on it.", "PhD C thought that it would be worthwhile to test on a single KLT. The professor agreed that since it would be pretty low-maintenance, the team should do that, but only if they can fit it in.", "The professor noted that the most important improvements over the years have been due to finding bugs. He also informed the team of some IBM processors that were available to them at the University of Washington. He finally congratulated them on their efforts.", "The meeting participants discuss results from experiments and challenges that the model was facing. There was a significant server side delay, so they could not accommodate silence detection. Members noted that reducing model dimensions had a detrimental effect on model performance. The professor wanted to know the size of words that the word error rate was calculated on and explained that there would be no new training. From this point, they can start talking about future directions and work on fixing the system."], "input": "Professor B: OK So uh today we 're looking at a number of uh things we 're trying and uh fortunately for listeners to this uh we lost some of it 's visual but um got tables in front of us . Um what is {disfmarker} what does combo mean ?\nPhD C: So combo is um a system where we have these features that go through a network and then this same string of features but low - pass filtered with the low - pass filter used in the MSG features . And so these low - pass filtered goes through M eh {disfmarker} another MLP and then the linear output of these two MLP 's are combined just by adding the values and then there is this KLT . Um the output is used as uh features as well .\nProfessor B: Um so let me try to restate this and see if I have it right . There is uh {disfmarker} there is the features uh there 's the OGI features and then um those features um go through a contextual {disfmarker} uh l l let 's take this bottom arr one pointed to by the bottom arrow . Um those features go through a contextualized KLT . Then these features also uh get um low - pass filtered\nPhD C: Yeah . Yeah so yeah I could perhaps draw this on the blackboard\nProfessor B: Sure . Yeah . Yeah .\nPhD C: Yeah .\nPhD D: The graph , yeah another one .\nProfessor B: Yeah , that 's good .\nPhD C: \nProfessor B: So\nPhD C: So we have these features from OGI that goes through the three paths .\nProfessor B: Yeah . Three , OK .\nPhD C: The first is a KLT using several frames of the features .\nProfessor B: Yeah . Yeah .\nPhD C: The second path is uh MLP also using nine frames {disfmarker} several frames of features\nProfessor B: Yeah . Uh - huh .\nPhD C: The third path is this low - pass filter .\nProfessor B: Uh - huh .\nPhD C: Uh , MLP\nProfessor B: Aha ! aha !\nPhD C: Adding the outputs just like in the second propose the {disfmarker} the proposal from {disfmarker} for the first evaluation .\nProfessor B: Yeah ? Yeah . Yeah .\nPhD C: And then the KLT and then the two together again .\nProfessor B: No , the KLT . And those two together . That 's it .\nPhD D: Two HTK .\nProfessor B: OK so that 's {disfmarker} that 's this bottom one .\nPhD C: Um . So this is {disfmarker} yeah\nProfessor B: And so uh and then the {disfmarker} the {disfmarker} the one at the top {disfmarker} and I presume these things that uh are in yellow are in yellow because overall they 're the best ?\nPhD C: Yeah that 's the reason , yeah .\nProfessor B: Oh let 's focus on them then so what 's the block diagram for the one above it ?\nPhD C: For the f the f first yellow line you mean ?\nProfessor B: Yeah .\nPhD C: Yeah so it 's uh basically s the same except that we don't have this uh low - pass filtering so we have only two streams .\nPhD D: Step .\nPhD C: Well . There 's {disfmarker} there 's no low {disfmarker} low - pass processing used as additional feature stream .\nProfessor B: Mm - hmm . Mm - hmm .\nPhD C: Um\nProfessor B: Do you e um they mentioned {disfmarker} made some {disfmarker} uh when I was on the phone with Sunil they {disfmarker} they mentioned some weighting scheme that was used to evaluate all of these numbers .\nPhD C: Yeah . Uh actually the way things seems to um well it 's uh forty percent for TI - digit , sixty for all the SpeechDat - Cars , well all these languages . Ehm the well match is forty , medium thirty five and high mismatch twenty - five . Yeah .\nProfessor B: Um and we don't have the TI - digits part yet ?\nPhD C: Uh , no .\nProfessor B: OK .\nPhD C: But yeah . Generally what you observe with TI - digits is that the result are very close whatever the {disfmarker} the system .\nProfessor B: OK . And so have you put all these numbers together into a single number representing that ?\nPhD C: Yeah .\nProfessor B: I mean not {disfmarker}\nPhD C: Uh not yet .\nProfessor B: OK so that should be pretty easy to do and that would be good {disfmarker}\nPhD C: No . Mmm yeah , yeah .\nProfessor B: then we could compare the two and say what was better .\nPhD C: Mmm . Yeah .\nProfessor B: Um and how does this compare to the numbers {disfmarker} oh so OGI two is just the top {disfmarker} top row ?\nPhD D: Yeah .\nPhD C: So yeah to {disfmarker} actually OGI two is the {disfmarker} the baseline with the OGI features but this is not exactly the result that they have because they 've {disfmarker} they 're still made some changes in the features\nProfessor B: OK .\nPhD C: and {disfmarker} well but uh actually our results are better than their results . Um I don't know by how much because they did not send us the new results\nProfessor B: OK .\nPhD C: Uh\nProfessor B: Uh OK so the one {disfmarker} one place where it looks like we 're messing things up a bit is in the highly mismatched Italian .\nPhD C: Yeah . Yeah .\nProfessor B: An\nPhD C: Yeah there is something funny happening here because {disfmarker} yeah .\nProfessor B: Yeah .\nPhD C: But there are thirty - six and then sometimes we are {disfmarker} we are {disfmarker} we are around forty - two and\nProfessor B: Now up\nPhD C: but\nProfessor B: Uh so one of the ideas that you had mentioned last time was having a {disfmarker} a second um silence detection .\nPhD C: Yeah . So there are some results here\nPhD D: For the Italian .\nPhD C: uh so the third and the fifth line of the table\nPhD D: For this one .\nProfessor B: So filt is what that is ?\nPhD C: Filt , yeah\nPhD D: Yeah .\nPhD C: Um yeah so it seems f for the {disfmarker} the well match and mismatched condition it 's uh it brings something . Uh but uh actually apparently there are {disfmarker} there 's no room left for any silence detector at the server side because of the delay . Uh well\nProfessor B: Oh we can't do it . Oh OK .\nPhD C: No .\nPhD D: For that {disfmarker} for that we {disfmarker}\nProfessor B: Oh .\nPhD C: Uh\nProfessor B: Too bad . Good idea , but can't do it .\nPhD C: Yeah .\nProfessor B: OK .\nPhD C: Except I don't know because they {disfmarker} I think they are still working well .\nProfessor B: Uh - huh .\nPhD C: Uh t two days ago they were still working on this trying to reduce the delay of the silence detector so but yeah if we had time perhaps we could try to find uh some kind of compromise between the delay that 's on the handset and on the server side . Perhaps try to reduce the delay on the handset and {disfmarker} but well hmm For the moment they have this large delay on the {disfmarker} the feature computation and so we don't\nProfessor B: OK . So Alright so for now at least that 's not there you have some results with low - pass filter cepstrum doesn't have a huge effect but it {disfmarker} but it looks like it you know maybe could help in a couple places .\nPhD C: I th\nProfessor B: Uh little bit .\nPhD C: Yeah .\nProfessor B: Um and um um Yeah and uh let 's see What else did we have in there ? Uh I guess it makes a l um at this point this is I {disfmarker} I guess I should probably look at these others a little bit uh And you {disfmarker} you yellowed these out uh but uh uh Oh I see yeah that {disfmarker} that one you can't use because of the delay . Those look pretty good . Um let 's see that one Well even the {disfmarker} just the {disfmarker} the second row doesn't look that bad right ? That 's just uh yeah ?\nPhD C: Yep .\nProfessor B: And {disfmarker} and that looks like an interesting one too .\nPhD D: Mmm yeah .\nProfessor B: Uh\nPhD C: Actually the {disfmarker} yeah the second line is uh pretty much like the first line in yellow except that we don't have this KLT on the first {disfmarker} on the left part of the diagram . We just have the features as they are .\nProfessor B: Mm - hmm .\nPhD C: Um\nProfessor B: Yeah . Yeah so when we do this weighted measure we should compare the two cuz it might even come out better . And it 's {disfmarker} it 's {disfmarker} it 's a little {disfmarker} slightly simpler .\nPhD C: Mm - hmm . Yeah .\nProfessor B: So {disfmarker} so there 's {disfmarker} so I {disfmarker} I would put that one also as a {disfmarker} as a maybe . Uh and it {disfmarker} yeah and it 's actually {vocalsound} does {disfmarker} does significantly better on the uh uh highly mismatched Italian , so s and little worse on the mis on the MM case , but uh Well yeah it 's worse than a few things\nPhD C: Mm - hmm .\nProfessor B: so uh let 's see how that c that c c see how that comes out on their {disfmarker} their measure and {disfmarker} are {disfmarker} are we running this uh for TI - digits or uh\nPhD C: Yeah .\nProfessor B: Now is TI di {disfmarker} is is that part of the result that they get for the uh development {disfmarker} th the results that they 're supposed to get at the end of {disfmarker} end of the month , the TI - digits are there also ?\nPhD C: Yeah . Yeah . It 's included , yeah .\nProfessor B: Oh OK . OK . And see what else there is here . Um Oh I see {disfmarker} the one {disfmarker} I was looking down here at the {disfmarker} the o the row below the lower yellowed one . Uh that 's uh that 's with the reduced uh KLT size {disfmarker} reduced dimensionality .\nPhD C: Mm - hmm ? Yeah . Yeah .\nProfessor B: What happens there is it 's around the same and so you could reduce the dimension as you were saying before a bit perhaps .\nPhD C: Yeah , it 's {disfmarker} it 's significantly worse well but {disfmarker} Mm - hmm .\nProfessor B: It 's significantly worse {disfmarker} it 's {disfmarker} it 's uh it 's {disfmarker} it 's mostly worse .\nPhD C: Exc - except for the HM\nPhD D: For many a mismatch it 's worse .\nPhD C: but\nProfessor B: Yeah . But it is little . I mean not {disfmarker} not by a huge amount , I don't know . What are {disfmarker} what are the sizes of any of these sets , I {disfmarker} I 'm {disfmarker} I 'm sure you told me before , but I 've forgotten . So {disfmarker} you know how many words are in uh one of these test sets ?\nPhD C: Uh\nPhD D: I don't remember .\nProfessor B: About ?\nPhD C: Um it 's {disfmarker} it depends {disfmarker} well {disfmarker} the well matched is generally larger than the other sets and I think it 's around two thousand or three thousand words perhaps , at least .\nPhD D: Ye But words {disfmarker} well word {disfmarker} I don't know .\nPhD C: Hmm ? The words , yeah . S sentences .\nPhD D: Sentences .\nPhD C: Some sets have five hundred sentences , so .\nPhD D: Yeah .\nProfessor B: So the {disfmarker} so the sets {disfmarker} so the test sets are between five hundred and two thousand sentences , let 's say\nPhD C: Mmm .\nProfessor B: and each sentence on the average has four or five digits or is it {disfmarker} most of them longer or\nPhD C: Yeah .\nPhD D: Yeah for the Italian even seven digits y more or less\nPhD C: It {disfmarker} it d Seven digits .\nPhD D: but sometime the sentence have only one digit and sometime uh like uh the number of uh credit cards , something like that .\nProfessor B: Mm - hmm . Right , so between one and sixteen . See the {disfmarker} I mean the reason I 'm asking is {disfmarker} is {disfmarker} is we have all these small differences and I don't know how seriously to take them , right ?\nPhD C: Mm - hmm ?\nProfessor B: So uh i if {disfmarker} if you had uh just you know {disfmarker} to give an example , if you had uh um if you had a thousand words then uh a {disfmarker} a tenth of a percent would just be one word ,\nPhD C: Yeah .\nProfessor B: right ? So {disfmarker} so it wouldn't mean anything .\nPhD D: Yeah .\nProfessor B: Oh\nPhD C: Yeah .\nProfessor B: um so um yeah it be kind of {disfmarker} I 'd kind of like to know what the sizes of these test sets were actually .\nPhD C: Yeah .\nPhD D: The size that we have ?\nPhD C: We could {disfmarker} we could run {disfmarker} run some kind of significance tests\nProfessor B: Yeah since these {disfmarker} well also just to know the numbers ,\nPhD C: or\nPhD D: Yeah .\nProfessor B: right . So these {disfmarker} these are word error rates\nPhD C: Yeah .\nProfessor B: so this is on how many words .\nPhD C: Yep .\nPhD D: Yeah we have the result that the output of the HTK\nProfessor B: Yeah .\nPhD D: The number of {disfmarker} of sentences , no it 's the number isn't .\nPhD C: Yeah sure {disfmarker} sure . Yeah sure .\nProfessor B: Yeah so anyway if you could just mail out what those numbers are and then {disfmarker} then {disfmarker} that {disfmarker} that be great .\nPhD C: Yeah .\nPhD D: Yeah .\nProfessor B: Um {vocalsound} what else is there here ? Um see the second {disfmarker} second from the bottom it says SIL , but this is some different kind of silence or thing or {disfmarker} what was that ?\nPhD C: Uh\nPhD D: It the {disfmarker} the output silence of the MLP .\nPhD C: Oh yeah I see .\nPhD D: It 's only one small experiment to know what happened . To apply also to in include also the {disfmarker} the silence of the MLP we have the fifty - six form and the silence to pick up the silence and we include those .\nProfessor B: Yes . Uh - huh , uh - huh . The silence plus the KLT output ? Oh so you 're only using the silence .\nPhD C: Yeah .\nPhD D: Yeah , because when we apply the KLT\nPhD C: No they 're {disfmarker} I think there is this silence in addition to the um KLT outputs\nProfessor B: No .\nPhD D: in addition , yes .\nPhD C: it is because we {disfmarker} we {disfmarker} we just keep uh we don't keep all the dimensions after the KLT\nPhD D: In addition t\nPhD C: and {disfmarker} yeah .\nPhD D: and we not s we are not sure if we pick {disfmarker} we have the silence .\nPhD C: So we try to add the silence also in addition to the {disfmarker} these twenty - eight dimensions .\nProfessor B: I see . OK . And what {disfmarker} and what 's OGI forty - five ? The bottom one there ?\nPhD C: Uh it 's o it 's OGI two , it 's {disfmarker} so the {disfmarker} th it 's the features from the first line\nPhD D: It 's in fact OGI two .\nProfessor B: S\nPhD C: and {disfmarker} yeah .\nProfessor B: Right , but I mean what 's the {disfmarker} what does the last row mean ?\nPhD C: So it 's uh basically this but without the KLT on the {disfmarker} from the left path .\nProfessor B: I thought that was the one {disfmarker} I thought that was the second row . So what 's the difference between the second\nPhD C: Uh the second line you don't have this combo stuff so you just\nProfessor B: Oh .\nPhD C: uh\nProfessor B: So this is like the second line but with {disfmarker} with the combo stuff .\nPhD C: Yeah . Yeah .\nPhD D: And with the {disfmarker} all the output of the combo .\nProfessor B: OK . Yeah .\nPhD C: Yeah .\nPhD D: Uh\nProfessor B: OK , so {disfmarker} alright so it looks to me {disfmarker} I guess the same {disfmarker} given that we have to take the filt ones out of the {disfmarker} the running because of this delay problem {disfmarker} so it looks to me like the ones you said I agree are {disfmarker} are the ones to look at\nPhD C: Mm - hmm .\nProfessor B: but I just would add the {disfmarker} the {disfmarker} the second row one\nPhD C: Yeah .\nProfessor B: and then um if we can um\nPhD C: Mmm .\nProfessor B: oh yeah also when {disfmarker} when they 're using this weighting scheme of forty , thirty - five , twenty - five is that on the percentages or on the raw errors ? I guess it 's probably on the percentages right ?\nPhD C: Uh {vocalsound} I guess , yeah .\nProfessor B: Yeah OK .\nPhD C: I guess , yeah . Mmm .\nProfessor B: Alright .\nPhD C: It 's not clear here .\nProfessor B: OK . Maybe {disfmarker} maybe they 'll argue about it . Um OK so if we can know what {disfmarker} how many words are in each and then um Dave uh Dave promised to get us something tomorrow which will be there as far as they 've gotten {vocalsound} Friday\nPhD C: Mm - hmm .\nProfessor B: and then we 'll operate with that\nPhD C: Yeah .\nProfessor B: and uh how long did it I guess if we 're not doing all these things {disfmarker} if we 're only doing um um I guess since this is development data it 's legitimate to do more than one , right ? I mean ordinarily if {disfmarker} in final test data you don't want to do several and {disfmarker} and take the best\nPhD C: Yeah . Mmm .\nProfessor B: that 's {disfmarker} that 's {disfmarker} that 's not proper but if this is development data we could still look at a couple .\nPhD C: Yeah . We can {disfmarker} yeah . Sure . But we have to decide {disfmarker} I mean we have to fix the system on this d on this data , to choose the best\nProfessor B: Yeah . I Right .\nPhD C: and these\nProfessor B: But the question is when {disfmarker} when do we fix the system ,\nPhD C: But we could\nProfessor B: do we fix the system uh tomorrow or do we fix the system on Tuesday ?\nPhD C: it d\nProfessor B: I {disfmarker} Yeah , OK except that we do have to write it up .\nPhD C: I think we fixed on Tuesday , yeah . Yeah . Mm - hmm . Mm - hmm .\nProfessor B: Also , so\nPhD C: Yeah . Yeah .\nProfessor B: Um\nPhD C: Uh yeah well . Well basically it 's this with perhaps some kind of printing and some {disfmarker} some other @ @ .\nProfessor B: Right so maybe what we do is we {disfmarker} we {disfmarker} we uh as soon as we get the data from them we start the training and so forth\nPhD C: Yeah but Mm - hmm .\nProfessor B: but we start the write - up right away because as you say there {disfmarker} there 's only minor differences between these .\nPhD C: I think you {disfmarker} we could {disfmarker} we could start soon , yeah .\nProfessor B: Yeah .\nPhD C: Write up something .\nProfessor B: Yeah , and {disfmarker} and I {disfmarker} I would {disfmarker} you know , I would {disfmarker} I 'd kind of like to see it\nPhD C: Um yeah . Mm - hmm .\nProfessor B: maybe I can {disfmarker} I can edit it a bit uh sure . The {disfmarker} my {disfmarker} what in this si i in this situation is my forte which is English .\nPhD C: Yeah .\nProfessor B: Uh so\nPhD C: Mmm .\nProfessor B: uh H yeah . Have y have you seen alt d do they have a format for how they want the system descriptions or anything ?\nPhD C: Uh not really .\nProfessor B: OK .\nPhD C: Um There is the format of the table which is {vocalsound} quite impressive .\nProfessor B: Yeah ? Uh I see . Yes , for those who are listening to this and not looking at it uh it 's not really that impressive , it 's just tiny . It 's all these little categories set a , set b , set c , multi - condition , clean . Uh No mitigation . Wow . Do you know what no {disfmarker} what no mitigation means here ?\nPhD C: Um it should be the the problem with the error {disfmarker} channel error\nProfessor B: Oh that 's probably the {disfmarker}\nPhD C: or\nProfessor B: this is probably channel error stuff\nPhD C: well , you {disfmarker}\nProfessor B: huh ? Oh this is i right , it says right above here channel {disfmarker} channel error resilience ,\nPhD C: Yeah . Yeah .\nProfessor B: yeah . So recognition performance is just the top part , actually . Uh and they have {disfmarker} yes , split between seen databases and non - seen so basically between development and {disfmarker} and evaluation .\nPhD C: Yeah .\nProfessor B: And {vocalsound} so {disfmarker} right , it 's presumed there 's all sorts of tuning that 's gone on on the see what they call seen databases and there won't be tuning for the uh unseen . Multi - condition {disfmarker} multi - condition . So they have {disfmarker} looks like they have uh uh\nPhD C: Mm - hmm .\nProfessor B: so they splitting up between the TI - digits and everything else , I see . So the everything else is the SpeechDat - Car , that 's the multi multilingual\nPhD C: Yeah , so it 's not divided between languages you mean or {disfmarker}\nProfessor B: Well , it is .\nPhD C: it just\nProfessor B: It is , but there 's also {disfmarker} there 's these tables over here for the {disfmarker} for the TI - digits and these tables over here for the car data which is {disfmarker} which is I guess all the multilingual stuff\nPhD C: Oh yeah .\nProfessor B: and then uh there 's {disfmarker} they also split up between multi - condition and clean only .\nPhD C: Yeah . For TI - digits .\nProfessor B: Yes .\nPhD C: Yeah , actually yeah . For the TI - digits they want to train on clean and on noisy\nProfessor B: Yeah .\nPhD C: and {disfmarker} yeah .\nProfessor B: So we 're doing that also , I guess .\nPhD C: Uh yeah . But uh we actually {disfmarker} do we have the features ? Yeah . For the clean TI - digits but we did not test it yet . Uh the clean training stuff .\nProfessor B: OK .\nPhD C: Mmm .\nProfessor B: Well anyway , sounds like there 'll be a lot to do just to {vocalsound} work with our partners to fill out the tables {vocalsound} over the next uh next few days\nPhD C: Mm - hmm .\nPhD D: Yes .\nProfessor B: I guess they have to send it out {disfmarker} let 's see the thirty - first is uh uh Wednesday and I think the {disfmarker} it has to be there by some hour uh European time on Wednesday\nPhD C: Hmm - hmm .\nProfessor B: so {vocalsound} I think basically\nPhD D: We lost time uh Wednesday maybe because {vocalsound} that the difference in the time may be {disfmarker} is a long different of the time .\nProfessor B: E excuse me ?\nPhD D: Maybe the Thursday the twelfth of the night of the Thurs - thirty - one is {disfmarker} is not valid in Europe .\nPhD C: Yeah .\nPhD D: We don't know is happening .\nProfessor B: Yes , so I mean {disfmarker} I think we have to actually get it done Tuesday\nPhD D: Tuesday .\nProfessor B: right because I {disfmarker} I think\nPhD C: Yeah , well .\nProfessor B: uh Uh\nPhD C: Except if {disfmarker} if it 's the thirty - one at midnight or I don't know {disfmarker} we can {vocalsound} still do some work on Wednesday morning .\nProfessor B: yeah well . W i is but is {disfmarker} is it midni I thought it was actually something like five PM on {disfmarker}\nPhD C: Yeah , well . Yeah .\nPhD D: Yeah .\nPhD C: Mm - hmm .\nProfessor B: was like {disfmarker} I thought it was five PM or something , I didn't think it was midnight . I thought they said they wanted everything by\nPhD D: Yeah , five PM .\nProfessor B: well , so five PM their time is {disfmarker} is {disfmarker} if\nPhD D: Not five PM , three PM .\nProfessor B: three PM .\nPhD D: Three PM .\nProfessor B: Alright , that 's six in the morning here .\nPhD C: It 's d no .\nPhD D: Uh no three {disfmarker} three A - three PM ?\nPhD C: No , we are wondering about the {disfmarker} the {disfmarker} the hour that we have to eh I don't know if it 's three PM {disfmarker} it 's\nPhD D: Oh yeah , yeah , yeah , yeah . Three PM here is in Europe midnight .\nPhD C: Yeah , it 's {disfmarker} it 's midnight but\nProfessor B: Yes , yes , but I didn't think it was midnight that it was due , I thought it was due at some hour during the day like five PM or something .\nPhD D: Oh OK . Mm - hmm . Mm - hmm , \nProfessor B: In which case\nPhD D: maybe .\nProfessor B: so I {disfmarker} I {disfmarker} uh well we should look but my assumption is that we basically have to be done Tuesday . Um so then next Thursday we can sort of have a little aftermath\nPhD D: Yeah .\nProfessor B: but then {disfmarker} then we 'll actually have the new data which is the German and the Danish\nPhD C: Yeah .\nProfessor B: but that really will be much less work because uh the system will be fixed\nPhD C: Yeah .\nProfessor B: so all we 'll do is take whatever {vocalsound} they have and {disfmarker} and uh and run it through the process .\nPhD C: Yeah .\nProfessor B: Uh we won't be changing the training on anything\nPhD C: Mm - hmm .\nProfessor B: so there 'll be no new training , there 'll just be new HTK runs , so that 's means in some sense we can kind of relax from this after {disfmarker} after Tuesday and {disfmarker} and uh maybe next meeting we can start talking a little bit about where we want to go from here uh in terms of uh the research .\nPhD C: Mm - hmm .\nProfessor B: Um you know what things uh did you think of when you were uh doing this process that uh you just didn't really have time to adequately work on uh uh so\nPhD C: Mm - hmm . Yeah .\nProfessor B: What ?\nGrad A: Oh , Stephane always has these great ideas and {disfmarker} oh , but uh we don't have time .\nPhD C: Sure .\nProfessor B: Yeah .\nGrad A: Yeah .\nProfessor B: Yeah .\nPhD C: I 'm not sure these are great ideas .\nProfessor B: But they 're ideas . Yeah ? Oh , that was good .\nPhD C: Yeah .\nGrad A: Yeah .\nProfessor B: And {disfmarker} and uh also it 's still true that uh I think it 's true that {disfmarker} that we {disfmarker} we at least got fairly consistent i improved results by running uh the uh neural net transformation in parallel with the features\nPhD C: But\nProfessor B: rather than uh in sequence which was {disfmarker} was your suggestion and that {disfmarker} that {disfmarker} that seems to have been borne out .\nPhD C: Mm - hmm . Mm - hmm .\nProfessor B: The fact that none of these are {disfmarker} are {disfmarker} you know , enormous is {disfmarker} is {disfmarker} is not too surprising {disfmarker} most improvements aren't enormous and {vocalsound} uh\nPhD C: Yeah .\nProfessor B: some of them are but uh I mean you have something really really wrong {vocalsound} and you fix it {vocalsound} you can get big and really enormous improvements\nPhD C: Mm - hmm .\nProfessor B: but {vocalsound} uh {vocalsound} um Cuz our best improvements over the years that we 've gotten from finding bugs , but Anyway OK well I {disfmarker} I think {disfmarker} I see where we are and everybody knows what they 're doing and is there {disfmarker} is there anything else we should talk about or {disfmarker} or {disfmarker} are we done ?\nPhD C: Mm - hmm . I think it 's OK um . We so basically we will {disfmarker} I think we 'll try to {disfmarker} to focus on these three architectures and {disfmarker} and perhaps I was thinking also a fourth one with just {disfmarker} just a single KLT because we did not really test that {disfmarker}\nProfessor B: Uh - huh .\nPhD C: removing all these KLT 's and putting one single KLT at the end .\nProfessor B: Yeah , I mean that would be pretty low maintenance to try it .\nPhD C: Yeah .\nProfessor B: Uh if you can fit it in .\nPhD C: Mm - hmm .\nProfessor B: Oh I have {disfmarker} yeah I do have one other piece of information which uh I should tell people outside of this group too uh I don't know if we 're gonna need it uh but uh Jeff up at the uh University of Washington has uh gotten a hold of a uh uh some kind of server farm of uh of ten uh uh multiprocessor uh IBM machines RS six thousands\nPhD C: Mm - hmm .\nProfessor B: and {disfmarker} and uh so I think each one is four processors or something or {disfmarker} I don't know , eight hundred megahertz or something and there 's four processors in a box and there 's ten boxes and there 's some kind of ti so if {disfmarker} you know he 's got a lot of processing power and um we 'd have to schedule it but if we have some big jobs and we wanna {disfmarker} wanna {disfmarker} wanna run them he 's {disfmarker} he 's offering it .\nPhD C: Mm - hmm .\nProfessor B: So . It 's uh when he was here eh uh he {disfmarker} he used i not only every machine here but every machine on campus as far as I could tell , so {disfmarker} so in some ways he just got his payback , but uh again I {disfmarker} I don't know if we 'll end up with {disfmarker} if we 're gonna be CPU limited on anything that we 're doing in this group\nPhD C: Mm - hmm .\nProfessor B: but {disfmarker} but if {disfmarker} if we are that 's an offer . OK well uh you guys doing great stuff so that 's {disfmarker} that {disfmarker} that 's really neat and uh we 'll uh uh g don't think we need to uh um Oh well the other thing I guess that I will say is that uh the digits that we 're gonna record momentarily is starting to get {disfmarker} are starting to get into a pretty good size collection and um in addition to the SpeechDat stuff we will have those to work with really pretty soon now so that 's {disfmarker} that 's another source of data . Um which is s under somewhat better control and that we can {disfmarker} we can make measurements of the room the {disfmarker} uh that {disfmarker} you know if we feel there 's other measurements we don't have that we 'd like to have we can make them and uh Dave and I were just talking about that a little while ago so uh that 's another {disfmarker} another possibility for this {disfmarker} this kind of work .\nPhD C: Mm - hmm .\nProfessor B: K , uh if nobody has anything else maybe we should go around do {disfmarker} do our digits {disfmarker} do our digits duty . OK . OK I 'll start . Uh , let me say that again . OK . I guess we 're done .", "source": "meeting_summ", "evaluation": "rouge"}
{"instructions": ["Summarize the discussion on XML tools and meeting data quality", "Summarize the discussion on backups and collecting notes with meetings", "What did Grad H think about using XML tools?", "What did Grad G think about meeting data quality?", "What did grad G think about collecting notes and related data with meetings?", "What did the Postdoc think about collecting notes with meetings?", "Summarize the meeting"], "outputs": ["The team had started moving to XML as their general format to standardize their data. Though, there is still concern about the limitations of XML. The participants noted that sometimes the mic of one subject catches sound from another. They also discussed implementing tools to help participants know when the quality of their audio is bad.", "The team agreed that it was important to keep good backups. Their main concern was the time difference between getting more disks and recording new meetings. They did not want to rely on burning CD's at all because of potential loss of data. They also started discussing whether it would be a good idea to collect meeting notes from the participants as well, but that would entail installing new infrastructure.", "Grad H brought up that they were standardizing the data in XML, though Grad H was not satisfied with the current data format. Grad H was also building tools to extract information from XML's in various languages, mainly Java and Perl.", "Grad G thought that it would be important to collect seat information in the key files to know where someone was sitting. This would be useful when people had to be bleeped out upon being heard in someone else's microphone. Grad G wanted to figure out what seating arrangements led to other participants' voices showing up in the microphone.", "Grad G thought that it would be helpful to let the participants conveniently bleep things out during the meeting. While synchronizing bleeps from during the meeting would require some infrastructure, a faster version could be set up. Though, G did think that the synchronization infrastructure would be a useful addition.", "The postdoc thought that it was a good idea to collect digital notes during the meeting in principle, but was concerned about the noise it would add to the mic. Postdoc thought that notes could even be taken after the meeting, by transcribers. All in all, he thought notes were useful for generating summaries.", "The meeting discussed the progress of the transcription, the DARPA demos, tools to ensure meeting data quality, data standardization, backup tools, and collecting tangential meeting information. The team was making good progress on the transcription but was still concerned with correcting some of the data. Besides that, they were working on adapting the THISL GUI for their project and figuring out visual tools for meeting participants to help them know when their recording equipment was failing. The team also discussed collecting additional information, like laughter and breath data as well as meeting notes."], "input": "PhD E: Yeah .\nProfessor B: Um , so . If we can't , we can't . But uh we 're gonna try to make this an abbreviated meeting cuz the {disfmarker} the next {disfmarker} next occupants were pushing for it , so . Um . So . Agenda is {disfmarker} according to this , is transcription status , DARPA demos XML tools , disks , backups , et cetera and\nGrad H: Does anyone have anything to {pause} add to the agenda ?\nProfessor B: OK . Should we just go in order ? Transcription status ? Who 's {disfmarker} that 's probably you .\nPostdoc A: I can do that quickly . Um I hired several more transcribers , They 're making great progress .\nProfessor B: Seven ?\nPostdoc A: Seve - several , several .\nProfessor B: Oh .\nPostdoc A: And uh {disfmarker} and uh , uh I 've been uh finishing up the uh double checking . I hoped to have had that done by today but it 's gonna take one more week .\nGrad H: Um\nPhD D: I g\nGrad H: as a somewhat segue into the next topic , um could I get a hold of uh the data even if it 's not really corrected yet just so I can get the data formats and make sure the information retrieval stuff is working ?\nPostdoc A: Certainly . Yeah I mean , it 's in the same place it 's been .\nGrad H: So can you just {disfmarker} Oh , it is .\nPostdoc A: Uh - huh . No change .\nGrad H: OK . Just {disfmarker} So , \" transcripts \" is the sub - directory ?\nPostdoc A: Uh {disfmarker} Yes . Uh - huh .\nGrad H: OK . So I 'll {disfmarker} I 'll probably just make some copies of those rather than use the ones that are there .\nPostdoc A: OK .\nGrad H: Um and then just {disfmarker} we 'll have to remember to delete them once the corrections are made .\nPostdoc A: OK .\nProfessor B: OK , wh\nPhD D: I also got anot a short remark to the transcription . I 've uh just processed the first five EDU meetings and they are chunked up so they would {disfmarker} they probably can be sent to IBM whenever they want them .\nGrad C: Cool .\nPhD F: Well the second one of those\nPhD D: Yep . It 's already at IBM ,\nPhD F: is already at IBM .\nPhD D: but the other ones {disfmarker}\nPhD F: That 's the one that {pause} we 're waiting to hear from them on .\nPhD D: Yeah . Yeah .\nPostdoc A: OK .\nPhD F: Yeah .\nPostdoc A: These are separate from the ones that {disfmarker}\nPhD F: As soon as {disfmarker}\nPostdoc A: I mean , these are {disfmarker}\nPhD F: They 're the IBM set .\nPhD D: Yep .\nGrad H: It 's this one .\nPostdoc A: Excellent . Good .\nPhD F: Yeah . And so as soon as we hear from Brian that this one is OK\nGrad H: Is my mike on ? Yeah .\nPhD F: and we get the transcript back and we find out that hopefully there are no problems matching up the transcript with what we gave them , then uh we 'll be ready to go and we 'll just send them the next four as a big batch ,\nPostdoc A: Excellent .\nPhD F: and let them work on that .\nGrad H: And so we 're doing those as disjoint from the ones we 're transcribing here ?\nPhD F: Yes , exactly .\nGrad H: OK , good .\nPhD F: We 're sort of doing things in parallel , that way we can get as much done a at once .\nGrad H: Yeah , I think that 's the right way to do it ,\nPhD F: Yeah .\nGrad H: especially for the information retrieval stuff . Anything else on transcription status ?\nPostdoc A: Hm - mmm .\nGrad H: OK .\nProfessor B: DARPA demos , we had the submeeting the other day .\nGrad H: Right , which uh {disfmarker} So I 've been working on using the THISL tools to do information retrieval on meeting data and the THISL tools are {disfmarker} there 're two sets , there 's a back - end and a front - end , so the front - end is the user interface and the back - end is the indexing tool and the querying tool . And so I 've written some tools to convert everything into the right for file formats . And the command line version of the indexing and the querying is now working . So at least on the one meeting that I had the transcript for uh conveniently you can now do information retrieval on it , do {disfmarker} type in a {disfmarker} a string and get back a list of start - end times for the meeting ,\nPhD F: What {disfmarker} what kind of uh {disfmarker} what does that look like ? The string that you type in .\nGrad H: uh of hits .\nPhD F: What are you {disfmarker} are you {disfmarker} are they keywords , or are they {disfmarker} ?\nGrad H: Keywords .\nPhD F: OK . I see .\nGrad H: Right ? And so {disfmarker} and then it munges it to pass it to the THISL IR which uses an SGML - like format for everything .\nPhD F: I see .\nProfessor B: And then does it play something back or that 's something you 're having to program ?\nGrad H: Um , right now , I have a tool that will do that on a command line using our standard tools ,\nProfessor B: Yeah .\nGrad H: but my intention is to do a prettier user interface based either {disfmarker} So {disfmarker} so that 's the other thing I wanted to discuss , is well what should we do for the user interface ? We have two tools that have already been written . Um the SoftSound guys did a web - based one ,\nProfessor B: Mm - hmm .\nGrad H: um , which I haven't used , haven't looked at . Dan says it 's pretty good\nProfessor B: Mm - hmm .\nGrad H: but it does mean you need to be running a web server .\nProfessor B: Mm - hmm .\nGrad H: And so it {disfmarker} it 's pretty big and complex . Uh and it would be difficult to port to Windows because it means porting the web server to Windows .\nProfessor B: Mm - hmm .\nGrad H: Uh the other option is Dan did the Tcl - TK THISL GUI front - end for Broadcast News\nProfessor B: Yeah .\nGrad H: which I think looks great . I think that 's a nice demo . Um and that would be much easier to port to Windows . And so I think that 's the way we should go .\nPostdoc A: I {disfmarker} Can I ask a question ? So um as it stands within the {disfmarker} the Channeltrans interface , it 's possible to do a find and a play .\nGrad H: Mm - hmm .\nPostdoc A: You can find a searched string and play . So e Are you {disfmarker} So you 're adding like um , I don't know , uh are they fuzzy matches or are they {pause} uh {disfmarker} ?\nGrad H: It 's a sort of standard , text - retrieval - based {disfmarker} So it 's uh term frequency , inverse document frequency scoring .\nPostdoc A: OK .\nGrad H: Um and then there are all sorts of metrics for spacing how far apart they have to be and things like that . So it {disfmarker} it 's\nPostdoc A: It 's a lot more sophisticated than the uh the basically Windows - based {disfmarker}\nGrad H: i it 's like doing a Google query or anyth anything else like that .\nPostdoc A: OK .\nGrad H: So i it uses {disfmarker} So it pr produces an index ahead of time so you don't {disfmarker} you 're not doing a linear search through all the documents . Cuz you can imagine if {disfmarker} with {disfmarker} if we have the sixty hours ' worth you do {disfmarker} wouldn't wanna do a search .\nPostdoc A: Hm - mmm . Good .\nGrad H: Um you have to do preindexing and so that {disfmarker} these tools do all that . And so the work to get the front - end to work would be porting it {disfmarker} well {disfmarker} uh to get it to work on the UNIX systems , our side is just rewriting them and modifying them to work for meetings .\nProfessor B: Mm - hmm .\nGrad H: So that it understands that they 're different speakers and that it 's one big audio file instead of a bunch of little ones and just sorta things like that .\nProfessor B: Mm - hmm .\nPhD G: Mm - hmm .\nPhD F: So what does the user see as the result of the query ?\nGrad H: On which tool ?\nPhD F: THISL .\nGrad H: The THISL GUI tool which is the one that Dan wrote , Tcl - TK\nPhD F: Yeah .\nGrad H: um you type in a query and then you get back a list of hits and you can type on them and listen to them . Click on them rather {comment} with a mouse .\nPhD F: Ah .\nProfessor B: Mmm\nPhD F: So if you typed in \" small heads \" or something you could\nGrad H: Right , you 'd get {disfmarker}\nPhD F: get back a uh uh {comment} something that would let you click and listen to some audio where that phrase had occurred\nGrad H: something {disfmarker} You {disfmarker} you 'd get to listen to \" beep \" .\nPhD F: or some\nProfessor B: That was a really good look . It 's too bad that that couldn't {vocalsound} come into the {disfmarker}\nGrad H: You couldn't get a video .\nPhD G: Guess who I practice on ?\nPostdoc A: At some point we 're gonna have to say what that private joke is , that keeps coming up .\nProfessor B: Yeah . And then again , maybe not . So , {vocalsound} uh {disfmarker} Yeah , that soun that sounds reasonable . Yeah , it loo it {disfmarker} my {disfmarker} my recollection of it is it 's {disfmarker} it 's a pretty reasonable uh demo sort of format .\nGrad H: Right .\nPhD F: Yeah that sounds good .\nGrad H: And so I think there 'd be minimal effort to get it to work , minimally\nPhD F: That sounds really neat .\nGrad H: and then we 'd wanna add things like query by speaker and by meeting and all that sort of stuff . Um Dave Gelbart expressed some interest in working on that so I 'll work with him on it . And it {disfmarker} it 's looking pretty good , you know , the fact that I got the query system working . So if we wanna just do a video - based one I think that 'll be easy .\nProfessor B: Mm - hmm .\nGrad H: If we wanna get it to Windows it 's gonna be a little more work because the THISL IR , the information retrieval tool 's {disfmarker} um , I had difficulty just compiling them on Solaris .\nProfessor B: Mm - hmm .\nGrad H: So getting them to compile on Windows might be challenging .\nProfessor B: Mm - hmm .\nPhD F: But you were saying that {disfmarker} that the uh {disfmarker} that there 's that set of tools , uh , Cygnus tools , that {disfmarker}\nGrad H: So . It certainly helps .\nPhD F: Uh - huh .\nGrad H: Um , I mean without those I wouldn't even attempt it .\nProfessor B: Mm - hmm .\nPhD F: Yeah .\nGrad H: But what those {disfmarker} they {disfmarker} what those do is provide sort of a BSD compatibility layer ,\nProfessor B: Mm - hmm .\nGrad H: so that the normal UNIX function calls all work .\nProfessor B: Mm - hmm .\nPhD F: And you have to have all the o\nGrad H: Um , But the problem is that {disfmarker} that the THISL tools didn't use anything like Autoconf and so you have the normal porting problems of different header files and th some things are defined and some things aren't and uh different compiler work - arounds and so on . So the fact that um it took me a day to get it c to compile under Solaris means it 's probably gonna take me s significantly more than that to get it to compile under Windows .\nProfessor B: How about having it run under free BSD ?\nPhD E: Well what you need {disfmarker}\nGrad H: Free BSD would probably be easier .\nPhD E: All you need to do is say to Dan \" gee it would be nice if this worked under Autoconf \" and it 'll be done in a day .\nGrad H: That 's true .\nPhD D: Uh {disfmarker}\nPhD E: Right ?\nGrad H: Actually you know I should check because he did port it to SPRACHcore\nPhD E: Right .\nGrad H: so he might have done that already .\nPhD E: I {disfmarker} I {disfmarker} I wouldn't be surprised .\nProfessor B: So {disfmarker}\nGrad H: I 'll check at that {disfmarker}\nProfessor B: But it would {disfmarker} what would serve {disfmarker} would serve both purposes , is if you contact him and ask him if he 's already done it .\nPhD E: What I {disfmarker}\nPhD F: How does it play ?\nGrad H: Yeah , right .\nProfessor B: If he has then you learn , if he hasn't then he 'll do it .\nGrad H: Right .\nPostdoc A: Wow .\nPhD F: I hope he never listens to these meetings .\nGrad H: That 's right . So , and I 've been corresponding with Dan and also with uh uh , SoftSound guy , uh {disfmarker}\nPostdoc A: It 's amazing .\nProfessor B: Yeah .\nGrad H: Blanking on his name .\nProfessor B: Tony Robinson ?\nPhD F: Tony Robinson ?\nGrad H: Do I mean Tony ? I guess I do .\nProfessor B: Yeah .\nPhD E: James Christie .\nGrad H: Or S or Steve Renals .\nProfessor B: Steve Renal - Steve Renals .\nGrad H: Which one do I mean ?\nPhD E: Steve Renals is not SoftSound , is he ?\nProfessor B: No .\nGrad H: My brain is not working ,\nProfessor B: OK .\nGrad H: I don't remember who I 've been corresponding with .\nPhD E: Steve wro i it 's Ste - Steve Renals wrote THISL IR .\nGrad H: Then it 's Steve Renals .\nProfessor B: Oh , OK .\nPhD E: OK .\nGrad H: So uh just getting documentation and uh and f and formats ,\nProfessor B: Yeah .\nGrad H: so that 's all going pretty well ,\nProfessor B: Assuming we 're {disfmarker}\nPhD E: Right .\nPhD F: What about issues of playing sound files @ @ between the two platforms ?\nGrad H: I think we 'll be OK with that . Um we have {disfmarker} Well , that 's a good point too .\nPhD E: Here 's a {disfmarker} here 's a crazy idea {pause} actually .\nGrad H: I don't know .\nPhD E: Why don't you try and merge {pause} Transcriber {pause} and THISL IR ? They 're both Tcl interfaces .\nGrad H: Well this is one of the reasons {disfmarker} This is the {disfmarker} one of the reasons that I 'm gonna have uh Dave Gelbart {disfmarker} Gelbart {disfmarker} Having him volunteer to work on it is a really good thing because he 's worked on the Transcriber stuff\nPhD E: Right .\nGrad H: and he 's more familiar with Tcl - TK than I am .\nPhD E: And then you get {disfmarker} they {disfmarker} then you get the Windows media playing for free .\nGrad H: Well that 's Snack , not {disfmarker} not Transcriber .\nPhD E: Right . But the point is that the Transcriber uses Snack and then you can {disfmarker} but you can use a {disfmarker} a lot of the same functionality and it 's {disfmarker}\nGrad H: Yeah , yeah , I mean , I {disfmarker} I think THISL {disfmarker} THISL GUI probably uses Snack . And so my intention was just to base it on that .\nPhD E: Yeah . Well my thought was is that it would be nice {disfmarker} it would be nice to have the running transcripts um eh you know , from speaker to speaker .\nGrad H: And if it doesn't {disfmarker}\nPhD E: Right ? Do you have {disfmarker} you have , you know , a speaker mark here and a speaker mark here ?\nGrad H: Right , we 'll have to figure out a user interface for that , so .\nPhD E: Right . Well that {disfmarker} eh my thought was if you had like Multitrans or whatever do it . Or whatever .\nGrad H: Yeah . It might be fairly difficult to get that to work in {comment} the little short segments we 'd be talking about and having the search tools and so on . We {disfmarker} we can look into it ,\nPhD E: Yeah .\nGrad H: but {disfmarker}\nProfessor B: The thing I was asking about with , um , free BSD is that it might be easier to get PowerPoint shows running in free BSD than to get this other package running in {disfmarker}\nGrad H: Yeah , I mean we have to {disfmarker} I have to sit down and try it before I make too many judgments ,\nProfessor B: Yeah .\nGrad H: so uh Um My experience with the Gnu compatibility library is really it 's just as hard and just as easy to port to any system . Right ? The Windows system isn't any harder because it {disfmarker} it looks like a BSD system .\nProfessor B: Mm - hmm .\nGrad H: It 's just , you know , just like all of them , the \" include \" files are a little different and the function calls are a little different .\nProfessor B: Right .\nGrad H: So I {disfmarker} it might be a little easier but it 's not gonna be a lot easier .\nProfessor B: OK . So there was that demo , which was one of the main ones , then we talked about um some other stuff which would basically be um showing off the {disfmarker} the Transcriber interface itself and as you say , maybe we could even merge those in some sense , but {disfmarker} but um , uh {disfmarker} and part of that was showing off what the speech - non uh nonspeech {comment} stuff that Thilo has done {pause} s {pause} looks like .\nPhD D: Yeah .\nPostdoc A: Can I ask one more thing about THISL ? So with the IR stuff then you end up with a somewhat prioritized um {disfmarker} ?\nGrad H: Mm - hmm . Mm - hmm ,\nPostdoc A: Excellent .\nGrad H: ranked .\nPostdoc A: Excellent . Yeah .\nPhD G: So another idea I w t had just now actually for the demo was whether it might be of interest to sh to show some of the prosody uh {vocalsound} work that Don 's been doing .\nProfessor B: Mm - hmm .\nPhD G: Um actually show some of the features and then show for instance a task like finding sentence boundaries or finding turn boundaries . Um , you know , you can show that graphically , sort of what the features are doing . It , you know , it doesn't work great but it 's definitely giving us something .\nProfessor B: Well I think at {disfmarker} at the very least we 're gonna want something illustrative with that\nPhD G: I don't know if that would be of interest or not .\nProfessor B: cuz I 'm gonna want to talk about it and so i if there 's something that shows it graphically it 's much better than me just having a bullet point\nPhD G: Yeah .\nProfessor B: pointing at something I don't know much about ,\nPhD G: I mean , you 're looking at this now {disfmarker}\nProfessor B: so .\nPhD G: Are you looking at Waves or Matlab ?\nGrad C: Um yeah I 'm starting to and um {disfmarker} Yeah we can probably find some examples of different type of prosodic events going on .\nPhD G: Yeah def\nProfessor B: S so when we here were having this demo meeting , what we 're sort of coming up with is that we wanna have all these pieces together , to first order , by the end of the month\nPhD G: I\nProfessor B: and then that 'll give us a week or so .\nGrad C: Ooo . The end of {disfmarker}\nPhD G: Oh , the end of this month or next month ? Oh , you mean like today ?\nGrad H: This month .\nProfessor B: Ju\nPhD G: Oh .\nProfessor B: June . June . June .\nPhD G: Next month .\nGrad H: Oh sorry , next month .\nGrad C: Yeah .\nPhD G: Sorry .\nGrad H: Today isn't June first ,\nPhD F: There 's another one .\nGrad H: is it .\nProfessor B: Uh {disfmarker} that 'll {disfmarker} that 'll give us {disfmarker} that 'll give us a week or so to uh {disfmarker} to port things over to my laptop and make sure that works ,\nPhD E: Exactly .\nPhD G: Sorry .\nProfessor B: yeah .\nPhD G: I think , I mean eh where {disfmarker}\nGrad C: Yeah , I mean I 'll be here .\nPhD G: Yeah if d if Don can sort of talk to whoever 's {disfmarker}\nProfessor B: Yeah .\nPhD G: cuz we 're doing this anyway as part of our {disfmarker} you know , the research , visualizing what these features are doing\nProfessor B: Yeah .\nPhD G: and so either {disfmarker} it might not be integrated but it {disfmarker} it could potentially be in it .\nProfessor B: Yeah . Well , this is to an audience of researchers\nPhD G: Could find some .\nProfessor B: so I mean , you know , to let s the goal is to let them know what it is we 're doing .\nPhD G: I mean it 's different .\nProfessor B: So that 's {disfmarker}\nPhD G: I don't think anyone has done this on meeting data so it might be neat , you know .\nProfessor B: Yeah . Good . Done with that . XML tools ?\nGrad H: Um . So I 've been doing a bunch of XML tools where you {disfmarker} we 're sort of moving to XML as the general format for everything and I think that 's definitely the right way to go because there are a lot of tools that let you do extraction and reformatting of XML tools . Um . So yet again we should probably meet to talk about transcription formats in XML because I 'm not particularly happy with what we have now . I mean it works with Transcriber but it {disfmarker} it 's a pain to use it in other tools uh because it doesn't mark start and end .\nPhD F: Start and end of each {disfmarker} ?\nPhD D: Yeah .\nGrad H: Uh {disfmarker} Utterance .\nPhD F: Utterance . Just marks {disfmarker} ?\nGrad H: So it 's implicit in {disfmarker} in there\nPhD F: Yeah .\nGrad H: but you have to do a lot of processing to get it .\nPhD F: Right . Right .\nGrad H: And so {disfmarker} and also I 'd like to do the indirect time line business . Um but regardless , I mean , w that 's something that you , me , and Jane can talk about later . Um , but I 've installed XML tools of various sorts in various languages and so if people are interested in doing {disfmarker} extracting any information from any of these files , either uh information on users because the user database is that way {disfmarker} I 'm converting the Key files to XML so that you can extract m uh various inf uh sorted information on individual meetings\nGrad C: Cool .\nPhD D: Yeah .\nGrad H: and then also the transcripts . And so l just let me know there {disfmarker} it 's mostly Java and Perl but we can get other languages too if {disfmarker} if that 's desirable .\nPhD G: Oh , quick question on that . Is {disfmarker} do we have the {disfmarker} {vocalsound} the seat information ? In {disfmarker} in the Key files now ?\nPostdoc A: Mm - hmm .\nGrad H: The seat information is on the Key files for the ones which\nPostdoc A: Ah .\nPhD G: Oh in {disfmarker} For the new one\nGrad H: it 's been recorded ,\nPhD G: OK .\nGrad H: yeah .\nProfessor B: Seat ?\nPhD G: Great . Sea - yeah .\nGrad H: Where {disfmarker} where you 're sitting .\nProfessor B: Oh ! Not {disfmarker} not the quality or anything . No .\nPhD D: n\nGrad H: Right .\nProfessor B: OK . I see .\nGrad H: \" It 's pretty soft and squishy . \"\nProfessor B: Yeah . Yeah .\nPhD G: Alright .\nProfessor B: OK .\nPhD G: OK .\nGrad H: Oh , but that might just be me . Um .\nPhD G: Alright .\nProfessor B: That 's more seat information than we wanted .\nPhD G: Never mind .\nPhD E: Hmm .\nPhD G: I 'm just trying to figure out , you know , when Morgan 's voice appears on someone 's microphone are they next to him or are they across from him ?\nProfessor B: Yeah .\nGrad H: Maybe we should bleep that out .\nProfessor B: Mmm , yeah .\nPhD F: Wait a minute ,\nProfessor B: Yeah .\nPhD F: how {disfmarker} how w eh where is it in the Key file ?\nGrad H: Right . The square bracket .\nPhD G: Cuz I mean I haven't been putting it in and {disfmarker} in by {disfmarker}\nGrad H: You haven't been putting it in .\nPhD G: Right .\nPostdoc A: Well bu\nPhD G: I have not .\nGrad H: Oh , OK .\nPostdoc A: Isn't it always on the digits ?\nProfessor B: Some of these are missing .\nPhD G: And {disfmarker}\nProfessor B: Aren't they ?\nPostdoc A: Isn't it always on the digits forms ?\nProfessor B: Some fall out of {disfmarker}\nPhD G: Well it\nGrad H: Yeah so we can go back and fill them in for the ones we have .\nGrad C: Ooo .\nPhD G: I mean they 're on th right , these , but I just hadn't ever been putting it in the Key files .\nPhD F: Yeah I {disfmarker} I never {disfmarker}\nPhD G: And I don't think Chuck was either\nPhD F: I never knew we were supposed to put it in the Key file .\nPhD G: cuz {disfmarker}\nGrad H: I had told you guys about it\nPhD F: Oh really ?\nPhD G: Oh , so we 're both sorry .\nGrad H: but {disfmarker}\nPhD G: So {disfmarker}\nGrad H: I mean this is why I wanna use a g a tool to do it rather than the plain text\nPhD G: OK .\nPhD F: OK .\nGrad H: because with the plain text it 's very easy to skip those things .\nPhD G: OK .\nGrad H: So . Um if you use the Edit - key , or Key - edit {disfmarker}\nPhD D: Edit - key .\nGrad H: I think it 's Edit - key , {comment} command {disfmarker} Did I show you guys that ?\nPhD D: Yep .\nPhD F: You mentioned it ,\nGrad H: I did show it to you ,\nPhD F: yeah . Yeah .\nGrad H: but I think you both said \" no , you 'll just use text file \" .\nPhD F: Text .\nGrad H: Um it has it in there , a place to fill it in .\nPhD G: OK .\nPhD F: OK .\nGrad H: Yeah , and so if you don't fill it in , you 're not gonna get it in the meetings .\nPhD G: So if {disfmarker} Right . Well I {disfmarker} I just realized I hadn't been doing it\nGrad H: So .\nPhD G: and probably {disfmarker} So {disfmarker}\nGrad H: Yep .\nGrad C: u\nGrad H: Yeah and then the other thing also that Thilo noticed is , on the microphone , on channel zero it says hand - held mike or Crown mike ,\nPhD G: Yeah . Right .\nGrad H: you actually have to say which one .\nPhD G: I know {disfmarker} Yeah , I usually delete the {disfmarker}\nGrad H: So .\nPhD F: Oh ! OK . I didn't do that either .\nPhD G: I don't ,\nPhD D: Yeah .\nPhD G: maybe I forgot to d\nPhD F: Takes me no time at all to edit these .\nPhD G: But it 's almost {disfmarker} Yeah .\nGrad H: Yeah that 's cuz you kn\nPhD F: I 'm not doing anything .\nGrad H: I {disfmarker} I know why .\nPhD G: And I was {disfmarker} I was looking at Chuck 's , like , \" oh what did Chuck do , OK I 'll do that \" . So .\nGrad H: And then uh also in a couple of places instead of filling the participants under \" participants \" they were filled in under \" description \" .\nProfessor B: Ah , OK .\nPhD G: Uh {disfmarker}\nGrad H: And so that 's also a problem . So anyway .\nPhD G: We will do better .\nGrad H: That 's it . Oh uh also I 'm working on another version of this tool , the {disfmarker} the one that shows up here , {comment} that will flash yellow if the mike isn't connected . And it 's not quite ready to go yet because um it 's hard to tell whether the mike 's connected or not because the best quality ones , the Crown ones , {comment} are about the same level if they 're off and no one 's o off or if they 're on and no one 's talking .\nGrad C: Huh .\nGrad H: Um these {disfmarker} these ones , they are much easier , there 's a bigger difference . So I 'm working on that and it {disfmarker} it sorta works and so eventually we will change to that and then you 'll be able to see graphically if your mike is dropping in or out .\nGrad C: Will that also include like batteries dying ? Just a any time the mike 's putting out zeros basically .\nGrad H: Yep . Yep . Yep .\nPhD F: But with the screensaver kicking in , it {disfmarker}\nPhD D: But\nGrad H: Now {disfmarker}\nPhD D: y yeah .\nGrad C: Yeah .\nPhD D: Yeah .\nGrad H: Well I 'll turn off the screensaver too .\nGrad C: Oops . Speaking of which .\nGrad H: Um the other thing is as I 've said before , it is actually on the thing . There 's a little level meter but of course no one ever pays attention to it . So I think having it on the screen is more easy to notice .\nPostdoc A: It would be nice if {disfmarker} if these had little light indicators , little L E Ds for {disfmarker}\nGrad H: Uh buzzer .\nPostdoc A: Yeah , a buzzer .\nGrad H: \" Bamp , bamp ! \"\nProfessor B: Small shocks\nPostdoc A: Yeah . Actually {disfmarker}\nProfessor B: administered to the {disfmarker} OK . Oh {disfmarker}\nGrad H: OK , disk backup , et cetera ? Um I spoke with Dave Johnson about putting all the Meeting Recorder stuff on non - backed - up disk to save the overhead of backup and he pretty much said \" yeah , you could do that if you want \" but he thought it was a bad idea . In fact what he said is doing the manual one , {comment} doing uh NW archive to copy it {comment} is a good idea and we should do that and have it backed up . He w he 's a firm believer in {disfmarker} in lots of different modalities of backup . I mean , his point was well taken . This data cannot be recovered .\nPhD G: Yeah .\nGrad H: And so if a mistake is made and we lose the backup we should have the archive and if then a mistake is made and we lose the archive we should have the backup .\nProfessor B: Well I guess it is true that even with something that 's backed up it 's not gonna {disfmarker} if it 's stationary it 's not going to go through the increment it 's not gonna burden things in the incremental backups .\nGrad H: Just {disfmarker} just the monthly full .\nPostdoc A: Hmm .\nProfessor B: Yeah , so the monthly full will be a bear but {disfmarker}\nGrad H: Yeah . But he said that {disfmarker} that we sh shouldn't worry too much about that , that we 're getting a new backup system and we 're far enough away from saturation on full backups that it 's w probably OK .\nProfessor B: Really ?\nGrad H: And uh , so the only issue here is the timing between getting more disks and uh recording meetings .\nProfessor B: So I guess the idea is that we would be reserving the non - backed - up space for things that took less than twenty - four hours to recreate or something like that , right ?\nGrad H: Things that are recreatable easily and also {disfmarker} Yeah , basically things that are recreatable .\nProfessor B: Yeah . Yeah .\nGrad H: The expanded files and things like that .\nProfessor B: OK .\nGrad H: They take up a lot more room anyway .\nProfessor B: Yeah .\nGrad H: Uh but we do need more disk .\nProfessor B: So we can get more disk . Yeah . So .\nGrad H: Yeah . And I {disfmarker} I think I agree with him . I mean his point was well taken that if we lose one of these we cannot get it back .\nProfessor B: OK .\nGrad H: I don't think there was any other et cetera there .\nProfessor B: Well I was allowing someone else to come up with something related that they had uh {disfmarker}\nPhD E: I thought you guys were gonna burn C Ds ?\nGrad H: Um unfortunately {disfmarker} we could burn C Ds but first of all it 's a pain .\nPhD E: Yeah .\nGrad H: Because you have to copy it down to the PC and then burn it and that 's a multi - step procedure . And second of all the {disfmarker} the write - once burners as opposed to a professional press don't last .\nPhD E: Yeah .\nGrad H: So I think burning them for distribution is fine but burning them for backup is not a good idea .\nPhD E: I see . OK .\nGrad H: Cuz th they {disfmarker} they fail after a couple years .\nPhD E: Alright .\nPostdoc A: I do have uh uh {disfmarker} It 's a different topic . Can I add one top topic ? We have time ? I wanted to ask , I know that uh that Thilo you were , um , bringing the Channeltrans interface onto the Windows machine ? And I wanted to know is th\nPhD D: Yeah it 's {disfmarker} it {disfmarker} Basically it 's done ,\nPostdoc A: It 's all done ? That 's g wonderful . Great .\nPhD D: yeah . Yeah .\nGrad H: Yes , since Tcl - TK runs on it , basically things 'll just work .\nPhD D: Yeah it {disfmarker} Yeah , it was just a problem with the Snack version and the Transcriber version but it 's solved .\nPostdoc A: Does {disfmarker} and that {disfmarker} does that mean , I {disfmarker}\nPhD D: So .\nPostdoc A: maybe I should know this but I don't . Does this mean that the {disfmarker} that this could be por uh ported to a Think - Pad note or some other type of uh {disfmarker}\nPhD D: Yeah , basically uh I did install it on my laptop and yeah\nPostdoc A: Wonderful .\nPhD D: it worked .\nPostdoc A: Wonderful .\nProfessor B: Hmm ! Good . CrossPads ? CrossPads ?\nGrad H: Uh got an email from uh James Landay who basically said \" if you 're not using them , could you return them ? \" So he said he doesn't need them , he just periodically w at the end of each term sends out email to everyone who was recorded as having them and asks them if they 're still using them .\nProfessor B: So we 've never used them .\nPostdoc A: We used them once .\nProfessor B: Once ?\nGrad H: We {disfmarker} we used them a couple times ,\nPostdoc A: Mm - hmm . Couple times .\nPhD F: Them ? There 's more than one ?\nGrad H: but {disfmarker}\nPostdoc A: Yeah .\nProfessor B: i\nGrad H: Yeah , we have two . Um .\nProfessor B: But {disfmarker}\nGrad H: My opinion on it is , first , I never take notes anyway so I 'm not gonna use it , um and second , it 's another level of infrastructure that we have to deal with .\nPostdoc A: And I have {disfmarker} uh so my {disfmarker} my feeling on it is that I think in principle it 's a really nice idea , and you have the time tags which makes it better tha than just taking ra raw notes . On the other hand , I {disfmarker} the down side for me was that I think the pen is really noisy . So you have ka kaplunk , kaplunk , kaplunk . And I {disfmarker} and I don't know if it 's audible on the {disfmarker} but I {disfmarker} I sort of thought that was a disadvantage . I do take notes , I mean , I could be taking notes on these things and I guess the plus with the CrossPads would be the time markings but {disfmarker} I don't know .\nPhD D: Uh , what is a CrossPad ?\nProfessor B: So it 's {disfmarker} it 's um {disfmarker} it 's a regular pad , just a regular pad of paper but there 's this pen which indicates position .\nGrad C: Thank you .\nProfessor B: And so you have time and position stuff stored\nPhD D: OK .\nProfessor B: so that you can {disfmarker} you have a record of whatever it is you 've written .\nPhD D: OK .\nGrad H: And then you can download it and they have OCR and searching and all sorts of things .\nPhD D: OK . OK .\nGrad H: So i if you take notes it 's a great little device .\nPostdoc A: Could {disfmarker} Mm - hmm .\nGrad H: But I don't take notes ,\nProfessor B: And one of the reasons that it was brought up originally was because uh we were interested in {disfmarker} in higher - level things ,\nGrad H: so .\nProfessor B: not just the , you know , microphone stuff but also summarization and so forth and the question is if you were going to go to some gold standard of what wa what was it that happened in the meeting you know , where would it come from ? And um I think that was one of the things ,\nPhD D: Yeah .\nPhD G: Yeah .\nGrad H: Yep .\nProfessor B: right ? And so the {disfmarker} it seemed like a neat idea . We 'll have a {disfmarker} you know , have a scribe , have somebody uh take good notes and then that 's part of the record of the meeting . And then we did it once or twice and we sort of {disfmarker}\nGrad H: Yep , and then just sort of died out .\nProfessor B: probably chose the wrong scribe but it was {disfmarker} {vocalsound} It 's uh {disfmarker}\nPhD G: I mean {disfmarker}\nGrad H: Yeah that 's right .\nPostdoc A: Well I did it one time\nGrad H: Yep .\nPostdoc A: but um {disfmarker}\nProfessor B: Yeah .\nPostdoc A: u but I guess the {disfmarker} the other thing I 'm thinking is if we wanted that kind of thing I wonder if we 'd lose that much by having someone be a scribe by listening to the tape , to the recording afterwards and taking notes in some other interface .\nPhD F: I mean we 're transcribing it anyways , why do we need notes ?\nPostdoc A: Oh it 's la it 's useful ,\nGrad H: Because that 's summary .\nPostdoc A: have a summary and high points .\nProfessor B: Summary .\nPhD G: I think {disfmarker} there 's also {disfmarker} there 's this use that {disfmarker}\nPhD F: Summarize it from the transcription .\nPhD G: the {disfmarker} Well , what if you 're sitting there and you just wanna make an X and you don't wanna take notes and you 're {disfmarker} you just wanna\nPhD F: Doodle .\nPhD G: get the summary of the transcript from this time location like {disfmarker} you know , and {disfmarker} and then while you 're bored you don't do anything and once in a while , maybe there 's a joke and you put a X and {disfmarker} {comment} But {disfmarker} in {disfmarker} in other words you can use that just to highlight times in a very simple way . Also with {disfmarker} I was thinking and I know Morgan disagrees with me on this but suppose you have a group in here and you wanna let them note whenever they think there might be something later that they might not wanna distribute in terms of content , they could just sort of make an X near that point or a question mark that sort of alerts them that when they get the transcript back they c could get some red flags in that transcript region and they can then look at it . So . I know we haven't been using it but I w I can imagine it being useful just for sort of marking time periods\nGrad H: Right .\nPhD G: which you then get back in a transcript\nPostdoc A: Well .\nProfessor B: I guess {disfmarker} so , you know , what {disfmarker} what makes one think i is maybe we should actually schedule some periods where people go over something later\nPhD G: so .\nProfessor B: and {disfmarker} and {disfmarker} and put some kind of summary or something uh you know , some {disfmarker} there 'd be some scribe who would actually listen , w who 'd agreed to actually listen to the whole thing , not transcribe it , but just sort of write down things that struck them as important . But {disfmarker} then you don't {disfmarker} you don't have the time reference uh that you 'd have if you had it live .\nPhD G: Right . And you don't have a lot of other cues that might be useful ,\nProfessor B: Yeah .\nPhD F: How do you synchronize the time in the CrossPad and the time of the recording ?\nPhD G: so .\nGrad H: I mean that was one of the issues we talked about originally and that that 's w part of the difficulty is that we need an infrastructure for using the time {disfmarker} the CrossPads and so that means synchronizing the time {disfmarker}\nPhD G: \nPostdoc A: Mm - hmm .\nGrad H: You know you want it pretty close and there 's a fair amount of skew because it 's a hand - held unit with a battery\nPostdoc A: Well when {disfmarker} when I d\nGrad H: and so you {disfmarker}\nPostdoc A: OK .\nGrad H: so you have to synchronize at the beginning of each meeting all the pads that are being used , so that it 's synchronized with the time on that and then you have to download to an application , and then you have to figure out what the data formats are and convert it over if you wanna do anything with this information .\nPostdoc A: w Mm - hmm .\nPhD E: Why {disfmarker}\nGrad H: And so there 's a lot of infrastructure which\nPostdoc A: There is an alternative .\nGrad H: unless someone {disfmarker}\nPostdoc A: There is an alternative , I mean , it 's still , there 's uh {disfmarker} you know , your point stands about there be {disfmarker} needing to be an infrastructure , but it doesn't have to be synchronized with the little clock 's timer on it . You c I mean , I {disfmarker} when I {disfmarker} when I did it I synchronized it by voice , by whispering \" one , two , three , four \" onto the microphone\nGrad H: Hmm .\nPostdoc A: and uh , you know .\nGrad H: Well , but then there 's the infrastructure at the other end\nPhD E: Right .\nGrad H: which someone has to listen to that and find that point ,\nPostdoc A: Yeah , it 's transcribed . It 's in the transcript .\nGrad H: and then mark it .\nPostdoc A: Yeah .\nGrad H: So .\nPostdoc A: Well it 's in the transcript .\nPhD G: Well , could we keep one of these things for another year ? Would h I mean is there a big cau\nGrad H: We can keep all {disfmarker} both of them for the whole whole year .\nPhD G: just {disfmarker} just in case we {disfmarker}\nGrad H: I mean , it 's just {disfmarker}\nPhD G: even maybe some of the transcribers who might be wanting to annotate uh f just there 's a bunch of things that might be neat to do but I {disfmarker} it might not be the case that we can actually synchronize them and then do all the infrastructure but we could at least try it out .\nProfessor B: Well {disfmarker} one thing that we might try um is on some set of meetings , some collection of meetings , maybe EDU is the right one or maybe something else , we {disfmarker} we get somebody to buy into the idea of doing this as part of the task . I mean ,\nPhD G: Right .\nProfessor B: uh part of the reason {disfmarker} I think part of the reason that Adam was so interested in uh the SpeechCorder sort of f idea from the beginning is he said from the beginning he hated taking notes and {disfmarker}\nGrad H: Yep .\nProfessor B: and so forth so and {disfmarker} and Jane is more into it but eh uh you know I don't know if you wanna really do {disfmarker} do this all the time so I think the thing is to {disfmarker} to get someone to actually buy into it and have at least some series of meetings where we do it . Um {disfmarker} and if so , it 's probably worth having one . The p the {disfmarker} the problem with the {disfmarker} the more extended view , all these other you know with uh quibbling about particular applications of it is that it looks like it 's hard to get people to um uh routinely use it , I mean it just hasn't happened anyway . But maybe if we can get a person to {disfmarker}\nPhD G: Yeah I don't think it has to be part of a what everybody does in a meeting but it might be a useful , neat part of the project that we can , you know , show off as a mechanism for synchronizing events in time that happen that you just wanna make a note of , like what Jane was talking about with some later browsing , just {disfmarker} just as a convenience , even if it 's not a full - blown note taking substitute .\nPhD E: Well if you wanted to do that maybe the right architecture for it is to get a PDA with a wireless card . And {disfmarker} and that way you can synchronize very easily with the {disfmarker} the {disfmarker} the meeting because you 'll be synchroni you can synchronize with the {disfmarker} the Linux server and uh {disfmarker}\nPhD G: So what kind of input would you be {disfmarker} ?\nPhD E: so {disfmarker} so , I mean , if you 're not worried about {disfmarker}\nGrad H: Buttons .\nPhD G: You 'd just be pressing like a {disfmarker} a {disfmarker}\nPhD E: Well {disfmarker} well you have a PDA and may and you could have the same sort of X interface or whatever , I mean , you 'd have to do a little eh a little bit of coding to do it .\nPhD G: Mm - hmm .\nPhD E: But you could imagine ,\nPhD G: Yeah , that be good .\nPhD E: I mean , if {disfmarker} if all you really wanted was {disfmarker} you didn't want this secondary note - taking channel but just sort of being able to use m markers of some sort , a PDA with a l a wireless card would be the {disfmarker} probably the right way to go . I mean even buttons you could do , sort of , I mean , as you said .\nGrad H: I mean for what {disfmarker} what you 've been describing buttons would be even more convenient than anything else ,\nPhD G: M right .\nPhD E: Right .\nPhD G: That would be fine too .\nGrad H: right ? You have the {disfmarker}\nPhD G: I mean , I don't have , you know , grandiose ideas in mind but I 'm just sort of thinking well we 've {disfmarker} we 're getting into the next year now and we have a lot of these things worked out at {disfmarker} in terms of the speech maybe somebody will be interested in this and {disfmarker}\nPostdoc A: I like this PDA idea . Yeah .\nProfessor B: Yeah , I do like the idea of having a couple buttons\nPhD G: Yeah .\nGrad H: Well I 'm sure there would {disfmarker}\nPostdoc A: Yeah .\nProfessor B: where like one {disfmarker} one button was \" uh - oh \" and then another button was \" that 's great \" and another button \" that 's f \"\nPhD G: Or like this is my \" I 'm supposed to do this \" kind of button ,\nPostdoc A: Yeah .\nPhD G: like \" I better remember to {disfmarker} \"\nGrad H: Action item .\nPhD G: Yeah something like that or {disfmarker}\nPostdoc A: And then {disfmarker}\nGrad H: I mean I think the CrossPad idea is a good one .\nPostdoc A: Uh - huh .\nGrad H: It 's just a question of getting people to use it and getting the infrastructure set up in such a way that it 's not a lot of extra work . I mean that 's part of the reason why it hasn't happened is that it 's been a lot of extra work for me\nPhD G: Yeah .\nProfessor B: Right .\nPostdoc A: Well , and not just for you .\nGrad H: and {disfmarker}\nPostdoc A: But it 's also , it has this problem of having to go from an analog to a d a digital record too ,\nPhD G: W\nPostdoc A: doesn't it ? I mean {disfmarker}\nGrad H: Well it 's digital but it 's in a format that is not particularly standard .\nPostdoc A: But I mean , say , if i if {disfmarker} if you 're writing {disfmarker} if you 're writing notes in it does {disfmarker} it {disfmarker} it can't do handwriting recognition , right ?\nProfessor B: No , no , but it 's just {disfmarker} it 's just storing the pixel informa position information ,\nPostdoc A: OK .\nProfessor B: it 's all digital .\nPostdoc A: I {disfmarker} I guess what I 'm thinking is that the PDA solution you h you have it already without needing to go from the pixelization to a {disfmarker} to a {disfmarker} I mean {disfmarker}\nProfessor B: Right . You don't have to {disfmarker}\nPhD E: The transfer function is less errorful ,\nPostdoc A: Oh , nicely put .\nProfessor B: Yeah .\nPhD E: yes .\nPhD G: Yeah , yeah .\nProfessor B: Yeah . Yeah .\nPhD G: Well it also {disfmarker} it 's maybe realistic cuz people are supposed to be bringing their P D As to the meeting eventually , right ? That 's why we have this little {disfmarker} I don't know what {disfmarker} I don't wanna cause more work for anyone but I can imagine some interesting things that you could do with it and so if we don't have to return it and we can keep it for a year {disfmarker} I don't know .\nGrad H: Well {disfmarker} w we don't {disfmarker} we certainly don't have to return it , as I said . All {disfmarker} all he said is that if you 're not using it could you return it , if you are using it feel free to keep it . The point is that we haven't used it at all and are we going to ?\nProfessor B: So we have no but {disfmarker} uh by I {disfmarker} I would suggest you return one . Because we {disfmarker} we you know , we {disfmarker} we haven't used it at all .\nPhD G: Yeah .\nGrad H: OK .\nPhD G: We c\nProfessor B: We have some aspirations of using them\nPhD G: One would probably be fine .\nProfessor B: and {disfmarker}\nPhD G: Maybe we could do like a student project , you know , maybe someone who wants to do this as their main like s project for something would be cool .\nProfessor B: Yeah .\nGrad H: Yep . I mean if we had them out and sitting on the table people might use them a little more\nProfessor B: Maybe Jeremy could sit in some meetings and press a button when there {disfmarker} when {disfmarker} when somebody laughed .\nGrad H: although there is a little {disfmarker}\nPhD G: Well , I 'm {disfmarker} yeah , that 's not a bad {disfmarker}\nProfessor B: Yeah , yeah . Yeah .\nPhD G: Jeremy 's gonna be an {disfmarker} he 's a new student starting on modeling brea breath and laughter , actually , which sounds funny but I think it should be cool ,\nProfessor B: Yeah .\nPhD G: so .\nGrad H: Sounds breathy to me .\nPhD G: OK . \" Ha - ha - ha . \"\nGrad H: Breath and lau \" ha - ha - ha - ha \" . \" Ha - ha - ha - ha . \"\nProfessor B: Well dear .\nGrad H: Um .\nProfessor B: Hmm .\nGrad H: That reminded me of something . Oh well , too late . It slipped out .\nProfessor B: OK .\nPhD G: You 're {disfmarker} you 're gonna tease me ?\nGrad H: Oh , equipment .\nPhD G: OK .\nGrad H: Ordered {disfmarker} Uh , well I 'm always gonna do that . W uh {disfmarker} {comment} We ordered uh more wireless , and so they should be coming in at some point .\nPhD G: Great .\nGrad H: And then at the same time I 'll probably rewire the room as per Jane 's suggestion so that uh the first N channels are wireless , eh are the m the close - talking and the next N are far - field .\nProfessor B: You know what he means but isn't that funny sounding ? \" We ordered more wireless . \" It 's like wires are the things so you 're wiring {disfmarker} you 're {disfmarker} you 're {disfmarker} you {disfmarker} we 're {disfmarker} we ordered more absence of the thing .\nPhD G: That 's a very philosophical statement from Morgan .\nGrad H: wired less , wired more .\nPhD G: I just {disfmarker} it 's sort of a anachronism , I mean it 's like {disfmarker} It 's great .\nProfessor B: Anyway .\nGrad H: Should we do digits ? Do we have anything else ?\nProfessor B: Yeah .\nPostdoc A: OK .\nProfessor B: I mean there 's {disfmarker} there 's all this stuff going on uh between uh Andreas and {disfmarker} and {disfmarker} and Dave and Chuck and others with various kinds of runs uh um {disfmarker} recognition runs , trying to figure things out about the features but it 's {disfmarker} it 's all sort of in process , so there 's not much to say right now . Uh why don't we start with our {disfmarker} our esteemed guest .\nPhD E: OK . Alright .\nGrad H: So just the transcript number and then the {disfmarker} then the {disfmarker}\nPhD E: This is {disfmarker} Yes , this is number two for me today .\nProfessor B: See all you have to do is go away to move way up in the {disfmarker}\nPhD E: Oh .\nPhD G: We could do simultaneous . Initiate him .\nProfessor B: We {disfmarker} we could .\nGrad H: Should we do simultaneous ?\nPhD G: Well , I 'm just thinking , are you gonna try to save the data before this next group comes in ?\nProfessor B: Yeah .\nGrad H: Yeah , absolutely .\nPhD G: Yeah , so we might wanna do it simultaneous .\nGrad H: I mean you hav sorta have to .\nProfessor B: Well OK , so let 's do one of those simultaneous ones .\nPhD G: Right , so {disfmarker} so we might n we might need to do that actually .\nProfessor B: That sounds good .\nGrad H: OK .\nPhD E: OK .\nProfessor B: Everybody ready ?\nPostdoc A: Yeah .\nProfessor B: A one .\nPhD G: You have to plug your ears , by the way uh Eric ,\nGrad H: Well I have to ,\nPhD D: You don't have to .\nPhD E: OK , alright .\nPhD G: or {disfmarker} or you start laughing .\nGrad H: I don't know about other people .\nProfessor B: OK , a one and a two and a three . OK , babble , take five .", "source": "meeting_summ", "evaluation": "rouge"}
{"instructions": ["Summarize the discussion on the mean log magnitude spectral subtraction", "What was the professor's take on the 12 second mean?", "What did Grad E think about the goal of his experiment?", "Summarize the discussion on latency in the system", "Why did the professor not like latency?", "How long was the latency?", "Summarize the meeting"], "outputs": ["The log magnitude spectral subtraction used twelve seconds from the past and future to calculate the mean. The short window did not have a big effect on the model performance, which was much desired. The silence, for the most part, had been cut out to make the model more effective. The professor added that the system was similar to caching utterances.", "The professor suggested that the model essentially improved performance after the first utterance as it had more data. There was a higher error probability for the first utterance. This issue could potentially be resolved using a second-pass system, in which the initial utterance was processed differently.", "Grad E thought that the idea of doing mean log magnitude spectral subtraction was figuring out the effect of training time on the model performance. It seemed that longer times had diminishing returns after a certain point.", "PhD D informed the team that there was additional latency in the system with spectral subtraction. The professor wanted the team to be cognizant of the latency. The team suggested a spectral whitening approach or using a probability focused approach to solve the problem.", "The professor wanted to make sure that the team does not end up in a bind. If they later had to cut latency, it would create a problem. This was his preferred conservative approach.", "The latency of the recursion was fifty milliseconds. The recursion added that much to the overall latency of the system. Though, PhD B suggested doing tasks in parallel to reduce total latency.", "The meeting began with a short introduction to Hans Guenter, who was arriving soon and would be visiting for a few weeks. The team then discussed integrating mean log magnitude spectral subtraction into the SmartKom system. It seemed, however, that lengthening the time for this task was not very effective. The team also learned more about Wiener filtering which worked well when mixed with other approaches. It was almost as effective as the best systems. The team then delved into spectral subtraction and discussed the various ways in which it could be refined. The meeting ended with comments on the additional latency that was caused by this method."], "input": "PhD A: OK , we 're going .\nPhD D: Damn .\nProfessor C: And uh Hans - uh , Hans - Guenter will be here , um , I think by next {disfmarker} next Tuesday or so .\nPhD B: Oh , OK .\nPhD D: Mm - hmm .\nProfessor C: So he 's {disfmarker} he 's going to be here for about three weeks ,\nPhD B: Oh ! That 's nice .\nPhD A: Just for a visit ?\nProfessor C: and , uh {disfmarker} Uh , we 'll see .\nPhD A: Huh .\nProfessor C: We might {disfmarker} might end up with some longer collaboration or something .\nPhD A: Cool .\nProfessor C: So he 's gonna look in on everything we 're doing\nPhD D: Mm - hmm .\nProfessor C: and give us his {disfmarker} his thoughts . And so it 'll be another {disfmarker} another good person looking at things .\nPhD B: Oh . Hmm .\nGrad E: Th - that 's his spectral subtraction group ?\nProfessor C: Yeah ,\nGrad E: Is that right ?\nProfessor C: yeah .\nGrad E: Oh , OK . So I guess I should probably talk to him a bit too ?\nProfessor C: Oh , yeah . Yeah . Yeah . No , he 'll be around for three weeks . He 's , uh , um , very , very , easygoing , easy to talk to , and , uh , very interested in everything .\nPhD A: Really nice guy .\nProfessor C: Yeah , yeah .\nPhD B: Yeah , we met him in Amsterdam .\nProfessor C: Yeah , yeah , he 's been here before .\nPhD B: Oh , OK .\nProfessor C: I mean , he 's {disfmarker} he 's {disfmarker} he 's {disfmarker} he 's {disfmarker}\nPhD A: Wh - Back when I was a grad student he was here for a , uh , uh {disfmarker} a year or {comment} n six months .\nPhD B: I haven't noticed him .\nProfessor C: N nine months .\nPhD A: Something like that .\nProfessor C: Something like that .\nPhD A: Yeah .\nProfessor C: Yeah . Yeah . He 's {disfmarker} he 's done a couple stays here .\nPhD B: Hmm .\nProfessor C: Yeah .\nPhD A: So , um , {vocalsound} {comment} I guess we got lots to catch up on . And we haven't met for a couple of weeks . We didn't meet last week , Morgan . Um , I went around and talked to everybody , and it seemed like they {disfmarker} they had some new results but rather than them coming up and telling me I figured we should just wait a week and they can tell both {disfmarker} you know , all of us . So , um , why don't we {disfmarker} why don't we start with you , Dave , and then , um , we can go on .\nGrad E: Oh , OK .\nPhD A: So .\nGrad E: So , um , since we 're looking at putting this , um {disfmarker} mean log m magnitude spectral subtraction , um , into the SmartKom system , I I did a test seeing if , um , it would work using past only {comment} and plus the present to calculate the mean . So , I did a test , um , {vocalsound} where I used twelve seconds from the past and the present frame to , um , calculate the mean . And {disfmarker}\nPhD A: Twelve seconds {disfmarker} Twelve {disfmarker} twelve seconds back from the current {pause} frame , is that what you mean ?\nGrad E: Uh {disfmarker} Twelve seconds , um , counting back from the end of the current frame ,\nPhD A: OK , OK .\nGrad E: yeah . So it was , um , twen I think it was twenty - one frames and that worked out to about twelve seconds .\nPhD A: Mm - hmm .\nGrad E: And compared to , um , do using a twelve second centered window , I think there was a drop in performance but it was just a slight drop .\nPhD A: Hmm !\nProfessor C: Mm - hmm .\nGrad E: Is {disfmarker} is that right ?\nProfessor C: Um , yeah , I mean , it was pretty {disfmarker} it was pretty tiny . Yeah .\nGrad E: Uh - huh . So that was encouraging . And , um , that {disfmarker} that {disfmarker} um , that 's encouraging for {disfmarker} for the idea of using it in an interactive system like And , um , another issue I 'm {disfmarker} I 'm thinking about is in the SmartKom system . So say twe twelve seconds in the earlier test seemed like a good length of time , but what happens if you have less than twelve seconds ? And , um {disfmarker} So I w bef before , um {disfmarker} Back in May , I did some experiments using , say , two seconds , or four seconds , or six seconds . In those I trained the models using mean subtraction with the means calculated over two seconds , or four seconds , or six seconds . And , um , here , I was curious , what if I trained the models using twelve seconds but I f I gave it a situation where the test set I was {disfmarker} subtracted using two seconds , or four seconds , or six seconds . And , um {disfmarker} So I did that for about three different conditions . And , um {disfmarker} I mean , I th I think it was , um , four se I think {disfmarker} I think it was , um , something like four seconds and , um , six seconds , and eight seconds . Something like that . And it seems like it {disfmarker} it {disfmarker} it hurts compared to if you actually train the models {comment} using th that same length of time but it {disfmarker} it doesn't hurt that much . Um , u usually less than point five percent , although I think I did see one where it was a point eight percent or so rise in word error rate . But this is , um , w where , um , even if I train on the , uh , model , and mean subtracted it with the same length of time as in the test , it {disfmarker} the word error rate is around , um , ten percent or nine percent . So it doesn't seem like that big a d a difference .\nProfessor C: But it {disfmarker} but looking at it the other way , isn't it {disfmarker} what you 're saying that it didn't help you to have the longer time for training , if you were going to have a short time for {disfmarker}\nGrad E: That {disfmarker} that 's true . Um ,\nProfessor C: I mean , why would you do it , if you knew that you were going to have short windows in testing .\nGrad E: Wa\nPhD A: Yeah , it seems like for your {disfmarker} I mean , in normal situations you would never get twelve seconds of speech , right ? I 'm not {disfmarker} e u\nPhD B: You need twelve seconds in the past to estimate , right ? Or l or you 're looking at six sec {disfmarker} seconds in future and six in {disfmarker}\nProfessor C: Yeah .\nGrad E: Um , t twelve s\nProfessor C: No , total .\nGrad E: N n uh {disfmarker} For the test it 's just twelve seconds in the past .\nPhD B: No , it 's all {disfmarker} Oh , OK .\nPhD A: Is this twelve seconds of {disfmarker} uh , regardless of speech or silence ? Or twelve seconds of speech ?\nGrad E: Of {disfmarker} of speech .\nPhD A: OK .\nPhD B: Mm - hmm .\nProfessor C: The other thing , um , which maybe relates a little bit to something else we 've talked about in terms of windowing and so on is , that , um , I wonder if you trained with twelve seconds , and then when you were two seconds in you used two seconds , and when you were four seconds in , you used four seconds , and when you were six {disfmarker} and you basically build up to the twelve seconds . So that if you have very long utterances you have the best ,\nGrad E: Yeah .\nProfessor C: but if you have shorter utterances you use what you can .\nGrad E: Right . And that 's actually what we 're planning to do in\nProfessor C: OK . Yeah .\nGrad E: But {disfmarker} s so I g So I guess the que the question I was trying to get at with those experiments is , \" does it matter what models you use ? Does it matter how much time y you use to calculate the mean when you were , um , tra doing the training data ? \"\nProfessor C: Right . But I mean the other thing is that that 's {disfmarker} I mean , the other way of looking at this , going back to , uh , mean cepstral subtraction versus RASTA kind of things , is that you could look at mean cepstral subtraction , especially the way you 're doing it , uh , as being a kind of filter . And so , the other thing is just to design a filter . You know , basically you 're {disfmarker} you 're {disfmarker} you 're doing a high - pass filter or a band - pass filter of some sort and {disfmarker} and just design a filter . And then , you know , a filter will have a certain behavior and you loo can look at the start up behavior when you start up with nothing .\nGrad E: Mm - hmm .\nProfessor C: And {disfmarker} and , you know , it will , uh , if you have an IIR filter for instance , it will , um , uh , not behave in the steady - state way that you would like it to behave until you get a long enough period , but , um , uh , by just constraining yourself to have your filter be only a subtraction of the mean , you 're kind of , you know , tying your hands behind your back because there 's {disfmarker} filters have all sorts of be temporal and spectral behaviors .\nGrad E: Mm - hmm .\nProfessor C: And the only thing , you know , consistent that we know about is that you want to get rid of the very low frequency component .\nGrad E: Hmm .\nPhD B: But do you really want to calculate the mean ? And you neglect all the silence regions {comment} or you just use everything that 's twelve seconds , and {disfmarker}\nGrad E: Um , you {disfmarker} do you mean in my tests so far ?\nPhD B: Ye - yeah .\nGrad E: Most of the silence has been cut out .\nPhD B: OK .\nGrad E: Just {disfmarker} There 's just inter - word silences .\nPhD B: Mm - hmm . And they are , like , pretty short . Shor\nGrad E: Pretty short .\nPhD B: Yeah , OK .\nGrad E: Yeah .\nPhD B: Yeah . Mm - hmm . So you really need a lot of speech to estimate the mean of it .\nGrad E: Well , if I only use six seconds , it still works pretty well .\nPhD B: Yeah . Yeah . Uh - huh .\nGrad E: I saw in my test before . I was trying twelve seconds cuz that was the best {pause} in my test before\nPhD B: OK .\nGrad E: and that increasing past twelve seconds didn't seem to help .\nPhD B: Hmm . Huh .\nGrad E: th um , yeah , I guess it 's something I need to play with more to decide how to set that up for the SmartKom system . Like , may maybe if I trained on six seconds it would work better when I only had two seconds or four seconds , and {disfmarker}\nProfessor C: Yeah . Yeah . And , um {disfmarker}\nGrad E: OK .\nProfessor C: Yeah , and again , if you take this filtering perspective and if you essentially have it build up over time . I mean , if you computed means over two and then over four , and over six , essentially what you 're getting at is a kind of , uh , ramp up of a filter anyway . And so you may {disfmarker} may just want to think of it as a filter . But , uh , if you do that , then , um , in practice somebody using the SmartKom system , one would think {comment} {disfmarker} if they 're using it for a while , it means that their first utterance , instead of , you know , getting , uh , a forty percent error rate reduction , they 'll get a {disfmarker} uh , over what , uh , you 'd get without this , uh , um , policy , uh , you get thirty percent . And then the second utterance that you give , they get the full {disfmarker} you know , uh , full benefit of it if it 's this ongoing thing .\nPhD A: Oh , so you {disfmarker} you cache the utterances ? That 's how you get your , uh {disfmarker}\nProfessor C: Well , I 'm saying in practice , yeah ,\nGrad E: M\nPhD A: Ah . OK .\nProfessor C: that 's {disfmarker} If somebody 's using a system to ask for directions or something ,\nPhD A: OK .\nProfessor C: you know , they 'll say something first . And {disfmarker} and to begin with if it doesn't get them quite right , ma m maybe they 'll come back and say , \" excuse me ? \"\nPhD A: Mm - hmm .\nProfessor C: uh , or some {disfmarker} I mean it should have some policy like that anyway .\nPhD A: Mm - hmm .\nProfessor C: And {disfmarker} and , uh , uh , in any event they might ask a second question . And it 's not like what he 's doing doesn't , uh , improve things . It does improve things , just not as much as he would like . And so , uh , there 's a higher probability of it making an error , uh , in the first utterance .\nPhD A: What would be really cool is if you could have {disfmarker} uh , this probably {disfmarker} users would never like this {disfmarker} but if you had {disfmarker} could have a system where , {vocalsound} before they began to use it they had to introduce themselves , verbally .\nProfessor C: Mm - hmm .\nPhD A: You know . \" Hi , my name is so - and - so ,\nProfessor C: Yeah .\nPhD A: I 'm from blah - blah - blah . \" And you could use that initial speech to do all these adaptations and {disfmarker}\nProfessor C: Right .\nGrad E: Mm - hmm .\nProfessor C: Oh , the other thing I guess which {disfmarker} which , uh , I don't know much about {disfmarker} as much as I should about the rest of the system but {disfmarker} but , um , couldn't you , uh , if you {disfmarker} if you sort of did a first pass I don't know what kind of , uh , uh , capability we have at the moment for {disfmarker} for doing second passes on {disfmarker} on , uh , uh , some kind of little {disfmarker} small lattice , or a graph , or confusion network , or something . But if you did first pass with , um , the {disfmarker} with {disfmarker} either without the mean sub subtraction or with a {disfmarker} a very short time one , and then , um , once you , uh , actually had the whole utterance in , if you did , um , the , uh , uh , longer time version then , based on everything that you had , um , and then at that point only used it to distinguish between , you know , top N , um , possible utterances or something , you {disfmarker} you might {disfmarker} it might not take very much time . I mean , I know in the large vocabulary stu uh , uh , systems , people were evaluating on in the past , some people really pushed everything in to make it in one pass but other people didn't and had multiple passes . And , um , the argument , um , against multiple passes was u u has often been \" but we want to this to be r you know {disfmarker} have a nice interactive response \" . And the counterargument to that which , say , uh , BBN I think had , {comment} was \" yeah , but our second responses are {disfmarker} second , uh , passes and third passes are really , really fast \" .\nPhD A: Mm - hmm .\nProfessor C: So , um , if {disfmarker} if your second pass takes a millisecond who cares ? Um .\nGrad E: S so , um , the {disfmarker} the idea of the second pass would be waiting till you have more recorded speech ? Or {disfmarker} ?\nProfessor C: Yeah , so if it turned out to be a problem , that you didn't have enough speech because you need a longer {disfmarker} longer window to do this processing , then , uh , one tactic is {disfmarker} you know , looking at the larger system and not just at the front - end stuff {comment} {disfmarker} is to take in , um , the speech with some simpler mechanism or shorter time mechanism ,\nGrad E: Mm - hmm .\nProfessor C: um , do the best you can , and come up with some al possible alternates of what might have been said . And , uh , either in the form of an N - best list or in the form of a lattice , or {disfmarker} or confusion network , or whatever .\nGrad E: Mm - hmm .\nProfessor C: And then the decoding of that is much , much faster or can be much , much faster if it isn't a big bushy network . And you can decode that now with speech that you 've actually processed using this longer time , uh , subtraction .\nGrad E: Mmm .\nProfessor C: So I mean , it 's {disfmarker} it 's common that people do this sort of thing where they do more things that are more complex or require looking over more time , whatever , in some kind of second pass .\nGrad E: Mm - hmm . OK .\nProfessor C: um , and again , if the second pass is really , really fast {disfmarker} Uh , another one I 've heard of is {disfmarker} is in {disfmarker} in connected digit stuff , um , going back and l and through backtrace and finding regions that are considered to be a d a digit , but , uh , which have very low energy .\nGrad E: Mm - hmm . OK .\nProfessor C: So , uh {disfmarker} I mean , there 's lots of things you can do in second passes , at all sorts of levels . Anyway , I 'm throwing too many things out . But .\nPhD A: So is that , uh {disfmarker} that it ?\nGrad E: I guess that 's it .\nPhD A: OK , uh , do you wanna go , Sunil ?\nPhD B: Yep . Um , so , the last two weeks was , like {disfmarker} So I 've been working on that Wiener filtering . And , uh , found that , uh , s single {disfmarker} like , I just do a s normal Wiener filtering , like the standard method of Wiener filtering . And that doesn't actually give me any improvement over like {disfmarker} I mean , uh , b it actually improves over the baseline but it 's not like {disfmarker} it doesn't meet something like fifty percent or something . So , I 've been playing with the v\nPhD A: Improves over the base line MFCC system ? Yeah .\nPhD B: Yeah . Yeah . Yeah . So , um {disfmarker} So that 's {disfmarker} The improvement is somewhere around , like , thirty percent over the baseline .\nProfessor C: Is that using {disfmarker} in combination with something else ?\nPhD B: No , just {disfmarker} just one stage Wiener filter\nProfessor C: With {disfmarker} with a {disfmarker}\nPhD B: which is a standard Wiener filter .\nProfessor C: No , no , but I mean in combination with our on - line normalization or with the LDA ?\nPhD B: Yeah , yeah , yeah , yeah . So I just plug in the Wiener filtering .\nProfessor C: Oh , OK .\nPhD B: I mean , in the s in our system , where {disfmarker}\nPhD A: Oh , OK .\nPhD B: So , I di i di\nProfessor C: So , does it g does that mean it gets worse ? Or {disfmarker} ?\nPhD B: No . It actually improves over the baseline of not having a Wiener filter in the whole system . Like I have an LDA f LDA plus on - line normalization , and then I plug in the Wiener filter in that ,\nProfessor C: Yeah ?\nPhD B: so it improves over not having the Wiener filter . So it improves but it {disfmarker} it doesn't take it like be beyond like thirty percent over the baseline . So {disfmarker}\nProfessor C: But that 's what I 'm confused about , cuz I think {disfmarker} I thought that our system was more like forty percent without the Wiener filtering .\nPhD B: No , it 's like , uh ,\nPhD D: Mmm .\nPhD A: Is this with the v new VAD ?\nPhD B: well , these are not {disfmarker} No , it 's the old VAD . So my baseline was , {vocalsound} uh , {vocalsound} nine {disfmarker} This is like {disfmarker} w the baseline is ninety - five point six eight , and eighty - nine , and {disfmarker}\nProfessor C: So I mean , if you can do all these in word errors it 's a lot {disfmarker} a lot easier actually .\nPhD B: What was that ? Sorry ?\nProfessor C: If you do all these in word error rates it 's a lot easier , right ?\nPhD B: Oh , OK , OK , OK . Errors , right , I don't have .\nProfessor C: OK , cuz then you can figure out the percentages .\nPhD B: It 's all accuracies .\nProfessor C: Yeah .\nPhD D: The baseline is something similar to a w I mean , the t the {disfmarker} the baseline that you are talking about is the MFCC baseline , right ?\nPhD B: The t yeah , there are two baselines .\nPhD D: Or {disfmarker} ?\nPhD B: OK . So the baseline {disfmarker} One baseline is MFCC baseline that {disfmarker} When I said thirty percent improvement it 's like MFCC baseline .\nPhD D: Mm - hmm .\nProfessor C: So {disfmarker} so {disfmarker} so what 's it start on ? The MFCC baseline is {disfmarker} is what ? Is at what level ?\nPhD B: It 's the {disfmarker} it 's just the mel frequency and that 's it .\nProfessor C: No , what 's {disfmarker} what 's the number ?\nPhD B: Uh , so I I don't have that number here . OK , OK , OK , I have it here . Uh , it 's the VAD plus the baseline actually . I 'm talking about the {disfmarker} the MFCC plus I do a frame dropping on it . So that 's like {disfmarker} the word error rate is like four point three . Like {disfmarker} Ten point seven .\nProfessor C: Four point three . What 's ten point seven ?\nPhD B: It 's a medium misma OK , sorry . There 's a well ma well matched , medium mismatched , and a high matched .\nProfessor C: Ah .\nPhD B: So I don't have the {disfmarker} like the {disfmarker}\nProfessor C: Yeah .\nPhD B: So {disfmarker}\nProfessor C: OK , four point three , ten point seven ,\nPhD B: And forty forty .\nProfessor C: and {disfmarker}\nPhD B: Forty percent is the high mismatch .\nProfessor C: OK .\nPhD B: And that becomes like four point three {disfmarker}\nProfessor C: Not changed .\nPhD B: Yeah , it 's like ten point one . Still the same . And the high mismatch is like eighteen point five .\nProfessor C: Eighteen point five .\nPhD B: Five .\nProfessor C: And what were you just describing ?\nPhD B: Oh , the one is {disfmarker} this one is just the baseline plus the , uh , Wiener filter plugged into it .\nProfessor C: But where 's the , uh , on - line normalization and so on ?\nPhD B: Oh , OK . So {disfmarker} Sorry . So , with the {disfmarker} with the on - line normalization , the performance was , um , ten {disfmarker} OK , so it 's like four point three . Uh , and again , that 's the ba the ten point , uh , four and twenty point one . That was with on - line normalization and LDA . So the h well matched has like literally not changed by adding on - line or LDA on it . But the {disfmarker} I mean , even the medium mismatch is pretty much the same . And the high mismatch was improved by twenty percent absolute .\nProfessor C: OK , and what kind of number {disfmarker} an and what are we talking about here ?\nPhD B: It 's the It - it 's Italian .\nProfessor C: Is this TI - digits\nPhD B: I 'm talking about Italian ,\nProfessor C: or {disfmarker} Italian ?\nPhD B: yeah .\nProfessor C: And what did {disfmarker} So , what was the , um , uh , corresponding number , say , for , um , uh , the Alcatel system for instance ?\nPhD B: Mmm . \nProfessor C: Do you know ?\nPhD D: Yeah , so it looks to be , um {disfmarker}\nPhD B: You have it ?\nPhD D: Yep , it 's three point four , uh , eight point , uh , seven , and , uh , thirteen point seven .\nPhD B: Yep .\nProfessor C: OK .\nPhD B: So {disfmarker} Thanks .\nProfessor C: OK .\nPhD D: Mm - hmm .\nProfessor C: OK .\nPhD B: So , uh , this is the single stage Wiener filter , with {disfmarker} The noise estimation was based on first ten frames .\nProfessor C: Mm - hmm .\nPhD B: Actually I started with {disfmarker} using the VAD to estimate the noise and then I found that it works {disfmarker} it doesn't work for Finnish and Spanish because the VAD endpoints are not good to estimate the noise because it cuts into the speech sometimes , so I end up overestimating the noise and getting a worse result . So it works only for Italian by u for {disfmarker} using a VAD to estimate noise .\nProfessor C: Mm - hmm .\nPhD B: It works for Italian because the VAD was trained on Italian .\nProfessor C: Mm - hmm .\nPhD B: So , uh {disfmarker} so this was , uh {disfmarker} And so this was giving {disfmarker} um , this {disfmarker} this was like not improving a lot on this baseline of not having the Wiener filter on it . And , so , uh , I ran this stuff with one more stage of Wiener filtering on it but the second time , what I did was I {disfmarker} estimated the new Wiener filter based on the cleaned up speech , and did , uh , smoothing in the frequency to {disfmarker} to reduce the variance {disfmarker}\nProfessor C: Mm - hmm .\nPhD B: I mean , I have {disfmarker} I 've {disfmarker} I 've observed there are , like , a lot of bumps in the frequency when I do this Wiener filtering which is more like a musical noise or something . And so by adding another stage of Wiener filtering , the results on the SpeechDat - Car was like , um {disfmarker} So , I still don't have the word error rate . I 'm sorry about it . But the overall improvement was like fifty - six point four six . This was again using ten frames of noise estimate and two stage of Wiener filtering . And the rest is like the LDA plu and the on - line normalization all remaining the same . Uh , so this was , like , compared to , uh , uh {disfmarker} Fifty - seven is what you got by using the French Telecom system , right ?\nPhD D: No , I don't think so .\nPhD B: Y i\nPhD D: Is it on Italian ?\nPhD B: No , this is over the whole SpeechDat - Car . So {disfmarker}\nPhD D: Oh , yeah , fifty - seven {disfmarker}\nPhD B: point {disfmarker}\nPhD D: Right .\nPhD B: Yeah , so the new {disfmarker} the new Wiener filtering schema is like {disfmarker} some fifty - six point four six which is like one percent still less than what you got using the French Telecom system .\nPhD D: Uh - huh . Mm - hmm .\nProfessor C: But it 's a pretty similar number in any event .\nPhD B: It 's very similar .\nProfessor C: Yeah . But again , you 're {disfmarker} you 're more or less doing what they were doing , right ?\nPhD B: It 's {disfmarker} it 's different in a sense like I 'm actually cleaning up the cleaned up spectrum which they 're not doing . They 're d what they 're doing is , they have two stage {disfmarker} stages of estimating the Wiener filter , but {disfmarker} the final filter , what they do is they {disfmarker} they take it to their time domain by doing an inverse Fourier transform .\nProfessor C: Yeah .\nPhD B: And they filter the original signal using that fil filter ,\nProfessor C: Uh - huh .\nPhD B: which is like final filter is acting on the input noisy speech rather than on the cleaned up . So this is more like I 'm doing Wiener filter twice , but the only thing is that the second time I 'm actually smoothing the filter and then cleaning up the cleaned up spectrum first level . And so that {disfmarker} that 's {disfmarker} that 's what the difference is .\nProfessor C: OK .\nPhD B: And actually I tried it on s the original clean {disfmarker} I mean , the original spectrum where , like , I {disfmarker} the second time I estimate the filter but actually clean up the noisy speech rather the c s first {disfmarker} output of the first stage and that doesn't {disfmarker} seems to be a {disfmarker} giving , I mean , that much improvement . I {disfmarker} I didn didn't run it for the whole case . And {disfmarker} and what I t what I tried was , by using the same thing but {disfmarker} Uh , so we actually found that the VAD is very , like , crucial . I mean , just by changing the VAD itself gives you the {disfmarker} a lot of improvement\nProfessor C: Mm - hmm .\nPhD B: by instead of using the current VAD , if you just take up the VAD output from the channel zero , {comment} when {disfmarker} instead of using channel zero and channel one , because that was the p that was the reason why I was not getting a lot of improvement for estimating {comment} the noise . So I just used the channel zero VAD to estimate the noise so that it gives me some reliable mar markers for this noise estimation .\nProfessor C: What 's a channel zero VAD ?\nPhD B: Um ,\nProfessor C: I 'm {disfmarker} I 'm confused about that .\nPhD B: so , it 's like {disfmarker}\nPhD D: So it 's the close - talking microphone .\nPhD B: Yeah , the close - talking without {disfmarker}\nProfessor C: Oh , oh , oh , oh .\nPhD B: So because the channel zero and channel one are like the same speech , but only w I mean , the same endpoints .\nProfessor C: \nPhD B: But the only thing is that the speech is very noisy for channel one , so you can actually use the output of the channel zero for channel one for the VAD . I mean , that 's like a cheating method .\nProfessor C: Right . I mean , so a are they going to pro What are they doing to do , do we know yet ? about {disfmarker} as far as what they 're {disfmarker} what the rules are going to be and what we can use ?\nPhD D: Yeah , so actually I received a {disfmarker} a new document , describing this .\nPhD B: Yeah , that 's {disfmarker}\nPhD D: And what they did finally is to , mmm , uh , not to align the utterances but to perform recognition , um , only on the close - talking microphone ,\nPhD B: Which is the channel zero .\nPhD D: and to take the result of the recognition to get the boundaries uh , of speech .\nProfessor C: So it 's not like that 's being done in one place or one time .\nPhD D: And {disfmarker}\nProfessor C: That 's {disfmarker} that 's just a rule and we 'd {disfmarker} you {disfmarker} you were permitted to do that . Is {disfmarker} is that it ?\nPhD D: Uh , I think they will send , um , files but we {disfmarker} we don't {disfmarker} Well , apparently {disfmarker}\nProfessor C: Oh , so they will send files so everybody will have the same boundaries to work with ?\nPhD D: Yeah . Yeah .\nPhD B: But actually their alignment actually is not seems to be improving in like on all cases .\nProfessor C: OK .\nPhD D: Oh , i Yeah , so what happened here is that , um , the overall improvement that they have with this method {disfmarker} So {disfmarker} Well , to be more precise , what they have is , they have these alignments and then they drop the beginning silence and {disfmarker} and the end silence but they keep , uh , two hundred milliseconds before speech and two hundred after speech . And they keep the speech pauses also . Um , and the overall improvement over the MFCC baseline So , when they just , uh , add this frame dropping in addition it 's r uh , forty percent , right ?\nProfessor C: Mm - hmm .\nPhD D: Fourteen percent , I mean .\nProfessor C: Mm - hmm .\nPhD B: Yeah , which is {disfmarker}\nPhD D: Um , which is , um , t which is the overall improvement . But in some cases it doesn't improve at all . Like , uh , y do you remember which case ?\nProfessor C: Mm - hmm .\nPhD B: It gives like negative {disfmarker} Well , in {disfmarker} in like some Italian and TI - digits ,\nPhD D: Yeah , some @ @ .\nPhD B: right ?\nPhD D: Right .\nPhD B: Yeah . So by using the endpointed speech , actually it 's worse than the baseline in some instances , which could be due to the word pattern .\nPhD D: Mmm . Yeah .\nProfessor C: Yeah ,\nPhD D: And {disfmarker} Yeah , the other thing also is that fourteen percent is less than what you obtain using a real VAD .\nPhD B: Yeah , our neural net {disfmarker}\nPhD D: So with without cheating like this .\nPhD B: Yeah , yeah .\nPhD D: So {disfmarker} Uh {disfmarker} So I think this shows that there is still work {disfmarker} Uh , well , working on the VAD is still {disfmarker} still important I think .\nProfessor C: Yeah , c\nPhD D: Uh {disfmarker}\nPhD A: Can I ask just a {disfmarker} a high level question ? Can you just say like one or two sentences about Wiener filtering and why {disfmarker} why are people doing that ?\nPhD B: Hmm .\nPhD A: What 's {disfmarker} what 's the deal with that ?\nPhD B: OK , so the Wiener filter , it 's {disfmarker} it 's like {disfmarker} it 's like you try to minimize {disfmarker} I mean , so the basic principle of Wiener filter is like you try to minimize the , uh , d uh , difference between the noisy signal and the clean signal if you have two channels . Like let 's say you have a clean t signal and you have an additional channel where you know what is the noisy signal .\nPhD A: Mm - hmm .\nPhD B: And then you try to minimize the error between these two .\nPhD A: Mm - hmm .\nPhD B: So that 's the basic principle . And you get {disfmarker} you can do that {disfmarker} I mean , if {disfmarker} if you have only a c noisy signal , at a level which you , you w try to estimate the noise from the w assuming that the first few frames are noise or if you have a w voice activity detector , uh , you estimate the noise spectrum .\nPhD A: Mm - hmm .\nPhD B: And then you {disfmarker}\nPhD A: Do you assume the noise is the same ?\nPhD B: Yeah . in {disfmarker} yeah , after the speech starts .\nPhD A: Uh - huh .\nPhD B: So {disfmarker} but that 's not the case in , uh , many {disfmarker} many of our cases but it works reasonably well .\nPhD A: I see .\nPhD B: And {disfmarker} and then you What you do is you , uh b fff . So again , I can write down some of these eq Oh , OK . Yeah . And then you do this {disfmarker} uh , this is the transfer function of the Wiener filter , so \" SF \" is a clean speech spectrum , power spectrum\nPhD A: Mm - hmm .\nPhD B: And \" N \" is the noisy power spectrum . And so this is the transfer function .\nProfessor C: Right\nPhD B: And ,\nProfessor C: actually , I guess {disfmarker}\nPhD B: Yeah .\nProfessor C: Yeah .\nPhD B: And then you multiply your noisy power spectrum with this . You get an estimate of the clean power spectrum .\nPhD A: I see . OK .\nPhD B: So {disfmarker} but the thing is that you have to estimate the SF from the noisy spectrum , what you have . So you estimate the NF from the initial noise portions and then you subtract that from the current noisy spectrum to get an estimate of the SF . So sometimes that becomes zero because you do you don't have a true estimate of the noise . So the f filter will have like sometimes zeros in it\nPhD A: Mm - hmm .\nPhD B: because some frequency values will be zeroed out because of that . And that creates a lot of discontinuities across the spectrum because @ @ the filter . So , uh , so {disfmarker} that 's what {disfmarker} that was just the first stage of Wiener filtering that I tried .\nPhD A: So is this , um , basically s uh , similar to just regular spectral subtraction ?\nPhD B: It {disfmarker}\nProfessor C: It 's all pretty related ,\nPhD B: Yeah .\nProfessor C: yeah . It 's {disfmarker} it 's {disfmarker} there 's a di there 's a whole class of techniques where you try in some sense to minimize the noise .\nPhD A: Uh - huh .\nProfessor C: And it 's typically a mean square sense , uh {disfmarker} uh {disfmarker} uh , i in {disfmarker} in {disfmarker} in some way . And , uh {disfmarker} uh , spectral subtraction is {disfmarker} is , uh {disfmarker} uh , one approach to it .\nPhD A: Do people use the Wiener filtering in combination with the spectral subtraction typically , or is i are they sort of competing techniques ?\nPhD B: Not seen . They are very s similar techniques .\nPhD A: Yeah . O oh , OK .\nPhD B: So it 's like I haven't seen anybody using s Wiener filter with spectral subtraction .\nPhD D: Mm - hmm .\nPhD A: I see , I see .\nProfessor C: I mean , in the long run you 're doing the same thing\nPhD A: Mm - hmm .\nPhD B: Yeah .\nProfessor C: but y but there you make different approximations , and {disfmarker} in spectral subtraction , for instance , there 's a {disfmarker} a {disfmarker} an estimation factor .\nPhD A: Mmm .\nProfessor C: You sometimes will figure out what the noise is and you 'll multiply that noise spectrum times some constant and subtract that rather than {disfmarker} and sometimes people {disfmarker} even though this really should be in the power domain , sometimes people s work in the magnitude domain because it {disfmarker} it {disfmarker} it works better .\nPhD A: Mm - hmm .\nProfessor C: And , uh , uh , you know .\nPhD A: So why did you choose , uh , Wiener filtering over some other {disfmarker} one of these other techniques ?\nPhD B: Uh , the reason was , like , we had this choice of using spectral subtraction , Wiener filtering , and there was one more thing which I which I 'm trying , is this sub space approach . So , Stephane is working on spectral subtraction .\nPhD A: Oh , OK .\nPhD B: So I picked up {disfmarker}\nPhD A: So you 're sort of trying @ @ them all .\nPhD B: Y Yeah ,\nPhD A: Ah ,\nPhD B: we just wanted to have a few noise production {disfmarker} compensation techniques\nPhD A: I see . Oh , OK .\nPhD B: and then pick some from that {disfmarker}\nPhD A: Mm - hmm .\nPhD B: pick one .\nProfessor C: I m I mean {disfmarker} yeah , I mean , there 's Car - Carmen 's working on another , on the vector Taylor series .\nPhD B: VA Yeah , VAD . w Yeah .\nProfessor C: So they were just kind of trying to cover a bunch of different things with this task and see , you know , what are {disfmarker} what are the issues for each of them .\nPhD A: Ah , OK . That makes sense .\nPhD B: Yeah .\nPhD A: Yeah . Mm - hmm . Mm - hmm .\nProfessor C: Um .\nPhD A: Cool , thanks .\nPhD B: So {disfmarker} so one of {disfmarker} one of the things that I tried , like I said , was to remove those zeros in the fri filter by doing some smoothing of the filter .\nProfessor C: Yeah .\nPhD A: Mm - hmm .\nPhD B: Like , you estimate the edge of square and then you do a f smoothing across the frequency so that those zeros get , like , flattened out .\nPhD A: Mm - hmm .\nPhD B: And that doesn't seems to be improving by trying it on the first time . So what I did was like I p did this and then you {disfmarker} I plugged in the {disfmarker} one more {disfmarker} the same thing but with the smoothed filter the second time .\nPhD A: Mm - hmm .\nPhD B: And that seems to be working .\nPhD A: Mm - hmm .\nPhD B: So that 's where I got like fifty - six point five percent improvement on SpeechDat - Car with that . And {disfmarker} So the other thing what I tried was I used still the ten frames of noise estimate but I used this channel zero VAD to drop the frames . So I 'm not {disfmarker} still not estimating . And that has taken the performance to like sixty - seven percent in SpeechDat - Car , which is {disfmarker} which {disfmarker} which like sort of shows that by using a proper VAD you can just take it to further , better levels . And {disfmarker} So .\nPhD A: So that 's sort of like , you know , best - case performance ?\nPhD B: Yeah , so far I 've seen sixty - seven {disfmarker} I mean , no , I haven't seen s like sixty - seven percent . And , uh , using the channel zero VAD to estimate the noise also seems to be improving but I don't have the results for all the cases with that . So I used channel zero VAD to estimate noise as a lesser 2 x frame , which is like , {vocalsound} everywhere I use the channel zero VAD . And that seems to be the best combination , uh , rather than using a few frames to estimate and then drop a channel .\nProfessor C: So I 'm {disfmarker} I 'm still a little confused . Is that channel zero information going to be accessible during this test .\nPhD B: Nnn , no . This is just to test whether we can really improve by using a better VAD .\nProfessor C: Mm - hmm .\nPhD B: So ,\nProfessor C: Mm - hmm .\nPhD B: I mean {disfmarker} So this is like the noise compensation f is fixed\nPhD D: Mm - hmm .\nPhD B: but you make a better decision on the endpoints . That 's , like {disfmarker} seems to be {disfmarker}\nProfessor C: Mm - hmm .\nPhD B: so we c so I mean , which {disfmarker} which means , like , by using this technique what we improve just the VAD\nProfessor C: Yes .\nPhD B: we can just take the performance by another ten percent or better .\nProfessor C: OK .\nPhD B: So , that {disfmarker} that was just the , uh , reason for doing that experiment . And , w um {disfmarker} Yeah , but this {disfmarker} all these things , I have to still try it on the TI - digits , which is like I 'm just running . And there seems to be not improving a {disfmarker} a lot on the TI - digits , so I 'm like investigating that , why it 's not . And , um , um {disfmarker} Well after that . So , uh {disfmarker} so the other {disfmarker} the other thing is {disfmarker} like I 've been {disfmarker} I 'm doing all this stuff on the power spectrum . So {disfmarker} Tried this stuff on the mel as well {disfmarker} mel and the magnitude , and mel magnitude , and all those things . But it seems to be the power spectrum seems to be getting the best result . So , one of {disfmarker} one of reasons I thought like doing the averaging , after the filtering using the mel filter bank , that seems to be maybe helping rather than trying it on the mel filter ba filtered outputs .\nProfessor C: Mm - hmm . Mm - hmm .\nPhD B: So just th\nProfessor C: Ma Makes sense .\nPhD B: Yeah , th that 's {disfmarker} that 's the only thing that I could think of why {disfmarker} why it 's giving improvement on the mel . And , yep . So that 's it .\nProfessor C: Uh , how about the subspace stuff ?\nPhD B: Subspace , {comment} I 'm {disfmarker} I 'm like {disfmarker} that 's still in {disfmarker} a little bit in the back burner because I 've been p putting a lot effort on this to make it work , on tuning things and other stuff .\nProfessor C: OK .\nPhD B: So I was like going parallely but not much of improvement . I 'm just {disfmarker} have some skeletons ready , need some more time for it .\nProfessor C: OK .\nPhD B: Mmm .\nPhD A: Tha - that it ?\nPhD B: Yep . Yep .\nPhD A: Cool . Do you wanna go , Stephane ?\nPhD D: Uh , yeah . So , {vocalsound} I 've been , uh , working still on the spectral subtraction . Um , So to r to remind you {vocalsound} {vocalsound} a little bit of {disfmarker} of what I did before , is just {vocalsound} to apply some spectral subtraction with an overestimation factor also to get , um , an estimate of the noise , uh , spectrum , and subtract this estimation of the noise spectrum from the , uh , signal spectrum , {comment} but subtracting more when the SNR is {disfmarker} is , uh , low , which is a technique that it 's often used .\nPhD A: \" Subtracting more \" , meaning {disfmarker} ?\nPhD D: So you overestimate the noise spectrum . You multiply the noise spectrum by a factor , uh , which depends on the SNR .\nPhD A: Oh , OK . I see .\nPhD D: So , above twenty DB , it 's one , so you just subtract the noise .\nPhD A: Mm - hmm .\nPhD D: And then it 's b Generally {disfmarker} Well , I use , actually , a linear , uh , function of the SNR ,\nPhD A: Mm - hmm .\nPhD D: which is bounded to , like , two or three , {comment} when the SNR is below zero DB .\nPhD A: Mm - hmm . Mm - hmm .\nPhD D: Um , doing just this , uh , either on the FFT bins or on the mel bands , um , t doesn't yield any improvement\nProfessor C: Oh ! Um , uh , what are you doing with negative , uh , powers ?\nPhD D: o Yeah . So there is also a threshold , of course , because after subtraction you can have negative energies ,\nPhD A: Mm - hmm .\nPhD D: and {disfmarker} So what I {disfmarker} I just do is to put , uh {disfmarker} to {disfmarker} to add {disfmarker} to put the threshold first and then to add a small amount of noise , which right now is speech - shaped . Um {disfmarker}\nPhD A: Speech - shaped ?\nPhD D: Yeah , so it 's {disfmarker} a it has the overall {disfmarker} overall energy , uh {disfmarker} pow it has the overall power spectrum of speech . So with a bump around one kilohertz .\nPhD A: So when y when you talk about there being something less than zero after subtracting the noise , is that at a particular frequency bin ?\nPhD D: i Uh - huh . Yeah .\nPhD A: OK .\nPhD D: There can be frequency bins with negative values .\nPhD A: And so when you say you 're adding something that has the overall shape of speech , is that in a {disfmarker} in a particular frequency bin ? Or you 're adding something across all the frequencies when you get these negatives ?\nPhD D: For each frequencies I a I 'm adding some , uh , noise , but the a the amount of {disfmarker} the amount of noise I add is not the same for all the frequency bins .\nPhD A: Ah ! OK . I gotcha . Right .\nPhD D: Uh . Right now I don't think if it makes sense to add something that 's speech - shaped , because then you have silence portion that have some spectra similar to the sp the overall speech spectra .\nPhD A: Mm - hmm .\nPhD D: But {disfmarker} Yeah . So this is something I can still work on ,\nPhD A: So what does that mean ?\nPhD D: but {disfmarker} Hmm .\nPhD A: I 'm trying to understand what it means when you do the spectral subtraction and you get a negative . It means that at that particular frequency range you subtracted more energy than there was actually {disfmarker}\nPhD D: That means that {disfmarker} Mm - hmm . Yeah . So {disfmarker} so yeah , you have an {disfmarker} an estimation of the noise spectrum , but sometimes , of course , it 's {disfmarker} as the noise is not perfectly stationary , sometimes this estimation can be , uh , too small , so you don't subtract enough . But sometimes it can be too large also . If {disfmarker} if the noise , uh , energy in this particular frequency band drops for some reason .\nPhD A: Mm - hmm . Mm - hmm .\nPhD D: Mmm .\nPhD A: So in {disfmarker} in an ideal word i world {comment} if the noise were always the same , then , when you subtracted it the worst that i you would get would be a zero . I mean , the lowest you would get would be a zero , cuz i if there was no other energy there you 're just subtracting exactly the noise .\nProfessor C: Right .\nPhD D: Mm - hmm ,\nProfessor C: Yep , there 's all {disfmarker} there 's all sorts of , uh , deviations from the ideal here .\nPhD D: yeah .\nProfessor C: I mean , for instance , you 're {disfmarker} you 're talking about the signal and noise , um , at a particular point . And even if something is sort of stationary in ster terms of statistics , there 's no guarantee that any particular instantiation or piece of it is exactly a particular number or bounded by a particular range .\nPhD D: Mm - hmm .\nProfessor C: So , you 're figuring out from some chunk of {disfmarker} of {disfmarker} of the signal what you think the noise is . Then you 're subtracting that from another chunk ,\nPhD A: Mm - hmm .\nProfessor C: and there 's absolutely no reason to think that you 'd know that it wouldn't , uh , be negative in some places .\nPhD D: Mm - hmm . Hmm .\nProfessor C: Uh , on the other hand that just means that in some sense you 've made a mistake because you certainly have stra subtracted a bigger number than is due to the noise .\nPhD A: Mm - hmm .\nProfessor C: Um {disfmarker} Also , we speak {disfmarker} the whole {disfmarker} where all this stuff comes from is from an assumption that signal and noise are uncorrelated . And that certainly makes sense in s in {disfmarker} in a statistical interpretation , that , you know , over , um , all possible realizations that they 're uncorrelated\nPhD A: Mm - hmm .\nProfessor C: or assuming , uh , ergodicity that i that i um , across time , uh , it 's uncorrelated . But if you just look at {disfmarker} a quarter second , uh , and you cross - multiply the two things , uh , you could very well , uh , end up with something that sums to something that 's not zero . So in fact , the two signals could have some relation to one another . And so there 's all sorts of deviations from ideal in this . And {disfmarker} and given all that , you could definitely end up with something that 's negative . But if down the road you 're making use of something as if it is a power spectrum , um , then it can be bad to have something negative . Now , the other thing I wonder about actually is , what if you left it negative ? What happens ?\nPhD B: Is that the log ?\nProfessor C: I mean , because {disfmarker} Um , are you taking the log before you add them up to the mel ?\nPhD B: After that . No , after .\nProfessor C: Right . So the thing is , I wonder how {disfmarker} if you put your thresholds after that , I wonder how often you would end up with , uh {disfmarker} with negative values .\nPhD B: But you will {disfmarker} But you end up reducing some neighboring frequency bins {disfmarker} @ @ in the average , right ? When you add the negative to the positive value which is the true estimate .\nProfessor C: Yeah . But nonetheless , uh , you know , these are {disfmarker} it 's another f kind of smoothing , right ? that you 're doing .\nPhD B: Yeah .\nProfessor C: Right . So , you 've done your best shot at figuring out what the noise should be , and now i then you 've subtracted it off . And then after that , instead of {disfmarker} instead of , uh , uh , leaving it as is and adding things {disfmarker} adding up some neighbors , you artificially push it up .\nPhD B: Hmm .\nProfessor C: Which is , you know , it 's {disfmarker} there 's no particular reason that that 's the right thing to do either , right ?\nPhD B: Yeah , yeah .\nProfessor C: So , um , uh , i in fact , what you 'd be doing is saying , \" well , we 're d we 're {disfmarker} we 're going to definitely diminish the effect of this frequency in this little frequency bin in the {disfmarker} in the overall mel summation \" . It 's just a thought . I d I don't know if it would be {disfmarker}\nPhD A: Sort of the opposite of that would be if {disfmarker} if you find out you 're going to get a negative number , you don't do the subtraction for that bin .\nPhD B: Yeah . Uh - huh . That is true .\nProfessor C: Nnn , yeah ,\nPhD D: Mm - hmm .\nProfessor C: although {disfmarker}\nPhD A: That would be almost the opposite , right ? Instead of leaving it negative , you don't do it . If your {disfmarker} if your subtraction 's going to result in a negative number , you {disfmarker} you don't do subtraction in that .\nProfessor C: Yeah , but that means that in a situation where you thought that {disfmarker} that the bin was almost entirely noise , you left it .\nPhD A: Yeah . Yeah , I 'm just saying that 's like the opposite .\nPhD B: We just {disfmarker}\nProfessor C: Uh .\nPhD B: Yeah .\nProfessor C: Yeah .\nPhD A: Yeah .\nProfessor C: Well , yeah that 's {disfmarker} that 's the opposite ,\nPhD D: Mm - hmm .\nProfessor C: yeah .\nPhD D: And , yeah , some people also {disfmarker} if it 's a negative value they , uh , re - compute it using inter interpolation from the edges and bins .\nPhD B: For frames , frequency bins .\nProfessor C: Yeah .\nPhD D: Well , there are different things that you can do .\nPhD A: Oh .\nProfessor C: People can also , uh , reflect it back up and essentially do a full wave rectification instead of a {disfmarker} instead of half wave .\nPhD A: Oh .\nProfessor C: But it was just a thought that {disfmarker} that it might be something to try .\nPhD D: Mm - hmm . Mm - hmm . Yep . Well , actually I tried , {vocalsound} something else based on this , um , is to {disfmarker} to put some smoothing , um , because it seems to {disfmarker} to help or it seems to help the Wiener filtering\nProfessor C: Mm - hmm .\nPhD D: and , mmm {disfmarker} So what I did is , uh , some kind of nonlinear smoothing . Actually I have a recursion that computes {disfmarker} Yeah , let me go back a little bit . Actually , when you do spectral subtraction you can , uh , find this {disfmarker} this equivalent in the s in the spectral domain . You can uh compute , y you can say that d your spectral subtraction is a filter , um , and the gain of this filter is the , um , {vocalsound} signal energy minus what you subtract , divided by the signal energy . And this is a gain that varies over time , and , you know , of course , uh , depending on the s on the noise spectrum and on the speech spectrum . And {disfmarker} what happen actually is that during low SNR values , the gain is close to zero but it varies a lot . Mmm , and this {disfmarker} this is the cause of musical noise and all these {disfmarker} the {disfmarker} {comment} the fact you {disfmarker} we go below zero one frame and then you can have an energy that 's above zero .\nProfessor C: Mm - hmm .\nPhD D: And {disfmarker} Mmm . So the smoothing is {disfmarker} I did a smoothing actually on this gain , uh , trajectory . But it 's {disfmarker} the smoothing is nonlinear in the sense that I tried to not smooth if the gain is high , because in this case we know that , uh , the estimate of the gain is correct because we {disfmarker} we are not close to {disfmarker} to {disfmarker} to zero , um , and to do more smoothing if the gain is low . Mmm . Um . Yeah . So , well , basically that 's this idea , and it seems to give pretty good results , uh , although I 've just {disfmarker} just tested on Italian and Finnish . And on Italian it seems {disfmarker} my result seems to be a little bit better than the Wiener filtering ,\nPhD B: Mm - hmm . Yeah , the one you showed yesterday .\nPhD D: right ?\nPhD B: Right ?\nProfessor C: Yeah .\nPhD D: Uh , I don't know if you have these improvement the detailed improvements for Italian , Finnish , and Spanish there\nPhD B: Fff . No , I don't have , for each ,\nPhD D: or you have {disfmarker} just have your own .\nPhD B: I {disfmarker} I just {disfmarker} just have the final number here .\nPhD D: Mm - hmm .\nProfessor C: So these numbers he was giving before with the four point three , and the ten point one , and so forth , those were Italian , right ?\nPhD B: Yeah , yeah , yeah . So {disfmarker} so , no ,\nProfessor C: Yeah .\nPhD D: Uh {disfmarker}\nPhD B: I actually didn't give you the number which is the final one ,\nPhD D: uh , no , we 've {disfmarker}\nPhD B: which is , after two stages of Wiener filtering . I mean , that was I just {disfmarker} well , like the overall improvement is like fifty - six point five . So ,\nProfessor C: Right .\nPhD D: Mm - hmm .\nPhD B: I mean , his number is still better than what I got in the two stages of Wiener filtering .\nPhD D: Yeah .\nProfessor C: Right .\nPhD D: On Italian . But on Finnish it 's a little bit worse , apparently .\nPhD B: Mm - hmm .\nPhD D: Um {disfmarker}\nProfessor C: But do you have numbers in terms of word error rates on {disfmarker} on Italian ? So just so you have some sense of reference ?\nPhD D: Yeah . Uh , so , it 's , uh , three point , uh , eight .\nProfessor C: Uh - huh .\nPhD D: Am I right ?\nPhD B: Oh , OK . Yeah , right , OK .\nPhD D: And then , uh , d uh , nine point , uh , one .\nProfessor C: Mm - hmm .\nPhD D: And finally , uh , sixteen point five .\nProfessor C: And this is , um , spectral subtraction plus what ?\nPhD D: Plus {disfmarker} plus nonlinear smoothing . Well , it 's {disfmarker} the system {disfmarker} it 's exactly the sys the same system as Sunil tried ,\nProfessor C: On - line normalization and LDA ?\nPhD D: but {disfmarker}\nProfessor C: Yeah . Yeah .\nPhD D: Yeah . But instead of double stage Wiener filtering , it 's {disfmarker} it 's this smoothed spectral subtraction . Um , yeah .\nPhD A: What is it the , um , France Telecom system uses\nProfessor C: Right .\nPhD A: for {disfmarker} Do they use spectral subtraction , or Wiener filtering , or {disfmarker} ?\nPhD B: They use spectral subtraction , right .\nPhD D: For what ?\nPhD B: French Telecom .\nPhD D: It {disfmarker} it 's Wiener filtering ,\nPhD B: Oh , it 's {disfmarker} it 's Wiener filtering .\nPhD D: am I right ?\nPhD A: Oh .\nPhD B: Sorry .\nPhD D: Well , it 's some kind of Wiener filtering {disfmarker}\nPhD B: Yeah , filtering . Yeah , it 's not exactly Wiener filtering but some variant of Wiener filtering .\nPhD D: Yeah .\nPhD A: I see .\nPhD B: Yeah .\nProfessor C: Yeah , plus , uh , I guess they have some sort of cepstral normalization , as well .\nPhD B: s They have like {disfmarker} yeah , th the {disfmarker} just noise compensation technique is a variant of Wiener filtering ,\nPhD D: Mm - hmm .\nPhD B: plus they do some {disfmarker} some smoothing techniques on the final filter . The {disfmarker} th they actually do the filtering in the time domain .\nPhD A: Mmm .\nPhD D: Yeah .\nPhD A: Hmm .\nPhD B: So they would take this HF squared back , taking inverse Fourier transform . And they convolve the time domain signal with that .\nPhD A: Oh , I see .\nPhD B: And they do some smoothing on that final filter , impulse response .\nPhD A: Hmm .\nPhD D: But they also have two {disfmarker} two different smoothing @ @ .\nPhD B: I mean , I 'm {disfmarker} I 'm @ @ .\nPhD D: One in the time domain and one in the frequency domain by just taking the first , um , coefficients of the impulse response .\nPhD B: But .\nPhD D: So , basically it 's similar . I mean , what you did , it 's similar\nPhD B: It 's similar in the smoothing and {disfmarker}\nPhD D: because you have also two {disfmarker} two kind of smoothing .\nPhD B: Yeah .\nPhD D: One in the time domain , and one in the frequency domain ,\nPhD B: Yeah . The frequency domain .\nPhD D: yeah .\nPhD A: Does the smoothing in the time domain help {disfmarker}\nPhD D: Um {disfmarker}\nPhD A: Well , do you get this musical noise stuff with Wiener filtering or is that only with , uh , spectral subtraction ?\nPhD B: No , you get it with Wiener filtering also .\nPhD D: Yeah .\nPhD A: Does the smoothing in the time domain help with that ? Or some other smoothing ?\nPhD B: Oh , no , you still end up with zeros in the s spectrum . Sometimes .\nPhD D: Yeah .\nPhD A: Hmm .\nProfessor C: I mean , it 's not clear that these musical noises hurt us in recognition .\nPhD A: Hmm .\nProfessor C: We don't know if they do .\nPhD B: Yeah .\nProfessor C: I mean , they {disfmarker} they sound bad .\nPhD A: Mm - hmm .\nPhD B: Yeah , I know .\nProfessor C: But we 're not listening to it , usually .\nPhD D: Mm - hmm .\nPhD A: Hmm .\nPhD D: Uh , actually the {disfmarker} the smoothing that I did {disfmarker} do here reduced the musical noise . Well , it {disfmarker}\nPhD B: Mm - hmm . Yeah , yeah ,\nPhD D: Mmm .\nPhD B: the {disfmarker}\nPhD D: Well , I cannot {disfmarker} you cannot hear beca well , actually what I d did not say is that this is not in the FFT bins . This is in the mel frequency bands . Um {disfmarker} So , it could be seen as a f a {disfmarker} a smoothing in the frequency domain because I used , in ad mel bands in addition and then the other phase of smoothing in the time domain . Mmm . But , when you look at the spectrogram , if you don't have an any smoothing , you clearly see , like {disfmarker} in silence portions , and at the beginning and end of speech , you see spots of high energy randomly distributed over the {disfmarker} the spectrogram .\nPhD A: Mm - hmm . Mm - hmm .\nPhD D: Um {disfmarker}\nPhD A: That 's the musical noise ?\nPhD D: Which is musical noise ,\nPhD A: Mm - hmm .\nPhD D: yeah , if {disfmarker} if it {disfmarker} If you listen to it {disfmarker} uh , if you do this in the FFT bins , then you have spots of energy randomly distributing . And if you f if you re - synthesize these spot sounds as , like , sounds ,\nPhD A: Mm - hmm .\nPhD D: uh {disfmarker}\nProfessor C: Well , none of these systems , by the way , have {disfmarker} I mean , y you both are {disfmarker} are working with , um , our system that does not have the neural net ,\nPhD D: And {disfmarker}\nPhD B: Yep .\nProfessor C: right ?\nPhD B: Yeah .\nPhD D: Mm - hmm .\nProfessor C: OK . So one would hope , presumably , that the neural net part of it would {disfmarker} would improve things further as {disfmarker} as they did before .\nPhD D: Yeah . Yeah . Um {disfmarker} Yeah , although if {disfmarker} if we , um , look at the result from the proposals , {comment} one of the reason , uh , the n system with the neural net was , um , more than {disfmarker} well , around five percent better , is that it was much better on highly mismatched condition . I 'm thinking , for instance , on the TI - digits trained on clean speech and tested on noisy speech .\nProfessor C: Mm - hmm .\nPhD D: Uh , for this case , the system with the neural net was much better .\nProfessor C: Mm - hmm .\nPhD D: But not much on the {disfmarker} in the other cases .\nProfessor C: Yeah .\nPhD D: And if we have no , uh , spectral subtraction or Wiener filtering , um , i the system is {disfmarker} Uh , we thought the neural {disfmarker} neural network is much better than before , even in these cases of high mismatch . So , maybe the neural net will help less but , um {disfmarker}\nProfessor C: Maybe .\nPhD A: Could you train a neural net to do spectral subtraction ?\nProfessor C: Yeah , it could do a nonlinear spectral subtraction\nPhD D: Mm - hmm .\nProfessor C: but I don't know if it {disfmarker} I mean , you have to figure out what your targets are .\nPhD A: Yeah , I was thinking if you had a clean version of the signal and {disfmarker} and a noisy version , and your targets were the M F - uh , you know , whatever , frequency bins {disfmarker}\nPhD D: Mm - hmm .\nProfessor C: Right .\nPhD D: Mm - hmm .\nProfessor C: Yeah , well , that 's not so much spectral subtraction then ,\nPhD D: Mm - hmm .\nProfessor C: but {disfmarker} but {disfmarker} but it 's {disfmarker} but at any rate , yeah , people , uh {disfmarker}\nPhD A: People do that ?\nProfessor C: y yeah , in fact , we had visitors here who did that I think when you were here ba way back when .\nPhD D: Mm - hmm .\nPhD A: Hmm .\nProfessor C: Uh , people {disfmarker} d done lots of experimentation over the years with training neural nets . And it 's not a bad thing to do . It 's another approach .\nPhD A: Hmm .\nProfessor C: M I mean , it 's {disfmarker} it , um {disfmarker}\nPhD D: Mm - hmm .\nProfessor C: The objection everyone always raises , which has some truth to it is that , um , it 's good for mapping from a particular noise to clean but then you get a different noise .\nPhD A: Mm - hmm .\nProfessor C: And the experiments we saw that visitors did here showed that it {disfmarker} there was at least some , um , {vocalsound} {comment} gentleness to the degradation when you switched to different noises . It did seem to help . So that {disfmarker} you 're right , that 's another {disfmarker} another way to go .\nPhD A: How did it compare on {disfmarker} I mean , for {disfmarker} for good cases where it {disfmarker} it {disfmarker} uh , stuff that it was trained on ? Did it do pretty well ?\nProfessor C: Oh , yeah , it did very well .\nPhD A: Mmm .\nProfessor C: Yeah .\nPhD A: Mmm .\nProfessor C: Um ,\nPhD D: Mm - hmm .\nProfessor C: but to some extent that 's kind of what we 're doing . I mean , we 're not doing exactly that , we 're not trying to generate good examples but by trying to do the best classifier you possibly can , for these little phonetic categories ,\nPhD A: Mm - hmm . You could say it 's sort of built in .\nProfessor C: It 's {disfmarker} Yeah , it 's kind of built into that .\nPhD A: Hmm .\nProfessor C: And {disfmarker} and that 's why we have found that it {disfmarker} it does help .\nPhD A: Mm - hmm .\nProfessor C: Um {disfmarker} so , um , yeah , I mean , we 'll just have to try it . But I {disfmarker} I would {disfmarker} I would {disfmarker} I would imagine that it will help some . I mean , it {disfmarker} we 'll just have to see whether it helps more or less the same , but I would imagine it would help some .\nPhD D: Mm - hmm .\nProfessor C: So in any event , all of this {disfmarker} I was just confirming that all of this was with a simpler system .\nPhD D: Yeah ,\nProfessor C: OK ?\nPhD D: yeah . Um , Yeah , so this is th the , um {disfmarker} Well , actually , this was kind of the first try with this spectral subtraction plus smoothing ,\nProfessor C: Mm - hmm .\nPhD D: and I was kind of excited by the result .\nProfessor C: Mm - hmm .\nPhD D: Um , then I started to optimize the different parameters . And , uh , the first thing I tried to optimize is the , um , time constant of the smoothing . And it seems that the one that I chose for the first experiment was the optimal one , so {vocalsound} uh ,\nProfessor C: It 's amazing how often that happens .\nPhD D: Um , so this is the first thing . Um {disfmarker} Yeah , another thing that I {disfmarker} it 's important to mention is , um , that this has a this has some additional latency . Um . Because when I do the smoothing , uh , it 's a recursion that estimated the means , so {disfmarker} of the g of the gain curve . And this is a filter that has some latency . And I noticed that it 's better if we take into account this latency . So , instead o of using the current estimated mean to , uh , subtract the current frame , it 's better to use an estimate that 's some somewhere in the future . Um {disfmarker}\nPhD A: And that 's what causes the latency ? OK .\nPhD B: You mean , the m the mean is computed o based on some frames in the future also ?\nProfessor C: Mm - hmm .\nPhD D: Yeah .\nPhD B: Or {disfmarker} or no ?\nPhD D: It 's the recursion , so it 's {disfmarker} it 's the center recursion , right ?\nPhD B: Mm - hmm .\nPhD D: Um {disfmarker} and the latency of this recursion is around fifty milliseconds .\nProfessor C: One five ?\nPhD D: \nProfessor C: One five ? Five zero ?\nPhD D: Five zero ,\nProfessor C: Five zero .\nPhD D: yeah .\nProfessor C: Yeah .\nPhD D: Um ,\nPhD B: I 'm sorry ,\nPhD D: mmm .\nPhD B: why {disfmarker} why is that delay coming ? Like , you estimate the mean ?\nPhD D: Yeah , the mean estimation has some delay , right ?\nPhD B: Oh , yeah .\nPhD D: I mean , the {disfmarker} the filter that {disfmarker} that estimates the mean has a time constant .\nPhD B: It isn't {disfmarker} OK , so it 's like it looks into the future also . OK .\nPhD D: Yeah .\nProfessor C: What if you just look into the past ?\nPhD D: It 's , uh , not as good . It 's not bad .\nProfessor C: How m by how much ?\nPhD D: Um , it helps a lot over the ba the baseline but , mmm {disfmarker}\nProfessor C: By how much ?\nPhD D: it {disfmarker} It 's around three percent , um , relative .\nProfessor C: Worse .\nPhD D: Yeah . Yeah . Um ,\nProfessor C: Hmm .\nPhD D: mmm {disfmarker} So , uh {disfmarker}\nProfessor C: It 's depending on how all this stuff comes out we may or may not be able to add any latency .\nPhD D: Yeah , but {disfmarker} Yeah . So , yeah , it depends . Uh , y actually , it 's {disfmarker} it 's l it 's three percent . Right . Mmm . Yeah , b but I don't think we have to worry too much on that right now while {disfmarker} you kno . Mm - hmm .\nProfessor C: Um , s Yeah , I mean , I think the only thing is that {disfmarker}\nPhD D: So {disfmarker}\nProfessor C: I would worry about it a little .\nPhD D: Mm - hmm .\nProfessor C: Because if we completely ignore latency , and then we discover that we really have to do something about it , we 're going to be {disfmarker} find ourselves in a bind .\nPhD D: Mm - hmm .\nProfessor C: So , um , you know , maybe you could make it twenty - five . You know what I mean ?\nPhD D: Yeah .\nProfessor C: Yeah , just , you know , just be {disfmarker} be a little conservative\nPhD D: Oh yes .\nProfessor C: because we may end up with this crunch where all of a sudden we have to cut the latency in half or something .\nPhD D: s Mm - hmm . Yeah .\nProfessor C: OK .\nPhD D: Um . So , yeah , there are other things in the , um , algorithm that I didn't , uh , @ @ a lot yet ,\nPhD A: Oh !\nPhD D: which {disfmarker}\nPhD A: Sorry . A quick question just about the latency thing . If {disfmarker} if there 's another part of the system that causes a latency of a hundred milliseconds , is this an additive thing ? Or c or is yours hidden in that ?\nPhD D: Mm - hmm .\nPhD A: Uh {disfmarker}\nPhD D: No , it 's {disfmarker} it 's added .\nPhD A: It 's additive . OK .\nPhD D: Mm - hmm .\nPhD B: We can {disfmarker} OK . We can do something in parallel also , in some like {disfmarker} some cases like , if you wanted to do voice activity detection .\nPhD A: Uh - huh .\nPhD B: And we can do that in parallel with some other filtering you can do .\nPhD D: Mmm .\nPhD B: So you can make a decision on that voice activity detection and then you decide whether you want to filter or not .\nPhD D: Yeah .\nPhD B: But by then you already have the sufficient samples to do the filtering .\nPhD A: Mm - hmm .\nPhD B: So {disfmarker} So , sometimes you can do it anyway .\nPhD A: I mean , couldn't , uh {disfmarker} I {disfmarker} Couldn't you just also {disfmarker} I mean , i if you know that the l the largest latency in the system is two hundred milliseconds , don't you {disfmarker} couldn't you just buffer up that number of frames and then everything uses that buffer ?\nPhD B: Yeah .\nPhD A: And that way it 's not additive ?\nProfessor C: Well , in fact , everything is sent over in buffers cuz of {disfmarker} isn't it the TCP buffer some {disfmarker} ?\nPhD B: You mean , the {disfmarker} the data , the super frame or something ?\nPhD D: Mm - hmm .\nProfessor C: Yeah , yeah .\nPhD D: Yeah .\nPhD B: Yeah , but that has a variable latency because the last frame doesn't have any latency\nPhD D: Mm - hmm .\nPhD B: and first frame has a twenty framed latency . So you can't r rely on that latency all the time .\nProfessor C: Yeah .\nPhD B: Because {disfmarker} I mean the transmission over {disfmarker} over the air interface is like a buffer .\nPhD D: Yeah .\nPhD B: Twenty frame {disfmarker}\nPhD A: Yeah .\nPhD B: twenty four frames .\nPhD A: Yeah .\nPhD B: So {disfmarker} But the only thing is that the first frame in that twenty - four frame buffer has a twenty - four frame latency . And the last frame doesn't have any latency .\nPhD A: Mm - hmm .\nPhD B: Because it just goes as {disfmarker}\nPhD A: Yeah , I wasn't thinking of that one in particular\nPhD B: Yeah .\nPhD A: but more of , you know , if {disfmarker} if there is some part of your system that has to buffer twenty frames , uh , can't the other parts of the system draw out of that buffer and therefore not add to the latency ?\nProfessor C: Yeah . Yeah . And {disfmarker} and that 's sort of one of the {disfmarker} all of that sort of stuff is things that they 're debating in their standards committee .\nPhD A: Oh ! Hmm .\nPhD D: Mm - hmm . Yeah . So , um , there is uh , {comment} these parameters that I still have to {disfmarker} to look at . Like , I played a little bit with this overestimation factor , uh , but I still have to {disfmarker} to look more at this , um , at the level of noise I add after . Uh , I know that adding noise helped , um , the system just using spectral subtraction without smoothing , but I don't know right now if it 's still important or not , and if the level I choose before is still the right one . Same thing for the shape of the {disfmarker} the noise . Maybe it would be better to add just white noise instead of speech shaped noise .\nProfessor C: That 'd be more like the JRASTA thing in a sense . Yeah .\nPhD D: Mm - hmm . Um , yep . Uh , and another thing is to {disfmarker} Yeah , for this I just use as noise estimate the mean , uh , spectrum of the first twenty frames of each utterance . I don't remember for this experiment what did you use for these two stage {disfmarker}\nPhD B: I used ten {disfmarker} just ten frames . Yeah , because {disfmarker}\nPhD D: The ten frames ?\nPhD B: I mean , the reason was like in TI - digits I don't have a lot . I had twenty frames most of the time .\nPhD D: Mm - hmm . Um . But , so what 's this result you told me about , the fact that if you use more than ten frames you can {disfmarker} improve by t\nPhD B: Well , that 's {disfmarker} that 's using the channel zero . If I use a channel zero VAD to estimate the noise .\nPhD D: Oh , OK .\nPhD B: Which {disfmarker}\nPhD D: But this is ten frames plus {disfmarker} plus\nPhD B: Channel zero dropping .\nPhD D: channel {disfmarker}\nPhD B: Hmm .\nPhD D: Uh , no , these results with two stage Wiener filtering is ten frames\nPhD B: t Oh , this {disfmarker}\nPhD D: but possibly more . I mean , if channel one VAD gives you {disfmarker}\nPhD B: f Yeah . Mm - hmm . Yeah .\nPhD D: Yeah . OK . Yeah , but in this experiment I did {disfmarker} I didn't use any VAD . I just used the twenty first frame to estimate the noise . And {disfmarker} So I expected it to be a little bit better , {vocalsound} if , uh , I use more {disfmarker} more frames . Um . OK , that 's it for spectral subtraction . The second thing I was working on is to , um , try to look at noise estimation , {comment} mmm , and using some technique that doesn't need voice activity detection . Um , and for this I u simply used some code that , uh , {vocalsound} I had from {disfmarker} from Belgium , which is technique that , um , takes a bunch of frame , um , and for each frequency bands of this frame , takes a look at the minima of the energy . And then average these minima and take this as an {disfmarker} an energy estimate of the noise for this particular frequency band . And there is something more to this actually . What is done is that , {vocalsound} uh , these minima are computed , um , based on , um , high resolution spectra . So , I compute an FFT based on the long , uh , signal frame which is sixty - four millisecond {disfmarker}\nPhD A: So you have one minimum for each frequency ?\nPhD D: What {disfmarker} what I {disfmarker} what I d uh , I do actually , is to take a bunch of {disfmarker} to take a tile on the spectrogram and this tile is five hundred milliseconds long and two hundred hertz wide .\nPhD A: Mmm .\nPhD D: And this tile {disfmarker} Uh , in this tile appears , like , the harmonics if you have a voiced sound , because it 's {disfmarker} it 's the FTT bins . And when you take the m the minima of {disfmarker} of these {disfmarker} this tile , when you don't have speech , these minima will give you some noise level estimate , If you have voiced speech , these minima will still give you some noise estimate because the minima are between the harmonics . And {disfmarker} If you have other {disfmarker} other kind of speech sounds then it 's not the case , but if the time frame is long enough , uh , like s five hundred milliseconds seems to be long enough , {comment} you still have portions which , uh , are very close {disfmarker} whi which minima are very close to the noise energy .\nProfessor C: I 'm confused . You said five hundred milliseconds\nPhD D: Mmm ?\nProfessor C: but you said sixty - four milliseconds . Which is which ? What ?\nPhD D: Sixty - four milliseconds is to compute the FFT , uh , bins .\nProfessor C: Yeah ,\nPhD D: The {disfmarker} the FFT .\nProfessor C: yeah .\nPhD D: Um , actually it 's better to use sixty - four milliseconds because , um , if you use thirty milliseconds , then , uh , because of the {disfmarker} this short windowing and at low pitch , uh , sounds , {vocalsound} the harmonics are not , wha uh , correctly separated .\nProfessor C: Mm - hmm .\nPhD D: So if you take these minima , it {disfmarker} b {vocalsound} they will overestimate the noise a lot .\nProfessor C: So you take sixty - four millisecond F F Ts and then you average them {comment} over five hundred ? Or {disfmarker} ? Uh , what do you do over five hundred ?\nPhD D: So I take {disfmarker} to {disfmarker} I take a bunch of these sixty - four millisecond frame to cover five hundred milliseconds ,\nProfessor C: Ah . OK .\nPhD D: and then I look for the minima ,\nPhD A: Mmm .\nProfessor C: I see .\nPhD D: on the {disfmarker} on {disfmarker} on the bunch of uh fifty frames , right ?\nProfessor C: I see .\nPhD D: Mmm . So the interest of this is that , as y with this technique you can estimate u some reasonable noise spectra with only five hundred milliseconds of {disfmarker} of signal , so if the {disfmarker} the n the noise varies a lot , uh , you can track {disfmarker} better track the noise ,\nProfessor C: Mm - hmm .\nPhD D: which is not the case if you rely on the voice activity detector . So even if there are no no speech pauses , you can track the noise level . The only requirement is that you must have , in these five hundred milliseconds segment , {comment} you must have voiced sound at least . Cuz this {disfmarker} these will help you to {disfmarker} to track the {disfmarker} the noise level . Um . So what I did is just to simply replace the VAD - based , uh , noise estimate by this estimate , first on SpeechDat - Car {disfmarker} Well , only on SpeechDat - Car actually . And it 's , uh , slightly worse , like one percent relative compared to the VAD - based {pause} estimates . Um , I think the reason why it 's not better , is that the SpeechDat - Car noises are all stationary . Um . So , u y y there really is no need to have something that 's adaptive\nProfessor C: Mm - hmm .\nPhD D: and {disfmarker} Uh , well , they are mainly stationary . Um . But , I expect s maybe some improvement on TI - digits because , nnn , in this case the noises are all sometimes very variable . Uh , so I have to test it . Mmm .\nProfessor C: But are you comparing with something {disfmarker} e I 'm {disfmarker} I 'm {disfmarker} p s a little confused again , i it {disfmarker} Uh , when you compare it with the V A D - based ,\nPhD D: Mm - hmm .\nProfessor C: VAD - Is this {disfmarker} is this the {disfmarker} ?\nPhD D: It 's {disfmarker} It 's the France - Telecom - based spectra , s uh , Wiener filtering and VAD . So it 's their system but just I replace their noise estimate by this one .\nProfessor C: Oh , you 're not doing this with our system ?\nPhD D: In i I 'm not {disfmarker} No , no . Yeah , it 's our system but with just the Wiener filtering from their system . Right ? Mmm .\nProfessor C: OK .\nPhD D: Yeah . Actually , th the best system that we still have is , uh , our system but with their noise compensation scheme , right ?\nProfessor C: Right . But {disfmarker}\nPhD D: So I 'm trying to improve on this , and {disfmarker} by {disfmarker} by replacing their noise estimate by , uh , something that might be better .\nProfessor C: OK . But the spectral subtraction scheme that you reported on also re requires a {disfmarker} a noise estimate .\nPhD D: Yeah . Yeah .\nProfessor C: Couldn't you try this for that ?\nPhD D: But I di\nProfessor C: Do you think it might help ?\nPhD D: Not yet , because I did this in parallel ,\nProfessor C: I see ,\nPhD D: and I was working on one and the other .\nProfessor C: I see . Yeah .\nPhD D: Um ,\nPhD B: Yeah .\nPhD D: Yeah , for {disfmarker} for sure I will . I can try also , mmm , the spectral subtraction .\nPhD B: So I 'm also using that n new noise estimate technique on this Wiener filtering what I 'm trying .\nProfessor C: OK .\nPhD B: So I {disfmarker} I have , like , some experiments running , I don't have the results .\nPhD D: Mm - hmm .\nProfessor C: Yeah .\nPhD B: So .\nProfessor C: Yeah .\nPhD B: I don't estimate the f noise on the ten frames but use his estimate .\nProfessor C: Yeah .\nPhD D: Mm - hmm . Um . Yeah . I , um , also implemented a sp um {disfmarker} spectral whitening idea which is in the , um , Ericsson proposal . Uh , the idea is just to {vocalsound} um , flatten the log , uh , spectrum , um , and to flatten it more if the {disfmarker} the probability of silence is higher . So in this way , you can also reduce {disfmarker} somewhat reduce the musical noise and you reduce the variability if you have different noise shapes , because the {disfmarker} the spectrum becomes more flat in the silence portions . Um . Yeah . With this , no improvement , uh , but there are a lot of parameters that we can play with and , um {disfmarker} Actually , this {disfmarker} this could be seen as a soft version of the frame dropping because , um , you could just put the threshold and say that \" below the threshold , I will flatten {disfmarker} comp completely flatten the {disfmarker} the spectrum \" . And above this threshold , uh , keep the same spectrum . So it would be like frame dropping , because during the silence portions which are below the threshold of voice activity probability , {comment} uh , w you would have some kind of dummy frame which is a perfectly flat spectrum . And this , uh , whitening is something that 's more soft because , um , you whiten {disfmarker} you just , uh , have a function {disfmarker} the whitening is a function of the speech probability , so it 's not a hard decision .\nProfessor C: Mm - hmm .\nPhD D: Um , so I think maybe it can be used together with frame dropping and when we are not sure about if it 's speech or silence , well , maybe it has something do with this .\nProfessor C: It 's interesting . I mean , um , you know , in {disfmarker} in JRASTA we were essentially adding in , uh , white {disfmarker} uh , white noise dependent on our estimate of the noise .\nPhD D: Mm - hmm .\nProfessor C: On the overall estimate of the noise . Uh , I think it never occurred to us to use a probability in there .\nPhD D: Mm - hmm .\nProfessor C: You could imagine one that {disfmarker} that {disfmarker} that made use of where {disfmarker} where the amount that you added in was , uh , a function of the probability of it being s speech or noise .\nPhD D: Mm - hmm . Mm - hmm . Yeah , w Yeah , right now it 's a constant that just depending on the {disfmarker} the noise spectrum .\nPhD B: There 's {disfmarker}\nProfessor C: Yeah .\nPhD D: Mm - hmm . Mm - hmm .\nProfessor C: Cuz that {disfmarker} that brings in sort of powers of classifiers that we don't really have in , uh , this other estimate . So it could be {disfmarker} it could be interesting .\nPhD D: Mm - hmm . Mm - hmm .\nProfessor C: What {disfmarker} what {disfmarker} what point does the , uh , system stop recording ? How much {disfmarker}\nPhD A: It 'll keep going till {disfmarker} I guess when they run out of disk space ,\nProfessor C: It went a little long ? I mean , disk {disfmarker}\nPhD A: but {disfmarker} I think we 're OK .\nPhD D: So .\nProfessor C: OK .\nPhD D: Yeah . Uh {disfmarker} Yeah , so there are {disfmarker} with this technique there are some {disfmarker} I just did something exactly the same as {disfmarker} as the Ericsson proposal but , um , {vocalsound} the probability of speech is not computed the same way . And I think , i for {disfmarker} yeah , for a lot of things , actually a g a good speech probability is important . Like for frame dropping you improve , like {disfmarker} you can improve from ten percent as Sunil showed , if you use the channel zero speech probabilities .\nProfessor C: Mm - hmm . Mm - hmm .\nPhD D: For this it might help , um {disfmarker}\nProfessor C: Mm - hmm .\nPhD D: S so , yeah . Uh , so yeah , the next thing I started to do is to , {vocalsound} uh , try to develop a better voice activity detector . And , um {disfmarker} I d um {disfmarker} yeah , for this I think we can maybe try to train the neural network for voice activity detection on all the data that we have , including all the SpeechDat - Car data . Um {disfmarker} And so I 'm starting to obtain alignments on these databases . Um , and the way I mi I do that is that I just use the HTK system but I train it only on the close - talking microphone . And then I aligned {disfmarker} I obtained the Viterbi alignment of the training utterances . Um {disfmarker} It seems to be , uh i Actually what I observed is that for Italian it doesn't seem {disfmarker} Th - there seems to be a problem .\nPhD B: No . So , it doesn't seems to help by their use of channel zero or channel one .\nPhD D: Well . Because {disfmarker} What ?\nPhD B: Uh , you mean their d the frame dropping , right ? Yeah , it doesn't {disfmarker}\nPhD D: Yeah . Yeah . So , u but actually the VAD was trained on Italian also ,\nPhD B: Italian .\nPhD D: so {disfmarker} Um , the c the current VAD that we have was trained on , uh , t SPINE , right ?\nPhD B: TI - digits .\nPhD D: Italian , and TI - digits with noise and {disfmarker}\nPhD B: \nPhD D: Uh , yeah . And it seems to work on Italian but not on the Finnish and Spanish data . So , maybe one reason is that s s Finnish and Spanish noise are different . And actually we observed {disfmarker} we listened to some of the utterances and sometimes for Finnish there is music in the recordings and strange things , right ?\nPhD B: Yeah .\nPhD D: Um {disfmarker} Yeah , so the idea was to train all the databases and obtain an alignment to train on these databases , and , um , also to , um , try different kind of features , {vocalsound} uh , as input to the VAD network . And we came up with a bunch of features that we want to try like , um , the spectral slope , the , um , the degree o degree of voicing with the features that , uh , we started to develop with Carmen , um , e with , uh , the correlation between bands and different kind of features ,\nPhD B: Yeah . Mm - hmm .\nPhD D: and {disfmarker} Yeah .\nPhD B: The energy also .\nPhD D: The energy .\nPhD B: Yeah .\nProfessor C: Yeah , right .\nPhD D: Yeah . Of course . Yeah .\nProfessor C: OK . Well , Hans - Guenter will be here next week so I think he 'll be interested in all {disfmarker} all of these things . And , so .\nPhD D: Mm - hmm .\nProfessor C: Mmm .\nPhD A: OK , shall we , uh , do digits ?\nProfessor C: Yeah .\nPhD A: Want to go ahead , Morgan ?\nProfessor C: Sure .\nPhD A: OK .", "source": "meeting_summ", "evaluation": "rouge"}
{"instructions": ["Summarize the details about setting up the wizard and recruiting participants", "What did Grad D and Grad C discuss about who was acting as the computer and wizard?", "What did the Professor think about hiring Fey?", "Summarize the discussion about controlling size of combinatorial input", "What did the Professor think about controlling the size of the combinatorial input?", "What did Grad D think about managing the size of the combinatorial input?", "Summarize the meeting"], "outputs": ["The team listened to a recording of the interface's trial run. Litonya was asked to be the first subject of the interface and Fey acted as the wizard. The team was happy with Fey's performance and decided to hire her. Upon Fey's suggestion, they also decided that the wizard should be introduced in a more appropriate fashion. The team also agreed that the run was too long at 5 minutes.", "Grad C was concerned that the same person acting as the wizard and computer system might not be the best idea. Grad D had some way of making the wizard and computer seem distinct even though both were voiced by the same person and told Grad C that the recording would clarify things.", "The Professor was very supportive of the idea of hiring Fey. He thought that it would be helpful since she was also willing to take over the task of organizing subjects. In addition, he believed the project would provide her with a valuable learning experience for her own upcoming graduate school work in experimental paradigms.", "The team was concerned that the combinatorial input that would result from the various linguistic and contextual schemas would be enormous for the Bayes net. The Professor suggested that it's best to narrow down the decision variables, perhaps by studying the trade-offs between different input factors. The team thought that perhaps they could keep the kinds of objects in the environment to a small subset and make rules governing actions around those objects.", "The professor was the one to raise the issue and suggested that a knowledge engineering trick could be used to narrow down inputs. He thought that perhaps adding deterministic rules to properties that have actions would be helpful and the property types could be retrieved from the ontology.", "Grad D thought that the best way would be to add restrictive action types that are attached to the kind of object. For instance, there are specific actions that would be relevant to a landmark.", "The team began the meeting by discussing the logistics of setting up the interface for data collection. Some members ran a trial of it earlier and found someone who would make a suitable wizard. The team shared concern about how they would recruit non-university student participants. Grad D introduced the team to the second iteration of the bayes-net model and its schemas. Then, the discussion moved onto controlling the size of the bayes-net as it would otherwise be based on too much information. The team ended the meeting by delving into how the method of creating a Bayes-net in different scenarios could itself be abstracted, i.e. narrowing the input and output factors and the intermediate representation."], "input": "Grad A: Hey , you 're not supposed to be drinking in here dude .\nGrad D: OK .\nGrad A: Do we have to read them that slowly ? OK . Sounded like a robot . Um , this is t\nGrad C: OK .\nGrad A: When you read the numbers it kind of reminded me of beat poetry .\nGrad D: I tried to go for the EE Cummings sort of feeling , but {disfmarker}\nGrad A: Three three six zero zero . Four two zero zero one seven . That 's what I think of when I think of beat poetry .\nGrad C: Beat poetry .\nGrad A: You ever seen \" So I married an axe murderer \" ?\nGrad C: Uh parts of it .\nGrad D: Mm - hmm .\nGrad A: There 's a part wh there 's parts when he 's doing beat poetry .\nGrad C: Oh yeah ?\nGrad A: And he talks like that . That 's why I thi That uh probably is why I think of it that way .\nGrad D: Hmm . No , I didn't see that movie . Who did {disfmarker} who made that ?\nGrad A: Mike Meyers is the guy .\nGrad D: Oh . OK .\nGrad A: It - it 's his uh {disfmarker} it 's his cute romantic comedy . That 's {disfmarker} that 's {disfmarker} That 's his cute romantic comedy , yeah . The other thing that 's real funny , I 'll spoil it for you . is when he 's {disfmarker} he works in a coffee shop , in San Francisco , and uh he 's sitting there on this couch and they bring him this massive cup of espresso , and he 's like \" excuse me I ordered the large espresso ? \"\nGrad D: Uh . We 're having , {vocalsound} a tiramisu tasting contest this weekend .\nGrad A: Wait {disfmarker} do are y So you 're trying to decide who 's the best taster of tiramisu ?\nGrad D: No ? Um . There was a {disfmarker} a {disfmarker} a fierce argument that broke out over whose tiramisu might be the best and so we decided to have a contest where those people who claim to make good tiramisu make them ,\nGrad A: Ah .\nGrad D: and then we got a panel of impartial judges that will taste {disfmarker} do a blind taste {vocalsound} and then vote .\nGrad A: Hmm .\nGrad D: Should be fun .\nGrad A: Seems like {disfmarker} Seems like you could put a s magic special ingredient in , so that everyone know which one was yours . Then , if you were to bribe them , you could uh {disfmarker}\nGrad D: Mm - hmm . Well , I was thinking if um {disfmarker} y you guys have plans for Sunday ? We 're {disfmarker} we 're not {disfmarker} it 's probably going to be this Sunday , but um we 're sort of working with the weather here because we also want to combine it with some barbecue activity where we just fire it up and what {disfmarker} whoever brings whatever you know , can throw it on there . So only the tiramisu is free , nothing else .\nGrad A: Well , I 'm going back to visit my parents this weekend , so , I 'll be out of town .\nGrad D: So you 're going to the west Bay then ? No ,\nGrad A: No , the South Bay ,\nGrad D: south Bay ?\nGrad A: yeah .\nGrad D: South Bay .\nGrad C: Well , I should be free , so .\nGrad D: OK , I 'll let you know .\nGrad C: OK .\nGrad A: We are . Is Nancy s uh gonna show up ? Mmm . Wonder if these things ever emit a very , like , piercing screech right in your ear ?\nGrad D: They are gonna get more comfortable headsets . They already ordered them . OK .\nGrad C: Uh {disfmarker}\nGrad D: Let 's get started . The uh {disfmarker} Should I go first , with the uh , um , data . Can I have the remote {vocalsound} control . Thank you . OK . So . On Friday we had our wizard test data test and um {vocalsound} these are some of the results . This was the introduction . I actually uh , even though Liz was uh kind enough to offer to be the first subject , I sort of felt that she knew too much , so I asked uh Litonya . just on the spur of the moment , and she was uh kind enough to uh serve as the first subject .\nProfessor B: Mm - hmm .\nGrad D: So , this is what she saw as part of {disfmarker} as uh for instr introduction , this is what she had to read {pause} aloud . Uh , that was really difficult for her and uh {disfmarker}\nGrad C: Because of l all the names , you mean ?\nGrad D: The names and um this was the uh first three tasks she had to {disfmarker} to master after she called the system , and um then of course the system broke down , and those were the l uh uh I should say the system was supposed to break down and then um these were the remaining three tasks that she was going to solve , with a human {disfmarker} Um . There are {disfmarker} here are uh the results . Mmm . And I will not {disfmarker} We will skip the reading now . D Um . And um . The reading was five minutes , exactly . And now comes the {disfmarker} This is the phone - in phase of {disfmarker}\nGrad C: Wait , can I {disfmarker} I have a question . So . So there 's no system , right ? Like , there was a wizard for both uh {disfmarker} both parts , is this right ?\nGrad D: Yeah . It was bo it both times the same person .\nGrad C: OK .\nGrad D: One time , pretending to be a system , one time , to {disfmarker} pretending to be a human , which is actually not pretending .\nGrad C: OK . And she didn't {disfmarker}\nGrad D: I should {disfmarker}\nGrad C: I mean . Well . Isn't this kind of obvious when it says \" OK now you 're talking to a human \" and then the human has the same voice ?\nGrad D: No no no . We u Wait . OK , good question , but uh you {disfmarker} you just wait and see .\nGrad C: OK .\nGrad D: It 's {disfmarker} You 're gonna l learn . And um the wizard sometimes will not be audible , Because she was actually {disfmarker} they {disfmarker} there was some uh lapse in the um wireless , we have to move her closer .\nGrad A: Is she mispronouncing \" Anlage \" ? Is it \" Anlaga \" or \" Anlunga \"\nGrad D: They 're mispronouncing everything ,\nGrad A: OK .\nGrad D: but it 's {disfmarker} This is the system breaking down , actually . \" Did I call Europe ? \" So , this is it . Well , if we {disfmarker} we um\nProfessor B: So , are {disfmarker} are you trying to record this meeting ?\nGrad D: There was a strange reflex . I have a headache . I 'm really sort of out of it . OK , the uh lessons learned . The reading needs to be shorter . Five minutes is just too long . Um , that was already anticipated by some people suggested that if we just have bullets here , they 're gonna not {disfmarker} they 're {disfmarker} subjects are probably not gonna {disfmarker} going to follow the order . And uh she did not .\nGrad C: Really ?\nGrad D: She {disfmarker} No .\nGrad C: Oh , it 's surprising .\nGrad D: She {disfmarker} she jumped around quite a bit .\nProfessor B: S so if you just number them \" one \" , \" two \" , \" three \" it 's\nGrad D: Yeah , and make it sort of clear in the uh {disfmarker}\nProfessor B: OK . Right .\nGrad D: Um . We need to {disfmarker} So that 's one thing . And we need a better introduction for the wizard . That is something that Fey actually thought of a {disfmarker} in the last second that sh the system should introduce itself , when it 's called .\nProfessor B: Mm - hmm . True .\nGrad D: And um , um , another suggestion , by Liz , was that we uh , through subjects , switch the tasks . So when {disfmarker} when they have task - one with the computer , the next person should have task - one with a human , and so forth .\nProfessor B: Mm - hmm .\nGrad D: So we get nice um data for that . Um , we have to refine the tasks more and more , which of course we haven't done at all , so far , in order to avoid this rephrasing , so where , even though w we don't tell the person \" ask {pause} blah - blah - blah - blah - blah \" they still try , or at least Litonya tried to um repeat as much of that text as possible .\nGrad C: Say exactly what 's on there ? Yeah .\nGrad D: And uh my suggestion is of course we {disfmarker} we keep the wizard , because I think she did a wonderful job ,\nProfessor B: Great .\nGrad D: in the sense that she responded quite nicely to things that were not asked for , \" How much is a t a bus ticket and a transfer \" so this is gonna happen all the time , we d you can never be sure .\nProfessor B: Mm - hmm .\nGrad D: Um . Johno pointed out that uh we have maybe a grammatical gender problem there with wizard .\nGrad A: Yes .\nGrad D: So um .\nGrad A: I wasn't {disfmarker} wasn't sure whether wizard was the correct term for {pause} uh \" not a man \" .\nGrad C: There 's no female equivalent of {disfmarker}\nGrad D: But uh {disfmarker}\nGrad A: Are you sure ?\nGrad C: No , I don't know .\nProfessor B: Right .\nGrad C: Not that I know of .\nGrad D: Well , there is witch and warlock ,\nGrad A: Yeah , that 's so @ @ .\nProfessor B: Right .\nGrad C: Yeah , that 's what I was thinking , but {disfmarker}\nGrad D: and uh {disfmarker}\nProfessor B: Right . Uh .\nGrad D: OK . And um {disfmarker} So , some {disfmarker} some work needs to be done , but I think we can uh {disfmarker} And this , and {disfmarker} in case no {disfmarker} you hadn't seen it , this is what Litonya looked at during the uh {disfmarker} um while taking the {disfmarker} while partaking in the data collection .\nGrad C: Ah .\nProfessor B: OK , great . So {pause} first of all , I agree that um we should hire Fey , and start paying her . Probably pay for the time she 's put in as well . Um , do you know exactly how to do that , or is uh Lila {disfmarker} I mean , you know what exactly do we do to {disfmarker} to put her on the payroll in some way ?\nGrad D: I 'm completely clueless , but I 'm willing to learn .\nProfessor B: OK . Well , you 'll have to . Right . So anyway , um\nGrad D: N\nProfessor B: So why don't you uh ask Lila and see what she says about you know exactly what we do for someone in th\nGrad D: Student - type worker ,\nProfessor B: Well , yeah she 's un she 's not a {disfmarker} a student ,\nGrad D: or {disfmarker} ?\nProfessor B: she just graduated but anyway .\nGrad D: Hmm .\nProfessor B: So i if {disfmarker} Yeah , I agree , she sounded fine , she a actually was {pause} uh , more uh , present and stuff than {disfmarker} than she was in conversation , so she did a better job than I would have guessed from just talking to her .\nGrad D: Yeah .\nProfessor B: So I think that 's great .\nGrad D: This is sort of what I gave her , so this is for example h how to get to the student prison ,\nProfessor B: Yeah .\nGrad D: and I didn't even spell it out here and in some cases I {disfmarker} I spelled it out a little bit um more thoroughly ,\nProfessor B: Right .\nGrad D: this is the information on {disfmarker} on the low sunken castle , and the amphitheater that never came up , and um , so i if we give her even more um , instruments to work with I think the results are gonna be even better .\nProfessor B: Oh , yeah , and then of course as she does it she 'll {disfmarker} she 'll learn @ @ .  So that 's great . Um {pause} And also if she 's willing to take on the job of organizing all those subjects and stuff that would be wonderful .\nGrad D: Mmm .\nProfessor B: And , uh she 's {disfmarker} actually she 's going to graduate school in a kind of an experimental paradigm , so I think this is all just fine in terms of h her learning things she 's gonna need to know uh , to do her career .\nGrad D: Mmm .\nProfessor B: So , I {disfmarker} my guess is she 'll be r r quite happy to take on that job . And , so {disfmarker}\nGrad D: Yep . Yeah she {disfmarker} she didn't explicitly state that so .\nProfessor B: Great .\nGrad D: And um I told her that we gonna um figure out a meeting time in the near future to refine the tasks and s look for the potential sources to find people . She also agrees that you know if it 's all just gonna be students the data is gonna be less valuable because of that so .\nProfessor B: Well , as I say there is this s set of people next door , it 's not hard to\nGrad D: We 're already {disfmarker} Yeah .\nProfessor B: uh {disfmarker}\nGrad D: However , we may run into a problem with a reading task there . And um , we 'll see .\nProfessor B: Yeah . We could talk to the people who run it and um see if they have a way that they could easily uh tell people that there 's a task , pays ten bucks or something ,\nGrad D: Mm - hmm . Yeah .\nProfessor B: but um you have to be comfortable reading relatively complicated stuff . And {disfmarker} and there 'll probably be self - selection to some extent .\nGrad D: Mmm . Yep .\nProfessor B: Uh , so that 's good . Um . Now , {pause} I signed us up for the Wednesday slot , and part of what we should do is this .\nGrad D: OK .\nProfessor B: So , my idea on that was {pause} uh , partly we 'll talk about system stuff for the computer scientists , but partly I did want it to get the linguists involved in some of this issue about what the task is and all {disfmarker} um you know , what the dialogue is , and what 's going on linguistically , because to the extent that we can get them contributing , that will be good . So this issue about you know re - formulating things ,\nGrad D: Yep .\nProfessor B: maybe we can get some of the linguists sufficiently interested that they 'll help us with it , uh , other linguists , if you 're a linguist , but in any case ,\nGrad D: Yep .\nProfessor B: um , the linguistics students and stuff . So my idea on {disfmarker} on Wednesday is partly to uh {disfmarker} you {disfmarker} I mean , what you did today would {disfmarker} i is just fine . You just uh do \" this is what we did , and here 's the {pause} thing , and here 's s some of the dialogue and {disfmarker} and so forth . \" But then , the other thing of course is we should um give the computer scientists some idea of {disfmarker} of what 's going on with the system design , and where we think the belief - nets fit in and where the pieces are and stuff like that . Is {disfmarker} is this {pause} make sense to everybody ?\nGrad D: Yep .\nProfessor B: Yeah . So , I don't {disfmarker} I don't think it 's worth a lot of work , particularly on your part , to {disfmarker} to {disfmarker} to make a big presentation . I don't think you should {disfmarker} you don't have to make any new {pause} uh PowerPoint or anything . I think we got plenty of stuff to talk about . And , then um just see how a discussion goes .\nGrad D: Mm - hmm . Sounds good . The uh other two things is um we 've {disfmarker} can have Johno tell us a little about this\nProfessor B: Great .\nGrad D: and we also have a l little bit on the interface , M - three - L enhancement , and then um that was it , I think .\nGrad A: So , what I did for this {disfmarker} this is {disfmarker} uh , a pedagogical belief - net because I was {disfmarker} I {disfmarker} I took {disfmarker} I tried to conceptually do what you were talking about with the nodes that you could expand out {disfmarker} so what I did was I took {disfmarker} I made these dummy nodes called Trajector - In and Trajector - Out that would isolate the things related to the trajector .\nProfessor B: Yep .\nGrad A: And then there were the things with the source and the path and the goal .\nProfessor B: Yep .\nGrad A: And I separated them out . And then I um did similar things for our {disfmarker} our net to {disfmarker} uh with the context and the discourse and whatnot , um , so we could sort of isolate them or whatever in terms of the {disfmarker} the top layer .\nProfessor B: Mm - hmm .\nGrad A: And then the bottom layer is just the Mode . So .\nProfessor B: So , let 's {disfmarker} let 's {disfmarker} Yeah , I don't understand it . Let 's go {disfmarker} Slide all the way up so we see what the p the p very bottom looks like , or is that it ?\nGrad A: Yeah , there 's just one more node and it says \" Mode \" which is the decision between the {disfmarker}\nGrad D: Yeah .\nProfessor B: OK , great . Alright .\nGrad A: So basically all I did was I took the last {pause} belief - net\nProfessor B: So {disfmarker} Mm - hmm .\nGrad A: and I grouped things according to what {disfmarker} how I thought they would fit in to uh image schemas that would be related . And the two that I came up with were Trajector - landmark and then Source - path - goal as initial ones .\nProfessor B: Yep . Mm - hmm .\nGrad A: And then I said well , uh the trajector would be the person in this case probably .\nProfessor B: Right , yep .\nGrad A: Um , you know , we have {disfmarker} we have the concept of what their intention was , whether they were trying to tour or do business or whatever ,\nProfessor B: Right .\nGrad A: or they were hurried . That 's kind of related to that . And then um in terms of the source , the things {disfmarker} uh the only things that we had on there I believe were whether {disfmarker} Oh actually , I kind of , {disfmarker} I might have added these cuz I don't think we talked too much about the source in the old one but uh whether the {disfmarker} where I 'm currently at is a landmark might have a bearing on whether {disfmarker}\nGrad D: Mm - hmm .\nGrad A: or the \" landmark - iness \" of where I 'm currently at . And \" usefulness \" is basi basically means is that an institutional facility like a town hall or something like that that 's not {disfmarker} something that you 'd visit for tourist 's {disfmarker} tourism 's sake or whatever . \" Travel constraints \" would be something like you know , maybe they said they can {disfmarker} they only wanna take a bus or something like that , right ? And then those are somewhat related to the path ,\nProfessor B: Mm - hmm .\nGrad A: so that would determine whether we 'd {disfmarker} could take {disfmarker} we would be telling them to go to the bus stop or versus walking there directly . Um , \" Goal \" . Similar things as the source except they also added whether the entity was closed and whether they have somehow marked that is was the final destination . Um , and then if you go up , Robert , Yeah , so {disfmarker} um , in terms of Context , what we had currently said was whether they were a businessman or a tourist of some other person . Um , Discourse was related to whether they had asked about open hours or whether they asked about where the entrance was or the admission fee , or something along those lines .\nProfessor B: Mm - hmm .\nGrad A: Uh , Prosody I don't really {disfmarker} I 'm not really sure what prosody means , in this context , so I just made up you know whether {disfmarker} whether what they say is {disfmarker} or h how they say it is {disfmarker} is that .\nProfessor B: Right , OK .\nGrad A: Um , the Parse would be what verb they chose , and then maybe how they modified it , in the sense of whether they said \" I need to get there quickly \" or whatever .\nProfessor B: Mm - hmm .\nGrad A: And um , in terms of World Knowledge , this would just basically be like opening and closing times of things , the time of day it is , and whatnot .\nGrad D: What 's \" tourbook \" ?\nGrad A: Tourbook ? That would be , I don't know , the \" landmark - iness \" of things ,\nGrad D: Mm - hmm .\nGrad A: whether it 's in the tourbook or not .\nProfessor B: Ch - ch - ch - ch . Now . Alright , so I understand what 's {disfmarker} what you got . I don't yet understand {pause} how you would use it . So let me see if I can ask\nGrad A: Well , this is not a working Bayes - net .\nProfessor B: a s Right . No , I understand that , but {disfmarker} but um So , what {disfmarker} Let 's slide back up again and see {disfmarker} start at the {disfmarker} at the bottom and Oop - bo - doop - boop - boop . Yeah . So , you could imagine w Uh , go ahead , you were about to go up there and point to something .\nGrad A: Well I {disfmarker} OK , I just {disfmarker} Say what you were gonna say .\nProfessor B: Good , do it !\nGrad A: OK .\nProfessor B: No no , go do it .\nGrad A: Uh {disfmarker} I {disfmarker} I 'd {disfmarker} No , I was gonna wait until {disfmarker}\nProfessor B: Oh , OK . So , so if you {disfmarker} if we made {disfmarker} if we wanted to make it into a {disfmarker} a real uh Bayes - net , that is , you know , with fill {disfmarker} you know , actually f uh , fill it @ @ in , then uh {disfmarker}\nGrad A: So we 'd have to get rid of this and connect these things directly to the Mode .\nProfessor B: Well , I don't {disfmarker} That 's an issue . So , um {disfmarker}\nGrad A: Cuz I don't understand how it would work otherwise .\nProfessor B: Well , here 's the problem . And {disfmarker} and uh {disfmarker} Bhaskara and I was talking about this a little earlier today {disfmarker} is , if we just do this , we could wind up with a huge uh , combinatoric input to the Mode thing . And uh {disfmarker}\nGrad A: Well I {disfmarker} oh yeah , I unders I understand that , I just {disfmarker} uh it 's hard for me to imagine how he could get around that .\nProfessor B: Well , i But that 's what we have to do .\nGrad A: OK .\nProfessor B: OK , so , so , uh . There {disfmarker} there are a variety of ways of doing it . Uh . Let me just mention something that I don't want to pursue today which is there are technical ways of doing it , uh I I slipped a paper to Bhaskara and {disfmarker} about Noisy - OR 's and Noisy - MAXes and there 're ways to uh sort of back off on the purity of your Bayes - net - edness .\nGrad A: Mmm .\nProfessor B: Uh , so . If you co you could ima and I now I don't know that any of those actually apply in this case , but there is some technology you could try to apply .\nGrad A: So it 's possible that we could do something like a summary node of some sort that {disfmarker} OK .\nProfessor B: Yeah . Yeah . And , um So .\nGrad A: So in that case , the sum we 'd have {disfmarker} we {disfmarker} I mean , these wouldn't be the summary nodes . We 'd have the summary nodes like where the things were {disfmarker} I guess maybe if thi if things were related to business or some other {disfmarker}\nProfessor B: Yeah .\nGrad A: Yeah .\nProfessor B: So what I was gonna say is {disfmarker} is maybe a good at this point is to try to informally {disfmarker} I mean , not necessarily in th in this meeting , but to try to informally think about what the decision variables are . So , if you have some bottom line uh decision about which mode , you know , what are the most relevant things .\nGrad A: Mmm .\nProfessor B: And the other trick , which is not a technical trick , it 's kind of a knowledge engineering trick , is to make the n {pause} each node sufficiently narrow that you don't get this combinatorics . So that if you decided that you could characterize the decision as a trade - off between three factors , whatever they may be , OK ? then you could say \" Aha , let 's have these three factors \" , OK ? and maybe a binary version f for each , or some relatively compact decision node just above the final one .\nGrad A: Mmm .\nProfessor B: And then the question would be if {disfmarker} if those are the things that you care about , uh can you make a relatively compact way of getting from the various inputs to the things you care about . So that y so that , you know , you can sort of try to do a knowledge engineering thing\nGrad A: OK .\nProfessor B: given that we 're not gonna screw with the technology and just always use uh sort of orthodox Bayes - nets , then we have a knowledge engineering little problem of how do we do that . Um and\nGrad A: So what I kind of need to do is to take this one and the old one and merge them together ?\nProfessor B: \" Eh - eh - eh . \" Yeah .\nGrad A: So that {disfmarker}\nProfessor B: Well , mmm , something . I mean , so uh , Robert has thought about this problem f for a long time , cuz he 's had these examples kicking around , so he may have some good intuition about you know , what are the crucial things .\nGrad A: Mmm .\nProfessor B: and , um , I understand where this {disfmarker} the uh {disfmarker} this is a way of playing with this abs Source - path - goal trajector exp uh uh abstraction and {disfmarker} and sort of sh displaying it in a particular way .\nGrad A: Yeah .\nProfessor B: Uh , I don't think our friends uh on Wednesday are going to be able to {disfmarker} Well , maybe they will . Well , let me think about whether {disfmarker} whether I think we can present this to them or not . Um , Uh ,\nGrad D: Well , I think this is still , I mean , ad - hoc . This is sort of th the second {vocalsound} version and I {disfmarker} I {disfmarker} I {disfmarker} look at this maybe just as a , you know , a {disfmarker} a {disfmarker} whatever , UML diagram or , you know , as just a uh screen shot , not really as a Bayes - net as John {disfmarker} Johno said .\nGrad A: We could actually , y yeah draw it in a different way , in the sense that it would make it more abstract .\nGrad D: Yeah . But the uh {disfmarker} the {disfmarker} the nice thing is that you know , it just is a {disfmarker} is a visual aid for thinking about these things which has comple clearly have to be specified m more carefully\nProfessor B: Alright , well , le let me think about this some more ,\nGrad D: and uh\nProfessor B: and uh see if we can find a way to present this to this linguists group that {disfmarker} that is helpful to them .\nGrad D: I mean , ultimately we {disfmarker} we may w w we regard this as sort of an exercise in {disfmarker} in thinking about the problem and maybe a first version of uh a module , if you wanna call it that , that you can ask , that you can give input and it it 'll uh throw the dice for you , uh throw the die for you , because um I integrated this into the existing SmartKom system in {disfmarker} in the same way as much the same way we can um sort of have this uh {disfmarker} this thing . Close this down . So if this is what M - three - L um will look like and what it 'll give us , um {disfmarker} And a very simple thing . We have an action that he wants to go from somewhere , which is some type of object , to someplace .\nProfessor B: Mm - hmm .\nGrad D: And this {disfmarker} these uh {disfmarker} this changed now only um , um {disfmarker} It 's doing it twice now because it already did it once . Um , we 'll add some action type , which in this case is \" Approach \" and could be , you know , more refined uh in many ways .\nProfessor B: Mm - hmm . Good .\nGrad D: Or we can uh have something where the uh goal is a public place and it will give us then of course an action type of the type \" Enter \" . So this is just based on this one {disfmarker} um , on this one feature , and that 's {disfmarker} that 's about all you can do . And so in the f if this pla if the object type um here is {disfmarker} is a m is a landmark , of course it 'll be um \" Vista \" . And um this is about as much as we can do if we don't w if we want to avoid uh uh a huge combinatorial explosion where we specify \" OK , if it 's this and this but that is not the case \" , and so forth , it just gets really really messy .\nProfessor B: OK , I 'm sorry . You 're {disfmarker} you 're {disfmarker}\nGrad D: Hmm ?\nProfessor B: It was much too quick for me . OK , so let me see if I understand what you 're saying . So , I {disfmarker} I do understand that uh you can take the M - three - L and add not {disfmarker} and it w and you need to do this , for sure , we have to add , you know , not too much about um object types and stuff , and what I think you did is add some rules of the style that are already there that say \" If it 's of type \" Landmark \" , then you take {disfmarker} you 're gonna take a picture of it . \"\nGrad D: Exactly .\nProfessor B: F full stop , I mean , that 's what you do . Ev - every landmark you take a picture of ,\nGrad D: Every public place you enter , and statue you want to go as near as possible .\nProfessor B: you enter {disfmarker} You approach . OK . Uh , and certainly you can add rules like that to the existing SmartKom system . And you just did , right ? OK .\nGrad D: Yeah . And it {disfmarker} it would do us no good .\nProfessor B: Ah .\nGrad D: That {disfmarker} Ultimately .\nProfessor B: Well . So , s well , and let 's think about this .\nGrad D: W\nProfessor B: Um , that 's a {disfmarker} that 's another kind of baseline case , that 's another sort of thing \" OK , here 's a {disfmarker} another kind of minimal uh way of tackling this \" . Add extra properties , a deterministic rule for every property you have an action , \" pppt ! \" You do that . Um , then the question would be Uh Now , if that 's all you 're doing , then you can get the types from the ontology , OK ? because that 's all {disfmarker} you 're {disfmarker} all you 're using is this type {disfmarker} the types in the ontology and you 're done .\nGrad D: Hmm ?\nProfessor B: Right ? So we don't {disfmarker} we don't use the discourse , we don't use the context , we don't do any of those things .\nGrad D: No .\nProfessor B: Alright , but that 's {disfmarker} but that 's OK , and I mean it it 's again a kind of one minimal extension of the existing things . And that 's something the uh SmartKom people themselves would {disfmarker} they 'd say \" Sure , that 's no problem {disfmarker} you know , no problem to add types to the ont \" Right ?\nGrad D: Yeah . No . And this is {disfmarker} just in order to exemplify what {disfmarker} what we can do very , very easily is , um we have this {disfmarker} this silly uh interface and we have the rules that are as banal as of we just saw , and we have our content .\nProfessor B: Hmm .\nGrad D: Now , the content {disfmarker} I {disfmarker} whi which is sort of what {disfmarker} what we see here , which is sort of the Vista , Schema , Source , Path , Goal , whatever .\nProfessor B: Yeah . Yeah .\nGrad D: This will um be um a job to find ways of writing down Image schema , X - schema , constructions , in some {disfmarker} some form , and have this be in a {disfmarker} in a {disfmarker} in the content , loosely called \" Constructicon \" . And the rules we want to throw away completely . And um {disfmarker} and here is exactly where what 's gonna be replaced with our Bayes - net , which is exactly getting the input feeding into here . This decides whether it 's an whether action {disfmarker} the {disfmarker} the Enter , the Vista , or the whatever\nProfessor B: Uh , \" approach \" , you called it , I think this time .\nGrad D: uh Approach um construction should be activated , IE just pasted in .\nProfessor B: That 's what you said {disfmarker} Yeah , that 's fine . Yeah , but {disfmarker} Right . But it 's not construction there , it 's action . Construction is a d is a different story .\nGrad D: Yeah .\nGrad A: Right . This is uh {disfmarker} so what we 'd be generating would be a reference to a semantic uh like parameters for the {disfmarker} for the X - schema ?\nProfessor B: For {disfmarker} for {disfmarker} for {disfmarker} Yes .\nGrad A: OK .\nProfessor B: Yeah . So that {disfmarker} that uh i if you had the generalized \" Go \" X - schema and you wanted to specialize it to these three ones , then you would have to supply the parameters .\nGrad A: Right .\nProfessor B: And then uh , although we haven't worried about this yet , you might wanna worry about something that would go to the GIS and use that to actually get you know , detailed route planning . So , you know , where do you do take a picture of it and stuff like that .\nGrad A: Mm - hmm .\nProfessor B: But that 's not {disfmarker} It 's not the immediate problem .\nGrad A: Right .\nProfessor B: But , presumably that {disfmarker} that {disfmarker} that functionality 's there when {disfmarker} when we {disfmarker}\nGrad A: So the immediate problem is just deciding w which {disfmarker}\nGrad D: Aspects of the X - schema to add .\nProfessor B: Yeah , so the pro The immediate problem is {disfmarker} is back t t to what you were {disfmarker} what you are doing with the belief - net .\nGrad A: Yeah .\nProfessor B: You know , uh what are we going to use to make this decision {disfmarker}\nGrad A: Right and then , once we 've made the decision , how do we put that into the content ?\nProfessor B: Yeah . Right . Right . Well , that {disfmarker} that actually is relatively easy in this case .\nGrad A: OK .\nProfessor B: The harder problem is we decide what we want to use , how are we gonna get it ? And that the {disfmarker} the {disfmarker} that 's the hardest problem . So , the hardest problem is how are you going to get this information from some combination of the {disfmarker} what the person says and the context and the ontology . The h So , I think that 's the hardest problem at the moment is {disfmarker} is\nGrad A: OK .\nProfessor B: where are you gonna {disfmarker} how are you gonna g get this information . Um , and that 's {disfmarker} so , getting back to here , uh , we have a d a technical problem with the belief - nets that we {disfmarker} we don't want all the com\nGrad A: There 's just too many factors right now .\nProfessor B: too many factors if we {disfmarker} if we allow them to just go combinatorially .\nGrad A: Right .\nProfessor B: So we wanna think about which ones we really care about and what they really most depend on , and can we c you know , clean this {disfmarker} this up to the point where it {disfmarker}\nGrad A: So what we really wanna do i cuz this is really just the three layer net , we wanna b make it {disfmarker} expand it out into more layers basically ?\nProfessor B: Right . We might . Uh , I mean that {disfmarker} that 's certainly one thing we can do . Uh , it 's true that the way you have this , a lot of the times you have {disfmarker} what you 're having is the values rather than the variable . So uh {disfmarker}\nGrad A: Right . So instead of in instead it should really be {disfmarker} just be \" intention \" as a node instead of \" intention business \" or \" intention tour \" .\nProfessor B: OK ? So you {disfmarker} Yeah , right , and then it would have values , uh , \" Tour \" , \" Business \" , or uh \" Hurried \" .\nGrad A: Right .\nProfessor B: But then {disfmarker} but i it still some knowledge design to do , about i how do you wanna break this up , what really matters .\nGrad A: Right .\nProfessor B: I mean , it 's fine . You know , we have to {disfmarker} it 's {disfmarker} it 's iterative . We 're gonna have to work with it some .\nGrad A: I think what was going through my mind when I did it was someone could both have a business intention and a touring intention and the probabilities of both of them happening at the same time {disfmarker}\nProfessor B: Well , you {disfmarker} you could do that . And it 's perfectly OK {pause} to uh insist that {disfmarker} that , you know , th um , they add up to one , but that there 's uh {disfmarker} that {disfmarker} that it doesn't have to be one zero zero .\nGrad A: Mmm . OK .\nProfessor B: OK . So you could have the conditional p So the {disfmarker} each of these things is gonna be a {disfmarker} a {disfmarker} a probability . So whenever there 's a choice , uh {disfmarker} so like landmark - ness and usefulness ,\nGrad A: Well , see I don't think those would be mutually {disfmarker}\nProfessor B: OK {disfmarker}\nGrad A: it seems like something could both be {disfmarker}\nProfessor B: Absolutely right .\nGrad A: OK .\nProfessor B: And so that you might want to then have those b Th - Then they may have to be separate . They may not be able to be values of the same variable .\nGrad D: Object type , mm - hmm .\nProfessor B: So that 's {disfmarker} but again , this is {disfmarker} this is the sort of knowledge design you have to go through . Right . It 's {disfmarker} you know , it 's great {disfmarker} is {disfmarker} is , you know , as one step toward uh {disfmarker} toward where we wanna go .\nGrad D: Also it strikes me that we {disfmarker} we m may want to approach the point where we can sort of try to find a {disfmarker} uh , a specification for some interface , here that um takes the normal M - three - L , looks at it . Then we discussed in our pre - edu {disfmarker} EDU meeting um how to ask the ontology , what to ask the ontology um the fact that we can pretend we have one , make a dummy until we get the real one , and so um we {disfmarker} we may wanna decide we can do this from here , but we also could do it um you know if we have a {disfmarker} a {disfmarker} a belief - net interface . So the belief - net takes as input , a vector , right ? of stuff . And it {disfmarker} Yeah . And um it Output is whatever , as well . But this information is just M - three - L , and then we want to look up some more stuff in the ontology and we want to look up some more stuff in the {disfmarker} maybe we want to ask the real world , maybe you want to look something up in the GRS , but also we definitely want to look up in the dialogue history um some s some stuff . Based on we {disfmarker} we have uh {disfmarker} I was just made some examples from the ontology and so we have for example some information there that the town hall is both a {disfmarker} a {disfmarker} a building and it has doors and stuff like this , but it is also an institution , so it has a mayor and so forth and so forth and we get relations out of it and once we have them , we can use that information to look in the dialogue history , \" were any of these things that {disfmarker} that are part of the town hall as an institution mentioned ? \" ,\nProfessor B: Mm - hmm .\nGrad D: \" were any of these that make the town hall a building mentioned ? \" ,\nGrad C: Right .\nGrad D: and so forth , and maybe draw some inferences on that . So this may be a {disfmarker} a sort of a process of two to three steps before we get our vector , that we feed into the belief - net ,\nProfessor B: Yeah . I think that 's {disfmarker} I think that 's exactly right .\nGrad D: and then {disfmarker}\nProfessor B: There will be rules , but they aren't rules that come to final decisions , they 're rules that gather information for a decision process . Yeah ,\nGrad D: Yeah .\nProfessor B: no I think that 's {disfmarker} that 's just fine . Uh , yeah . So they 'll {disfmarker} they {disfmarker} presumably there 'll be a thread or process or something that \" Agent \" , yeah , \" Agent \" , whatever you wan wanna say , yeah , that uh is rule - driven , and can {disfmarker} can uh {disfmarker} can do things like that . And um there 's an issue about whether there will be {disfmarker} that 'll be the same agent and the one that then goes off and uh carries out the decision , so it probably will . My guess is it 'll be the same basic agent that um can go off and get information , run it through a {disfmarker} a c this belief - net that {disfmarker} turn a crank in the belief - net , that 'll come out with s uh more {disfmarker} another vector , OK , which can then be uh applied at what we would call the simulation or action end . So you now know what you 're gonna do and that may actually involve getting more information . So on once you pull that out , it could be that that says \" Ah ! Now that we know that we gonna go ask the ontology something else . \" OK ? Now that we know that it 's a bus trip , OK ? we didn't {disfmarker} We didn't need to know beforehand , uh how long the bus trip takes or whatever , but {disfmarker} but now that we know that 's the way it 's coming out then we gotta go find out more .\nGrad D: Mm - hmm .\nProfessor B: So I think that 's OK .\nGrad D: Mm - hmm . So this is actually , s if {disfmarker} if we were to build something that is um , and , uh , I had one more thing , the {disfmarker} it needs to do {disfmarker} Yeah . I think we {disfmarker} I {disfmarker} I can come up with a {disfmarker} a code for a module that we call the \" cognitive dispatcher \" , which does nothing ,\nProfessor B: OK .\nGrad D: but it looks of complect object trees and decides how {disfmarker} are there parts missing that need to be filled out , there 's {disfmarker} this is maybe something that this module can do , something that this module can do and then collect uh sub - objects and then recombine them and put them together . So maybe this is actually some {disfmarker} some useful tool that we can use to rewrite it , and uh get this part ,\nProfessor B: Oh , OK . Uh .\nGrad D: then . Yeah .\nProfessor B: I confess , I 'm still not completely comfortable with the overall story . Um . I i This {disfmarker} this is not a complaint , this is a promise to do more work . So I 'm gonna hafta think about it some more . Um . In particular {disfmarker} see what we 'd like to do , and {disfmarker} and this has been implicit in the discussion , is to do this in such a way that you get a lot of re - use . So . What you 're trying to get out of this deep co cognitive linguistics is the fact that w if you know about source {disfmarker} source , paths and goals , and nnn {comment} all this sort of stuff , that a lot of this is the same , for different tasks . And that {disfmarker} uh there 's {disfmarker} there 's some {disfmarker} some important generalities that you 're getting , so that you don't take each and every one of these tasks and hafta re - do it . And I don't yet see how that goes . Alright .\nGrad D: There 're no primitives upon which {pause} uh\nProfessor B: u u What are the primitives , and how do you break this {disfmarker}\nGrad D: yeah .\nProfessor B: So I y I 'm just {disfmarker} just there saying eee {comment} well you {disfmarker} I know how to do any individual case , right ? but I don't yet {disfmarker} see what 's the really interesting question is can you use uh deep uh cognitive linguistics to {pause} get powerful generalizations . And\nGrad D: Yep .\nProfessor B: um\nGrad D: Maybe we sho should we a add then the \" what 's this ? \" domain ? N I mean , we have to \" how do I get to X \" . Then we also have the \" what 's this ? \" domain , where we get some slightly different {disfmarker}\nProfessor B: Could . Uh .\nGrad C: Right .\nGrad D: Um Johno , actually , does not allow us to call them \" intentions \" anymore .\nProfessor B: Yeah .\nGrad D: So he {disfmarker} he dislikes the term .\nProfessor B: Well , I {disfmarker} I don't like the term either , so I have n i uh i i y w i i It uh {disfmarker}\nGrad D: But um , I 'm sure the \" what 's this ? \" questions also create some interesting X - schema aspects .\nProfessor B: Could be . I 'm not a {disfmarker} I 'm not op particularly opposed to adding that or any other task ,\nGrad D: So .\nProfessor B: I mean , eventually we 're gonna want a whole range of them .\nGrad D: Mm - hmm .\nProfessor B: Uh ,\nGrad C: That 's right .\nProfessor B: I 'm just saying that I 'm gonna hafta do some sort of first principles thinking about this . I just at the moment don't know .\nGrad D: Mm - hmm .\nProfessor B: H No . Well , no the Bayes {disfmarker} the Bayes - nets {disfmarker} The Bayes - nets will be dec specific for each decision . But what I 'd like to be able to do is to have the way that you extract properties , that will go into different Bayes - nets , be the {disfmarker} uh general . So that if you have sources , you have trajectors and stuff like that , and there 's a language for talking about trajectors , you shouldn't have to do that differently for uh uh going to something , than for circling it , for uh telling someone else how to go there ,\nGrad D: Getting out of {disfmarker}\nProfessor B: whatever it is . So that {disfmarker} that , the {disfmarker} the decision processes are gonna be different What you 'd really like of course is the same thing you 'd always like which is that you have um a kind of intermediate representation which looks the same o over a bunch of inputs and a bunch of outputs . So all sorts of different tasks {pause} and all sorts of different ways of expressing them use a lot of the same mechanism for pulling out what are the fundamental things going on . And that 's {disfmarker} that would be the really pretty result . And pushing it one step further , when you get to construction grammar and stuff , what you 'd like to be able to do is say you have this parser which is much fancier than the parser that comes with uh SmartKom , i that {disfmarker} that actually uses constructions and is able to tell from this construction that there 's uh something about the intent {disfmarker} you know , the actual what people wanna do or what they 're referring to and stuff , in independent of whether it {disfmarker} about {disfmarker} what is this or where is it or something , that you could tell from the construction , you could pull out deep semantic information which you 're gonna use in a general way . So that 's the {disfmarker} You might . You might . You might be able to {disfmarker} to uh say that this i this is the kind of construction in which the {disfmarker} there 's {disfmarker} Let 's say there 's a uh cont there {disfmarker} the {disfmarker} the land the construction implies the there 's a con this thing is being viewed as a container . OK . So just from this local construction you know that you 're gonna hafta treat it as a container you might as well go off and get that information . And that may effect the way you process everything else . So if you say \" how do I get into the castle \" OK , then um {disfmarker} Or , you know , \" what is there in the castle \" or {disfmarker} so there 's all sorts of things you might ask that involve the castle as a container and you 'd like to have this orthogonal so that anytime the castle 's referred to as a container , you crank up the appropriate stuff . Independent of what the goal is , and independent of what the surrounding language is .\nGrad D: Mm - hmm .\nProfessor B: Alright , so that 's {disfmarker} that 's the {disfmarker} that 's the thesis level\nGrad D: Mm - hmm .\nProfessor B: uh {disfmarker}\nGrad D: It 's unfortunate also that English has sort of got rid of most of its spatial adverbs because they 're really fancy then , in {disfmarker} in {disfmarker} for these kinds of analysis . But uh .\nProfessor B: Well , you have prepositional phrases that {disfmarker}\nGrad D: Yeah , but they 're {disfmarker} they 're easier for parsers .\nProfessor B: Right .\nGrad D: Parsers can pick those up but {disfmarker} but the {disfmarker} with the spatial adverbs , they have a tough time . Because the {disfmarker} mean the semantics are very complex in that .\nProfessor B: Right .\nGrad D: OK , yeah ? I had one more {pause} thing . I don't remember . I just forgot it again . No . Oh yeah , b But an architecture like this would also enable us maybe to {disfmarker} to throw this away and {disfmarker} and replace it with something else , or whatever , so that we have {disfmarker} so that this is sort of the representational formats we 're {disfmarker} we 're {disfmarker} we 're talking about that are independent of the problem , that generalize over those problems , and are oh , t of a higher quality than an any actual whatever um belief - net , or \" X \" that we may use for the decision making , ultimately . Should be decoupled , yeah . OK .\nProfessor B: Right . So , are we gonna be meeting here from now on ? I 'm {disfmarker} I 'm happy to do that . We {disfmarker} we had talked about it , cuz you have th th the display and everything , that seems fine .\nGrad D: Yeah , um , Liz also asks whether we 're gonna have presentations every time . I don't think we will need to do that but it 's {disfmarker}\nProfessor B: Right .\nGrad D: so far I think it was nice as a visual aid for some things and {disfmarker} and {disfmarker}\nProfessor B: Oh yeah . No I {disfmarker} I think it 's worth it to ass to meet here to bring this , and assume that something may come up that we wanna look at .\nGrad D: Yeah .\nProfessor B: I mean . Why not .\nGrad D: And um . Yeah , that was my {disfmarker}\nProfessor B: She was good . Litonya was good .\nGrad D: Yeah ? The uh {disfmarker} um , she w she was definitely good in the sense that she {disfmarker} she showed us some of the weaknesses\nProfessor B: Right .\nGrad D: and um also the um {disfmarker} {vocalsound} the fact that she was a real subject you know , is {disfmarker} is {disfmarker}\nProfessor B: Right . Yeah , and {disfmarker} and {disfmarker} and {disfmarker} yeah and {disfmarker} and she took it seriously and stuff l No , it was great .\nGrad D: Yeah .\nProfessor B: Yeah .\nGrad D: So I think that um {disfmarker} I mean , w Looking {disfmarker} just looking at this data , listening to it , what can we get out of it in terms of our problem , for example , is , you know , she actually m said {disfmarker} you know , she never s just spoke about entering , she just wanted to get someplace , and she said for buying stuff . Nuh ? So this is definitely interesting , and {disfmarker}\nGrad C: Yeah , right .\nGrad D: Um , and in the other case , where she wanted to look at the stuff at the graffiti , also , of course , not in the sentence \" How do you get there ? \" was pretty standard . Nuh ? except that there was a nice anaphora , you know , for pointing at what she talked about before , and there she was talking about looking at pictures that are painted inside a wall on walls , so\nGrad C: Right .\nGrad D: Actually , you 'd need a lot of world knowledge . This would have been a classical um uh \" Tango \" , actually . Um , because graffiti is usually found on the outside and not on the inside ,\nGrad C: Yeah .\nGrad D: but OK . So the mistake {comment} would have make a mistake {disfmarker} the system would have made a mistake here .\nGrad C: Yep .\nProfessor B: Click ? Alright .", "source": "meeting_summ", "evaluation": "rouge"}
{"instructions": ["Summarize the discussion of group warming and the introduction to the new remote control project.", "What did Project Manager recommend to do after introducing the design steps and why?", "Summarize the discussion of specific designing requirements of the new remote control.", "What did Project Manager\u2019s think of the water-proof design when discussing the designing requirements of the new remote control?", "What did the conferees think of the solution to water-proof and shock-proof technical demands when discussing the designing requirements of the new remote control?", "What did Industrial Designer and Project Manager think of the remote tracking method when discussing the designing requirements of the new remote control?", "Summarize the whole meeting."], "outputs": ["Mutual greeting heralded the beginning of the meeting and the goal of the new remote control project was introduced by Project Manager to the conferees as to win over competitive products by being original, trendy and user-friendly. Then Project Manager continued with the introduction of the design process, which was divided into three main parts\u2014functional design, conceptual design and desired design that respectively focused on the user-related technical functions, desirable user interface and different trends involved, and specific implementation and choice-detailing process of conceptual design.", "Project Manager recommended a drawing activity of conferees\u2019 favourite animals with the aim of inspiring and contributing to the design process of the remote control.", "Given the customer demand and conferees personal experiences, several designing requirements were proposed during the discussion. The remote control was decided to be adaptable to multiple devices with few buttons, be able to be lighted in the dark and held in hand, and be both water-proof and shock-proof along with a whistle tracking system, based on which advantage over competitors might well be gained at the price of a rising production cost.", "Considering the product originality, Project Manager believed that a water-proof remote control could be used in the bath conveniently while saving the customer\u2019s need to purchase an extra plastic cover. Therefore, originality and competitiveness might be gained over competitive products.", "Conferees agreed that the remote control could be sold with optional plastic protection and water-proof box for customers to choose.", "Industrial Designer first recommended adding a special beeping button on the TV set to remind users of where the remote controls were, but the plan was deemed impractical concerning TV sets that were not designed by them. Then Project Manager suggested whistle tracking and was approved by all the conferees as an original improvement.", "This meeting was primarily concerned with the design process and specific designing requirements of the remote control. Project Manager first introduced the goal of the new remote control project as to be original, trendy and user-friendly so as to bear an advantage over competitive products. Then three steps of the design process were respectively introduced and explained by Project Manager, and drawings of favourite animals then followed as an imagination-inspiring activity. According to Project Manager, the fifty-million-Euro financial objective of the project would be achieved at a production cost lower than 12.5 Euros and a twofold selling price. Competitiveness-endowing requirements for remote control design were then proposed and carefully discussed."], "input": "User Interface: {gap}\nProject Manager: {vocalsound}\nUser Interface: {vocalsound} How do you wear this thing ?\nProject Manager: Hmm . Mm mm mm . {vocalsound}\nUser Interface: Not too many cables and stuff .\nMarketing: {gap}\nUser Interface: {vocalsound} {vocalsound}\nProject Manager: {vocalsound}\nUser Interface: {vocalsound} Original . {vocalsound}\nProject Manager: {vocalsound} Is recorded ? Okay ? Okay so welcome everyone . So we are here for the kickoff meeting of uh the process of designing a new remote control . So I will first start with a warm welcome opening {vocalsound} stuff ,\nUser Interface: {vocalsound}\nProject Manager: then uh we will uh see what will be uh our product and what will be the different step we will have to design it . And uh then we will uh discuss if we have few ideas and we will uh end uh by uh dispatching the different task you will be {disfmarker} you will have to fulfil to complete this process . So {disfmarker}\nUser Interface: Uh . Just one thing . Uh , you said twenty-five minutes , but I have something else to do uh , so gotta have another meeting uh soon ,\nProject Manager: {vocalsound}\nUser Interface: so maybe you could hurry up a bit {disfmarker}\nProject Manager: {vocalsound} sorry ?\nUser Interface: It's true . I have another meeting so if you could uh {disfmarker}\nProject Manager: You have another meeting soon ?\nUser Interface: Yeah .\nProject Manager: So you have to be quick .\nIndustrial Designer: {vocalsound}\nUser Interface: Yeah , for the lawnmower project .\nProject Manager: Okay .\nUser Interface: Okay .\nProject Manager: So the the goal is to have a remote control so to have an advantage over our competitors we have to be original , we have to be trendy and we have to also try to be user-friendly .\nUser Interface: {vocalsound}\nProject Manager: So uh the design step will be divided in three uh main points . First it will be the functional design . Third is the conceptual design and then is the desired design . So the functional design is to identify the main user needs , the technical function the remote control should fulfil . And then we will move to f conceptual design where we'll specify the different component involved , what kind of user interf interface we want and what are the different uh trend in user interface and stuff like that .\nIndustrial Designer: {vocalsound}\nProject Manager: And then the desired devi design will consist in uh specifically implementing {vocalsound} and detailing the choice we've uh made in the second point . So I will now ask you which is very important for the design of a new remote control for to uh each of us to to draw uh your favourite animal on the white board .\nUser Interface: {vocalsound} What an original idea .\nProject Manager: {vocalsound} Do you have any idea of which animal you want to show us ? {vocalsound}\nUser Interface: Orangutan .\nProject Manager: Okay {vocalsound} that's good .\nIndustrial Designer: {vocalsound}\nUser Interface: {vocalsound}\nIndustrial Designer: No no n\nProject Manager: {vocalsound} n n {gap}\nUser Interface: Can I give you the\nProject Manager: You should {disfmarker}\nUser Interface: {disfmarker} no ? But I don't have to say anything . When I'm drawing the orangutan .\nProject Manager: {vocalsound} {vocalsound} If you want to react uh about this wonderful drawing uh {vocalsound} I'll let you uh comment .\nUser Interface: {vocalsound} {vocalsound}\nIndustrial Designer: {vocalsound}\nMarketing: {vocalsound}\nUser Interface: It's an abstract drawing of an orangutan .\nProject Manager: Okay it's an abstract drawing .\nUser Interface: Yes .\nProject Manager: I think it's nice and original . {vocalsound}\nIndustrial Designer: {vocalsound} You should write y the name I think . {vocalsound}\nMarketing: {vocalsound}\nUser Interface: I don't have a red colour . Usually orangutans have red hair so this is a very important but I don't have red pen , so {disfmarker}\nProject Manager: Okay .\nUser Interface: {vocalsound} Yes .\nProject Manager: You want to draw something Christine ? {vocalsound}\nMarketing: {vocalsound} {vocalsound}\nUser Interface: {vocalsound}\nMarketing: Okay uh sorry . You have to imagine a little bit {vocalsound} um .\nProject Manager: {vocalsound}\nMarketing: This {disfmarker}\nProject Manager: Of course your animal is recorded so it's not lost . {vocalsound}\nMarketing: {vocalsound} Sorry too {vocalsound} uh .\nUser Interface: Yes . I know .\nProject Manager: {vocalsound}\nMarketing: {vocalsound}\nUser Interface: {vocalsound}\nIndustrial Designer: {vocalsound}\nMarketing: {vocalsound}\nUser Interface: {vocalsound}\nProject Manager: Is this uh {disfmarker}\nUser Interface: Wha what is this strange beast ?\nMarketing: Is it beautiful ? {vocalsound}\nProject Manager: {vocalsound}\nIndustrial Designer: {vocalsound}\nUser Interface: Is it a monster ?\nProject Manager: {vocalsound}\nMarketing: Do you know ? It's a cat .\nUser Interface: It's a cat ?\nIndustrial Designer: {vocalsound}\nMarketing: {vocalsound} Isn't it ? {vocalsound}\nUser Interface: I thought these things did not exist .\nProject Manager: {vocalsound}\nMarketing: {vocalsound} Yes yes\nIndustrial Designer: Me {vocalsound}\nMarketing: is it {disfmarker} like that .\nUser Interface: Ah yeah {vocalsound}\nIndustrial Designer: Ah yeah . Yeah .\nMarketing: Is it better ?\nProject Manager: Ah okay it's pretty . {vocalsound}\nMarketing: {vocalsound} Okay .\nProject Manager: {vocalsound} Okay it's your cat . {vocalsound}\nMarketing: {vocalsound} It's my cat .\nUser Interface: Does have a name ?\nMarketing: {vocalsound} Yeah . {vocalsound}\nIndustrial Designer: {vocalsound}\nMarketing: The name is Caramel .\nUser Interface: Caramel . Ah-ha .\nIndustrial Designer: Caramel .\nMarketing: Yeah . {vocalsound}\nProject Manager: Okay . Olivier , do you want to {vocalsound}\nIndustrial Designer: {vocalsound} And you {vocalsound} {vocalsound} I think I'm too short for the cables . {vocalsound}\nMarketing: {vocalsound}\nProject Manager: {vocalsound} Okay I go , but next time you'll do something I'm sure . {vocalsound} {vocalsound} I'm a bit short on cable .\nUser Interface: Next time I concentrate .\nIndustrial Designer: {vocalsound}\nProject Manager: Okay . So what could I draw ? {vocalsound} Maybe I can draw like a very simplified cow . {vocalsound} I don't know if it looks like a cow {vocalsound}\nUser Interface: He looks like a bong .\nMarketing: {vocalsound}\nIndustrial Designer: {vocalsound}\nProject Manager: Like a what ? {vocalsound}\nUser Interface: Okay . Sorry . No .\nIndustrial Designer: Quite squarey .\nUser Interface: Scary ?\nProject Manager: {gap} {vocalsound}\nIndustrial Designer: He also . {vocalsound}\nMarketing: {vocalsound}\nProject Manager: I dunno it it looks more like a donkey in fact {vocalsound} I would say .\nUser Interface: {vocalsound}\nMarketing: {vocalsound}\nUser Interface: {vocalsound} I I think we will be finished this uh {disfmarker}\nIndustrial Designer: Mm .\nProject Manager: Okay so I hope that it helps you uh in the process of designing a remote control .\nUser Interface: Is it for uh for putting a {disfmarker} for logos , no .\nProject Manager: {vocalsound} Okay .\nUser Interface: {vocalsound} That's {disfmarker}\nProject Manager: Let's move on . So {disfmarker} Here the uh financial objective of our project . That is to say to to have a production cost lower than twelve point five Euros and have a selling price of twice that price t in order to target a profe profit of uh fifty uh million Euros .\nUser Interface: I is there a matter for a new remote control ?\nProject Manager: {vocalsound} Yeah if it's trendy , original I d fulfil the user needs .\nUser Interface: Is it uh a single device remote control or is it a multi-device remote control ?\nProject Manager: We have to discuss that point .\nUser Interface: Ah\nProject Manager: On {disfmarker}\nUser Interface: this is not defined at all ?\nProject Manager: yeah you you can suggest points like this . So what what {disfmarker}\nUser Interface: Ah , okay .\nProject Manager: so we have to decide for example if it can control one device or multiple . So what's {disfmarker} what are your ideas about that ?\nUser Interface: {vocalsound}\nProject Manager: Maybe I can have the {disfmarker} your opinion from the marketing side ?\nUser Interface: Well uh do we sell other stuff ? Uh if if we bundle the remote control with something uh to sell then it could be a single device , otherwise it could be programmable one otherwise who would buy a remote control from us .\nProject Manager: Okay , so if it selled uh by its own i it it would rather be for multiple device .\nUser Interface: Yeah .\nProject Manager: {vocalsound} Do you agree ?\nIndustrial Designer: Mm-hmm .\nProject Manager: Yeah . So maybe it should be for multiple devices . And uh do you have any ideas um of uh design ideas or any uh uh technical requirement we we should uh fulfil ?\nIndustrial Designer: {vocalsound} I think we shouldn't have too many b for my part . I think {disfmarker}\nUser Interface: No , I couldn I cannot fi think of any requirements right now . {vocalsound}\nIndustrial Designer: If we don't have so many buttons could be nice .\nProject Manager: {vocalsound} Few buttons . Okay .\nUser Interface: {vocalsound}\nProject Manager: And do you have it also to be {disfmarker} to be lighted in order to be used in the dark ? Might be a good idea .\nIndustrial Designer: {vocalsound} Yeah .\nProject Manager: Okay . And do you have any um any uh idea of the trend {disfmarker} the trend in domain , what it shouldn't {disfmarker} it should look like , or things like that ?\nIndustrial Designer: {vocalsound} Something which is not squarey maybe uh , not a box .\nUser Interface: Mm .\nProject Manager: With rou okay . Like for {disfmarker} okay .\nUser Interface: Something like that , least fits in your hand .\nProject Manager: Okay .\nUser Interface: {vocalsound} Yeah .\nIndustrial Designer: Yeah .\nUser Interface: The basic requirement .\nProject Manager: So . Fit in your hand , yeah .\nUser Interface: {vocalsound} Only a buck .\nProject Manager: And also it have , i it may be {vocalsound} it may be important for the remote control to be uh {disfmarker} To , to resist to various shocks that can happen if it fall .\nUser Interface: {vocalsound}\nIndustrial Designer: Mm-hmm .\nUser Interface: Waterproof . {vocalsound}\nProject Manager: {vocalsound} Water-proof as well .\nIndustrial Designer: {vocalsound} And I think we should have a device {disfmarker}\nProject Manager: Maybe it is original because you can uh use it in your uh {disfmarker} in your bath whereas the others can't .\nUser Interface: {vocalsound}\nMarketing: {vocalsound}\nProject Manager: Maybe water-proof would be very original .\nIndustrial Designer: Sorry . {gap}\nMarketing: {vocalsound}\nProject Manager: Havin having a water-proof remote control so that the people can uh use it in their bath .\nUser Interface: Mm .\nProject Manager: That could be uh {disfmarker}\nUser Interface: B it seems uh so , but uh if you don't have an waterproof remote control it means you can just cover it with some plastic and you can sort of f\nProject Manager: Yeah but , it is still something uh you have to buy and that is um not maybe very {disfmarker}\nUser Interface: And , and that's one of the {disfmarker} that's one of the shock {disfmarker} I mean there are people that have a remote control and they are worried that it's going to break and they put some extra plastic around it .\nProject Manager: Yeah , mayb B\nUser Interface: That's people {gap} they actually do it themselves .\nProject Manager: But maybe we can bulk it with uh already this plastic thing and uh the waterproof uh stuff as well .\nIndustrial Designer: Yeah . {gap} directly .\nUser Interface: I it will look a bulky in that case .\nProject Manager: Yeah . Maybe we can sell uh all that together , so so plastic protection and uh and a waterproof box as well .\nIndustrial Designer: Yeah .\nProject Manager: That might be good uh track to follow .\nUser Interface: Like as an optional thing .\nProject Manager: Optional or selled with it ?\nIndustrial Designer: {vocalsound} And I I think we should have something , most of the time I I lose my remote control .\nProject Manager: Yeah .\nIndustrial Designer: We should have s uh special bu button on the T_V_ to make the remote control beeping .\nProject Manager: Maybe we can have uh {disfmarker} But we don't design the T_V_ .\nMarketing: {vocalsound}\nProject Manager: Maybe we can have uh something you whistle and uh the remote control uh beep .\nIndustrial Designer: Ah yeah .\nMarketing: {vocalsound}\nUser Interface: Barks .\nIndustrial Designer: Yeah . {vocalsound}\nProject Manager: Yeah , barks , yeah .\nIndustrial Designer: {vocalsound} Barks .\nProject Manager: So we can uh have a whistle uh remote control ?\nIndustrial Designer: Yeah . Yeah whistle .\nProject Manager: I don't know , whistle-able ? {vocalsound} Th\nIndustrial Designer: Whistle tracking . {vocalsound}\nProject Manager: {vocalsound} Whistle tracking yeah . Whistle tracking remote control . That's a good idea , that's very original and that's can uh improve .\nUser Interface: {vocalsound} That's that's quite cool , but uh of course we {disfmarker} you don't normally need uh any audio uh recording stuff on your remote control right ?\nProject Manager: Yeah d d uh .\nUser Interface: So i it's just going to add t to the cost .\nProject Manager: Yeah but s still we have to mm we have to {vocalsound} have an advantage over our competitors . I think this is a good advantage .\nUser Interface: {vocalsound} It's cool . I think I like the idea , but I'm not sure about the what you ,\nProject Manager: Yeah . We have to ask {disfmarker}\nUser Interface: who is giving {disfmarker} who's giving who's giving our budget . Who's {disfmarker}\nProject Manager: Yeah . We have to ask the quest of that's uh design to the uh Industrial um Designer .\nUser Interface: Yeah . Yeah .\nIndustrial Designer: Yeah . {vocalsound} yeah {vocalsound}\nProject Manager: {vocalsound} Which is you .\nUser Interface: 'Kay . {vocalsound}\nProject Manager: {vocalsound} Okay so try to find that for next meeting . {vocalsound}\nIndustrial Designer: Okay . {vocalsound}\nProject Manager: Okay . So next meeting is in thirty minutes or so uh . {vocalsound} Don't pani .\nIndustrial Designer: {vocalsound} Don't panic . {vocalsound}\nProject Manager: So so I will ask the Industrial Designer to find out more about this industrial design so any working {disfmarker} any working function we have discussed .\nIndustrial Designer: Mm-hmm .\nProject Manager: So then I will ask the User Interf Interface Designer to to think about the point we discussed like the number of buttons , the the fact that is lighted or not , things like that , and what would be convenient for the user .\nUser Interface: Mm-hmm .\nProject Manager: And also um {vocalsound} I will ask the Market Expert to uh try to find out what are the absolute requirements , what is absolutely needed in a remote control uh for the user . So . And then uh I will uh just ask you to think about that and uh look at your mail because you will receive uh some good advice soon . {vocalsound}\nUser Interface: Mm .\nProject Manager: So . Thank you I think that's all for this point .\nUser Interface: Good .\nIndustrial Designer: Mm-hmm .\nUser Interface: {vocalsound}\nMarketing: Thank you {vocalsound}\nUser Interface: Uh , so we come back in five minutes ? Half an hour .\nProject Manager: Anyway you will receive some messages . {vocalsound} Be careful . You eat it ? Does it move uh ? Okay , but I don't know if it uh is still correctly uh {disfmarker} We'll see .\nIndustrial Designer: Ah . {gap}", "source": "meeting_summ", "evaluation": "LLM"}
{"instructions": ["Summarize the discussion on TORRENT schedule and intermediate categorization", "What did Grad F say about his proposal?", "What did Grad F think about intermediate categories?", "Summarize the discussion on mean subtraction in SRI", "What did the professor think about echoes and reverberation?", "What did PhD C think about the signal to noise ratio?", "Summarize the meeting"], "outputs": ["The professor told the team that the TORRENT chip schedule kept getting pushed. Then, Grad F talked about his proposal, in which he was done with the section on intermediate categories. Including features from intermediate categories was a potential way of reducing error.", "Grad F explained that he was focusing on writing his proposal for his qualification exams, which was on the 25th of July. He had to write a paper and pass it around before that date.", "Grad F informed the team that he was building a system that classified intermediate categories with multi-band techniques. Then, to reduce error for phoneme recognition, the intermediate categories could be added to improve performance. The method could be replicated for large vocabulary tasks like switchboard.", "The team got an improvement on the SRI system for TI- digits and Meeting Recorder digits but near mic performance worsened. The team explored the reasons for this difference. The professor suggested getting rid of low energy sections. The team also discussed how more nuanced normalization approaches could improve task performance.", "The professor thought it was possible to reduce the effects of reverberation by removing the low-energy segments. He thought a VAD-like approach would work. This would make it so that the model was more likely to keep an echo than throw out speech.", "PhD C was skeptical of why the signal was louder after processing. PhD C suggested that the system is not too dependent on the signal level, agreeing with the professor that improvement in the model was more likely dependent on the ratio.", "The meeting began with a discussion on the TORRENT project completion being pushed for two years. Grad F then introduced intermediate categorization, which was his topic for his qualification exams. The team then discussed mean subtraction from SRI. Using it had led to an improvement in Meeting Recorder digits though near mic performance worsened. The professor points to pre-echoes as the culprit. The team continued to study differences between SRI and Aurora. The team thought it would be interesting to do the Aurora tests with the SRI system instead of the HTK. The team was also exploring the Wiener filter and VTS. The professor did not seem too excited about the VTS."], "input": "Professor B: I think for two years we were two months , uh , away from being done .\nPhD A: And what was that , Morgan ? What project ?\nProfessor B: Uh , the , uh , TORRENT chip .\nPhD A: Oh .\nProfessor B: Yeah . We were two {disfmarker} we were {disfmarker}\nPhD C: Yeah .\nProfessor B: Uh , uh , we went through it {disfmarker} Jim and I went through old emails at one point and {disfmarker} and for two years there was this thing saying , yeah , we 're {disfmarker} we 're two months away from being done . It was very {disfmarker} very believable schedules , too . I mean , we went through and {disfmarker} with the schedules {disfmarker} and we {disfmarker}\nPhD A: It was true for two years .\nProfessor B: Yeah . Oh , yeah . It was very true .\nPhD A: So , should we just do the same kind of deal where we {pause} go around and do , uh , status report {pause} kind of things ? OK . And I guess when Sunil gets here he can do his last or something . So .\nProfessor B: Yeah . So we {pause} probably should wait for him to come before we do his .\nPhD C: Mm - hmm .\nPhD A: OK . That 's a good idea .\nProfessor B: Yeah .\nGrad F: OK .\nProfessor B: Yeah .\nPhD A: Any objection ? Do y OK , M\nProfessor B: All in favor\nPhD A: Do you want to start , Morgan ? Do you have anything , or {disfmarker} ?\nProfessor B: Uh , I don't do anything . I {disfmarker} No , I mean , I {disfmarker} I 'm involved in discussions with {disfmarker} with people about what they 're doing , but I think they 're {disfmarker} since they 're here , they can talk about it themselves .\nGrad F: OK . So should I go so that , uh ,\nPhD A: Yeah . Why don't you go ahead , Barry ?\nGrad F: you 're gonna talk about Aurora stuff , per se ?\nPhD A: OK .\nGrad F: OK . Um . Well , this past week I 've just been , uh , getting down and dirty into writing my {disfmarker} my proposal . So , um {disfmarker} Mmm . I just finished a section on , uh {disfmarker} on talking about these intermediate categories that I want to classify , um , as a {disfmarker} as a middle step . And , um , I hope to {disfmarker} hope to get this , um {disfmarker} a full rough draft done by , uh , Monday so I can give it to Morgan .\nPhD A: When is your , uh , meeting ?\nGrad F: Um , my meeting\nPhD A: Yeah .\nGrad F: with , uh {disfmarker} ? Oh , oh , you mean the {disfmarker} the quals .\nPhD A: The quals . Yeah .\nGrad F: Uh , the quals are happening in July twenty - fifth .\nPhD A: Oh . Soon .\nGrad F: Yeah .\nPhD A: Uh - huh .\nGrad F: D - Day .\nPhD A: Yeah .\nGrad F: Uh - huh .\nPhD A: So , is the idea you 're going to do this paper and then you pass it out to everybody ahead of time and {disfmarker} ?\nGrad F: Right , right . So , y you write up a proposal , and give it to people ahead of time , and you have a short presentation . And , um , and then , um {disfmarker} then everybody asks you questions .\nPhD A: Hmm .\nGrad F: Yeah .\nPhD A: I remember now .\nGrad F: Yep . So , um .\nPhD A: Have you d ? I was just gonna ask , do you want to say any {disfmarker} a little bit about it ,\nGrad F: Y s\nPhD A: or {disfmarker} ? Mmm .\nGrad F: Oh . Uh , a little bit about {disfmarker} ?\nPhD A: Wh - what you 're {disfmarker} what you 're gonna {disfmarker} You said {disfmarker} you were talking about the , uh , particular features that you were looking at ,\nGrad F: Oh , the {disfmarker} the {disfmarker}\nPhD A: or {disfmarker}\nGrad F: Right . Well , I was , um , I think one of the perplexing problems is , um , for a while I was thinking that I had to come up with a complete set of intermediate features {disfmarker} in intermediate categories to {disfmarker} to classify right away . But what I 'm thinking now is , I would start with {disfmarker} with a reasonable set . Something {disfmarker} something like , um , um {disfmarker} like , uh , re regular phonetic features , just to {disfmarker} just to start off that way . And do some phone recognition . Um , build a system that , uh , classifies these , um {disfmarker} these feat uh , these intermediate categories using , uh , multi - band techniques . Combine them and do phon phoneme recognition . Look at {disfmarker} then I would look at the errors produced in the phoneme recognition and say , OK , well , I could probably reduce the errors if I included this extra feature or this extra intermediate category . That would {disfmarker} that would reduce certain confusions over other confusions . And then {disfmarker} and then {vocalsound} reiterate . Um , build the intermediate classifiers . Uh , do phoneme recognition . Look at the errors . And then postulate new {disfmarker} or remove , um , intermediate categories . And then do it again .\nPhD A: So you 're gonna use TIMIT ?\nGrad F: Um , for that {disfmarker} for that part of the {disfmarker} the process , yeah , I would use TIMIT .\nPhD A: Mm - hmm .\nGrad F: And , um , then {disfmarker} after {disfmarker} after , uh , um , doing TIMIT . Right ?\nPhD A: Mm - hmm .\nGrad F: Um , that 's {disfmarker} {vocalsound} that 's , um {disfmarker} that 's just the ph the phone recognition task .\nPhD A: Yeah .\nGrad F: Uh , I wanted to take a look at , um , things that I could model within word . So , I would mov I would then shift the focus to , um , something like Schw - Switchboard , uh , where I 'd {disfmarker} I would be able to , um {disfmarker} to model , um , intermediate categories that span across phonemes ,\nPhD A: Mm - hmm .\nGrad F: not just within the phonemes , themselves , um , and then do the same process there , um , on {disfmarker} on a large vocabulary task like Switchboard . Uh , and for that {disfmarker} for that part I would {disfmarker} I 'd use the SRI recognizer since it 's already set up for {disfmarker} for Switchboard . And I 'd run some {disfmarker} some sort of tandem - style processing with , uh , my intermediate classifiers .\nPhD A: Oh . So that 's why you were interested in getting your own features into the SRI files .\nGrad F: Yeah . That 's why I {disfmarker} I was asking about that .\nPhD A: Yeah . Yeah .\nGrad F: Yeah . Um , and I guess that 's {disfmarker} that 's it . Any {disfmarker} any questions ?\nPhD A: Sounds good . So you just have a few more weeks , huh ?\nGrad F: Um , yeah . A few more .\nPhD A: It 's about a month from now ?\nGrad F: It 's a {disfmarker} it 's a month and {disfmarker} and a week .\nPhD A: Yeah .\nGrad F: Yeah .\nPhD A: So , uh , you want to go next , Dave ? And we 'll do {disfmarker}\nGrad E: Oh . OK , sure . So , um , last week I finally got results from the SRI system about this mean subtraction approach . And , um , we {disfmarker} we got an improvement , uh , in word error rate , training on the TI - digits data set and testing on Meeting Recorder digits of , um , {vocalsound} six percent to four point five percent , um , on the n on the far - mike data using PZM F , but , um , the near - mike performance worsened , um , from one point two percent to two point four percent . And , um , wh why would that be , um , {vocalsound} considering that we actually got an improvement in near - mike performance using HTK ? And so , uh , with some input from , uh , Andreas , I have a theory in two parts . Um , first of all HTK {disfmarker} sorry , SR - the SRI system is doing channel adaptation , and so HTK wasn't . Um , so this , um {disfmarker} This mean subtraction approach will do a kind of channel {pause} normalization and so that might have given the HTK use of it a boost that wouldn't have been applied in the SRI case . And also , um , the {disfmarker} Andreas pointed out the SRI system is using more parameters . It 's got finer - grained acoustic models . So those finer - grained acoustic models could be more sensitive to the artifacts {pause} in the re - synthesized audio . Um . And me and Barry were listening to the re - synthesized audio and sometimes it seems like you get of a bit of an echo of speech in the background . And so that seems like it could be difficult for training , cuz you could have {pause} different phones {pause} lined up with a different foreground phone , {vocalsound} um , {vocalsound} depending on {pause} the timing of the echo . So , um , I 'm gonna try training on a larger data set , and then , eh , the system will have seen more examples o of these artifacts and hopefully will be more robust to them . So I 'm planning to use the Macrophone set of , um , read speech , and , um {disfmarker} Hmm .\nProfessor B: I had another thought just now , which is , uh , remember we were talking before about {disfmarker} we were talking in our meeting about , uh , this stuff that {disfmarker} some of the other stuff that Avendano did , where they were , um , getting rid of low - energy {pause} sections ? Um , uh , if you {disfmarker} if you did a high - pass filtering , as Hirsch did in {pause} late eighties to reduce some of the effects of reverberation , uh , uh , Avendano and Hermansky were arguing that , uh , perhaps one of the reasons for that working was ma may not have even been the filtering so much but the fact that when you filter a {disfmarker} an all - positive power spectrum you get some negative values , and you gotta figure out what to do with them if you 're gonna continue treating this as a power spectrum . So , what {disfmarker} what Hirsch did was , uh , set them to zero {disfmarker} set the negative values to zero . So if you imagine a {disfmarker} a waveform that 's all positive , which is the time trajectory of energy , um , and , uh , shifting it downwards , and then getting rid of the negative parts , that 's essentially throwing away the low - energy things . And it 's the low - energy parts of the speech where the reverberation is most audible . You know , you have the reverberation from higher - energy things showing up in {disfmarker} So in this case you have some artificially imposed {pause} reverberation - like thing . I mean , you 're getting rid of some of the other effects of reverberation , but because you have these non - causal windows , you 're getting these funny things coming in , uh , at n And , um , what if you did {disfmarker} ? I mean , there 's nothing to say that the {disfmarker} the processing for this re - synthesis has to be restricted to trying to get it back to the original , according to some equation . I mean , you also could , uh , just try to make it nicer .\nGrad E: Uh - huh .\nProfessor B: And one of the things you could do is , you could do some sort of VAD - like thing\nGrad E: Mm - hmm .\nProfessor B: and you actually could take very low - energy sections and set them to some {disfmarker} some , uh , very low or {disfmarker} or near zero {pause} value . I mean , uh , I 'm just saying if in fact it turns out that {disfmarker} that these echoes that you 're hearing are , uh {disfmarker}\nGrad E: Uh - huh .\nProfessor B: or pre - echoes , whichever they are {disfmarker} are {disfmarker} are , uh , part of what 's causing the problem , you actually could get rid of them .\nGrad E: Uh - huh .\nProfessor B: Be pretty simple . I mean , you do it in a pretty conservative way\nGrad E: OK .\nProfessor B: so that if you made a mistake you were more likely to {pause} keep in an echo than to throw out speech .\nGrad E: Hmm .\nPhD G: Um , what is the reverberation time {pause} like {pause} there ?\nGrad E: In thi in this room ? Uh {disfmarker}\nPhD G: On , uh , the {disfmarker} the one what {disfmarker} the s in the speech that you are {disfmarker} you are using like ?\nGrad E: Y Yeah . I {disfmarker} I {disfmarker} I {disfmarker} I don't know .\nProfessor B: So , it 's this room .\nPhD G: It 's , uh {disfmarker}\nProfessor B: It 's {disfmarker} it 's this room .\nPhD G: Oh , this room ?\nProfessor B: So {disfmarker}\nPhD G: OK .\nProfessor B: so it 's {disfmarker} these are just microphone {disfmarker} this micro close microphone and a distant microphone , he 's doing these different tests on .\nGrad F: Oh .\nProfessor B: Uh , we should do a measurement in here . I g think we never have . I think it 's {disfmarker} I would guess , uh , point seven , point eight seconds f uh , R T\nGrad F: Hmm !\nProfessor B: something like that ? But it 's {disfmarker} you know , it 's this room .\nPhD G: Mm - hmm .\nProfessor B: So .\nPhD G: OK . Mm - hmm .\nProfessor B: Uh . But the other thing is , he 's putting in {disfmarker} w I was using the word \" reverberation \" in two ways . He 's also putting in , uh , a {disfmarker} he 's taking out some reverberation , but he 's putting in something , because he has {pause} averages over multiple windows stretching out to twelve seconds , which are then being subtracted from the speech . And since , you know , what you subtract , sometimes you 'll be {disfmarker} you 'll be subtracting from some larger number and sometimes you won't . And {disfmarker}\nPhD G: Mm - hmm . Mm - hmm .\nProfessor B: So you can end up with some components in it that are affected by things that are seconds away . Uh , and if it 's a low {pause} energy compo portion , you might actually hear some {pause} funny things .\nPhD G: Yeah .\nGrad E: O o one thing , um , I noticed is that , um , the mean subtraction seems to make the PZM signals louder after they 've been re - synthesized . So I was wondering , is it possible that one reason it helped with the Aurora baseline system is {pause} just as a kind of gain control ? Cuz some of the PZM signals sound pretty quiet if you don't amplify them .\nPhD C: Mm - hmm . I don't see why {disfmarker} why your signal is louder after processing , because yo\nGrad E: Yeah . I don't know why - y , uh , either .\nPhD C: Yeah .\nProfessor B: I don't think just multiplying the signal by two would have any effect .\nPhD C: Mm - hmm .\nGrad E: Oh , OK .\nProfessor B: Yeah . I mean , I think if you really have louder signals , what you mean is that you have {pause} better signal - to - noise ratio .\nPhD C: Well , well {disfmarker}\nProfessor B: So if what you 're doing is improving the signal - to - noise ratio , then it would be better .\nPhD C: Mm - hmm .\nProfessor B: But just it being bigger if {disfmarker} with the same signal - to - noise ratio {disfmarker}\nGrad E: It w i i it wouldn't affect things .\nProfessor B: No .\nPhD C: Yeah .\nGrad E: OK .\nPhD C: Well , the system is {disfmarker} use {pause} the absolute energy , so it 's a little bit dependent on {disfmarker} on the {pause} signal level . But , not so much , I guess .\nProfessor B: Well , yeah . But it 's trained and tested on the same thing .\nPhD C: Mmm .\nProfessor B: So if the {disfmarker} if the {disfmarker} if you change {vocalsound} in both training and test , the absolute level by a factor of two , it will n have no effect .\nPhD C: Mm - hmm . Yeah .\nPhD A: Did you add {pause} this data to the training set , for the Aurora ? Or you just tested on this ?\nGrad E: Uh {disfmarker} Um . Did I w what ?\nPhD A: Well , Morgan was just saying that , uh , as long as you do it in both training and testing , it shouldn't have any effect .\nGrad E: Sorry ? Yeah .\nPhD A: But I {disfmarker} I was {pause} sort of under the impression that you just tested with this data .\nGrad E: I {disfmarker} I b\nPhD A: You didn't {pause} train it also .\nGrad E: I {disfmarker} Right . I trained on clean TI - digits . I {disfmarker} I did the mean subtraction on clean TI - digits . But I didn't {disfmarker} I 'm not sure if it made the clean ti TI - digits any louder .\nProfessor B: Oh , I see .\nGrad E: I only remember noticing it made the , um , PZM signal louder .\nProfessor B: OK . Well , I don't understand then . Yeah .\nGrad E: Huh . I don't know . If it 's {disfmarker} if it 's {disfmarker} like , if it 's trying to find a {disfmarker} a reverberation filter , it could be that this reverberation filter is making things quieter . And then if you take it out {disfmarker} that taking it out makes things louder . I mean .\nProfessor B: Uh , no . I mean , {vocalsound} uh , there 's {disfmarker} there 's nothing inherent about removing {disfmarker} if you 're really removing ,\nGrad E: Nuh - huh .\nProfessor B: uh , r uh , then I don't {pause} see how that would make it louder .\nGrad E: The mean . OK . Yeah , I see .\nProfessor B: So it might be just some {disfmarker}\nGrad E: Yeah . OK . So I should maybe listen to that stuff again .\nProfessor B: Yeah . It might just be some artifact of the processing that {disfmarker} that , uh , if you 're {disfmarker} Uh , yeah . I don't know .\nGrad E: Oh . OK .\nPhD A: I wonder if there could be something like , uh {disfmarker} for s for the PZM data ,\nPhD C: Eh\nPhD A: uh , you know , if occasionally , uh , somebody hits the table or something , you could get a spike . Uh . I 'm just wondering if there 's something about the , um {disfmarker} you know , doing the mean normalization where , uh , it {disfmarker} it could cause {pause} you to have better signal - to - noise ratio . Um .\nProfessor B: Well , you know , there is this . Wait a minute . It {disfmarker} it {disfmarker} i maybe {disfmarker} i If , um {disfmarker} Subtracting the {disfmarker} the mean log spectrum is {disfmarker} is {disfmarker} is like dividing by the spectrum . So , depending what you divide by , if your {disfmarker} if s your estimate is off and sometimes you 're {disfmarker} you 're {disfmarker} you 're getting a small number , you could make it bigger .\nPhD A: Mm - hmm .\nGrad E: Mm - hmm .\nProfessor B: So , it 's {disfmarker} it 's just a {disfmarker} a question of {disfmarker} there 's {disfmarker} It {disfmarker} it could be that there 's some normalization that 's missing , or something to make it {disfmarker}\nGrad E: Mm - hmm .\nProfessor B: Uh , y you 'd think it shouldn't be larger , but maybe in practice it is . That 's something to think about .\nGrad E: Hmm .\nProfessor B: I don't know .\nPhD C: I had a question about the system {disfmarker} the SRI system . So , {vocalsound} you trained it on TI - digits ? But except this , it 's exactly the same system as the one that was tested before and that was trained on {pause} Macrophone . Right ? So on TI - digits it gives you one point two percent error rate and on Macrophone it 's still O point eight . Uh , but is it {pause} exactly the same system ?\nGrad E: Uh . I think so .\nPhD C: Hmm .\nGrad E: If you 're talking about the Macrophone results that Andreas had about , um , a week and a half ago , I think it 's the same system .\nPhD C: Mm - hmm . So you use VTL - uh , vocal tract length normalization and , um , like MLLR transformations also ,\nGrad E: Mm - hmm .\nPhD C: and {disfmarker}\nProfessor B: I 'm sorry , was his point eight percent , er , a {disfmarker} a result on testing on Macrophone or {disfmarker} or training ?\nPhD C: all that stuff .\nGrad E: That 's {disfmarker}\nPhD C: It was {pause} training on Macrophone and testing {disfmarker} yeah , on {disfmarker} on meeting digits .\nProfessor B: Oh . So that was done already . So we were {disfmarker} Uh , and it 's point eight ? OK .\nPhD C: Mm - hmm .\nProfessor B: OK .\nPhD C: Yeah . I {disfmarker} I 've just been text {comment} testing the new {pause} Aurora front - end with {disfmarker} well , Aurora system actually {disfmarker} so front - end and HTK , um , acoustic models on the meeting digits and it 's a little bit better than the previous system . We have {disfmarker} I have two point seven percent error rate . And before with the system that was proposed , it 's what ? It was three point nine . So .\nProfessor B: Oh , that 's a lot better .\nPhD C: We are getting better .\nProfessor B: So , what {disfmarker} w ?\nPhD C: And {disfmarker}\nPhD G: With the {disfmarker} with the HTK back - end ? What we have for Aurora ?\nPhD C: Yeah . Two point seven .\nPhD G: I know in the meeting , like {disfmarker}\nPhD C: On the meeting we have two point seven .\nPhD G: Right . Oh .\nGrad F: That 's with the new IIR filters ?\nPhD C: Uh . Yeah , yeah . So , yeah ,\nGrad F: OK .\nPhD C: we have {pause} the new LDA filters , and {disfmarker} I think , maybe {disfmarker} I didn't look , but one thing that makes a difference is this DC offset compensation . Uh , eh {disfmarker} Do y did you have a look at {disfmarker} at the meet uh , meeting digits , if they have a DC component , or {disfmarker} ?\nGrad E: I {disfmarker} I didn't . No .\nPhD C: Oh .\nProfessor B: Hmm .\nPhD G: No . The DC component could be negligible . I mean , if you are {pause} recording it through a mike . I mean , any {disfmarker} all of the mikes have the DC removal {disfmarker} some capacitor sitting right in {pause} that bias it .\nProfessor B: Yeah . But this {disfmarker} uh , uh , uh , no . Because , uh , there 's a sample and hold in the A - toD. And these period these typically do have a DC offset .\nPhD G: Oh , OK .\nProfessor B: And {disfmarker} and they can be surprisingly large . It depends on the electronics .\nPhD G: Oh , so it is the digital {disfmarker} OK . It 's the A - toD that introduces the DC in .\nProfessor B: Yeah . The microphone isn't gonna pass any DC .\nPhD G: Yeah . Yeah . Yeah .\nProfessor B: But {disfmarker} but ,\nPhD G: OK .\nProfessor B: typi you know , unless {disfmarker} Actually , there are {pause} instrumentation mikes that {disfmarker} that do pass {disfmarker} go down to DC . But {disfmarker} but ,\nPhD G: Mm - hmm .\nProfessor B: uh , no , it 's the electronics . And they {disfmarker} and {disfmarker}\nPhD G: Mm - hmm .\nProfessor B: then there 's amplification afterwards . And you can get , I think it was {disfmarker} I think it was in the {pause} Wall Street Journal data that {disfmarker} that {disfmarker} I can't remember , one of the DARPA things . There was this big DC - DC offset\nPhD A: Mm - hmm .\nProfessor B: we didn't {disfmarker} we didn't know about for a while , while we were {pause} messing with it . And we were getting these terrible results . And then we were talking to somebody and they said , \" Oh , yeah . Didn't you know ? Everybody knows that . There 's all this DC offset in th \" So , yes . You can have DC offset in the data .\nPhD G: Oh , OK .\nProfessor B: Yeah .\nPhD G: OK .\nPhD A: So was that {disfmarker} was that everything , Dave ?\nGrad E: Oh . And I also , um , did some experiments {pause} about normalizing the phase . Um . So I c I came up with a web page that people can take a look at . And , um , the interesting thing that I tried was , um , Adam and Morgan had this idea , um , since my original attempts to , um , take the mean of the phase spectra over time and normalize using that , by subtracting that off , didn't work . Um , so , well , that we thought that might be due to , um , problems with , um , the arithmetic of phases . They {disfmarker} they add in this modulo two pi way and , um , there 's reason to believe that that approach of taking the mean of the phase spectrum wasn't really {pause} mathematically correct . So , {vocalsound} what I did instead is I {vocalsound} took the mean of the FFT spectrum without taking the log or anything , and then I took the phase of that , and I subtracted that phase {pause} off to normalize . But that , um , didn't work either .\nProfessor B: See , we have a different interpretation of this . He says it doesn't work . I said , I think it works magnificently , but just not for the task we intended . Uh , it gets rid of the speech .\nPhD A: What does it leave ?\nGrad F: Uh , gets rid of the speech .\nProfessor B: Uh , it leaves {disfmarker} you know , it leaves the junk . I mean , I {disfmarker} I think it 's {disfmarker} it 's tremendous .\nGrad F: Oh , wow .\nProfessor B: You see , all he has to do is go back and reverse what he did before , and he 's really got something .\nPhD A: Well , could you take what was left over and then subtract that ?\nProfessor B: Ex - exactly . Yeah , you got it .\nGrad F: Yeah .\nPhD G: Yeah .\nProfessor B: So , it 's {disfmarker} it 's a general rule .\nPhD G: Oh , it 's {disfmarker}\nProfessor B: Just listen very carefully to what I say and do the opposite . Including what I just said .\nGrad E: And , yeah , that 's everything .\nPhD A: All set ? Do you want to go , Stephane ?\nPhD C: Um . Yeah . Maybe , concerning these d still , these meeting digits . I 'm more interested in trying to figure out what 's still the difference between the SRI system and the Aurora system . And {disfmarker} Um . Yeah . So , I think I will maybe train , like , gender - dependent models , because {pause} this is also one big difference between {pause} the two systems . Um , the other differences were {pause} the fact that maybe the acoustic models of the SRI are more {disfmarker} SRI system are more complex . But , uh , Chuck , you did some experiments with this and\nPhD A: It didn't seem to help in the HTK system .\nPhD C: it was hard t to {disfmarker} to have some exper some improvement with this . Um .\nProfessor B: Well , it sounds like they also have {disfmarker} he {disfmarker} he 's saying they have all these , uh , uh , different kinds of adaptation .\nPhD C: Mm - hmm .\nProfessor B: You know , they have channel adaptation . They have speaker adaptation .\nPhD C: Yeah . Right .\nPhD A: Well , there 's also the normalization .\nProfessor B: Yeah . Yeah .\nPhD C: Yeah .\nGrad F: Yeah .\nPhD A: Like they do , um {disfmarker} I 'm not sure how they would do it when they 're working with the digits ,\nPhD C: The vocal tr\nPhD A: but , like , in the Switchboard data , there 's , um {disfmarker} conversation - side normalization for the {pause} non - C - zero components ,\nPhD C: Yeah . Yeah . This is another difference . Their normalization works like on {disfmarker} on the utterance levels .\nPhD A: Mm - hmm .\nPhD C: But we have to do it {disfmarker} We have a system that does it on - line .\nPhD A: Right .\nPhD C: So , it might be {disfmarker} it might be better with {disfmarker} it might be worse if the {pause} channel is constant ,\nPhD A: Yeah .\nPhD C: or {disfmarker} Nnn .\nPhD G: And the acoustic models are like - k triphone models or {disfmarker} or is it the whole word ?\nPhD C: SRI {disfmarker} it 's {disfmarker} it 's tr\nGrad F: SRI .\nPhD G: Yeah .\nPhD C: Yeah . I guess it 's triphones .\nPhD G: It 's triphone .\nProfessor B: I think it 's probably more than that .\nPhD C: Huh .\nProfessor B: I mean , so they {disfmarker} they have {disfmarker} I {disfmarker} I thin think they use these , uh , uh , genone things . So there 's {disfmarker} there 's these kind of , uh , uh , pooled models and {disfmarker} and they can go out to all sorts of dependencies .\nPhD G: Oh . It 's like the tied state .\nProfessor B: So .\nPhD A: Mm - hmm .\nProfessor B: They have tied states and I think {disfmarker} I {disfmarker} I {disfmarker} I don't real I 'm talk I 'm just guessing here . But I think {disfmarker} I think they {disfmarker} they don't just have triphones .\nPhD G: OK .\nProfessor B: I think they have a range of {disfmarker} of , uh , dependencies .\nPhD C: Mm - hmm .\nPhD G: Mm - hmm .\nPhD C: Mm - hmm .\nGrad F: Hmm .\nPhD C: And {disfmarker} Yeah . Well . Um . Well , the first thing I {disfmarker} that I want to do is just maybe these gender things . Uh . And maybe see with {pause} Andreas if {disfmarker} Well , I {disfmarker} I don't know {pause} how much it helps , what 's the model .\nPhD A: So {disfmarker} so the n stuff on the numbers you got , the two point seven , is that using the same training data that the SRI system used and got one point two ?\nPhD C: That 's right . So it 's the clean {pause} TI - digits training set .\nPhD A: So exact same training data ?\nPhD C: Right .\nPhD A: OK .\nPhD C: Mm - hmm . I guess you used the clean training set .\nGrad E: Right .\nPhD C: Mm - hmm .\nGrad E: For {disfmarker} with the SRI system {disfmarker}\nPhD C: Well .\nGrad E: You know , the {disfmarker} the Aurora baseline is set up with these , um {disfmarker} {vocalsound} this version of the clean training set that 's been filtered with this G - seven - one - two filter , and , um , to train the SRI system on digits S - Andreas used the original TI - digits , um , under U doctor - speech data TI - digits , which don't have this filter . But I don't think there 's any other difference .\nPhD C: Mm - hmm . Mm - hmm . Yeah .\nProfessor B: So is that {disfmarker} ? Uh , are {disfmarker} are these results comparable ? So you {disfmarker} you were getting with the , uh , Aurora baseline something like two point four percent {pause} on clean TI - digits , when , uh , training the SRI system with clean TR digits {disfmarker} {comment} TI - digits . Right ? And {disfmarker}\nGrad E: Um . Uh - huh .\nProfessor B: Yeah . And , so , is your two point seven comparable , where you 're , uh , uh , using , uh , the submitted system ?\nPhD C: Yeah . I think so .\nProfessor B: OK .\nPhD C: Yeah .\nProfessor B: So it 's {pause} about the same ,\nPhD C: Mm - hmm .\nProfessor B: maybe a little worse .\nGrad E: W w it was one {disfmarker} one point two\nPhD C: Ye\nGrad E: with the SRI system ,\nProfessor B: I 'm sorry .\nPhD C: Yeah .\nGrad E: I {disfmarker}\nPhD C: The complete SRI system is one point two .\nProfessor B: You {disfmarker} you were HTK .\nPhD C: Yeah .\nProfessor B: Right ? OK . That 's right . So {disfmarker}\nPhD C: Mm - hmm .\nProfessor B: OK , so {pause} the comparable number then , uh {pause} for what you were talking about then , since it was HTK , would be the {pause} um , two point f\nPhD C: It was four point something . Right ? The HTK system with , uh , b\nGrad E: D d\nProfessor B: Oh , right , right , right , right .\nPhD C: MFCC features {disfmarker}\nGrad E: Do you mean the b ? The baseline Aurora - two system , trained on TI - digits , tested on Meeting Recorder near , I think we saw in it today , and it was about six point six percent .\nProfessor B: Right . Right , right , right .\nPhD C: Oh .\nProfessor B: OK . Alright . So {disfmarker} He 's doing some {pause} different things .\nPhD C: So {disfmarker} Yeah . The only difference is the features , right now , between this and {disfmarker}\nProfessor B: Yes . OK , good . So they are helping .\nPhD C: Mm - hmm .\nProfessor B: That 's good to hear . Yeah .\nPhD C: They are helping . Yeah . Um . Yeah . And another thing I {disfmarker} I maybe would like to do is to {pause} just test the SRI system that 's trained on Macrophone {disfmarker} test it on , uh , the noisy TI - digits ,\nProfessor B: Yeah .\nPhD C: cuz I 'm still wondering {pause} where this {pause} improvement comes from . When you train on Macrophone , it seems better on meeting digits . But I wonder if it 's just because maybe {pause} Macrophone is acoustically closer to the meeting digits than {disfmarker} than TI - digit is , which is {disfmarker} TI - digits are very {pause} clean recorded digits\nProfessor B: Mm - hmm .\nPhD C: and {disfmarker}\nPhD A: You know , it would also be interesting to see , uh {disfmarker} to do the regular Aurora test ,\nPhD C: Uh , f s\nPhD A: um , but use the SRI system instead of HTK .\nPhD C: That 's {disfmarker} Yeah . That 's what {pause} I wanted , just , uh {disfmarker} Yeah . So , just using the SRI system , test it on {disfmarker} and test it on {pause} Aurora TI - digits . Right .\nPhD A: Why not the full Aurora , uh , test ?\nPhD C: Um . Yeah . There is this problem of multilinguality yet .\nPhD A: Mm - hmm .\nPhD C: So we don't {disfmarker}\nProfessor B: You 'd have to train the SRI system with {disfmarker} with all the different languages .\nPhD C: i i\nPhD A: Right .\nPhD C: We would have to train on {disfmarker}\nPhD A: Yeah . That 's what I mean .\nPhD C: Yeah .\nPhD A: So , like , comple\nProfessor B: It 'd be a {pause} lot of work . That 's the only thing .\nPhD C: Yeah .\nPhD A: Mmm .\nPhD C: It 's {disfmarker}\nPhD A: Well , I mean ,\nPhD C: Mmm .\nPhD A: uh , uh , I guess the work would be into getting the {disfmarker} the files in the right formats , or something . Right ? I mean {disfmarker}\nPhD C: Mm - hmm .\nPhD A: Because when you train up the Aurora system , you 're , uh {disfmarker} you 're also training on all the data .\nPhD C: That 's right .\nPhD A: I mean , it 's {disfmarker}\nPhD C: Yeah . Yeah . I see . Oh , so , OK . Right . I see what you mean .\nProfessor B: That 's true , but I think that also when we 've had these meetings week after week , oftentimes people have not done the full arrange of things\nPhD A: Mm - hmm .\nProfessor B: because {disfmarker} on {disfmarker} on whatever it is they 're trying , because it 's a lot of work , even just with the HTK .\nPhD A: Mm - hmm .\nProfessor B: So , it 's {disfmarker} it 's a good idea , but it seems like {pause} it makes sense to do some pruning\nPhD A: Mm - hmm .\nProfessor B: first with a {disfmarker} a test or two that makes sense for you ,\nPhD A: Yeah .\nProfessor B: and then {pause} take the likely candidates and go further .\nPhD A: Yeah .\nPhD C: Mm - hmm . Yeah . But , just testing on TI - digits would already give us some information {pause} about what 's going on . And {disfmarker} mm - hmm . Uh , yeah . OK . Uh , the next thing is this {disfmarker} this VAD problem that , um , um {disfmarker} So , I 'm just talking about the {disfmarker} the curves that I {disfmarker} I sent {disfmarker} {vocalsound} I sent you {disfmarker} so , whi that shows that {vocalsound} when the SNR decrease , {vocalsound} uh , the current {pause} VAD approach doesn't drop much frames {pause} for some particular noises , uh , which might be then noises that are closer to speech , uh , acoustically .\nProfessor B: I i Just to clarify something for me . I They were supp Supposedly , in the next evaluation , they 're going to be supplying us with boundaries .\nPhD C: Mm - hmm .\nProfessor B: So does any of this matter ? I mean , other than our interest in it . Uh {disfmarker}\nPhD C: Uh {disfmarker} Well . First of all , the boundaries might be , uh {disfmarker} like we would have t two hundred milliseconds or {disfmarker} before and after speech . Uh . So removing more than that might still make {pause} a difference {pause} in the results .\nProfessor B: Do we {disfmarker} ? I mean , is there some reason that we think that 's the case ?\nPhD C: And {disfmarker} No . Because we don't {disfmarker} didn't looked {pause} that much at that .\nProfessor B: Yeah .\nPhD C: But , {vocalsound} still , I think it 's an interesting problem .\nProfessor B: Oh , yeah .\nPhD C: And {disfmarker} Um . Yeah .\nProfessor B: But maybe we 'll get some insight on that when {disfmarker} when , uh , the gang gets back from Crete . Because {pause} there 's lots of interesting problems , of course .\nPhD C: Mm - hmm .\nProfessor B: And then the thing is if {disfmarker} if they really are going to have some means of giving us {pause} fairly tight , uh , boundaries , then that won't be so much the issue .\nPhD C: Yeah , yeah . Mm - hmm . Mm - hmm .\nProfessor B: Um But {vocalsound} I don't know .\nPhD G: Because w we were wondering whether that {pause} VAD is going to be , like , a realistic one or is it going to be some manual segmentation . And then , like , if {disfmarker} if that VAD is going to be a realistic one , then we can actually use their markers to shift the point around , I mean , the way we want\nProfessor B: Mm - hmm .\nPhD G: to find a {disfmarker} I mean , rather than keeping the twenty frames , we can actually move the marker to a point which we find more {pause} suitable for us .\nProfessor B: Right .\nPhD G: But if that is going to be something like a manual , uh , segmenter , then we can't {pause} use that information anymore ,\nPhD C: Mm - hmm .\nPhD G: because that 's not going to be the one that is used in the final evaluation .\nProfessor B: Right .\nPhD G: So . We don't know what is the type of {pause} {vocalsound} {pause} VAD which they 're going to provide .\nProfessor B: Yeah .\nPhD C: Yeah . And actually there 's {disfmarker} Yeah . There 's an {disfmarker} uh , I think it 's still for {disfmarker} even for the evaluation , uh , it might still be interesting to {vocalsound} work on this because {pause} the boundaries apparently that they would provide is just , {vocalsound} um , starting of speech and end of speech {pause} uh , at the utterance level . And {disfmarker} Um .\nPhD G: With some {disfmarker} some gap .\nPhD C: So {disfmarker}\nPhD G: I mean , with some pauses in the center , provided they meet that {disfmarker} whatever the hang - over time which they are talking .\nPhD C: Yeah . But when you have like , uh , five or six frames , both {disfmarker}\nPhD G: Yeah . Then the they will just fill {disfmarker} fill it up .\nPhD C: it {disfmarker} it {disfmarker} with {disfmarker}\nPhD G: I mean , th {disfmarker} Yeah .\nPhD C: Yeah .\nProfessor B: So if you could get at some of that , uh {disfmarker}\nPhD C: So {disfmarker}\nProfessor B: although that 'd be hard .\nPhD C: Yeah . It might be useful for , like , noise estimation , and a lot of other {pause} things that we want to work on .\nProfessor B: But {disfmarker} but {disfmarker} Yeah .\nPhD G: Yeah .\nProfessor B: Right . OK .\nPhD C: But {disfmarker} Mmm . Yeah . So I did {disfmarker} I just {pause} started to test {pause} putting together two VAD which was {disfmarker} was not much work actually . Um , I im re - implemented a VAD that 's very close to the , {vocalsound} um , energy - based VAD {vocalsound} that , uh , the other Aurora guys use . Um . So , which is just putting a threshold on {pause} the noise energy ,\nProfessor B: Mm - hmm .\nPhD C: and , detect detecting the first {pause} group of four frames {pause} that have a energy that 's above this threshold , and , uh , from this point , uh , tagging the frames there as speech . So it removes {vocalsound} the first silent portion {disfmarker} portion of each utterance . And it really removes it , um , still o on the noises where {pause} our MLP VAD doesn't {pause} work a lot .\nProfessor B: Mmm .\nPhD C: Uh ,\nProfessor B: Cuz I would have thought that having some kind of spectral {pause} information ,\nPhD C: and {disfmarker}\nProfessor B: uh {disfmarker} uh , you know , in the old days people would use energy and zero crossings , for instance {disfmarker} uh , would give you some {pause} better performance . Right ? Cuz you might have low - energy fricatives or {disfmarker} or , uh {pause} stop consonants , or something like that .\nPhD C: Mm - hmm .\nProfessor B: Uh .\nPhD C: Yeah . So , your point is {disfmarker} will be to u use whatever {disfmarker}\nProfessor B: Oh , that if you d if you use purely energy and don't look at anything spectral , then you don't have a good way of distinguishing between low - energy speech components and {pause} nonspeech . And , um ,\nPhD C: Mm - hmm .\nProfessor B: just as a gross generalization , most nonsp many nonspeech noises have a low - pass kind of characteristic , some sort of slope . And {disfmarker} and most , um , low - energy speech components that are unvoiced have a {disfmarker} a high - pass kind of characteristic {disfmarker}\nPhD C: Mm - hmm .\nProfessor B: an upward slope . So having some kind of a {disfmarker}\nPhD C: Yeah .\nProfessor B: uh , you know , at the beginning of a {disfmarker} of a {disfmarker} of an S sound for instance , just starting in , it might be pretty low - energy ,\nPhD C: Mm - hmm .\nProfessor B: but it will tend to have this high - frequency component . Whereas , {vocalsound} a {disfmarker} a lot of rumble , and background noises , and so forth will be predominantly low - frequency . Uh , you know , by itself it 's not enough to tell you , but it plus energy is sort of {disfmarker}\nPhD C: Yeah .\nProfessor B: it plus energy plus timing information is sort of {disfmarker}\nPhD C: Mm - hmm .\nProfessor B: I mean , if you look up in Rabiner and Schafer from like twenty - five years ago or something , that 's sort of {pause} what they were using then .\nPhD C: Mm - hmm .\nProfessor B: So it 's {disfmarker} it 's not a {disfmarker}\nPhD C: Mm - hmm .\nGrad F: Hmm .\nPhD C: So , yeah . It {disfmarker} it might be that what I did is {disfmarker} so , removes like {vocalsound} low , um , {vocalsound} uh {disfmarker} low - energy , uh , speech frames . Because {pause} the way I do it is I just {disfmarker} I just combine the two decisions {disfmarker} so , the one from the MLP and the one from the energy - based {disfmarker} with the {disfmarker} with the and {pause} operator . So , I only {pause} keep the frames where the two agree {pause} that it 's speech . So if the energy - based dropped {disfmarker} dropped low - energy speech , mmm , they {disfmarker} they are {disfmarker} they are lost . Mmm .\nProfessor B: Mm - hmm .\nPhD C: But s still , the way it 's done right now it {disfmarker} it helps on {disfmarker} on the noises where {disfmarker} it seems to help on the noises where {vocalsound} our VAD was not very {pause} good .\nProfessor B: Well , I guess {disfmarker} I mean , one could imagine combining them in different ways . But {disfmarker} but , I guess what you 're saying is that the {disfmarker} the MLP - based one has the spectral information . So .\nPhD C: Yeah . But {disfmarker} Yeah . But the way it 's combined wi is maybe done {disfmarker} Well , yeah .\nProfessor B: Well , you can imagine {disfmarker}\nPhD C: The way I use a an a \" AND \" operator is {disfmarker} So , it {disfmarker} I , uh {disfmarker}\nProfessor B: Is {disfmarker} ?\nPhD C: The frames that are dropped by the energy - based system are {disfmarker} are , uh , dropped , even if the , um , MLP decides to keep them .\nProfessor B: Right . Right . And that might not be optimal ,\nPhD C: But , yeah .\nProfessor B: but {disfmarker}\nPhD C: Mm - hmm .\nPhD A: No\nProfessor B: but {disfmarker} I mean , I guess in principle what you 'd want to do is have a {disfmarker} {vocalsound} uh , a probability estimated by each one and {disfmarker} and put them together .\nPhD C: Yeah . Mmm . M Yeah .\nPhD A: Something that {disfmarker} that I 've used in the past is , um {disfmarker} when just looking at the energy , is to look at the derivative . And you {pause} make your decision when the derivative is increasing for {pause} so many frames . Then you say that 's beginning of speech .\nPhD C: Uh - huh .\nPhD A: But , I 'm {disfmarker} I 'm trying to remember if that requires that you keep some amount of speech in a buffer . I guess it depends on how you do it . But {pause} I mean , that 's {disfmarker} that 's been a useful thing .\nProfessor B: Yeah .\nPhD C: Mm - hmm .\nGrad F: Mm - hmm .\nPhD G: Yeah . Well , every everywhere has a delay associated with it . I mean , you still have to k always keep a buffer ,\nPhD A: Mm - hmm .\nPhD G: then only make a decision because {pause} you still need to smooth the {pause} decision further .\nPhD A: Right . Right .\nPhD G: So that 's always there .\nPhD A: Yeah . OK .\nPhD C: Well , actually if I don't {disfmarker} maybe don't want to work too much of {disfmarker} on it right now . I just wanted to {disfmarker} to see if it 's {disfmarker} {vocalsound} what I observed was the re was caused by this {disfmarker} this VAD problem .\nProfessor B: Mm - hmm .\nPhD C: And it seems to be the case . Um . Uh , the second thing is the {disfmarker} this spectral subtraction . Um . Um , which I 've just started yesterday to launch a bunch of , uh , {nonvocalsound} twenty - five experiments , uh , with different , uh , values for the parameters that are used . So , it 's the Makhoul - type spectral subtraction which use {pause} an over - estimation factor . So , we substr I subtract more , {vocalsound} {vocalsound} um , {nonvocalsound} {vocalsound} noise than the noise spectra that {pause} is estimated {pause} on the noise portion of the s uh , the utterances . So I tried several , uh , over - estimation factors . And after subtraction , I also add {pause} a constant noise , and I also try different , uh , {vocalsound} noise , uh , values and we 'll see what happen .\nProfessor B: Hmm . OK .\nPhD C: Mm - hmm . Mm - hmm . But st still when we look at the , um {disfmarker} Well , it depends on the parameters that you use , but for moderate over - estimation factors and moderate noise level that you add , you st have a lot of musical noise . Um . On the other hand , when you {pause} subtract more and when you add more noise , you get rid of this musical noise but {pause} maybe you distort a lot of speech . So . Well . Mmm . Well , it {disfmarker} until now , it doesn't seem to help . But We 'll see . So the next thing , maybe I {disfmarker} what I will {pause} try to {disfmarker} to do is just {pause} to try to smooth mmm , {vocalsound} the , um {disfmarker} to smooth the d the result of the subtraction , to get rid of the musical noise , using some kind of filter , or {disfmarker}\nPhD G: Can smooth the SNR estimate , also .\nPhD C: Yeah . Right . Mmm .\nPhD G: Your filter is a function of SNR . Hmm ?\nPhD C: Yeah . So , to get something that 's {disfmarker} would be closer to {pause} what you tried to do with Wiener filtering .\nPhD G: Yeah .\nPhD C: And {disfmarker} Mm - hmm . Yeah .\nPhD G: Actually , it 's , uh {disfmarker} Uh . I don't know , it 's {disfmarker} go ahead .\nPhD C: It {disfmarker}\nPhD G: And it 's {disfmarker}\nPhD C: Maybe you can {disfmarker}\nPhD G: go ahead .\nPhD C: I think it 's {disfmarker} That 's it for me .\nPhD G: OK . So , uh {disfmarker} u th I 've been playing with this Wiener filter , like . And there are {disfmarker} there were some bugs in the program , so I was p initially trying to clear them up . Because one of the bug was {disfmarker} I was assuming that always the VAD {disfmarker} uh , the initial frames were silence . It always started in the silence state , but it wasn't for some utterances . So the {disfmarker} it wasn't estimating the noise initially , and then it never estimated , because I assumed that it was always silence .\nPhD C: Mm - hmm . So this is on SpeechDat - Car Italian ?\nPhD G: Yeah .\nPhD C: So , in some cases s there are also {disfmarker}\nPhD G: SpeechDat - Car Italian . Yeah . There 're a few cases , actually , which I found later , that there are .\nPhD C: o Uh - huh .\nPhD G: So that was one of the {pause} bugs that was there in estimating the noise . And , uh , so once it was cleared , uh , I ran a few experiments with {pause} different ways of smoothing the estimated clean speech and how t estimated the noise and , eh , smoothing the SNR also . And so the {disfmarker} the trend seems to be like , {vocalsound} uh , smoothing the {pause} current estimate of the clean speech for deriving the SNR , which is like {pause} deriving the Wiener filter , seems to be helping . Then updating it quite fast using a very small time constant . So we 'll have , like , a few results where the {disfmarker} estimating the {disfmarker} the {disfmarker} More smoothing is helping . But still it 's like {disfmarker} it 's still comparable to the baseline . I haven't got anything beyond the baseline . But that 's , like , not using any Wiener filter . And , uh , so I 'm {disfmarker} I 'm trying a few more experiments with different time constants for smoothing the noise spectrum , and smoothing the clean speech , and smoothing SNR . So there are three time constants that I have . So , I 'm just playing around . So , one is fixed in the line , like {pause} Smoothing the clean speech is {disfmarker} is helping , so I 'm not going to change it that much . But , the way I 'm estimating the noise and the way I 'm estimating the SNR , I 'm just trying {disfmarker} trying a little bit . So , that h And the other thing is , like , putting a floor on the , uh , SNR , because that {disfmarker} if some {disfmarker} In some cases the clean speech is , like {disfmarker} when it 's estimated , it goes to very low values , so the SNR is , like , very low . And so that actually creates a lot of variance in the low - energy region of the speech . So , I 'm thinking of , like , putting a floor also for the SNR so that it doesn't {pause} vary a lot in the low - energy regions . And , uh . So . The results are , like {disfmarker} So far I 've been testing only with the {pause} baseline , which is {disfmarker} which doesn't have any LDA filtering and on - line normalization . I just want to separate the {disfmarker} the contributions out . So it 's just VAD , plus the Wiener filter , plus the baseline system , which is , uh , just the spectral {disfmarker} I mean , the mel sp mel , uh , frequency coefficients . Um . And the other thing that I tried was {disfmarker} but I just {vocalsound} took of those , uh , {pause} {vocalsound} Carlos filters , which Hynek had , to see whether it really h helps or not . I mean , it was just a {disfmarker} a run to see whether it really degrades or it helps . And it 's {disfmarker} it seems to be like it 's not {vocalsound} hurting a lot by just blindly picking up one filter which is nothing but a {pause} four hertz {disfmarker} a band - pass m m filter on the cubic root of the power spectrum . So , that was the filter that Hy - uh , Carlos had . And so {disfmarker} Yeah . Just {disfmarker} just to see whether it really {disfmarker} it 's {disfmarker} it 's {disfmarker} is it worth trying or not . So , it doesn't seems to be degrading a lot on that . So there must be something that I can {disfmarker} that can be done with that type of noise compensation also , which {disfmarker} {vocalsound} I guess I would ask Carlos about that . I mean , how {disfmarker} how he derived those filters and {disfmarker} and where d if he has any filters which are derived on OGI stories , added with some type of noise which {disfmarker} what we are using currently , or something like that . So maybe I 'll {disfmarker}\nProfessor B: This is cubic root of power spectra ?\nPhD G: Yeah . Cubic root of power spectrum .\nProfessor B: So , if you have this band - pass filter , you probably get n you get negative values . Right ?\nPhD G: Yeah . And I 'm , like , floating it to z zeros right now .\nProfessor B: OK .\nPhD G: So it has , like {disfmarker} the spectrogram has , like {disfmarker} Uh , it actually , uh , enhances the onset and offset of {disfmarker} I mean , the {disfmarker} the begin and the end of the speech . So it 's {disfmarker} there seems to be , like , deep valleys in the begin and the end of , like , high - energy regions ,\nProfessor B: Mm - hmm .\nPhD G: because the filter has , like , a sort of Mexican - hat type structure .\nProfessor B: Mm - hmm .\nPhD G: So , those are the regions where there are , like {disfmarker} when I look at the spectrogram , there are those deep valleys on the begin and the end of the speech . But the rest of it seems to be , like , pretty nice .\nProfessor B: Mm - hmm .\nPhD G: So . That 's {pause} something I observe using that filter . And {disfmarker} Yeah . There are a few {disfmarker} very {disfmarker} not a lot of {disfmarker} because the filter doesn't have a {disfmarker} really a deep negative portion , so that it 's not really creating a lot of negative values in the cubic root . So , I 'll {disfmarker} I 'll s may continue with that for some w I 'll {disfmarker} I 'll {disfmarker} Maybe I 'll ask Carlos a little more about how to play with those filters , and {disfmarker} but while {pause} making this Wiener filter better . So . Yeah . That {disfmarker} that 's it , Morgan .\nProfessor B: Uh , last week you were also talking about building up the subspace {pause} stuff ?\nPhD G: Yeah . I {disfmarker} I {disfmarker} I would actually m m didn't get enough time to work on the subspace last week . It was mostly about {pause} finding those bugs and\nProfessor B: OK .\nPhD G: th you know , things , and I didn't work much on that .\nPhD A: How about you , Carmen ?\nPhD D: Well , I am still working with , eh , VTS . And , one of the things that last week , eh , say here is that maybe the problem was with the diff because the signal have different level of energy .\nProfessor B: Hmm ?\nPhD D: And , maybe , talking with Stephane and with Sunil , we decide that maybe it was interesting to {disfmarker} to apply on - line normalization before applying VTS . But then {vocalsound} we decided that that 's {disfmarker} it doesn't work absolutely , because we modified also the noise . And {disfmarker} Well , thinking about that , we {disfmarker} we then {disfmarker} we decide that maybe is a good idea . We don't know . I don't hav I don't {disfmarker} this is {disfmarker} I didn't {pause} do the experiment yet {disfmarker} to apply VTS in cepstral domain .\nProfessor B: The other thing {pause} is {disfmarker} So {disfmarker} so , in {disfmarker} i i and {disfmarker} Not {disfmarker} and C - zero would be a different {disfmarker} So you could do a different normalization for C - zero than for other things anyway . I mean , the other thing I was gonna suggest is that you could have {pause} two kinds of normalization with {disfmarker} with , uh , different time constants . So , uh , you could do some normalization {vocalsound} s uh , before the VTS , and then do some other normalization after . I don't know . But {disfmarker} but C - zero certainly acts differently than the others do ,\nPhD D: Uh .\nProfessor B: so that 's {disfmarker}\nPhD C: Mm - hmm .\nPhD D: Well , we s decide to m to {disfmarker} to obtain the new expression if we work in the cepstral domain . And {disfmarker} Well . I am working in that now ,\nProfessor B: Uh - huh .\nPhD D: but {vocalsound} I 'm not sure if that will be usefu useful . I don't know . It 's k it 's k It 's quite a lot {disfmarker} It 's a lot of work .\nProfessor B: Uh - huh .\nPhD D: Well , it 's not too much , but this {disfmarker} it 's work .\nProfessor B: Yeah .\nPhD D: And I want to know if {disfmarker} if we have some {pause} feeling that {pause} the result {disfmarker} I {disfmarker} I would like to know if {disfmarker} I don't have any feeling if this will work better than apply VTS aft in cepstral domain will work better than apply in m mel {disfmarker} in filter bank domain . I r I 'm not sure . I don't {disfmarker} I don't know absolutely nothing .\nPhD C: Mm - hmm .\nProfessor B: Yeah . Well , you 're {disfmarker} I think you 're the first one here to work with VTS , so , uh , maybe we could call someone else up who has , ask them their opinion . Uh ,\nPhD C: Mm - hmm .\nProfessor B: I don't {disfmarker} I don't have a good feeling for it . Um .\nPhD G: Pratibha .\nPhD C: Actually , the VTS that you tested before was in the log domain and so {pause} the codebook is e e kind of dependent on the {pause} level of the speech signal .\nPhD D: Yeah ?\nPhD C: And {disfmarker} So I expect it {disfmarker} If {disfmarker} if you have something that 's independent of this , I expect it to {disfmarker} it {disfmarker} to , uh , be a better model of speech .\nPhD D: To have better {disfmarker}\nPhD C: And . Well .\nProfessor B: You {disfmarker} you wouldn't even need to switch to cepstra . Right ? I mean , you can just sort of normalize the {disfmarker}\nPhD C: No . We could normali norm I mean , remove the median .\nProfessor B: Yeah . Yeah . And then you have {pause} one number which is very dependent on the level cuz it is the level ,\nPhD D: Mm - hmm .\nProfessor B: and the other which isn't .\nPhD C: Mm - hmm . Yeah . But here also we would have to be careful about removing the mean {pause} of speech and not of noise .\nPhD D: Ye\nPhD C: Because it 's like {pause} first doing general normalization\nPhD D: Yea\nPhD C: and then noise removal , which is {disfmarker}\nPhD D: Yeah . We {disfmarker} I was thinking to {disfmarker} to {disfmarker} to estimate the noise {pause} with the first frames and then apply the VAD ,\nProfessor B: Mm - hmm .\nPhD C: Mm - hmm .\nPhD D: before the on - line normalization .\nPhD C: Mm - hmm .\nPhD D: We {disfmarker} we see {disfmarker} Well , I am thinking {vocalsound} about that and working about that ,\nProfessor B: Yeah .\nPhD D: but I don't have result this week .\nProfessor B: Sure . I mean , one of the things we 've talked about {disfmarker} maybe it might be star time to start thinking about pretty soon , is as we look at the pros and cons of these different methods , how do they fit in with one another ? Because {pause} we 've talked about potentially doing some combination of a couple of them . Maybe {disfmarker} maybe pretty soon we 'll have some sense of what their {pause} characteristics are ,\nPhD D: Mm - hmm .\nProfessor B: so we can see what should be combined .\nPhD C: Mm - hmm .\nPhD A: Is that it ? OK ?\nProfessor B: OK . Why don't we read some digits ?\nPhD A: Yep . Want to go ahead , Morgan ?\nProfessor B: Sure .\nPhD A: Transcript L dash two one five .\nProfessor B: O K .", "source": "meeting_summ", "evaluation": "human"}
{"instructions": ["Summarize discussion on what to include in the meeting corpus and how to structure it", "Summarize discussion on issues with data storage", "What did the participants think about what constitutes a meeting?", "What did PhD I think about segmentation?", "What did the Professor think about storing data?", "What did the participants think about using CD's for backup?", "Summarize the meeting"], "outputs": ["The discussion centered on the extent to which the recordings should be segmented for the corpus and which recordings should be included in the corpus. The team expressed that it would be helpful to filter out breath and non-verbal sounds. It also expressed that for two person conversations and transcripts that do not follow their general meeting setup, it could create a different directory.", "The team felt that the current file system they were using was running out of space, specifically back-up capacity. They needed to figure out a way to back-up the data they were collecting. They decided that the tape system that ICSI has is pretty reliable. But they needed to discuss the matter with the system administrator.", "The participants were skeptical that a two person conversation in the hallway constituted a meeting for their purposes. They thought that it would be okay to include this kind of data in their corpus for future researchers, but they should separate it. The Professor has a strong opinion that these interactions were not actually meetings.", "PhD I thought that the team should re-evaluate recognition without cheating on the segmentation. PhD I explained to the team that they had so far been using a simplified version of the scoring and brought up that Thilo wanted to use recognizer alignments to train his speech detector. He was not sure how much hand labeling would be needed to generate data for the detector.", "The professor expressed that the team should not recycle backed up disk space and explained the rate at which they could acquire disks. He was surprised that burned CD's wear out after a year or two. He thought that putting the data on tape was a good idea.", "PhD I suggested putting the data on a CD-ROM but was informed that the data gets lost in a few years. PhD F expressed that it was generally a bad idea to have a copy on a medium that failed. Professionally pressed discs last longer, but they would be burning them in-house. The idea of re-burning the CD's each year was also not adopted.", "The participants discussed how meetings would be transcribed, what kind of information to include in their corpus as well as how to structure it, issues with storing data, and their model. They were particularly concerned with how IBM could assist with transcribing meetings and how they would manage large amounts of data if they include more information in their corpus, given that they were running low on storage. They decided that they could store the data on tapes for backup, and that they would wait and see how IBM transcribes their meetings. As for the modeling, PhD I reported several results and a few members of the team decided to further discuss progress in a smaller meeting later on."], "input": "Grad H: st\nGrad F: So we 're on .\nGrad H: Yeah . That 's better .\nGrad F: And , {comment} somewhere is my agenda . I think the most important thing is Morgan wanted to talk about , uh , the ARPA {pause} demo .\nProfessor D: Well , so , here 's the thing . Um , why don't we s again start off with {disfmarker} with , uh , Yeah , I 'll get it . I 'll get the door . Um , I think we want to start off with the agenda . And then , given that , uh , Liz and Andreas are gonna be {pause} ten , fifteen minutes late , we can try to figure out what we can do most effectively without them here . So {disfmarker} {vocalsound} So {disfmarker} so , one thing is , yeah , talk about demo ,\nGrad F: OK . So , uh {disfmarker} uh , IBM transcription status ,\nProfessor D: IBM transcription . Uh , what else ?\nGrad F: \nProfessor D:  What 's SmartKom ? SmartKom ?\nGrad F: Uh , we wanna talk about if w if we wanna add the data to the mar Meeting Recorder corpus .\nPhD E: The data . The data which we are collecting here .\nProfessor D: What {disfmarker} what {disfmarker} what are we collecting here ?\nPhD E: Data ?\nGrad F: So why don't we have that on the agenda and we 'll {disfmarker} we 'll get to it and talk about it ?\nPhD E: The SmartKom data ?\nProfessor D: Yeah , right .\nPhD E: Yeah .\nProfessor D: Uh , right . Uh .\nGrad F: Uh , reorganization status .\nProfessor D: Reorganization status .\nPostdoc A: Oh . Files and directories ?\nProfessor D: Files and directories .\nGrad F: Yep . Uh - huh . Absinthe , which is the multiprocessor UNIX {disfmarker} Linux . I think it was {pause} Andreas wanted to talk about segmentation and recognition , and update on SRI recognition experiments .\nProfessor D: Um {disfmarker}\nGrad F: And then if ti if there 's time I wanted to talk about digits , but it looked like we were pretty full , so I can wait till next week .\nProfessor D: Right . OK . Well , let 's see . I think the a certainly the segmentation and recognition we wanna maybe focus on when An - Andreas is here since that was particularly his thing .\nPhD E: And also the SmartKom thing should b\nProfessor D: SmartKom also , Andreas . Absinthe , I think also he has sort of been involved in a lot of those things .\nGrad F: At least ,\nProfessor D: Yeah .\nGrad F: yeah , he 'll t he 'll probably be interested .\nProfessor D: Yeah .\nGrad F: But .\nProfessor D: Um So , I mean , I think they 'll be inter I 'll be interested in all this , but {disfmarker} but , uh , probably , if we had to pick something {pause} that we would talk on for ten minutes or so while they 're coming here . Or I guess it would be , you think , reorganization status , or {disfmarker} ?\nGrad F: Yeah . I mean , I think , Chuck was the one who added out the agenda item . I don't really have anything to say other than that we still haven't done it .\nPhD B: Well , I mean , I uh {disfmarker} {vocalsound} just basically that {disfmarker}\nGrad F: So .\nPhD B: maybe I said {disfmarker} maybe we said this before {disfmarker} just that we met and we talked about it and we sort of have a plan for getting things organized and {disfmarker}\nPostdoc A: And I {disfmarker} and I think a crucial part of that is the idea of {disfmarker} of not wanting to do it until right before the next level zero back - up so that there won't be huge number of {disfmarker} of added ,\nPhD B: Right .\nPostdoc A: uh {disfmarker}\nGrad F: Right .\nPhD B: That {disfmarker} that was basically it . Not {disfmarker} not much @ @ {disfmarker}\nGrad F: Although Dave basically said that if we wanna do it , just tell him and he 'll do a d level zero then .\nPostdoc A: Yeah . Uh - huh . Oh , excellent .\nGrad F: So .\nPostdoc A: Oh , good .\nPhD B: Oh , so maybe we should just go ahead and get everything ready , and {disfmarker}\nGrad F: Yep . So , I think we do need to talk a little bit about {disfmarker} Well , we don't need to do it during this meeting .\nPhD B: Yeah .\nGrad F: We have a little more to discuss . But , uh , we 're {disfmarker} we 're basically ready to do it . And , uh , I have some web pages on ts {comment} more of the background . So , naming conventions and things like that , that I 've been trying to keep actually up to date . So . And I 've been sharing them with U - d UW folks also .\nPostdoc A: I 'm sorry , you 've been what ? Showing them ?\nProfessor D: OK .\nPostdoc A: Sharing them .\nGrad F: Sharing them with the UW folks .\nPostdoc A: OK . OK .\nProfessor D: OK . Well , maybe uh , since that {disfmarker} that was a pretty short one , maybe we should talk about the IBM transcription status . Someone can {vocalsound} fill in Liz and Andreas later . Uh\nGrad F: OK . So , we , uh {disfmarker} we did another version of the beeps , where we separated each beeps with a spoken digit . Chuck came up here and recorded some di himself speaking some digits , and so it just goes \" beep one beep \" and then the phrase , and then \" beep two beep \" and then the phrase . And that seems pretty good . Um , I think they 'll have a b easier time keeping track of where they are in the file .\nPhD E: And we have done that on the {pause} automatic segmentations .\nGrad F: And we did it with the automatic segmentation , and I don't think {disfmarker} We ne we didn't look at it in detail . We just sent it to IBM . We {disfmarker} we sorta spot - checked it .\nPhD B: I listened to {pause} probably , uh , five or ten minutes of it from the beginning .\nPhD E: Yeah .\nGrad F: Oh , really ?\nPhD B: Yeah .\nGrad F: OK .\nPhD B: And {disfmarker}\nGrad F: I sorta spot - checked here and there and it sounded pretty good . So . I think it 'll work .\nProfessor D: OK .\nGrad F: And , uh , we 'll just hafta see what we get back from them . Uh {disfmarker}\nPhD B: And the main thing will be if we can align what they give us with what we sent them . I mean , that 's the crucial part .\nGrad F: Right .\nPhD B: And I think we 'll be able to do that at {disfmarker} with this new beep format .\nGrad F: Yep . Well , I think it 's also they are much less likely to d have errors .\nPhD B: Mm - hmm .\nGrad F: I mean , so the problem wi last time is that there were errors in the transcripts where they put beeps where there weren't any , or {disfmarker} and they put in extraneous beeps .\nPhD B: Right . Yeah .\nGrad F: And with the numbers there , it 's much less likely .\nPhD B: Yeah , one interesting note is {disfmarker} uh , or problem {disfmarker} I dunno if this was just because of how I play it back , I say , uh , SND - play and then the file , every once in a while , @ @ {comment} uh , like a beep sounds like it 's cut into two beeps .\nPhD E: Yeah . Into two pieces .\nPhD B: Yeah , and I {disfmarker} I dunno if that 's an , uh , artifact of playback {disfmarker}\nPhD E: Yeah . Yep .\nPhD B: bu uh , I don't think it 's probably in the original file . Um , but , uh {disfmarker}\nPhD E: I recognize that , too . Yeah .\nGrad F: Ha . That 's interesting . I didn't hear that .\nPhD B: Yeah . But with this new format , um , that hopefully they 're not hearing that , and if they are , it shouldn't throw them .\nPhD E: Yep .\nPhD B: So .\nGrad F: Well , maybe we better listen to it again , make sure , but , I mean , certainly the software shouldn't do that ,\nPhD B: Yeah . That 's what I thought .\nGrad F: so .\nPostdoc A: Mm - hmm .\nPhD B: I it 's probably just , you know , mmm , somehow the audio {pause} device gets hung for a second ,\nPhD E: Yeah . Some latency or something .\nGrad F: Hiccups .\nPhD E: Yeah ?\nPostdoc A: As long as they have one number , and they know that there 's only one beep maximum {vocalsound} that goes with that number .\nPhD B: or {disfmarker}\nPhD E: Yeah .\nPhD B: Yeah . Right .\nGrad F: Yeah . The only {disfmarker} the only part that might be confusing is when Chuck is reading digits .\nPhD B: Right .\nPhD E: Yep .\nPostdoc A: Well , you know , actually , are we having them {disfmarker}\nPhD B: So {vocalsound} th\nGrad F: \" Seven four eight beep seven beep {vocalsound} eight three two \" .\nPostdoc A: Yeah , but are we having them do digits ?\nGrad F: Yes . Because , uh , we don't {disfmarker} we didn't {disfmarker} In order to cut them out we 'd have to listen to it .\nPhD B: We {disfmarker} we didn't cut those out .\nPhD E: Yeah . They are not transcribed yet . So . Yeah .\nPostdoc A: OK .\nPhD E: Yeah .\nGrad F: And we wanted to avoid doing that ,\nPostdoc A: OK .\nGrad F: so we {disfmarker} they are transcribing the digits .\nPostdoc A: OK .\nPhD B: We can {disfmarker} we can ignore it when we get it back ,\nGrad F: Although we could tell them {disfmarker} {comment} {vocalsound} we could tell them , if you hear someone reading a digits string just say \" bracket digit bracket \"\nPhD B: huh .\nGrad F: and don't bother actually computing the di writing down the digits .\nPhD B: Yeah .\nPostdoc A: That 'd be great . That 'd be what I 'm having the transcribers here do , cuz it can be extracted later .\nGrad F: Yep . And then I wanted to talk about {disfmarker} but as I said I {disfmarker} we may not have time {disfmarker} what we should do about digits . We have a whole pile of digits that haven't been transcribed .\nProfessor D: Le - let 's talk about it , because that 's {disfmarker} that 's something that I {disfmarker} I know Andreas is less interested in than Liz is ,\nGrad F: OK .\nProfessor D: so , you know . It 's good {disfmarker}\nGrad F: Do we have anything else to say about transcription ? About IBM stuff ?\nPhD B: Uh , Brian {disfmarker} I {disfmarker} I {vocalsound} sent bresset {disfmarker} {vocalsound} {vocalsound} sent Brian a message about {pause} {vocalsound} the meeting and I haven't heard back yet . So . I g hope he got it and hopefully he 's {disfmarker}\nGrad F: OK .\nPostdoc A: Hmm .\nPhD B: maybe he 's gone , I dunno . He didn't even reply to my message . So . I should probably ping him just to make sure that he got it . \nGrad F: Alright . So , we have a whole bunch of digits , if we wanna move on to digits .\nProfessor D: Actually , maybe I {disfmarker} One {disfmarker} one relate more related thing in transcription . So that 's the IBM stuff . We 've got that sorted out . Um , how 're we doing on the {disfmarker} on the rest of it ?\nPostdoc A: We 're doing well . I {disfmarker} I hire {disfmarker} I 've hired two extra people already , expect to hire two more .\nGrad F: Hmm .\nPostdoc A: And , um , {vocalsound} I 've prepared , um , uh , a set of five which I 'm {disfmarker} which I 'm calling set two , which are now being edited by my head transcriber , {vocalsound} in terms of spelling errors and all that . She 's also checking through and mar and {disfmarker} {vocalsound} and monitoring , um , the transcription of another transcriber . You know , I mean , she 's going through and doing these kinds of checks .\nProfessor D: Uh - huh .\nPostdoc A: And , I 've moved on now to what I 'm calling set three . I sort of thought if I do it in sets {disfmarker} groups of five , then I can have , like , sort of a {disfmarker} a parallel processing through {disfmarker} through the {disfmarker} the current .\nProfessor D: Uh - huh .\nPostdoc A: And {disfmarker} and you indicated to me that we have a g a goal now , {vocalsound} for the {disfmarker} for the , um , {nonvocalsound} {vocalsound} the , uh , DARPA demo , of twenty hours . So , I 'm gonna go up to twenty hours , be sure that everything gets processed , and released , and {disfmarker} {pause} {comment} and that 's {disfmarker} that 's what my goal is . Package of twenty hours right now , {vocalsound} and then once that 's done , move on to the next .\nProfessor D: Yeah , uh , so twenty hours . But I guess the other thing is that , um , that {disfmarker} that 's kinda twenty hours ASAP because the longer before the demo we actually have the twenty hours , the more time it 'll be for people to actually do cool things with it .\nPostdoc A: Mm - hmm . Good . I 'm {disfmarker} I 'm hiring people who , {vocalsound} uh , really are {disfmarker}\nProfessor D: So . OK .\nPostdoc A: They would like to do it full - time , several of these people . And {disfmarker} and I don't think it 's {vocalsound} possible , really , to do this full - time , but , that {disfmarker} what it shows is motivation to do as many hours as possible .\nProfessor D: Mm - hmm .\nGrad F: It 'll keep your accuracy up . Yep .\nProfessor D: Yeah .\nPostdoc A: And they 're really excellent .\nProfessor D: Yeah . Well , that 's good .\nPostdoc A: Yeah . Got a good core group now .\nProfessor D: Yeah , I mean , I guess the {disfmarker} So the difference if {disfmarker} if , um , if the IBM stuff works out , the difference in the job would be that they p primarily would be checking through things that were already done by someone else ?\nPostdoc A: Again . Mm - hmm .\nProfessor D: Is that most of what it {disfmarker} ?\nGrad F: And correcting .\nProfessor D: I mean {disfmarker} Correcting .\nGrad F: Correcting . We 'll {disfmarker} we 'll expect that they 'll have to move some time bins and do some corrections .\nPostdoc A: And I {disfmarker} you know , I 've also d uh , discovered {disfmarker} So with the new transcriber I 'm {disfmarker} um {disfmarker} So {disfmarker} Uh , lemme say that my , uh {disfmarker} So , um {disfmarker} At present , um , the people have been doing these transcriptions a channel at a time . And , that sort of , um , {vocalsound} is useful , and t you know , and then once in a while they 'll have to refer to the other channels to clear something up . OK . Well , {vocalsound} I realize that , um , w i we we 're using the pre - segmented version , and , um , the pre - segmented version is extremely useful , and wouldn't it be , useful also to have the visual representation of those segments ? And so I 've {disfmarker} {pause} uh , {pause} I , uh , uh , I 've {comment} trained the new one {disfmarker} uh , the new the newest one , {vocalsound} to , um , {vocalsound} use the visual from the channel that is gonna be transcribed at any given time . And that 's just amazingly helpful . Because what happens then , is you scan across the signal and once in a while you 'll find a blip that didn't show up in the pre - segmentation .\nGrad F: Oh , right .\nPostdoc A: And that 'll be something like {disfmarker} {vocalsound} I it 's ver {disfmarker} it 's interesting .\nGrad F: I see what you mean . A backchannel , or {disfmarker}\nPostdoc A: Once in a while it 's a backchannel .\nPhD E: Yep .\nPostdoc A: Sometimes it seems to be , um , similar to the ones that are being picked up .\nGrad F: Mm - hmm .\nPostdoc A: And they 're rare events , but you can really go through a meeting very quickly . You just {disfmarker} you just , you know , yo you s you scroll from screen to screen , looking for blips . And , I think that we 're gonna end up with , uh {pause} better coverage of the backchannels ,\nProfessor D: Yeah .\nPostdoc A: but at the same time we 're benefitting tremendously from the pre - segmentation because {vocalsound} there are huge places where there is just absolutely no activity at all . And , uh , the audio quality is so good {disfmarker}\nProfessor D: Mm - hmm .\nPhD B: So they can {disfmarker} they can , um , scroll through that pretty quick ?\nPostdoc A: Yeah . Mm - hmm .\nPhD B: That 's great .\nPostdoc A: Yeah . So I think that that 's gonna , also {pause} eh , {comment} you know , speed the efficiency of this part of the process .\nProfessor D: Hmm . OK . Uh , yeah . So , uh {disfmarker} Yeah . So let 's talk about the digits , since they 're not here yet .\nGrad F: Uh , so , we have a whole bunch of digits that we 've read and we have the forms and so on , um , but only a small number of that ha well , not a small number {disfmarker} only a subset of that has been transcribed . And so we need to decide what we wanna do . And , uh , Liz and Andreas {disfmarker} actually they 're not here , but , they did say at one point that they thought they could do a pretty good job of just doing a forced alignment . And , again , I don't think we 'll be able to do with that alone , because , um , sometimes people correct themselves and things like that . But {disfmarker} so , I was just wondering what people thought about how automated can we make the process of finding where the people read the digits , doing a forced alignment , and doing the timing .\nProfessor D: Well , forced alignment would be one thing . What about just actually doing recognition ?\nGrad F: Well , we {disfmarker} we know what they read , because we have the forms .\nProfessor D: No , they make mistakes .\nGrad F: Right . But , the point is that we wanna get a set of clean digits .\nPhD B: You 're talking about as a pre - processing step .\nProfessor D: Right .\nPhD B: Right , Morgan ?\nProfessor D: Um {disfmarker}\nPhD B: Is that what you 're {disfmarker} ?\nProfessor D: Yeah , I 'm {disfmarker} I 'm not quite sure what I 'm talking about . I mean {disfmarker} I {disfmarker} I mean , uh , we 're talking about digits now . And {disfmarker} and so , um , there 's a bunch of stuff that hasn't been marked yet . Uh . And , um , {vocalsound} there 's the issue that {disfmarker} that they {disfmarker} we know what {disfmarker} what was said , but do we ?\nGrad F: I mean , so one option i\nProfessor D: Because people make mistakes and stuff . I was just asking , just out of curiosity , if {disfmarker} if with , uh {disfmarker} uh , the SRI recognizer getting one percent word error , uh , would we {disfmarker} would we do {pause} better {disfmarker} ? So , if you do a forced alignment but the force but the {disfmarker} but the transcription you have is wrong because they actually made mistakes , uh , or {vocalsound} false starts , it 's {disfmarker} it 's much less c {vocalsound} it 's {pause} much less common than one percent ?\nGrad F: But that 's pretty uncommon . Um , if we could really get one percent on {disfmarker}\nProfessor D: We should be able to .\nGrad F: Well , I guess {disfmarker} yeah , I guess if we segmented it , we could get one percent on digits .\nProfessor D: Right ?\nPhD B: Yeah .\nProfessor D: Yeah . So that 's just my question . I 'm not saying it should be one way or the other , but it 's {disfmarker} If {disfmarker}\nGrad F: But , Well , there {disfmarker} there 're a couple different of doing it . We could use the tools I 've already developed and transcribe it . Hire some people , or use the transcribers to do it . We could let IBM transcribe it . You know , they 're doing it anyway , and unless we tell them different , they 're gonna transcribe it . Um , or we could try some automated methods .\nProfessor D: Well {disfmarker}\nGrad F: And my {disfmarker} my tendency right now is , well , if IBM comes back with this meeting and the transcript is good , just let them do it .\nProfessor D: Yeah , it 's {disfmarker} Y you raised a point , kind of , uh , euphemistically {disfmarker} but , I mean , m maybe it is a serious problem . Ho - what will they do when they go {disfmarker} hear \" beep {pause} seven {pause} beep {pause} seven three five two \" {disfmarker} I mean , {vocalsound} you think they 'll {disfmarker} we 'll get {disfmarker} ?\nGrad F: It 's pretty distinct .\nProfessor D: Yeah ?\nGrad F: The beeps are {pause} pre - recorded .\nPhD B: It 'll {comment} only be a problem for m for mine .\nPhD E: Yeah .\nPostdoc A: Well it {disfmarker} it {disfmarker} well , it 'd be preceded by \" I 'm reading transcript so - and - so \" ?\nPhD B: Yeah .\nGrad F: Yes .\nPostdoc A: So , I think if they 're processing it at {disfmarker}\nGrad F: I mean , it 'll be {disfmarker} it will be in the midst of a digit string .\nProfessor D: Yeah .\nGrad F: So {disfmarker} I mean it {disfmarker} sure , there {disfmarker} there might be a place where it 's \" beep seven {pause} beep eight {pause} beep {pause} eight {pause} beep \" . But , you know , they {disfmarker} they 're {disfmarker} they 're gonna macros for inserting the beep marks . And so , I {disfmarker} I don't think it 'll be a problem . We 'll have to see , but I don't think it 's gonna be a problem .\nProfessor D: OK . Well , I {disfmarker} I {disfmarker} I dunno , I {disfmarker} I think that that 's {disfmarker} if they are in fact going to transcribe these things , uh , certainly any process that we 'd have to correct them , or whatever is {disfmarker} needs to be much less elaborate for digits than for other stuff .\nGrad F: Right .\nProfessor D: So , why not ? Sure . That was it ?\nGrad F: That was it . Just , what do we do with digits ?\nProfessor D: OK .\nGrad F: We have so many of them , {vocalsound} and it 'd be nice to {pause} actually do something with them .\nProfessor D: Well , we {disfmarker} we {disfmarker} we wanna have them . Yeah , I {disfmarker}\nPhD I: You mean there 're more than ten ?\nGrad F: Anything else ? Your mike is a little low there .\nProfessor D: I in Berkeley , yeah . So , {vocalsound} uh {pause} You {disfmarker} you have to go a little early , right ? At twenty {disfmarker}\nPhD I: Well , I can stay till about , uh , three forty .\nProfessor D: Alright . So le let 's make sure we do the ones that {disfmarker} that , uh , saved you .\nPhD I: Yeah . Mm - hmm .\nProfessor D: So there was some {disfmarker} Uh {pause} {vocalsound} In {disfmarker} in {disfmarker} Adam 's agenda list , he had something from you about segmentation this last recognition ?\nPhD I: Well , yeah . So this is just partly to inform everybody , um , and {disfmarker} and of course to get , um , input .\nGrad F: Oops .\nPhD I: Um , so , {nonvocalsound} uh , we had a discussion {disfmarker} Don and Liz and I had discussion last week about how to proceed with , uh , you know , with Don 's work ,\nPhD E: Ch\nPhD I: and {disfmarker} {vocalsound} and {disfmarker} and , uh , one of the obvious things that occur to us was that we 're {disfmarker} since we now have Thilo 's segmenter and it works , you know , amazingly well , {vocalsound} um , we should actually basically re - evaluate the recognition , um , results using {disfmarker} you know , without cheating on the segmentations .\nPhD E: So {disfmarker}\nPhD I: And , that should be fairly {disfmarker}\nPhD E: And how do we find the transcripts for those so that {disfmarker} ? Yeah . The references for {disfmarker} for {pause} those segments ?\nPhD I: Oh , OK . So , there 's actually {disfmarker}\nPhD E: It 's not that {disfmarker}\nPhD I: Why do you ask ?\nGrad F: I could {disfmarker}\nPhD I: No , actually , um , NIST has , um m a fairly sophisticated scoring program {vocalsound} that you can give a , um {disfmarker} {vocalsound} a time ,\nGrad F: Hand ones .\nPhD G: Well {disfmarker}\nPhD E: OK .\nPhD I: uh {disfmarker} You know , you basically just give two {pause} time - marked sequences of words , and it computes the um {disfmarker} the , {comment} uh {disfmarker} {comment} you know , the {disfmarker} the {disfmarker} th\nPhD B: It does all the work for you .\nPhD I: it does all the work for you .\nPhD B: Yeah .\nPhD E: OK .\nPhD I: So , it {disfmarker} we just {disfmarker} and we use that actually in Hub - five to do the scoring . Um . So what we 've been using so far was sort of a {pause} simplified version of the scoring . And we can {disfmarker} we can handle the {disfmarker} the {disfmarker} the type of problem we have here .\nPhD E: So , basically you give some time constraints for {disfmarker} for the references and for {disfmarker} for the hypothesis ,\nPhD I: So , we ha Yeah . Right .\nPhD E: and {disfmarker} Yeah , OK .\nPhD G: Yeah .\nPhD I: Right .\nPhD G: Maybe the {pause} start of your speech and the end of it ,\nPhD I: So do\nPhD E: OK .\nPhD G: or stuff like that .\nPhD I: Right . It does time - constrained word - alignment .\nPhD E: OK .\nPhD I: So . So that should be possible . I mean that shouldn't be a problem . Uh , so that was the one thing , and the other was that , um {disfmarker} What was the other problem ? Oh ! That Thilo wanted to use {pause} the recognizer alignments to train up his , um , speech detector .\nPhD E: Yeah .\nPhD I: Um , so that we could use , uh {disfmarker} you know there wouldn't be so much hand {vocalsound} labelling needed to , uh {disfmarker} to generate training data for {disfmarker} for the speech detector .\nPhD E: Yeah . I 'm just in progress of {disfmarker} of doing that . So .\nPhD I: And I think you 're in the process of doing that .\nPhD E: Yeah .\nPhD I: So , you can {disfmarker} {comment} you can {disfmarker}\nPhD B: It 'll give you a lot more data , too . Won't it ?\nPhD E: Yeah . So , it 's basically {disfmarker} s I think , eight meetings or something which {disfmarker} which I 'm using , and , {vocalsound} it 's {disfmarker} {vocalsound} before it was twenty minutes of one meeting .\nPhD I: Mm - hmm .\nPhD E: So {disfmarker} should {comment} be a little bit better .\nPhD I: Right .\nPhD B: Great .\nPhD I: That won't be perfect {disfmarker} the alignments aren't perfect ,\nPhD E: Yeah . But {disfmarker}\nPhD I: but , um , it 's probably still better to have all this extra data , than {disfmarker}\nPhD G: Yeah .\nPhD E: Yeah . Yep .\nPhD I: Yeah .\nPhD E: We 'll see that .\nPhD I: Yeah .\nProfessor D: OK .\nPhD G: Actually , I had a question about that . If you find that you can {vocalsound} lower the false alarms that you get where there 's no speech , that would be useful {pause} for us to know . So , um {disfmarker}\nPhD E: There were the false alarms .\nPhD G: Yeah . So , {vocalsound} r right now you get f fal you know , false {disfmarker} false , uh , speech regions when it 's just like , um , {vocalsound} breath or something like that ,\nPhD E: OK . Yeah . Yep .\nPhD G: and I 'd be interested to know the {disfmarker} wha if you retrain um ,\nPhD E: Yeah .\nPhD G: do those actually go down or not ? Because {pause} of {disfmarker}\nPhD E: Yeah . I 'll {disfmarker} can make {disfmarker} an can , like , make a c comparison of {disfmarker} of the old system to the {disfmarker} to the new one , and {pause} then {disfmarker}\nPhD G: Yeah , just to see if by doing nothing in the modeling of {disfmarker} just having that training data wh what happens .\nPhD E: Yeah . Yeah . Yep .\nProfessor D: Um another one that we had on Adam 's agenda {pause} that definitely involved you was s something about SmartKom ?\nGrad F: Right . So , Rob Porzel {disfmarker} eh , Porzel ? and the , uh {disfmarker} Porzel {disfmarker} and the , uh , SmartKom group are collecting some dialogues .\nPhD I: Porzel . Porzel .\nGrad F: Basically they have one person sitting in here , looking at a picture , and a wizard sitting in another room somewhere . And , uh , they 're doing a travel task . And , uh , it involves starting {disfmarker} I believe starting with a {disfmarker} It 's {disfmarker} it 's always the wizard , but it starts where the wizard is pretending to be a computer and it goes through a , uh , {vocalsound} speech generation system .\nPhD E: Yeah . Actually , it 's changed to a synthesis for {disfmarker} for the first part now .\nGrad F: Synthesis system .\nPhD E: Yeah .\nGrad F: Um , and then , it goes to a real wizard and they 're evaluating that . And they wanted to use this equipment , and so the w question came up , is {disfmarker} well , here 's some more data . Should this be part of the corpus or not ? And my attitude was yes , because there might be people who are using this corpus for {pause} acoustics , as opposed to just for language . Um , or also for dialogue of various sorts . Um , so it 's not a meeting . Right ? Because it 's two people and they 're not face to face .\nProfessor D: Wait a minute . So , I just wanted to understand it , cuz I {disfmarker} I 'm {disfmarker} uh , hadn't quite followed this process .\nPhD E: Yeah .\nProfessor D: Um . So , it 's wizard in the sen usual sense that the person who is asking the questions doesn't know that it 's , uh , a machi not a machine ?\nPhD I: Right .\nGrad F: At the beginning .\nPhD I: Actually {disfmarker} actually , w w the {disfmarker} the {disfmarker} We do this {disfmarker} I dunno who came up with it , but I think it 's a really clever idea . We simulate a computer breakdown halfway through the session , and so then after that , the person 's told that they 're now talking to a , uh {disfmarker} to a human .\nProfessor D: Yeah .\nPhD E: It 's a human operator .\nProfessor D: Yeah .\nPhD E: Yeah .\nGrad F: But of course they don't know that it 's the same person both times .\nPhD I: So , we {disfmarker} we collect {disfmarker} we collect both human - computer and human - human data , essentially , in the same session .\nProfessor D: You might wanna try collecting it the other way around sometime , saying that th the computer isn't up yet\nPostdoc A: Hmm .\nProfessor D: and then {disfmarker} so then you can separate it out whether it 's the beginning or end kind of effects .\nPhD I: That 's an idea .\nProfessor D: But , yeah .\nGrad F: Yep .\nPhD I: Yeah .\nPostdoc A: That 's a good idea .\nGrad F: \" I have to go now . You can talk to the computer . \"\nPhD B: It 's a lot more believable , too ,\nGrad F: \" No ! \"\nPhD B: if you tell them that they 're {disfmarker} the computer part is running on a Windows machine . And the whole breakdown thing kinda makes sense .\nPhD I: O Just {disfmarker} just reboot it .\nGrad F: Abort {disfmarker} abort , retry , fail ?\nPhD G: So did they actually save the far - field {pause} data ?\nPhD E: Yes .\nGrad F: Well , this was {disfmarker} this was the question .\nPhD G: Cuz at first they weren't {disfmarker} they weren't sa\nPhD I: Yeah .\nGrad F: So {disfmarker} so they were saying they were not going to ,\nPhD E: Yeah .\nPhD G: OK .\nGrad F: and I said , \" well that 's silly , if {disfmarker} if we 're gonna try to do it for a corpus , there might be people who are interested in acoustics . \"\nPhD G: Yeah .\nPhD I: Wow .\nPhD E: No .\nPhD G: Or {disfmarker}\nPhD E: projector {comment} We were not saying we are not {pause} doing it .\nPhD G: Yeah .\nProfessor D: S\nPhD E: We wer we just wanted to do {disfmarker}\nPhD I: No , the {disfmarker} the question is do we save one or two far - field channels or all of them ?\nPhD G: Right .\nPhD E: Yeah . Yeah .\nGrad F: I {disfmarker} I see no reason not to do all of them .\nProfessor D: Um {disfmarker}\nGrad F: That {disfmarker} that if we have someone who is doing acoustic studies , uh , it 's nice to have the same for every recording .\nPhD G: Nnn . Yeah .\nPhD I: Hmm .\nProfessor D: So , what is the purpose of this recording ?\nPhD I: Mm - hmm .\nProfessor D: This is to get acoustic and language model training data for SmartKom. OK .\nPhD I: It 's to be traini to b training data and development data for the SmartKom {pause} system .\nPhD E: The English system ? Yeah .\nPhD I: Yeah . Right . Right .\nPhD B: Where does this {disfmarker} ?\nProfessor D: \nPhD G: Maybe we can have him vary the microphones , too ,\nProfessor D: Well ,\nPhD E: B\nPhD G: or they 're different s speakers .\nGrad F: Right . So {disfmarker} so {disfmarker} so for their usage , they don't need anything .\nProfessor D: so why not {disfmarker} ?\nPhD E: Yeah .\nGrad F: Right ?\nPhD E: But {disfmarker} but I 'm not sure about the legal aspect of {disfmarker} of that . Is {disfmarker} is there some contract with SmartKom or something about the data ?\nPhD I: Yeah .\nPhD E: What they {disfmarker} or , is {disfmarker} is that our data which we are collecting here ,\nProfessor D: We 've never signed anything that said that we couldn't use anything that we did .\nPhD E: or {disfmarker} ? OK . OK .\nPhD I: We weren't supposed to collect any data .\nPhD E: So . OK .\nProfessor D: Yeah .\nPhD E: So . Yeah , th th that was the question .\nPhD I: This was all {disfmarker}\nPhD E: If {disfmarker} if {disfmarker} ? Yeah .\nPhD I: Yeah .\nProfessor D: No that 's not a problem .\nPhD E: Basically .\nProfessor D: I {disfmarker} L look , it seems to me that if we 're doing it anyway and we 're doing it for these {disfmarker} these purposes that we have , {vocalsound} and we have these distant mikes , we definitely should re should save it all as long as we 've got disk space ,\nPhD I: Mm - hmm .\nProfessor D: and disk is pretty cheap .\nPhD I: OK .\nProfessor D: So should we save it ?\nGrad F: And then {disfmarker}\nProfessor D: Now th Yeah . So we save it because it 's {disfmarker} it {disfmarker} it 's potentially useful . And now , what do we do with it is {disfmarker} is a s separate question .\nGrad F: Right .\nProfessor D: I mean , anybody who 's training something up could {vocalsound} choose to put it {disfmarker} eh , to u include this or not .\nPhD I: Right .\nProfessor D: I {disfmarker} I would not say it was part of the meetings corpus . It isn't . But it 's some other data we have , and if somebody doing experiment wants to train up including that then they can . Right ?\nPhD I: Mm - hmm .\nGrad F: So it 's {disfmarker} It {disfmarker} it {disfmarker} I guess it {disfmarker} the {disfmarker} begs the question of what is the meeting corpus . So if , at UW they start recording two - person hallway conversations is that part of the meeting corpus ?\nProfessor D: I think it 's {disfmarker} I {disfmarker} I think {disfmarker} I th think the idea of two or more people conversing with one another is key .\nGrad F: Well , this has two or more people conversing with each other .\nProfessor D: Nnn , well\nPhD E: Yeah .\nPostdoc A: Well this {disfmarker}\nGrad F: They 're just not face to face .\nPhD G: What if we just give it a {disfmarker} a name like we give these meetings a name ?\nProfessor D: No , it doesn't . Right ? It has {disfmarker}\nGrad F: I mean , that was my intention .\nPhD G: And then later on some people will consider it a meeting and some people won't ,\nPostdoc A: Well this {disfmarker}\nProfessor D: Yeah .\nGrad F: That was my intention . So {disfmarker} so {disfmarker} s {vocalsound} so part of the reason that I wanted to bring this up is , {vocalsound} do we wanna handle it as a special case or do we wanna fold it in ,\nPhD G: and {disfmarker} Just give it a {vocalsound} title .\nPostdoc A: Oh .\nProfessor D: I think it is a s\nGrad F: we give everyone who 's involved as their own user ID , give it session I Ds , {vocalsound} let all the tools that handle Meeting Recorder handle it , or do we wanna special case it ? And if we were gonna special case it , who 's gonna do that ?\nPhD E: So .\nPhD I: Well , it {disfmarker} it makes sense to handle it with the same infrastructure , since we don't want to duplicate things unnecessarily .\nPhD E: It {disfmarker} it {disfmarker} it {disfmarker}\nPostdoc A: I think {disfmarker}\nPhD I: But as far as distributing it , we shouldn't label it as part of this meeting corpus .\nProfessor D: Yeah .\nPhD I: We should let it be its own corp\nPostdoc A: Well it 's {disfmarker} it {disfmarker} well , because {disfmarker}\nGrad F: I don't see why not . It 's just a different topic .\nPostdoc A: I ha I have an extra point , which is the naturalness issue . Because we have , like , meetings that have a reason . That 's one of the reasons that we were talking about this . And {disfmarker} and those {disfmarker} and this sounds like it 's more of an experimental setup .\nProfessor D: Yeah .\nPostdoc A: It 's got a different purpose .\nProfessor D: It 's scenario - based , it 's {disfmarker} it 's human - computer interface {disfmarker} {vocalsound} it 's really pretty different .\nPostdoc A: Yeah .\nProfessor D: But I I {disfmarker} I have no problem with somebody folding it in for some experiment they 're gonna do , but I don't think i it {disfmarker} it doesn't match anything that we 've described about meetings .\nGrad F: Mm - hmm .\nProfessor D: Whereas everything that we talked about them doing at {disfmarker} at UW and so forth really does . They 're actually talking {disfmarker}\nGrad F: OK . So w so what does that mean for how we are gonna organize things ?\nPostdoc A: Hmm .\nPhD E: Yeah .\nProfessor D: You can {disfmarker} you can {disfmarker} Again , as {disfmarker} as I think Andreas was saying , {vocalsound} if you wanna use the same tools and the same conventions , there 's no problem with that . It 's just that it 's , you know , different directory , it 's called something different , it 's {disfmarker} you know . It is different . You can't just fold it in as if it 's {disfmarker} I mean , digits are different , too . Right ?\nGrad F: Yeah , but those are folded in ,\nPhD I: It might also be potentially confusing .\nGrad F: and it 's just {disfmarker} you just mark the transcripts differently . So {disfmarker} so one option is you fold it in ,\nPhD I: Right .\nGrad F: and just simply in the file you mark somewhere that this is this type of interaction , rather than another type of interaction .\nPhD I: Yeah , I th\nProfessor D: Well , I don I wouldn't call reading digits \" meetings \" . Right ? I mean , we {disfmarker} we {disfmarker} we were doing {disfmarker}\nGrad F: Well , but {disfmarker} but , {vocalsound} I put it under the same directory tree .\nProfessor D: Well {disfmarker}\nGrad F: You know , it 's in \" user doctor speech data MR \" .\nPhD G: Can we just have a directory called , like , \" other stuff \" ?\nGrad F: Other .\nPhD G: And {disfmarker} Well {disfmarker} or , I dunno .\nProfessor D: I mean , I don't care what directory tree you have it under .\nPhD G: And {disfmarker} {vocalsound} and just , um , store it there .\nProfessor D: Right ? I mean that 's just a {disfmarker}\nGrad F: OK . My preference is to have a single procedure so that I don't have to think too much about things .\nPhD I: Yes .\nPhD G: I mean {disfmarker}\nProfessor D: Yeah .\nGrad F: And , just have a marking .\nProfessor D: O - You {disfmarker} you can use whatever procedure you want that 's p convenient for you .\nGrad F: If we do it any other way that means that we need a separate procedure , and someone has to do that .\nProfessor D: All I 'm saying is that there 's no way that we 're gonna tell people that reading digits is meetings . And similarly we 're not gonna tell them that someone talking to a computer to get travel information is meetings .\nGrad F: Right .\nProfessor D: Those aren't meetings . But if it makes it easier for you to pu fold them in the same procedures and have them under the same directory tree , knock yourself out .\nPhD B: There 's a couple other questions that I have too ,\nProfessor D: You know ?\nPhD B: and {disfmarker} and {pause} one of them is , what about , uh , consent issues ? And the other one is , what about transcription ? Are {disfmarker} ?\nPhD E: Transcription is done in Munich .\nPhD B: OK . So we don't have to worry about transcribing it ?\nProfessor D: Alright .\nPhD E: Yeah .\nGrad F: So , w we will hafta worry about format .\nPhD I: That 's a {disfmarker} that 's another argument to keep it separate , because it 's gonna follow the SmartKom transcription conventions and not the ICSI meeting transcription conventions .\nPhD E: Yeah .\nGrad F: Oh , OK .\nProfessor D: Ah . Good point .\nGrad F: OK . Well , I didn't realize that . That 's {disfmarker} that 's a {disfmarker}\nProfessor D: Good point . But I 'm sure no one would have a problem with our folding it in for some acoustic modeling or {disfmarker} or some things . Um . Do we h do we have , uh , um , American - born folk , uh , reading German {disfmarker} German , uh , pla uh , place names and so forth ? Is that {disfmarker} ?\nPhD E: Yeah .\nPhD I: Exactly .\nProfessor D: Yeah , great .\nPhD E: Yeah .\nGrad F: Yep .\nPhD I: Yeah .\nGrad F: They {disfmarker} they even have a reading list .\nPhD B: I bet that sounds good , huh ?\nProfessor D: Yeah .\nGrad F: It 's pretty funny .\nPhD I: Yeah .\nPhD E: You can do that if you want .\nPhD B: OK .\nProfessor D: Yeah .\nPhD B: I dunno if you want that .\nProfessor D: Right .\nPhD I: Yeah .\nPostdoc A: Hmm .\nProfessor D: Heidelberg\nGrad F: So {disfmarker}\nPhD I: Exactly\nGrad F: Disk might eventually be an issue so we might {disfmarker} we {disfmarker} we might need to , uh , {vocalsound} get some more disk pretty soon .\nPhD I: Do you wanna be a subject ?\nProfessor D: Yeah , I be pretty good .\nPhD I: We {disfmarker} Yeah .\nGrad F: We 're about {disfmarker} we 're about half {disfmarker} halfway through our disk right now .\nPhD B: Yeah .\nPhD I: That was one of our concerns .\nPhD B: Are we only half ? I thought we were more than that .\nGrad F: We 're probably a little more than that because we 're using up some space that we shouldn't be on . So , once everything gets converted over to the disks we 're supposed to be using we 'll be probably , uh , seventy - five percent .\nPhD B: Well , when I was looking for space for Thilo , I found one disk that had , uh , I think it was nine gigs and another one had seventeen .\nGrad F: Yep .\nPhD B: And everything else was sorta committed . Uh {disfmarker}\nGrad F: Were those backed - up or non - backed - up ?\nPhD B: Those were non - backed - up .\nPhD E: Non - back - up .\nGrad F: Right . So that 's different .\nPhD B: S oh , you 're talking about backed - up .\nGrad F: I 'm much more concerned about the backed - up . The non - backed - up ,\nPhD B: I haven't looked to see how much of that we have .\nGrad F: yeah , i is cheap . I mean , if we need to we can buy a disk , hang it off a s uh , workstation . If it 's not backed - up the sysadmins don't care too much .\nProfessor D: Yeah . So , I mean , pretty much anytime we need a disk , we can get it at the rate that we 're {disfmarker}\nPhD I: You can {disfmarker} I shouldn't be saying this , but , you can just {disfmarker} you know , since the back - ups are every night , you can recycle the backed - up diskspace .\nGrad F: Yeah . But that 's {disfmarker} that 's {disfmarker} {pause} that 's risky .\nProfessor D: Yeah . You really shouldn't be saying {disfmarker}\nGrad F: Mmm . Mmm .\nPhD I: I didn't say that .\nGrad F: Yeah , that 's right .\nPhD I: I didn't say that .\nGrad F: Beep that out .\nProfessor D: Da - we had allowed Dave to listen to these {disfmarker} {vocalsound} these , {vocalsound} uh , recordings .\nPhD I: Right .\nProfessor D: Um {disfmarker} {vocalsound} Yeah , I me and there 's been this conversation going on about getting another file server , and {disfmarker} and {vocalsound} we can do that .\nPhD I: Mm - hmm .\nProfessor D: We 'll take the opportunity and get another big raft of {disfmarker} {vocalsound} of disk , I guess .\nGrad F: Yeah . It 's really the back - up issue rather than the file server issue .\nPhD I: Well , I think {disfmarker} {comment} I think there 's an argument for having {disfmarker} you know , you could use our old file server for {disfmarker} for disks that have data that {pause} is very rarely accessed , and then have a fast new file server for data that is , um , heavily accessed .\nGrad F: Yeah . My understanding is , the issue isn't really the file server .\nPhD I: Yeah .\nGrad F: We could always put more disks on .\nPhD I: Yeah . It 's the back it 's the back - up capaci\nGrad F: It 's the back - up system .\nPhD I: Yeah .\nGrad F: So {disfmarker} which is near saturation , apparently . So .\nPhD B: I think {disfmarker} I think the file server could become an issue as we get a whole bunch more new compute machines .\nProfessor D: Soon .\nPhD B: And we 've got , you know , fifty machines trying to access data off of Abbott at once .\nGrad F: Well , we 're alright for now because the network 's so slow .\nPhD I: I mean , I think {disfmarker} I think we 've raised this before and someone said this is not a reliable way to do it , but the {disfmarker} What about putting the stuff on , like , C - CD - ROM or DVD or something ?\nGrad F: Yeah . That was me . I was the one who said it was not reliable . The - they {disfmarker} they wear out .\nPhD I: OK . Oh , OK .\nGrad F: Yeah . The {disfmarker} the {disfmarker} th\nPhD I: But they wear out just from sitting on the shelf ?\nGrad F: Yep . Absolutely .\nPhD I: Or from being {pause} read and read ?\nGrad F: No . Read and write don't hurt them too much unless you scratch them .\nPhD I: Oh , OK .\nGrad F: But the r the write once , and the read - writes , don't last . So you don't wa you don't wanna put ir un reproduceable data {pause} on them .\nPhD I: Uh - huh .\nPhD B: Wear out after what amount of time ?\nGrad F: Year or two .\nPostdoc A: Would it be {disfmarker} ?\nProfessor D: Year or two ?\nGrad F: Yep .\nProfessor D: Wow .\nPostdoc A: Hmm .\nPhD I: But if that {disfmarker} then you would think you 'd {pause} hear much more clamoring about data loss\nPhD E: Yeah .\nPhD I: and {disfmarker}\nProfessor D: I mean , yeah , all the L\nGrad F: I {disfmarker} I don't know many people who do it on CD . I mean , they 're {disfmarker} the most {disfmarker} fo\nProfessor D: LDC - all the LDC distributions are on CD - ROM .\nPhD G: Yeah .\nGrad F: They 're on CD , but they 're not {disfmarker} tha that 's not the only source .\nPhD G: Like {disfmarker}\nGrad F: They have them on disk . And they burn new ones every once in a while . But if you go {disfmarker} {vocalsound} if you go k\nPhD I: But , you know , we have {disfmarker}\nPhD G: But we have like thirty {pause} you know , from {pause} ten years ago ?\nProfessor D: We have all sorts of CD - ROMs from a long time ago .\nPhD G: No .\nPhD E: Yeah .\nPhD G: Yeah !\nGrad F: Well , th th OK .\nPhD G: Ten years ago .\nPhD I: Right .\nPhD G: Ninety - one , and they 're still all fine .\nProfessor D: Yeah .\nGrad H: Were they burned or were they pressed ?\nPhD G: Uh , both . I 've burned them and they 're still OK .\nGrad H: Yeah .\nGrad F: The {disfmarker} the pressed ones last for\nPhD G: I mean , usually they 're {disfmarker}\nGrad F: well , not forever , they 've been finding even those degrade .\nProfessor D: Oh , I see .\nGrad F: But , uh , the burned ones {disfmarker} I mean , when I say two or three years what I 'm saying is that I have had disks which are gone in a year .\nPhD G: That 's what I {disfmarker}\nGrad F: On the average , it 'll probably be three or four years . But , uh {disfmarker} I {disfmarker} I {disfmarker} you don't want to per p have your only copy on a media that fails .\nPhD I: Mmm .\nGrad F: And they do . Um , if you have them professionally pressed , y you know , they 're good for decades .\nPhD I: So how about {disfmarker} ? So {disfmarker} so how about putting them on that plus , like on a {disfmarker} on {disfmarker} on DAT or some other medium that isn't risky ?\nGrad F: I think th um , we can already put them on tape . And the tape is hi is very reliable .\nPhD I: OK . Mm - hmm .\nGrad F: So the {disfmarker} the only issue is then {pause} if we need access to them . So that 's fine f if we don't need access to them .\nPhD I: Right . Well , if {disfmarker} if {disfmarker} if you {disfmarker} if they last {disfmarker} Say , they actually last , like , five years , huh , in {disfmarker} in the typical case , and {disfmarker} and occasionally you might need to recreate one , and then you get your tape out , but otherwise you don't . Can't you just {disfmarker} you just put them on {disfmarker} ?\nGrad H: So you just archive it on the tape , and then put it on CD as well ?\nPhD I: Yeah . Right .\nGrad F: Oh . So you 're just saying put them on C Ds for normal access .\nGrad H: Yeah .\nPhD I: Right .\nPhD B: What you {disfmarker}\nGrad F: Yeah . I mean , you can do that but that 's pretty annoying , because the C Ds are so slow .\nPhD G: See {disfmarker} Yeah .\nGrad H: Yeah .\nPhD I: Mmm .\nPhD B: What 'd be nice is a system that re - burned the C Ds every {vocalsound} year .\nPhD G: H everytime it was a \" gonna \" {disfmarker} \" gonna die \" .\nProfessor D: Well {disfmarker}\nGrad F: Well , I mean , the C Ds are {disfmarker} are an op\nPhD E: Yeah .\nPhD I: It 's like {disfmarker} like dynamic ra DRAM .\nPhD E: Just before .\nPhD B: Yeah .\nPhD G: Just before they be before it goes bad , it burns them in .\nGrad F: The {disfmarker} the CD is an alternative to tape .\nGrad H: Yeah .\nGrad F: ICSI already has a perfectly good tape system and it 's more reliable .\nProfessor D: You know {disfmarker} I would think {disfmarker}\nGrad F: So for archiving , we 'll just use tape .\nPhD I: One {disfmarker} one thing I don't understand is , if you have the data {disfmarker} if {disfmarker} if you if the meeting data is put on disk exactly once , then it 's backed - up once and the back - up system should never have to bother with it , uh , more than once .\nGrad F: Well , regardless {disfmarker} Well , first of all there was , um , a problem with the archive in that I was every once in a while doing a chmod on all the directories an or recursive chmod and chown , because {vocalsound} they weren't getting set correctly every once in a while ,\nPhD I: Mm - hmm .\nGrad F: and I was just , {vocalsound} doing a minus R star , {vocalsound} not realizing that that caused {pause} it to be re - backed - up .\nPhD I: Mm - hmm .\nPhD G: Ah .\nGrad F: But normally you 're correct . But even without that , the back - up system is becoming saturated .\nPhD I: But {disfmarker} but this back - up system is smart enough to figure out that something hasn't changed and doesn't need to be {pause} backed - up again .\nProfessor D: The b I think th the {disfmarker} at least the once tha that you put it on , it would {disfmarker} {vocalsound} it would {comment} {vocalsound} kill that .\nGrad F: Sure , but we still have enough changed that the nightly back - ups are starting to take too long .\nPhD I: OK . So {disfmarker} so then , if {disfmarker} So {disfmarker} so then , let 's {disfmarker}\nProfessor D: So .\nGrad F: It has nothing to do with the meeting . It 's just the general ICSI back - up system is becoming saturated .\nPhD I: Right . OK . Right . So , what if we buy , uh {disfmarker} uh , what {disfmarker} what do they call these , um {pause} high density {disfmarker} ?\nGrad F: Well , why don't you have this {disfmarker} have a {disfmarker} this conversation with Dave Johnson tha rather than with me ?\nPhD I: No , no . Because this is {pause} maybe something that we can do without involving Dave , and {disfmarker} and , putting more burden on him . How about we buy , uh {disfmarker} uh {disfmarker} uh , one of these high density tape drives ? And we put the data actually on non - backed - up disks . And we do our own back - up once and for all {disfmarker} all , and then {disfmarker} and we don't have to bother this @ @ up ?\nGrad F: Actually , you know , we could do that just with the tape {disfmarker} with the current tape .\nPhD I: I dunno what the these tapes {disfmarker} uh , at some point these {disfmarker} I dunno . What kind of tape drive is it ?\nGrad F: I dunno but it 's an automatic robot so it 's very convenient .\nPhD I: Is it {disfmarker} is {disfmarker} ?\nProfessor D: Wh The o the one that we have ?\nGrad F: You just run a program to restore them .\nPhD I: Right .\nProfessor D: The {disfmarker} I mean {disfmarker}\nGrad F: Yeah .\nPhD I: But it might interfere with their back - up schedule ,\nPhD G: But {disfmarker}\nProfessor D: No , we have s we {disfmarker} Don't we have our own ?\nPhD I: eh .\nProfessor D: Something wi th that doesn't {disfmarker} that isn't used by the back - up gang ? Don't we have something downstairs ?\nPostdoc A: Well they {disfmarker}\nPhD B: What kinda tape drive ?\nProfessor D: Just in {disfmarker} ? Yeah .\nGrad F: Well {disfmarker} but {disfmarker} no , but Andreas 's point is a good one . And we don't have to do anything ourselves to do that . They 're already right now on tape .\nPhD I: Right .\nGrad F: Right . So your {disfmarker} your point is , and I think it 's a good one , that we could just get more disk and put it there .\nPhD I: Mmm . On an XH {disfmarker} uh , X {disfmarker} X whatever partition .\nGrad F: Yeah . That 's not a bad idea .\nPhD I: Yeah .\nProfessor D: Yeah , that 's basically what I was gonna say , is that a disk is {disfmarker} is so cheap it 's es essentially , you know , close to free . And the only thing that costs is the back - up {pause} issue , {vocalsound} eh , to first order .\nGrad F: So once it 's on tape {disfmarker}\nPhD I: Right . Right .\nProfessor D: And we can take care of that by putting it on non - back {pause} up drives and just backing it up once onto this tape .\nPhD I: Mm - hmm .\nGrad F: I think that 's a good idea .\nPhD I: Right .\nProfessor D: Oh . Yeah .\nPhD I: OK .\nProfessor D: Good . It 's good .\nPhD G: So , who 's gonna do these back - ups ? The people that collect it ?\nGrad F: Uh Well , I 'll talk to Dave , and {disfmarker} and see what th how {disfmarker} {nonvocalsound} what the best way of doing that is .\nPhD B: It 's probably gonna n\nGrad F: There 's a little utility that will manually burn a tape for you , and that 's probably the right way to do it .\nPhD B: Yeah , and we should probably make that part of the procedure for recording the meetings .\nPhD G: Well , s\nGrad F: Yep .\nPhD G: Yeah . That 's what I 'm wondering , if {disfmarker}\nGrad F: Well {pause} we 're g we 're gonna automate that .\nPhD G: OK .\nGrad F: My intention is to {pause} do a script that 'll do everything .\nPhD G: I mean , you don't have to physically put a tape in the drive ?\nGrad F: No . It 's all tape robot ,\nPhD G: Or s ? s ? {comment} Oh , OK .\nGrad F: so you just sit down at your computer and you type a command .\nPhD G: So it 's just {disfmarker} Oh , OK .\nPhD I: Yeah , but then you 're effectively using the resources of the back - up system . Or is that a different tape robot ?\nGrad F: Yeah .\nPhD G: But not at the same time .\nGrad F: But y but you would be anyway .\nPhD B: No , no , no .\nGrad F: Right ?\nPhD B: He 's saying get a whole different drive .\nGrad F: Because {disfmarker}\nPhD I: No , no . See {disfmarker}\nGrad F: But there 's no reason to do that .\nPhD I: Yeah , just give a dedi\nGrad F: It {disfmarker} we already have it there and it {disfmarker} it 's {disfmarker}\nPhD I: Well , I 'm saying is @ @ i if you go to Dave , and {disfmarker} and {disfmarker} and ask him \" can I use your tape robot ? \" , he will say , \" well {pause} that 's gonna screw up our back - up operation . \"\nGrad F: No , we won't . He 'll say \" if {disfmarker} if that means {pause} that it 's not gonna be backed - up standardly , great . \"\nProfessor D: He - I {disfmarker} Dave has {disfmarker} has promoted this in the past . So I don't think he 's actually against it .\nGrad F: Yeah . It 's {disfmarker} it 's definitely no problem .\nPhD I: Oh , OK . Alright .\nProfessor D: Yeah .\nPhD I: Alright .\nProfessor D: OK .\nPhD I: Good .\nPhD G: What about if the times overlap with the normal back - up time ?\nGrad F: Um , it 's {disfmarker} it 's just {disfmarker} it 's just a utility which queues up . It just queues it up and {disfmarker} and when it 's available , it will copy it .\nPhD G: OK .\nProfessor D: Yeah .\nGrad F: And then you can tell it to then remove it from the disk or you can , you know , do it a a few days later or whatever you wanna do , after you confirm that it 's really backed - up .\nPhD G: OK .\nGrad F: NW {disfmarker} ?\nPostdoc A: You saying NW archive ?\nGrad F: NW archive .\nPostdoc A: Yep {comment} {vocalsound} And if you did that during the day it would never make it to the nightly back - ups .\nGrad F: That 's what it is .\nProfessor D: OK .\nGrad F: Right .\nPostdoc A: And then there wouldn't be this extra load .\nPhD I: Well , it {disfmarker} if he {disfmarker} you have to put the data on a {disfmarker} on a non - backed - up disk to begin with .\nPostdoc A: Well , but you can have it NW archive to {disfmarker} you can have , {vocalsound} uh , a non - backed - up disk NW archived ,\nGrad F: Right .\nPhD I: So that {disfmarker} so that {disfmarker} otherwise you don't {disfmarker} you {disfmarker}\nPostdoc A: and it 'll never show up on the nightly back - ups .\nGrad F: Right . And then it never {disfmarker}\nPhD I: Right . Right .\nGrad F: Right . Which I 'm sure would make ever the sysadmins very happy .\nPhD I: Right .\nPostdoc A: Yeah .\nGrad F: So , I think that 's a good idea .\nPhD I: OK .\nGrad F: That 's what we should do .\nPhD I: OK .\nGrad F: So , that means we 'll probably wanna convert all {disfmarker} all those files {disfmarker} filesystems to non - backed - up media .\nPhD B: That sounds good .\nProfessor D: Yeah .\nGrad F: Yep .\nProfessor D: Um , another , thing on the agenda said SRI recognition experiments ? What 's that ?\nPhD I: SRI recognition ? Oh .\nGrad F: That wasn't me .\nProfessor D: Uh .\nPhD I: Um . well ,\nProfessor D: Who 's that ?\nPhD I: we have lots of them . Uh , I dunno . Chuck , do you have any {disfmarker} any updates ?\nPhD B: N I 'm successfully , uh , increasing the error rate . Uh {disfmarker}\nGrad F: That 's good .\nGrad H: Mmm .\nPhD I: Oh .\nPhD G: Lift the Herve approach .\nPhD B: Yeah . So , I mean I 'm just playing with , um , the number of Gaussians that we use in the {disfmarker} the recognizer , and {disfmarker}\nPhD I: Well , you have to sa you have to {pause} tell people that you 're {disfmarker} you 're doing {disfmarker} you 're trying the tandem features .\nPhD B: Yes , I 'm using tandem features .\nGrad F: Oh you are ?\nPhD B: And {disfmarker}\nGrad F: Cool .\nPhD I: A and I 'm still tinkering with the PLP features .\nGrad F: \nProfessor D: Yeah , I got confused by the results . It sai because {disfmarker} uh , the {pause} meeting before , {vocalsound} you said \" OK , we got it down to where they 're {disfmarker} they 're within a tenth of a percent \" .\nPhD B: That was on males .\nPhD I: Right . That was {disfmarker} that was before I tried it on the females .\nProfessor D: Oh .\nPhD I: See , women are nothi are , trouble .\nProfessor D: It 's the women are the problem . OK .\nPhD I: Right ? As we all know . So .\nPhD G: Well , let 's just say that men are simple .\nPhD I: So {disfmarker} {comment} so , when {disfmarker} So I {disfmarker} I had {disfmarker} I ha\nGrad F: That was a quick response .\nPhD I: So , we had reached the point where {disfmarker}\nPhD G: I 'm well rehearsed .\nProfessor D: Yeah .\nPhD I: we had reached the point where , {comment} um , on the male portion of the {pause} development set , the , um {disfmarker} or one of the development sets , I should say {disfmarker} {vocalsound} the , um {disfmarker} the male error rate with , uh , ICSI PLP features was pretty much identical with , uh , SRI features . which are {pause} MFCC . So , um , then I thought , \" Oh , great . I 'll j I 'll {disfmarker} just let 's make sure everything works on the females . \" And the error rate {disfmarker} you know , there was a three percent difference .\nProfessor D: Oh . Uh - huh .\nPhD I: So ,\nPhD G: Is there less training data ?\nPhD I: uh {disfmarker}\nPhD G: I mean , we don\nPhD I: No , actually there 's more training data .\nPhD G: This is on just digits ?\nProfessor D: No .\nPhD I: No , no .\nGrad F: No .\nPhD B: Hub - five .\nGrad F: It 's , uh , Swi\nPhD G: Oh , sorry . OK . This is on {disfmarker}\nPhD I: This is Hub - five .\nPhD G: Oh , OK .\nGrad F: Hub - five . Yeah .\nPhD I: Yeah . Um , and the test data is CallHome and Switchboard . So , uh {disfmarker} so then {pause} um {disfmarker} Oh , and plus the {disfmarker} the vocal tract {pause} length normalization didn't {disfmarker} actually made things worse . So something 's really seriously wrong . So {disfmarker} Um {disfmarker}\nProfessor D: Aha ! OK .\nPhD I: So {disfmarker} So {disfmarker}\nProfessor D: So {disfmarker} but you see , now , between {disfmarker} between the males and the females , there 's certainly a much bigger difference in the scaling range , than there is , say , just within the males . And what you were using before was scaling factors that were just from the {disfmarker} the m the {pause} SRI front - end . And that worked {disfmarker} that worked fine .\nPhD I: That 's true . Yeah .\nProfessor D: Uh , but now you 're looking over a larger range and it may not be so fine .\nPhD I: Well , um {disfmarker} So {disfmarker} I just {disfmarker} d so the one thing that I then tried was to put in the low - pass filter , which we have in the {disfmarker} So , most {disfmarker} most Hub - five systems actually band - limit the {disfmarker} uh , at about , uh , thirty - seven hundred , um , hertz .\nProfessor D: Uh - huh .\nPhD I: Although , you know , normally , I mean , the channel goes to four {disfmarker} four thousand . Right ? So , um {disfmarker} And that actually helped , uh {disfmarker} uh , a little bit .\nProfessor D: Uh - huh .\nPhD I: Um {pause} and it didn't hurt on the males either . So , um {disfmarker} And I 'm now , uh , trying the {disfmarker} Oh , and suddenly , also the v the vocal tract length normalization only in the test se on the test data . So , you can do vocal tract length normalization on the test data only or on both the training and the test .\nProfessor D: Yeah .\nPhD I: And you expect it to help a little bit if you do it only on the test , and s more if you do it on both training and test .\nProfessor D: Yeah .\nPhD I: And so the {disfmarker} It now helps , if you do it only on the test , and I 'm currently retraining another set of models where it 's both in the training and the test , and then we 'll {disfmarker} we 'll have , hopefully , even better results . So {disfmarker} But there 's {disfmarker} It looks like there will still be some difference , maybe between one and two percent , um , for the females .\nProfessor D: Huh .\nPhD I: And so , um , you know , I 'm open to suggestions .\nGrad F: Mm - hmm .\nPhD I: And it is true that the , uh {disfmarker} that the {disfmarker} {vocalsound} you know , we are using the {disfmarker} But {disfmarker} it can't be just the VTL ,\nProfessor D: Uh - huh .\nPhD I: because if you don't do VTL in both systems , uh , you know , the {disfmarker} the females are considerably worse in the {disfmarker} with the PLP features .\nProfessor D: No {disfmarker} no . I {disfmarker} I remember that .\nGrad F: It 's much worse . Yeah .\nPhD I: So there must be some {disfmarker} something else going on .\nPhD G: Well , what 's the standard {disfmarker} ? Yeah , so I thought the performance was actually a little better on females than males .\nGrad F: That 's what I thought , too .\nPhD I: Um , {pause} that {pause} ye {comment} overall , yes , but on this particular development test set , they 're actually a little worse . But that 's beside the point . We 're looking at the discrepancy between the SRI system and the SRI system when trained with ICSI features .\nPhD G: Right . I 'm just wondering if that {disfmarker} if {disfmarker} if you have any indication of your standard features ,\nGrad F: What 's {disfmarker} Are the freq ?\nPhD G: you know , if that 's also different {pause} or in the same direction or not .\nProfessor D: You 're {disfmarker} This is {disfmarker} lemme ask a q more basic que\nPhD G: Cuz {disfmarker}\nProfessor D: I mean , is this , uh {disfmarker} uh , iterative , Baum - Welch training ?\nPhD I: Mm - hmm .\nProfessor D: Or is it Viterbi training ? Or {disfmarker} ?\nPhD I: It 's Baum - Welch training .\nProfessor D: Baum - Welch training . And how do you determine when to {disfmarker} to stop iterating ?\nPhD I: Um {disfmarker} Well , actually , we {disfmarker} we just basically do a s a fixed number of iterations .\nGrad F: Hmm .\nPhD I: Uh , in this case four . Um , which {disfmarker} Eh , we used to do only three , and then we found out we can squeeze {disfmarker} And it was basically , we 're s we 're keeping it on the safe side . But you 're d Right . It might be that one more iteration {vocalsound} would {disfmarker} would help , but it 's sort of\nProfessor D: Or maybe {disfmarker} or maybe you 're doing one too many .\nPhD I: you know .\nProfessor D: I mean it 's {disfmarker} it 's {disfmarker}\nPhD I: No , but with Baum - Welch , there shouldn't be an over - fitting issue , really .\nProfessor D: Uh . {comment} Well , there can be . Sure .\nGrad F: Well , you can try each one on a cross - validation set ,\nPhD I: Um .\nProfessor D: It d if you {disfmarker} if you remember some years ago Bill Byrne did a thing where he was {disfmarker} he was looking at that ,\nGrad F: can't you ?\nProfessor D: and he showed that you could get it .\nPhD I: Yeah .\nProfessor D: So . But {disfmarker} {comment} but {disfmarker} {vocalsound} but , um {disfmarker}\nPhD I: Well , yeah . We can {disfmarker} Well , that 's {disfmarker} that 's the easy one to check ,\nProfessor D: Yeah .\nPhD I: because we save all the intermediate models\nGrad F: Do you {disfmarker} ?\nPhD I: and we can {disfmarker}\nProfessor D: And in each case , ho\nGrad F: What {disfmarker} ?\nProfessor D: um , I 'm sorry {disfmarker} in each case how do you determine , you know , the {disfmarker} the usual {pause} fudge factors ? The , uh {disfmarker} {vocalsound} the , uh , language , uh , scaling , acoustic scaling , uh , uh {disfmarker}\nPhD I: Um {pause} I uh {disfmarker} {comment} I 'm actually re - optimizing them . Although that hasn't shown to make {pause} a big difference .\nProfessor D: OK . And the pru the question he was asking at one point about pruning , uh {disfmarker} Remember that one ?\nPhD I: Pruning {disfmarker} ?\nProfessor D: Well , he was {disfmarker} he 's {disfmarker} it looked like the probabil at one point he was looking at the probabilities he was getting out {disfmarker} at the likelihoods he was getting out of PLP versus mel cepstrum , and they looked pretty different ,\nPhD I: Pruning in the {disfmarker} ?\nPhD B: Yeah , the likelihoods were {pause} lower for the PLP .\nProfessor D: as I recall .\nPhD G: Oh .\nProfessor D: And so , uh , there 's the question {disfmarker}\nPhD I: I you mean {disfmarker} did you see this in the SRI system ?\nPhD B: Mm - hmm . Was just looking through the log files ,\nPhD I: Um . Well , the likelihoods are {disfmarker}\nPhD B: and {disfmarker}\nPhD I: You can't directly compare them , because , for every set of models you compute a new normalization . And so these log probabilities , they aren't directly comparable\nPhD B: Oh .\nPhD I: because you have a different normalization constants for each model you train .\nPhD B: Hmm .\nProfessor D: But , still it 's a question {disfmarker}\nPhD I: So {disfmarker}\nProfessor D: if you have some threshold somewhere in terms of beam search or something ,\nPhD B: Well , yeah . That 's what I was wondering .\nProfessor D: or {disfmarker} ?\nPhD I: W yeah . I mean {disfmarker} Uh {disfmarker}\nPhD B: I mean , if you have one threshold that works well because the range of your likelihoods is in this area {disfmarker}\nPhD I: We prune very conservatively . I mean , as we saw with the meeting data , um {pause} we could probably tighten the pruning without really {disfmarker} So we we basically we have a very open beam .\nProfessor D: But , you 're only talking about a percent or two .\nPhD B: Yeah .\nProfessor D: Right ? Here we 're - we 're saying that we there {disfmarker} gee , there 's this b eh , there 's this difference here . And {pause} it {disfmarker} See cuz , i i {comment} there could be lots of things . Right ? But {disfmarker} but {disfmarker} but {disfmarker} but , um , let 's suppose just for a second that , uh , we 've sort of taken out a lot of the {disfmarker} the major differences , uh , between the two .\nPhD I: Right . Course . Mm - hmm . Right .\nProfessor D: I mean , we 're already sort of using the mel scale and we 're using the same style filter integration , and {vocalsound} and , well , we 're making sure that low and high {disfmarker}\nPhD I: Actually , there is {disfmarker} the difference in that . So , for the PLP features we use the triangular filter shapes . And for the {disfmarker} in the SRI front - end we use the trapezoidal one .\nGrad F: And what 's the top frequency of each ?\nPhD I: Well , now it 's the same . It 's thirty {disfmarker} thirty to seven hundred and sixty hertz .\nGrad F: Yeah . Exp - one 's triangular , one 's trapezoidal . So {disfmarker}\nPhD I: No , no . But {disfmarker}\nProfessor D: Before we {disfmarker} i i th with straight PLP , it 's trapezoidal also .\nPhD I: Well {disfmarker} But {disfmarker}\nProfessor D: But then we had a slight difference in the {disfmarker} in the scale . Uh , so .\nPhD I: Since currently the Feacalc program doesn't allow me to change {pause} the filter shape independently of the scale .\nGrad F: Uh - huh .\nPhD I: And , I did the experiment on the SRI front - end where I tried the {disfmarker} y where the standard used to be to use trapezoidal filters . You can actually continuously vary it between the two . And so I wen I swi I tried the trap eh , triangular ones . And it did slightly worse , but it 's really a small difference .\nGrad F: Hmm .\nProfessor D: Coup - Couple tenths of a percent or something .\nPhD I: So {disfmarker}\nGrad F: OK .\nProfessor D: Right .\nGrad F: So it 's not just losing some {vocalsound} frequency range .\nPhD I: Yeah , exactly . So , it 's not {disfmarker} I don't think the filter shape by itself will make a huge {comment} difference .\nProfessor D: Yeah . Right . So the oth {vocalsound} the other thing that {disfmarker}\nGrad F: Yeah .\nProfessor D: So , f i We 've always viewed it , anyway , as the major difference between the two , is actually in the smoothing , that the {disfmarker} that the , um , {vocalsound} PLP , and {disfmarker} and the reason PLP has been advantageous in , uh , slightly noisy situations is because , {vocalsound} PLP does the smoothing at the end by an auto - regressive model ,\nPhD I: Mm - hmm . Mm - hmm .\nProfessor D: and mel cepstrum does it by just computing the lower cepstral coefficients .\nPhD I: Mm - hmm .\nProfessor D: Um . So , um {disfmarker} Mm - hmm .\nPhD I: OK . So {pause} one thing I haven't done yet is to actually do all of this with a much larger {disfmarker} with our full training set . So right now , we 're using a {disfmarker} I don't know , forty ? I i it 's {disfmarker} it 's {disfmarker} eh {comment} it 's a f training set that 's about , um , you know , by a factor of four smaller than what we use when we train the full system . So , some of these smoothing issues are over - fitting for that matter .\nProfessor D: Mm - hmm .\nPhD I: And the Baum - Welch should be much less of a factor , if you go full {disfmarker} whole hog .\nProfessor D: Could be . Yeah .\nPhD I: And so , w so , just um {disfmarker} so the strategy is to first sort of treat things {pause} with fast turn - around on a smaller training set and then , {vocalsound} when you 've sort of , narrowed it down , you try it on a larger training set .\nProfessor D: Yeah .\nPhD I: And so , we haven't done that yet .\nProfessor D: Now the other que related question , though , is {disfmarker} is , {vocalsound} uh , what 's the boot models for these things ?\nPhD I: Th - th the boot models are trained from scratch . So we compute , um {disfmarker} So , we start with a , um , alil alignment that we computed with the b sort of the best system we have . And {disfmarker} and then we train from scratch . So we com we do a , you know , w um {disfmarker} {vocalsound} We collect the {disfmarker} uh , the observations from those alignments under each of the feature sets that {disfmarker} that we {pause} train . And then , from there we do , um {disfmarker} There 's a lot of , actually {disfmarker} {vocalsound} The way it works , you first train a phonetically - tied mixture model . Um . You do a total of {disfmarker} First you do a context - independent PTM model . Then you switch to a context {disfmarker} You do two iterations of that . Then you do two iterations of {disfmarker} of {disfmarker} of context - dependent phonetically - tied mixtures . And then from that you {disfmarker} you do the {disfmarker} you {disfmarker} you go to a state - clustered model ,\nProfessor D: Yeah .\nPhD I: and you do four iterations of that . So there 's a lot of iterations overall between your original boot models and the final models . I don't think that {disfmarker} Hmm . We have never seen big differences . Once I thought \" oh , I can {disfmarker} Now I have these much better models . I 'll re - generate my initial alignments . Then I 'll get much better models at the end . \" Made no difference whatsoever . It 's {disfmarker} I think it 's {disfmarker} eh , i\nProfessor D: Right . Well , mis for making things better .\nPhD I: the boot models are recur\nProfessor D: Yeah . But , this for making things worse . This it migh Th - the thought is {disfmarker} is {disfmarker} is possible {disfmarker} another possible {pause} partial cause is if the boot models {vocalsound} used a comple used a different feature set , that {disfmarker}\nPhD I: Mm - hmm . Mm - hmm . But there are no boot models , in fact . You {disfmarker} you 're not booting from initial models . You 're booting from initial alignments .\nProfessor D: Which you got from a different feature set .\nPhD I: That 's correct .\nProfessor D: So , those features look at the data differently , actually .\nPhD I: Yeah , but {disfmarker}\nProfessor D: I mean , you know , they {disfmarker} they will find boundaries a little differently , though {disfmarker} You know , all th all that sort of thing is actually slightly different . I 'd expect it to be a minor effect ,\nPhD I: But {disfmarker} but {disfmarker} but , what I 'm {disfmarker} what I 'm saying is {disfmarker}\nProfessor D: but {disfmarker}\nPhD I: So , we e w f w For a long time we had used boot alignments that had been trained with a {disfmarker} {vocalsound} with the same front - end but with acoustic models that were , like , fifteen percent worse than what we use now .\nProfessor D: Mm - hmm .\nPhD I: And with a dict different dictionary {disfmarker} with a considerably different dictionary , which was much less detailed and much less well - suited .\nProfessor D: Mm - hmm . Yeah .\nPhD I: And so , {vocalsound} then we switched to new boot alignments , which {disfmarker} which now had the benefit of all these improvements that we 've made over two years in the system .\nProfessor D: Right .\nPhD I: And , the result in the end was no different .\nProfessor D: Right .\nPhD I: So , what I 'm saying is , the exact nature of these boot alignments is probably not {pause} a big factor in the quality of the final models .\nProfessor D: Yeah , maybe not . But {pause} it {disfmarker} it {disfmarker} I st still see it as {disfmarker} I mean , {vocalsound} there 's {disfmarker} there 's a history to this , too ,\nPhD I: Yeah .\nProfessor D: but I {disfmarker} uh , I don't wanna go into ,\nPhD I: Mm - hmm .\nProfessor D: but {disfmarker} but I {disfmarker} I {disfmarker} I th I think it could be the things {pause} that it {disfmarker} the data is being viewed in a certain way , uh , that a beginning is here rather than there and so forth ,\nPhD I: Yeah . Right .\nProfessor D: because the actual signal - processing you 're doing is slightly different .\nPhD I: Right .\nProfessor D: But , {vocalsound} it 's {disfmarker} it 's {disfmarker} that 's probably not it .\nPhD I: Yeah . Anyway , I {disfmarker} I {disfmarker} I should really reserve , uh , any conclusions until we 've done it on the large training set , um , and until we 've seen the results with the {disfmarker} with the VTL in training .\nProfessor D: Yeah . At some point you also might wanna take the same thing and try it on , uh , some Broadcast News data or something else that actually has {disfmarker} has some noisy {disfmarker} {vocalsound} noisy components , so we can see if any conclusions we come to holds {vocalsound} across {pause} different data .\nPhD I: So . Yeah . Right .\nProfessor D: Uh {disfmarker}\nPhD I: And , uh , with this , I have to leave .\nProfessor D: OK .\nGrad H: Hmm !\nProfessor D: So , is there something quick about Absinthe {pause} that you {disfmarker} ?\nPhD I: With this said .\nGrad F: Uh . Just what we were talking about before , which is that I ported a Blass library to Absinthe , and then got {disfmarker} got it working with fast - forward , and got {vocalsound} {vocalsound} a speedup roughly proportional to the number of processors times the clock cycle .\nPhD I: Oh .\nGrad F: So , that 's pretty good .\nPhD I: Oh ! Cool .\nGrad F: Um , I 'm in the process of doing it for Quicknet , but there 's something going wrong and it 's about half the speed that I was estimating it should be , and I 'm not sure why .\nPhD I: Mm - hmm .\nGrad F: But I 'll keep working on it . But the {disfmarker} what it means is that it 's likely that for net training and forward passes , we 'll {disfmarker} Absinthe will be a good machine . Especially if we get a few more processors and upgrade the processors .\nPhD I: A few more processors ? How many are you shooting for ?\nGrad F: There 're five now . It can hold eight .\nPhD I: Oh , OK .\nProfessor D: Yeah , we 'll just go buy them , I guess .\nGrad F: And it 's also five - fifty megahertz and you can get a gigahertz .\nPhD I: Yeah .\nGrad F: So .\nPhD I: Can you mix {pause} t uh , processors of different speed ?\nGrad F: I don't think so . I think we 'd have to do all {disfmarker}\nPhD I: OK .\nProfessor D: Probably just throw away the old ones , and {disfmarker}\nGrad F: Yep .\nProfessor D: Thank you {pause} for the box ,\nPhD I: Oh , OK .\nProfessor D: and {disfmarker} {vocalsound} I 'll just go buy their process .\nGrad H: Hmm !\nPhD I: Maybe we can stick them in another system . I dunno .\nGrad F: We 'd have to get a {disfmarker} almost certainly have to get a , uh , Netfinity server .\nPhD I: I see .\nGrad F: They 're pretty {disfmarker} pretty specialized .\nProfessor D: Yeah . OK .\nPhD I: OK .\nProfessor D: Is {disfmarker} is Liz coming back , do you know , or {disfmarker} ? I dunno . Yeah . Oh , you don't . OK . Alright . Alright . See you . Um . Alright . So {disfmarker} Uh , they 're having tea out there . So I guess the other thing that we were gonna talk about is {disfmarker} is , uh , demo . And , um , so , these are the demos for the {pause} uh , July , uh , meeting {pause} and , um {disfmarker} DARPA mee\nGrad F: July what ? Early July ? Late July ?\nProfessor D: Oh , I think it 's July fifteenth .\nPostdoc A: Sixteen to eighteen , I think .\nProfessor D: Is that it ?\nPostdoc A: Roughly .\nProfessor D: Yeah , sixteenth , eighteenth . Yeah . So , we talked about getting something together for that , but maybe , uh {disfmarker} maybe we 'll just put that off for now , given that {disfmarker} But I think maybe we should have a {disfmarker} a sub - meeting , I think , uh , probably , uh , Adam and {disfmarker} and , uh , Chuck and me should talk about {disfmarker} should get together and talk about that sometime soon .\nGrad F: Over a cappuccino tomorrow ?\nProfessor D: Yeah {comment} something like that . Um , uh , you know , maybe {disfmarker} maybe we 'll involve Dan Ellis at some {disfmarker} some level as well .\nGrad F: Mm - hmm .\nProfessor D: Um . OK . The {disfmarker} the tea is {disfmarker} is going , so , uh , I suggest we do , uh {disfmarker} uh , a unison .\nGrad F: A unison digits ?\nPostdoc A: OK .\nProfessor D: Yeah . Gets our {disfmarker}\nGrad F: Which is gonna be a little hard for a couple people because we have different digits forms .\nPhD E: Oops .\nGrad F: We have a {disfmarker} I found a couple of old ones .\nProfessor D: Oh .\nGrad H: Hmm .\nProfessor D: Well , that 'll be interesting . So , uh {disfmarker}\nGrad F: Have you done digits before ?\nProfessor D: No .\nGrad C: I haven't done it .\nGrad F: OK . So , uh , the idea is just to read each line {pause} with a short pause between lines ,\nGrad C: Alright .\nGrad F: not between {disfmarker} And , uh , since we 're in a hurry , we were just gonna read everyone all at once . So , if you sorta plug your ears and read {disfmarker}\nGrad C: OK .\nGrad F: So first read the transcript number , and then start reading the {pause} digits .\nGrad C: Sure .\nGrad F: OK ? One , two , three .\nProfessor D: OK we 're done .\nGrad F: And {disfmarker}", "source": "meeting_summ", "evaluation": "human"}
